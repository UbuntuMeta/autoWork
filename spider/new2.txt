
一． JavaEE的架构
二． JavaEE的核心技术简介
三． JavaEE平台中的角色
四． 当前流行的JavaEE平台
五．  JavaEE的应用
 
一．JavaEE架构：

JavaEE的运行环境定义了4种类型的应用组件：
l       Applet客户端
l       Application客户端
l       Web组件
l       EJB组件
 
 
二．JavaEE核心技术：13种
 
   EJB、CORBA、RMI、JSP、Java Servlet、JavaBean、JDBC、XML、……

EJB — JavaEE的基石：
l       EJB (Enterprise JavaBeans) ：
           一个Java服务器端组件开发的规范，定义了一个用来开发面向对象分布式应用组件的标准方法，软件厂商根据它来实现EJB服务器。
           Java程序员可以将一些EJB组件组合起来，从而方便、快捷地建构起分布式应用程序。EJB规范在简化分布式应用程序开发复杂性方面也做了大量的工作，EJB程序员不必太担心事务处理、多线程、资源管理等方面的问题，可以专注于支持应用所需的商业逻辑，而不用担心周围框架的实现问题。使用EJB可以使整个程序分块明确，并且EJB可以使用其它EJB或JDBC等服务，从而增强了分布式应用程序的可扩展性和性能；另外，EJB的使用增强了整个系统程序的可靠性、可管理性和可移植性。


l       EJB组件
     EJB分为三种：会话EJB、实体EJB和消息驱动EJB
 
l       EJB容器
      是EJB组件的运行环境，为部署的EJB组件提供各种服务（事务、安全、远程客户端的网络发布、资源管理等）。容器厂商也可以在容器或服务器中提供额外服务的接口。
 
l       EJB服务器
      管理EJB容器的高端进程或应用程序，并提供对系统服务的访问。EJB服务器也可以提供厂商自己的特性，如优化的数据库访问接口，对其他服务（如CORBA服务）的访问等。

CORBA体系结构：核心－ORB



CORBA技术：
l       CORBA（Common Object Request Broker Architecture）是一个开发分布式对象系统标准（规范），它独立于平台，也独立于语言。由OMG制定。
l       在这个体系结构中，一个对象可以被本机上的客户或远程客户通过方法激活来访问。客户（一个对象或应用）无须知道被调用对象（称为服务对象）的运行环境，也无须知道实现这个对象的编程语言，客户只要知道服务对象的逻辑地址和提供的接口。
l       这种互操作性的关键是IDL（Interface Definition Language、接口定义语言），IDL说明对象接口中的方法，这些方法可以被其它对象（或应用）激活。
 
RMI技术：
l       RMI(Remote Method Invoke)是一种被EJB使用的更底层的协议，正如其名字所表示的那样，RMI协议调用远程对象上方法，使用序列化方式在客户端和服务器端的对象之间传递数据。


RMI和CORBA相比：
l       两者的关键差别在于语言环境，Java RMI是一个分布式对象计算的纯Java解决方案(如，在Java RMI中，对象的接口用Java定义，而不是用IDL)；
l       其次，CORBA没有定义安全服务，而Java RMI继承了Java的安全性；
l       再者，CORBA有不同的实现，不同的独立软件开发商的不同实现均有独特性，这使得在不同平台上的匹配比较困难，而且不是所有CORBA产品开发商都支持所有平台，而几乎所有平台都支持Java虚拟机，因此Java RMI具有更高的可移植性。如果客户对象和服务对象都基于Java虚拟机，那么Java RMI是分布对象计算的最好选择。当然，IIOP（Internet Inter-ORB Protocol）已经提供了Java RMI和CORBA的互操作能力，而且两者的发展有互相借鉴的趋势。
 
JSP技术：
l       JSP是服务器端的脚本语言，是以Java和Servlet为基础开发而成的动态网页生成技术，它的底层实现是Java Servlet。
l       JSP(Java Server Pages)页面由HTML代码和嵌入其中的Java代码所组成。服务器在页面被客户端所请求以后对这些Java代码进行处理，然后将生成的HTML页面返回给客户端的浏览器。
 
l       特点：面向对象，跨平台，和Servlet一样稳定，可以使用Servlet提供的API，克服了Servlet的缺点。
l       应用：一般和JavaBeans结合使用，从而将界面表现和业务逻辑分离。


JSP和ASP的比较（一）：
相似：
 
l       都是运行于服务器端的脚本语言，两者都是动态网页生成技术。
l       这两项技术都使用HTML来决定网页的版面，都是在HTML 代码中混合某种程序代码，由语言引擎解释执行程序代码。HTML代码主要负责描述信息的显示样式，而程序代码则用来描述处理逻辑。
JSP和ASP的比较（二）：
不同：
 
l       JSP是由Sun推出的一项技术，是基于JavaServlet以及整个java体系的Web开发技术，利用这一技术可以建立先进、安全和跨平台的动态网站。ASP是MS公司推出的技术，只能在MS的平台上运行，无法实现跨平台，也无安全性保障。
l       ASP下的编程语言是 VBScript 之类的脚本语言，而JSP 使用的是Java。
l       ASP 与 JSP 还有一个更为本质的区别：两种语言引擎用完全不同的方式处理页面中嵌入的程序代码。在 ASP 下， VBScript 代码被 ASP 引擎解释执行；在 JSP 下，代码被编译成 Servlet 并由 Java 虚拟机执行，这种编译操作仅在对 JSP 页面的第一次请求时发生。
 
 
Java Servlet技术：
 
l       Servlets(＝Server ＋Applet)：是一些运行于Web服务器端的Java小程序，用来扩展Web服务器的功能。
l       Servlets用特定的Java解决方案替代了其它的Web服务器方编程模式（如：CGI，ISAPI等），因而继承了Java的所有特性(跨平台、多线程、OO)。
l       Servlets可以嵌入在不同的Java Web服务器之中，因为用来编写Servlets的Servlet API对于服务器环境和协议没有任何特殊的要求，所以Servlets具有很强的可移植性，也不像利用CGI程序等其它方式那样具有性能局限。
l       Servlets也同样使用HTTP协议与客户端进行通讯，所以有时也称Sevlets为“HTTP Servlets”。
l       Servlet是一种扩展Web服务器功能的简单而相似的技巧，而且由于它是用Java编写的，所以能够访问整个Java API库，包括用于访问企业数据库的JDBC API。
 
 
Java Servlet和JSP的比较：
l       两者都是基于Java的技术，所以都继承了Java的所有特性（跨平台、多线程、OO），都可以使用Java强大的API。
l       两者工作方式相似：JSP代码先被JSP容器转换为Servlet代码再编译为类。
l       两者在JavaEE体系结构中的工作层次相同，都负责与客户端的连接。
 
l       Servlets是一些运行于Web服务器端的Java小程序；而JSP是脚本，编写起来更简单容易。
l       Servlet主要用于从客户端接收请求信息，而JSP主要负责将服务器端信息传送到客户端。
l       使用Servlet的真正意义在于：可以将界面设计和业务逻辑设计分离。
 
 
JavaBean技术：
l       JavaBean是基于Java的组件模型，有点类似于Microsoft的COM组件。
l       在Java平台中，通过JavaBean可以无限扩充Java程序的功能，通过JavaBean的组合可以快速的生成新的应用程序。
l       对于程序员来说，最好的一点就是JavaBean可以实现代码的重复利用，另外对于程序的易维护性等等也有很重大的意义。
l       JavaBean通过Java虚拟机(Java Virtual Machine)执行，运行JavaBean最小的需求是JDK1.1或者以上的版本。
l       JavaBean传统的应用在于可视化的领域，如AWT下的应用。自从Jsp诞生后，JavaBean更多的应用在了非可视化领域，在服务器端应用方面表现出来了越来越强的生命力。
 
 
JDBC技术：
l       JDBC是一组API，定义了用来访问数据源的标准Java类库，使用这个类库可以以一种标准的方法、方便地访问数据库资源。
l       JDBC的目标是使应用程序开发人员使用JDBC可以连接任何提供了JDBC驱动程序的数据库系统，这样就使得程序员无需对特定的数据库系统的特点有过多的了解，从而大大简化和加快了开发过程。
l       JDBC API为访问不同的数据库提供了一种统一的途径，象ODBC一样，JDBC对开发者屏蔽了一些细节问题，
l       JDBC对数据库的访问也具有平台无关性。
 
XML技术：
l       XML(Extensible Markup Language)是一种可以用来定义其它标记语言的语言，被用来在不同的商务过程中共享数据。
l       XML的发展和Java是相互独立的，但是它和Java具有的相同目标即平台独立性。通过将Java和XML的组合，可以得到一个完美的具有平台独立性的解决方案。
l       JavaEE平台全面支持和实施XML，这种强大的组合可使XML具备跨平台的兼容性，甚至用于对XML代码进行语法检查和调试的工具也可与平台无关。
l       因为XML可实施独立于平台的数据，而JavaEE平台则可实施独立于平台的解决方案，所以JavaEE技术和XML技术分别是企业开发的阴阳两极。XML可通过移植的方式表现数据，因此就对Java技术的可移植性构成了补充。
 
JavaEE其它核心技术：
       JNDI(Java Naming and  Directory Interface)、           
       JMAPI(Java  Management API)、
       JTS/JTA(Java Transaction Service/API)、   
       JMS( Java Messaging Service)、
       Java Security API。
 
l       JavaEE核心技术中最常用的技术：
EJB、 JSP、Java Servlet、JavaBean、JDBC、……
 
l       开发大型应用：异构、分布、数据交换
 
三.JavaEE平台中的角色
 
在JavaEE平台中规定了七种角色，这七种角色在开发JavaEE平台及JavaEE应用中承担各自的任务。
（1）JavaEE平台开发商
（2）应用组件提供者
（3）应用组装者
（4）应用发布者
（5）系统管理员
（6）工具提供者
（7）系统组件提供者
 
（1）JavaEE平台开发商
l       JavaEE平台开发者提供实现基于JavaEE规范的产品，包括运行JavaEE应用的容器、JavaEE平台API。JavaEE平台开发者必须提供JavaEE规范规定的应用组件到网络协议的映射，提供JavaEE应用的发布与管理工具。
（2）应用组件提供者
应用组件提供者开发JavaEE应用组件，包括JSP、Servlet及EJB等。
（3）应用组装者
应用组装者负责将应用组件提供者开发的JavaEE应用组件组装为JavaEE应用。
（4）应用发布者
l       应用发布者将组装好的JavaEE应用发布到JavaEE应用的容器中，配置其运行环境，并启动JavaEE应用运行。
（5）系统管理员
l       系统管理员负责配置管理整个企业或组织的网络与计算环境，其中包括运行在JavaEE平台上的JavaEE应用。
（6）工具提供者
l       工具提供者提供JavaEE平台之外的JavaEE应用开发、组装、发布及管理工具。
（7）系统组件提供者
系统组件提供者提供系统级的通用的组件，如连接企业现有ERP系统的适配器等。
 
四．当前流行的JavaEE平台
l       目前市场上已经有许多成熟的实现JavaEE规范的产品，其中有的是商业公司的产品，而有的是开放源代码的免费产品。
 
商业公司的产品
 
商业公司的产品除Interstage外，另外主要还有BEA WebLogic、IBM WebSphere、Oracle Application Server、Borland Enterprise Server、SUN iPlanet Application Server等。这些产品一般都包括一组完整的产品线，用来支持JavaEE应用从开发、组装、发布及管理的整个过程。
 
组成
（1）应用服务器
      商业公司产品中的应用服务器一般都完全支持JavaEE规范的应用服务器，除包括Servlet容器、EJB容器外，还提供WEB Services、CORBA等服务。
（2）应用集成化开发环境
商业公司的产品提供支持开发JavaEE应用的集成开发环境，可以大大提高应用开发、调试的效率。
（3）JavaEE规范之外的工具
除了在JavaEE规范中规定的部分外，商业公司的产品一般还包括提供服务器负载均衡、安全控制、开发企业门户等功能在内的工具。
 
开放源代码的产品
l       开放源代码的产品中有如Apache Tomcat及JBOSS等产品。这些产品不仅是免费的，而且能够提供很好的功能和性能，因此也有很广泛的应用。
l       （1）Apache Tomcat
    Apache Tomcat 是一个Servlet容器，它支持Servlet/JSP规范。有些商业公司的JavaEE平台产品中使用它作为自己应用服务器的Servlet容器，或者在JavaEE应用集成开发环境中作为调试应用程序的服务器。
l       （2）JBOSS
      JBOSS 是一个EJB容器，但是因为它是基于JMX微内核结构开发的，所以很容易与其它产品集成在一起使用，如可以很方便地将JBOSS和Tomcat集成在一起使用。另外，JBOSS还有配置简单、应用热发布（不用停止服务器及应用的情况下发布或升级应用）等优点。
 
五．JavaEE的应用（一）
 


五．JavaEE的应用（二）

使用JavaEE开发企业应用要注意的问题：
       结合本企业的实际情况选用最适当的技术，需要终合考虑企业规模、业务特征、应用能力、预算费用、性能、开发周期、管理成本、维护成本等各种因素，还需要有一定的前瞻性。

1. Stream初体验

我们先来看看Java里面是怎么定义Stream的：


A sequence of elements supporting sequential and parallel aggregate operations.


我们来解读一下上面的那句话：

Stream是元素的集合，这点让Stream看起来用些类似Iterator；可以支持顺序和并行的对原Stream进行汇聚的操作；

大家可以把Stream当成一个高级版本的Iterator。原始版本的Iterator，用户只能一个一个的遍历元素并对其执行某些操作；高级版本的Stream，用户只要给出需要对其包含的元素执行什么操作，比如“过滤掉长度大于10的字符串”、“获取每个字符串的首字母”等，具体这些操作如何应用到每个元素上，就给Stream就好了！（这个秘籍，一般人我不告诉他：））大家看完这些可能对Stream还没有一个直观的认识，莫急，咱们来段代码。







1

//Lists是Guava中的一个工具类









2

List&lt;Integer&gt;
 nums = Lists.newArrayList(1,null,3,4,null,6);









3

nums.stream().filter(num
 -&gt; num != null).count();







上面这段代码是获取一个List中，元素不为null的个数。这段代码虽然很简短，但是却是一个很好的入门级别的例子来体现如何使用Stream，正所谓“麻雀虽小五脏俱全”。我们现在开始深入解刨这个例子，完成以后你可能可以基本掌握Stream的用法！
1.1 剖析Stream通用语法



图片就是对于Stream例子的一个解析，可以很清楚的看见：原本一条语句被三种颜色的框分割成了三个部分。红色框中的语句是一个Stream的生命开始的地方，负责创建一个Stream实例；绿色框中的语句是赋予Stream灵魂的地方，把一个Stream转换成另外一个Stream，红框的语句生成的是一个包含所有nums变量的Stream，进过绿框的filter方法以后，重新生成了一个过滤掉原nums列表所有null以后的Stream；蓝色框中的语句是丰收的地方，把Stream的里面包含的内容按照某种算法来汇聚成一个值，例子中是获取Stream中包含的元素个数。如果这样解析以后，还不理解，那就只能动用“核武器”–图形化，一图抵千言！



在此我们总结一下使用Stream的基本步骤：

创建Stream；转换Stream，每次转换原有Stream对象不改变，返回一个新的Stream对象（**可以有多次转换**）；对Stream进行聚合（Reduce）操作，获取想要的结果；
2. 创建Stream

最常用的创建Stream有两种途径：

通过Stream接口的静态工厂方法（注意：Java8里接口可以带静态方法）；通过Collection接口的默认方法（默认方法：Default method，也是Java8中的一个新特性，就是接口中的一个带有实现的方法，后续文章会有介绍）–stream()，把一个Collection对象转换成Stream
2.1 使用Stream静态方法来创建Stream

1. of方法：有两个overload方法，一个接受变长参数，一个接口单一值







1

Stream&lt;Integer&gt;
 integerStream = Stream.of(1, 2, 3, 5);









2

Stream&lt;String&gt;
 stringStream = Stream.of("taobao");







2. generator方法：生成一个无限长度的Stream，其元素的生成是通过给定的Supplier（这个接口可以看成一个对象的工厂，每次调用返回一个给定类型的对象）







1

Stream.generate(new Supplier&lt;Double&gt;()
 {









2

    @Override









3

    public Double
 get() {









4

        return Math.random();









5

    }









6

});









7

Stream.generate(()
 -&gt; Math.random());









8

Stream.generate(Math::random);







三条语句的作用都是一样的，只是使用了lambda表达式和方法引用的语法来简化代码。每条语句其实都是生成一个无限长度的Stream，其中值是随机的。这个无限长度Stream是懒加载，一般这种无限长度的Stream都会配合Stream的limit()方法来用。
3. iterate方法：也是生成无限长度的Stream，和generator不同的是，其元素的生成是重复对给定的种子值(seed)调用用户指定函数来生成的。其中包含的元素可以认为是：seed，f(seed),f(f(seed))无限循环







1

Stream.iterate(1,
 item -&gt; item + 1).limit(10).forEach(System.out::println);







这段代码就是先获取一个无限长度的正整数集合的Stream，然后取出前10个打印。千万记住使用limit方法，不然会无限打印下去。
2.2 通过Collection子类获取Stream

这个在本文的第一个例子中就展示了从List对象获取其对应的Stream对象，如果查看Java doc就可以发现Collection接口有一个stream方法，所以其所有子类都都可以获取对应的Stream对象。







1

public interface Collection&lt;E&gt; extends Iterable&lt;E&gt;
 {









2

    //其他方法省略









3

    default Stream&lt;E&gt;
 stream() {









4

        return StreamSupport.stream(spliterator(), false);









5

    }









6

}






3. 转换Stream

转换Stream其实就是把一个Stream通过某些行为转换成一个新的Stream。Stream接口中定义了几个常用的转换方法，下面我们挑选几个常用的转换方法来解释。
1. distinct: 对于Stream中包含的元素进行去重操作（去重逻辑依赖元素的equals方法），新生成的Stream中没有重复的元素；

distinct方法示意图(**以下所有的示意图都要感谢[RxJava](https://github.com/Netflix/RxJava)项目的doc中的图片给予的灵感, 如果示意图表达的有错误和不准确的地方，请直接联系我。**)：

2. filter: 对于Stream中包含的元素使用给定的过滤函数进行过滤操作，新生成的Stream只包含符合条件的元素；

filter方法示意图：

3. map: 对于Stream中包含的元素使用给定的转换函数进行转换操作，新生成的Stream只包含转换生成的元素。这个方法有三个对于原始类型的变种方法，分别是：mapToInt，mapToLong和mapToDouble。这三个方法也比较好理解，比如mapToInt就是把原始Stream转换成一个新的Stream，这个新生成的Stream中的元素都是int类型。之所以会有这样三个变种方法，可以免除自动装箱/拆箱的额外消耗；

map方法示意图：

4. flatMap：和map类似，不同的是其每个元素转换得到的是Stream对象，会把子Stream中的元素压缩到父集合中；

flatMap方法示意图：

5. peek: 生成一个包含原Stream的所有元素的新Stream，同时会提供一个消费函数（Consumer实例），新Stream每个元素被消费的时候都会执行给定的消费函数；

peek方法示意图：

6. limit: 对一个Stream进行截断操作，获取其前N个元素，如果原Stream中包含的元素个数小于N，那就获取其所有的元素；

limit方法示意图：

7. skip: 返回一个丢弃原Stream的前N个元素后剩下元素组成的新Stream，如果原Stream中包含的元素个数小于N，那么返回空Stream；

skip方法示意图：

8. 在一起,在一起！







1

List&lt;Integer&gt;
 nums = Lists.newArrayList(1,1,null,2,3,4,null,5,6,7,8,9,10);









2

System.out.println(“sum
 is:”+nums.stream().filter(num -&gt; num != null).









3

            distinct().mapToInt(num
 -&gt; num * 2).









4

            peek(System.out::println).skip(2).limit(4).sum());







这段代码演示了上面介绍的所有转换方法（除了flatMap），简单解释一下这段代码的含义：给定一个Integer类型的List，获取其对应的Stream对象，然后进行过滤掉null，再去重，再每个元素乘以2，再每个元素被消费的时候打印自身，在跳过前两个元素，最后去前四个元素进行加和运算(解释一大堆，很像废话，因为基本看了方法名就知道要做什么了。这个就是声明式编程的一大好处！)。大家可以参考上面对于每个方法的解释，看看最终的输出是什么。
9. 性能问题
有些细心的同学可能会有这样的疑问：在对于一个Stream进行多次转换操作，每次都对Stream的每个元素进行转换，而且是执行多次，这样时间复杂度就是一个for循环里把所有操作都做掉的N（转换的次数）倍啊。其实不是这样的，转换操作都是lazy的，多个转换操作只会在汇聚操作（见下节）的时候融合起来，一次循环完成。我们可以这样简单的理解，Stream里有个操作函数的集合，每次转换操作就是把转换函数放入这个集合中，在汇聚操作的时候循环Stream对应的集合，然后对每个元素执行所有的函数。
4. 汇聚（Reduce）Stream


汇聚这个词，是我自己翻译的，如果大家有更好的翻译，可以在下面留言。在官方文档中是reduce，也叫fold。


在介绍汇聚操作之前，我们先看一下Java doc中对于其定义：


A reduction operation (also called a fold) takes a sequence of input elements and combines them into a single summary result by repeated application of a combining operation, such as finding the sum or maximum of a set of numbers, or accumulating elements into
 a list. The streams classes have multiple forms of general reduction operations, called reduce() and collect(), as well as multiple specialized reduction forms such as sum(), max(), or count().


简单翻译一下：汇聚操作（也称为折叠）接受一个元素序列为输入，反复使用某个合并操作，把序列中的元素合并成一个汇总的结果。比如查找一个数字列表的总和或者最大值，或者把这些数字累积成一个List对象。Stream接口有一些通用的汇聚操作，比如reduce()和collect()；也有一些特定用途的汇聚操作，比如sum(),max()和count()。注意：sum方法不是所有的Stream对象都有的，只有IntStream、LongStream和DoubleStream是实例才有。

下面会分两部分来介绍汇聚操作：

可变汇聚：把输入的元素们累积到一个可变的容器中，比如Collection或者StringBuilder；其他汇聚：除去可变汇聚剩下的，一般都不是通过反复修改某个可变对象，而是通过把前一次的汇聚结果当成下一次的入参，反复如此。比如reduce，count，allMatch；
4.1 可变汇聚

可变汇聚对应的只有一个方法：collect，正如其名字显示的，它可以把Stream中的要有元素收集到一个结果容器中（比如Collection）。先看一下最通用的collect方法的定义（还有其他override方法）：







1

&lt;R&gt;
 R collect(Supplier&lt;R&gt; supplier,









2

                  BiConsumer&lt;R,
 ? super T&gt;
 accumulator,









3

                  BiConsumer&lt;R,
 R&gt; combiner);







先来看看这三个参数的含义：Supplier supplier是一个工厂函数，用来生成一个新的容器；BiConsumer accumulator也是一个函数，用来把Stream中的元素添加到结果容器中；BiConsumer combiner还是一个函数，用来把中间状态的多个结果容器合并成为一个（并发的时候会用到）。看晕了？来段代码！







1

List&lt;Integer&gt;
 nums = Lists.newArrayList(1,1,null,2,3,4,null,5,6,7,8,9,10);









2

    List&lt;Integer&gt;
 numsWithoutNull = nums.stream().filter(num -&gt; num != null).









3

            collect(()
 -&gt; new ArrayList&lt;Integer&gt;(),









4

                    (list,
 item) -&gt; list.add(item),









5

                    (list1,
 list2) -&gt; list1.addAll(list2));







上面这段代码就是对一个元素是Integer类型的List，先过滤掉全部的null，然后把剩下的元素收集到一个新的List中。进一步看一下collect方法的三个参数，都是lambda形式的函数（*上面的代码可以使用方法引用来简化，留给读者自己去思考*）。

第一个函数生成一个新的ArrayList实例；第二个函数接受两个参数，第一个是前面生成的ArrayList对象，二个是stream中包含的元素，函数体就是把stream中的元素加入ArrayList对象中。第二个函数被反复调用直到原stream的元素被消费完毕；第三个函数也是接受两个参数，这两个都是ArrayList类型的，函数体就是把第二个ArrayList全部加入到第一个中；

但是上面的collect方法调用也有点太复杂了，没关系！我们来看一下collect方法另外一个override的版本，其依赖[Collector](http://docs.oracle.com/javase/8/docs/api/java/util/stream/Collector.html)。







1

&lt;R,
 A&gt; R collect(Collector&lt;? super T,
 A, R&gt; collector);







这样清爽多了！少年，还有好消息，Java8还给我们提供了Collector的工具类–[Collectors](http://docs.oracle.com/javase/8/docs/api/java/util/stream/Collectors.html)，其中已经定义了一些静态工厂方法，比如：Collectors.toCollection()收集到Collection中, Collectors.toList()收集到List中和Collectors.toSet()收集到Set中。这样的静态方法还有很多，这里就不一一介绍了，大家可以直接去看JavaDoc。下面看看使用Collectors对于代码的简化：







1

List&lt;Integer&gt;
 numsWithoutNull = nums.stream().filter(num -&gt; num != null).









2

                collect(Collectors.toList());






4.2 其他汇聚

– reduce方法：reduce方法非常的通用，后面介绍的count，sum等都可以使用其实现。reduce方法有三个override的方法，本文介绍两个最常用的，最后一个留给读者自己学习。先来看reduce方法的第一种形式，其方法定义如下：







1

Optional&lt;T&gt;
 reduce(BinaryOperator&lt;T&gt; accumulator);







接受一个BinaryOperator类型的参数，在使用的时候我们可以用lambda表达式来。







1

List&lt;Integer&gt;
 ints = Lists.newArrayList(1,2,3,4,5,6,7,8,9,10);









2

System.out.println("ints
 sum is:" +
 ints.stream().reduce((sum, item) -&amp;gt; sum + item).get());







可以看到reduce方法接受一个函数，这个函数有两个参数，第一个参数是上次函数执行的返回值（也称为中间结果），第二个参数是stream中的元素，这个函数把这两个值相加，得到的和会被赋值给下次执行这个函数的第一个参数。要注意的是：**第一次执行的时候第一个参数的值是Stream的第一个元素，第二个参数是Stream的第二个元素**。这个方法返回值类型是Optional，这是Java8防止出现NPE的一种可行方法，后面的文章会详细介绍，这里就简单的认为是一个容器，其中可能会包含0个或者1个对象。
这个过程可视化的结果如图：

reduce方法还有一个很常用的变种：







1

T
 reduce(T identity, BinaryOperator&lt;T&gt; accumulator);







这个定义上上面已经介绍过的基本一致，不同的是：它允许用户提供一个循环计算的初始值，如果Stream为空，就直接返回该值。而且这个方法不会返回Optional，因为其不会出现null值。下面直接给出例子，就不再做说明了。







1

List&lt;Integer&gt;
 ints = Lists.newArrayList(1,2,3,4,5,6,7,8,9,10);









2

System.out.println("ints
 sum is:" +
 ints.stream().reduce(0,
 (sum, item) -&gt; sum + item));







– count方法：获取Stream中元素的个数。比较简单，这里就直接给出例子，不做解释了。







1

List&lt;Integer&gt;
 ints = Lists.newArrayList(1,2,3,4,5,6,7,8,9,10);









2

System.out.println("ints
 sum is:" +
 ints.stream().count());







– 搜索相关
– allMatch：是不是Stream中的所有元素都满足给定的匹配条件
– anyMatch：Stream中是否存在任何一个元素满足匹配条件
– findFirst: 返回Stream中的第一个元素，如果Stream为空，返回空Optional
– noneMatch：是不是Stream中的所有元素都不满足给定的匹配条件
– max和min：使用给定的比较器（Operator），返回Stream中的最大|最小值
下面给出allMatch和max的例子，剩下的方法读者当成练习。



查看源代码


打印帮助







1

List&lt;Integer&amp;gt;
 ints = Lists.newArrayList(1,2,3,4,5,6,7,8,9,10);









2

System.out.println(ints.stream().allMatch(item
 -&gt; item &lt; 100));









3

ints.stream().max((o1,
 o2) -&amp;gt; o1.compareTo(o2)).ifPresent(System.out::println);







java8的安装

工欲善其器必先利其器，首先安装JDK8。过程省略，大家应该都可以自己搞定。但是有一点这里强调一下（Windows系统）：目前我们工作的版本一般是java 6或者java 7，所以很多人安装java8基本都是学习为主。这样就在自己的机器上会存在多版本的JDK。而且大家一般是希望在命令行中执行java命令是基于老版本的jdk。但是在安装完jdk8并且没有设置path的情况下，你如果在命令行中输入：java -version，屏幕上会显示是jdk 8。这是因为jdk8安装的时候，会默认在C:/Windows/System32中增加java.exe，这个调用的优先级比path设置要高。所以即使path里指定是老版本的jdk，但是执行java命令显示的依然是新版本的jdk。这里我们要做的就是删除C:/Windows/System32中的java.exe文件（不要手抖！）。


Lambda初体验

下面进入本文的正题–lambda表达式。首先我们看一下什么是lambda表达式。以下是维基百科上对于”Lambda expression”的解释：


 a function (or a subroutine) defined, and possibly called, without being bound to an identifier。


简单点说就是：一个不用被绑定到一个标识符上，并且可能被调用的函数。这个解释还不够通俗，lambda表达式可以这样定义（不精确，自己的理解）：一段带有输入参数的可执行语句块。这样就比较好理解了吧？一例胜千言。有读者反馈：不理解Stream的含义，所以这里先提供一个没用stream的lambda表达式的例子。







1

//这里省略list的构造









2

List&lt;String&gt;
 names = ...;









3

Collections.sort(names,
 (o1, o2) -&gt; o1.compareTo(o2));







 







1

//这里省略list的构造









2

List&lt;String&gt;
 names = ...;









3

Collections.sort(names, new Comparator&lt;String&gt;()
 {









4

  @Override









5

  public int compare(String
 o1, String o2) {









6

    return o1.compareTo(o2);









7

  }









8

});







上面两段代码分别是：使用lambda表达式来排序和使用匿名内部类来排序。这个例子可以很明显的看出lambda表达式简化代码的效果。接下来展示lambda表达式和其好基友Stream的配合。







1

List&lt;String&gt;
 names = new ArrayList&lt;&gt;();









2

names.add("TaoBao");









3

names.add("ZhiFuBao");









4

List&lt;String&gt;
 lowercaseNames = names.stream().map((String name) -&gt; {return name.toLowerCase();}).collect(Collectors.toList());







这段代码就是对一个字符串的列表，把其中包含的每个字符串都转换成全小写的字符串（熟悉Groovy和Scala的同学肯定会感觉很亲切）。注意代码第四行的map方法调用，这里map方法就是接受了一个lambda表达式（其实是一个java.util.function.Function的实例，后面会介绍）。

为什么需要Lambda表达式呢？在尝试回答这个问题之前，我们先看看在Java8之前，如果我们想做上面代码的操作应该怎么办。

先看看普通青年的代码：







1

List&lt;String&gt;
 names = new ArrayList&lt;&gt;();









2

names.add("TaoBao");









3

names.add("ZhiFuBao");









4

List&lt;String&gt;
 lowercaseNames = new ArrayList&lt;&gt;();









5

for (String
 name : names) {









6

  lowercaseNames.add(name.toLowerCase());









7

}







接下来看看文艺青年的代码（借助Guava）：







1

List&lt;String&gt;
 names = new ArrayList&lt;&gt;();









2

names.add("TaoBao");









3

names.add("ZhiFuBao");









4

List&lt;String&gt;
 lowercaseNames = FluentIterable.from(names).transform(new Function&lt;String,
 String&gt;() {









5

  @Override









6

  public String
 apply(String name) {









7

    return name.toLowerCase();









8

  }









9

}).toList();







在此，我们不再讨论普通青年和文艺青年的代码风格孰优孰劣（有兴趣的可以去google搜索“命令式编程vs声明式编程”）。本人更加喜欢声明式的编程风格，所以偏好文艺青年的写法。但是在文艺青年代码初看起来看起来干扰信息有点多，Function匿名类的构造语法稍稍有点冗长。所以Java8的lambda表达式给我们提供了创建SAM（Single Abstract Method）接口更加简单的语法糖。

Lambda语法详解

我们在此抽象一下lambda表达式的一般语法：







1

(Type1
 param1, Type2 param2, ..., TypeN paramN) -&gt; {









2

  statment1;









3

  statment2;









4

  //.............









5

  return statmentM;









6

}







从lambda表达式的一般语法可以看出来，还是挺符合上面给出的非精确版本的定义–“一段带有输入参数的可执行语句块”。

上面的lambda表达式语法可以认为是最全的版本，写起来还是稍稍有些繁琐。别着急，下面陆续介绍一下lambda表达式的各种简化版：

1. 参数类型省略–绝大多数情况，编译器都可以从上下文环境中推断出lambda表达式的参数类型。这样lambda表达式就变成了：







1

(param1,param2,
 ..., paramN) -&gt; {









2

  statment1;









3

  statment2;









4

  //.............









5

  return statmentM;









6

}







所以我们最开始的例子就变成了（省略了List的创建）：







1

List&lt;String&gt;
 lowercaseNames = names.stream().map((name) -&gt; {return name.toLowerCase();}).collect(Collectors.toList());







2. 当lambda表达式的参数个数只有一个，可以省略小括号。lambda表达式简写为：







1

param1
 -&gt; {









2

  statment1;









3

  statment2;









4

  //.............









5

  return statmentM;









6

}







所以最开始的例子再次简化为：







1

List&lt;String&gt;
 lowercaseNames = names.stream().map(name -&gt; {return name.toLowerCase();}).collect(Collectors.toList());







3. 当lambda表达式只包含一条语句时，可以省略大括号、return和语句结尾的分号。lambda表达式简化为：







1

param1
 -&gt; statment







所以最开始的例子再次简化为：







1

List&lt;String&gt;
 lowercaseNames = names.stream().map(name -&gt; name.toLowerCase()).collect(Collectors.toList());







4. 使用Method Reference(具体语法后面介绍)







1

//注意，这段代码在Idea
 13.0.2中显示有错误，但是可以正常运行









2

List&lt;String&gt;
 lowercaseNames = names.stream().map(String::toLowerCase).collect(Collectors.toList());








Lambda表达式眼中的外部世界

我们前面所有的介绍，感觉上lambda表达式像一个闭关锁国的家伙，可以访问给它传递的参数，也能自己内部定义变量。但是却从来没看到其访问它外部的变量。是不是lambda表达式不能访问其外部变量？我们可以这样想：lambda表达式其实是快速创建SAM接口的语法糖，原先的SAM接口都可以访问接口外部变量，lambda表达式肯定也是可以（不但可以，在java8中还做了一个小小的升级，后面会介绍）。







1

String[]
 array = {"a", "b", "c"};









2

for(Integer
 i : Lists.newArrayList(1,2,3)){









3

  Stream.of(array).map(item
 -&gt; Strings.padEnd(item, i, '@')).forEach(System.out::println);









4

}







上面的这个例子中，map中的lambda表达式访问外部变量Integer i。并且可以访问外部变量是lambda表达式的一个重要特性，这样我们可以看出来lambda表达式的三个重要组成部分：

输入参数可执行语句存放外部变量的空间

不过lambda表达式访问外部变量有一个非常重要的限制：变量不可变（只是引用不可变，而不是真正的不可变）。







1

String[]
 array = {"a", "b", "c"};









2

for(int i
 = 1;
 i&lt;4;
 i++){









3

  Stream.of(array).map(item
 -&gt; Strings.padEnd(item, i, '@')).forEach(System.out::println);









4

}







上面的代码，会报编译错误。因为变量i被lambda表达式引用，所以编译器会隐式的把其当成final来处理（ps：大家可以想象问什么上一个例子不报错，而这个报错。）细心的读者肯定会发现不对啊，以前java的匿名内部类在访问外部变量的时候，外部变量必须用final修饰。Bingo，在java8对这个限制做了优化（前面说的小小优化），可以不用显示使用final修饰，但是编译器隐式当成final来处理。
lambda眼中的this

在lambda中，this不是指向lambda表达式产生的那个SAM对象，而是声明它的外部对象。


方法引用（Method reference）和构造器引用（construct reference）
方法引用

前面介绍lambda表达式简化的时候，已经看过方法引用的身影了。方法引用可以在某些条件成立的情况下，更加简化lambda表达式的声明。方法引用语法格式有以下三种：

objectName::instanceMethodClassName::staticMethodClassName::instanceMethod

前两种方式类似，等同于把lambda表达式的参数直接当成instanceMethod|staticMethod的参数来调用。比如System.out::println等同于x-&gt;System.out.println(x)；Math::max等同于(x, y)-&gt;Math.max(x,y)。

最后一种方式，等同于把lambda表达式的第一个参数当成instanceMethod的目标对象，其他剩余参数当成该方法的参数。比如String::toLowerCase等同于x-&gt;x.toLowerCase()。
构造器引用

构造器引用语法如下：ClassName::new，把lambda表达式的参数当成ClassName构造器的参数 。例如BigDecimal::new等同于x-&gt;new BigDecimal(x)。
吐槽一下方法引用

表面上看起来方法引用和构造器引用进一步简化了lambda表达式的书写，但是个人觉得这方面没有Scala的下划线语法更加通用。比较才能看出，翠花，上代码！







1

List&lt;String&gt;
 names = new ArrayList&lt;&gt;();









2

names.add("TaoBao");









3

names.add("ZhiFuBao");









4

names.stream().map(name
 -&gt; name.charAt(0)).collect(Collectors.toList());







上面的这段代码就是给定一个String类型的List，获取每个String的首字母，并将其组合成新的List。这段代码就没办法使用方法引用来简化。接下来，我们简单对比一下Scala的下划线语法（不必太纠结Scala的语法，这里只是做个对比）：







1

//省略List的初始化









2

List[String]
 names = ....









3

names.map(_.charAt(0))







在Scala中基本不用写lambda表达式的参数声明。

为什么？ 
   我们为什么需要Lambda表达式 
   主要有三个原因： 
   &gt; 更加紧凑的代码 
     比如Java中现有的匿名内部类以及监听器(listeners)和事件处理器(handlers）都显得很冗长 
   &gt; 修改方法的能力（我个人理解为代码注入，或者有点类似JavaScript中传一个回调函数给另外一个函数） 
     比如Collection接口的contains方法，当且仅当传入的元素真正包含在集合中，才返回true。而假如我们想对一个字符串集合，传入一个字符串，只要这个字符串出现在集合中（忽略大小写）就返回true。 
     简单地说，我们想要的是传入“一些我们自己的代码”到已有的方法中，已有的方法将会执行我们传入的代码。Lambda表达式能很好地支持这点 
   &gt; 更好地支持多核处理 
     例如，通过Java 8新增的Lambda表达式，我们可以很方便地并行操作大集合，充分发挥多核CPU的潜能。 
     并行处理函数如filter、map和reduce。
 
怎么做？ 
   实例1 FileFilter 


File dir = new File("/an/dir/");
   FileFilter directoryFilter = new FileFilter() {
      public boolean accept(File file) {
         return file.isDirectory();
      }
};

   通过Lambda表达式这段代码可以简化为如下：

File dir = new File("/an/dir/");
FileFilter directoryFilter = (File f) -&gt; f.isDirectory();
File[] dirs = dir.listFiles(directoryFilter);

   进一步简化：

File dir = new File("/an/dir/");
File[] dirs = dir.listFiles((File f) -&gt; f.isDirectory());


   Lambda表达式使得代码可读性增强了。我承认我开始学习Java的时候对那个匿名内部类感到很困扰，而现在Lambda表达式让这一切看起来都很自然（尤其是有.NET背景的童鞋会发现这个跟.NET中的Lambda表达式好像） 
   Lambda表达式利用了类型推断（type inference）技术：

编译器知道FileFilter只有一个方法accept()，所以accept()方法肯定对应(File f) -&gt; f.isDirectory()
而且accept()方法只有一个File类型的参数，所以(File f) -&gt; f.isDirectory()中的File f就是这个参数了，
.NET把类型推断做得更绝，如果上面用.NET Lambda表达式写法的话是这样的：
   File[] dirs = dir.ListFiles(f =&gt; f.isDirectory());
即压根就不需要出现File类型指示。

   实例2 Event Handler

Button bt = new Button();
   bt.addActionListener(new ActionListener() {
      public void actionPerformed(ActionEvent e) {
         ui.showSomething();
      }
});


   使用Lambda表达式后：

Button bt = new Button();
ActionListener listener = event -&gt; { ui.showSomething(); };
bt.addActionListener(listener);

   进一步简化： 

Button bt = new Button();
bt.addActionListener(event -&gt; { ui.showSomething(); });

 
外循环、内循环和Map、Reduce、Filter 
   一直到现在，处理Java集合的标准做法是采用外循环。比如：

List&lt;String&gt; list = new ArrayList&lt;String&gt;();
list.add("hello");
list.add("world");
for(int item: list) {
   // 处理item
}

   还有迭代器循环，它们都是外循环，并且都是顺序处理（sequential handling）。顺序特性也常常引发ConcurrentModificationException，只要我们尝试着并发修改集合。 
   Lambda表达式提供了内循环机制。 
   我们工作中可能经常面临下面的需求：

&gt; 过滤掉一个集合中不符合条件的元素得到一个新集合
&gt; 对集合中的每个元素进行某种转换，并且对转换后的集合进行处理
&gt; 统计整个集合的某个属性，比如统计集合元素值的总和或平均值

   这些任务即filter、map和reduce，他们的共同特点是： 
   需要对集合中的每个元素运行一小段相同的代码。 
   传统的实现这些任务的代码让人感到很乏味，幸运的是Java 8提供了完成这些任务的更简洁的方案，当然还是利用Lambda表达式，但也引入了一个新的类库java.util.functions，包含Predicate、Mapper和Block。 
   Java 8中，一个Predicate（谓词）是这样一个方法：它根据变量的值进行评估(evaluate），返回true或false。 
   比如下面：

List&lt;String&gt; list = getMyStrings();
for(String myString: list) {
   if(myString.contains(possible)) {
       System.out.println(myString + " contains " + possible);
   }
}

   使用Predicate和Filter后得到下面代码：

List&lt;String&gt; list = getMyStrings();
Predicate&lt;String&gt; matched = s -&gt; s.equalsIgnoreCase(possible);
list.filter(matched);

   进一步简化：

List&lt;String&gt; list = getMyStrings();
list.filter(s -&gt; s.equalsIgnoreCase(possible));

 
Lambda表达式语法规则 
   到目前为止Java 8中的Lambda表达式语法规则还没有完全确定。 
   但这里简单介绍下： 
   对于前面的：

File dir = new File("/an/dir/");
File[] dirs = dir.listFiles((File f) -&gt; f.isDirectory());

   accept()方法返回布尔值，这种情况f.isDirectory()显然也得是布尔值。这很简单。 
   而对于：

Button bt = new Button();
bt.addActionListener(event -&gt; { ui.showSomething(); });

   actionPerformed()方法的返回类型是void，所以需要特殊处理，即在ui.showSomething();左右加上花括号。（想象下不加会怎么样？如果不加的话，若showSomething()方法返回值是整数类型，那么就意味着actionPerformed()返回整数类型，显然不是，所以必须加花括号用来标记）。 
   如果Lambda表达式主体部分包含多条语句，也必须用花括号，并且return语句不能省。 
   比如下面这个：

File dir = new File("/an/dir/");
File[] dirs = dir.listFiles((File f) -&gt;  { 
                                            System.out.println("Log:...");
                                            return f.isDirectory(); 
                                         }
);



函数编程在C#、Python、JavaScript中都得到充分体现。而Java直到最新的Java 8才开始正式支持函数编程，最明显的改进就是对Lamba表达式的支持。正如C#之父Anders Hejlsberg在那篇文章 编程语言大趋势 中所讲，未来的编程语言将逐渐融合各自的特性，而不存在单纯的声明式语言（如之前的Java）或者单纯的函数编程语言。将来声明式编程语言借鉴函数编程思想，函数编程语言融合声明式编程特性...这几乎是一种必然趋势。如下图所示：

 

影响力较大的三个趋势

那具体而言我们为什么需要Lambda表达式呢？难道Java的OO和命令式编程（imperative programming）特性不够强大吗？下面让我们来分析下其原因。

1、内部循环和外部循环

先看一个大家耳熟能详的例子：
List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5, 6);   for (int number : numbers) {      System.out.println(number);  } 

是不是很常见呢？这个叫外部循环（External Iteration）。但是外部循环有什么问题呢？简单来说存在下面三个缺点：

1.只能顺序处理List中的元素（process one by one）

2.不能充分利用多核CPU

3.不利于编译器优化

而如果利用内部循环，代码写成下面这样：
List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5, 6);   numbers.forEach((Integer value) -&gt; System.out.println(value)); 

这样就能规避上面的三个问题：

1.不一定需要顺序处理List中的元素，顺序可以不确定

2.可以并行处理，充分利用多核CPU的优势

3.有利于JIT编译器对代码进行优化

类似的C#从4.0版本开始也支持集合元素并行处理，代码如下：
List&lt;int&gt; nums = new List&lt;int&gt; { 1, 2, 3, 4, 5, 6 };  Parallel.ForEach(nums, (value) =&gt;  {     Console.WriteLine(value);  }); 



2、传递行为，而不仅仅是传值

如果你使用C#有一段时间的话，那么你很可能已经明白这个标题的意思了。在C#中，经常看到一些函数的参数是Action或者Func类型，比如下面这个：
public class ArticleDac {     ...     public Article GetArticles(Func&lt;IDbSet&lt;Article&gt;, Article&gt; func)   // 这里传递的就是行为     {        using(var db = xx) {           return func(db.Articles);        }       }     ...  }  // 下面是调用  int articleId = 119;  var firstArticle = new ArticleDac().GetArticles(      articleDbSet =&gt;      articleDbSet.AsQueryable().FirstOrDefault(x =&gt; x.id == articleId)  ); 

看不懂？没关系。我们先来看一个体现传值局限性的场景吧，上代码：
List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5, 6);   public int sumAll(List&lt;Integer&gt; numbers) {      int total = 0;      for (int number : numbers) {          total += number;      }      return total;  } 

sumAll算法很简单，完成的是将List中所有元素相加。某一天如果我们需要增加一个对List中所有偶数求和的方法sumAllEven，如下：
public int sumAllEven(List&lt;Integer&gt; numbers) {      int total = 0;      for (int number : numbers) {          if (number % 2 == 0) {              total += number;          }      }      return total;  } 

又有一天，我们需要增加第三个方法：对List中所有大于3的元素求和，那是不是继续加下面的方法呢? 
public int sumAllEven(List&lt;Integer&gt; numbers) {      int total = 0;      for (int number : numbers) {          if (number &gt; 3) {              total += number;          }      }      return total;  } 

比较这三个方法，我们发现了一个很明显的“代码臭味”—— 代码重复（详情参考《重构》），三个方法的唯一区别在于if判断这一行代码。如果脱离这里的上下文，我们会怎么做呢？我首先会先想到利用策略模式重构代码如下：
public interface Strategy {     public boolean test(int num);  }   public class SumAllStrategy implements Strategy {     public boolean test(int num) {        return true;     }  }   public class SumAllEvenStrategy implements Strategy {     public boolean test(int num) {        return num % 2 == 0;     }  }   public class ContextClass {     private Strategy stragegy = null;     private final static Strategy DEFAULT_STRATEGY = new SumAllStrategy();      public ContextClass() {        this(null);     }      public ContextClass(Stragegy stragegy) {        if(strategy != null) {           this.strategy = strategy;         }        else {           this.strategy = DEFAULT_STRATEGY;        }     }      public int sumAll(List&lt;Integer&gt; numbers) {        int total = 0;        for (int number : numbers) {           if (strategy.test(number)) {              total += number;           }        }         return total;     }  }    // 调用  ContextClass context = new ContextClass();  context.sumAll(numbers); 

设计模式在这里发挥了作用，OO特性还是蛮强大的！但这是唯一的解决方案吗（当然不考虑用其他设计模式来解决，因为都是OO范畴！）？当然有，该轮到Java 8 Lambda表达式中的谓词（Predicate）发挥作用了！
public int sumAll(List&lt;Integer&gt; numbers, Predicate&lt;Integer&gt; p) {      int total = 0;      for (int number : numbers) {          if (p.test(number)) {              total += number;          }      }      return total;  }   sumAll(numbers, n -&gt; true);  sumAll(numbers, n -&gt; n % 2 == 0);  sumAll(numbers, n -&gt; n &gt; 3); 

代码是不是比上面简洁很多了？语义应该也很明确，就不多解释了。从这里也可以看出未引入Lambda表达式之前的Java代码的冗长（Java这点被很多人诟病）。

当然C#早已经支持这种用法，用C#改写上面的代码如下：
public int SumAll(IEnumerable&lt;int&gt; numbers, Predicate&lt;int&gt; predicate) {          return numbers.Where(i =&gt; predicate(i)).Sum();   }    SumAll(numbers, n =&gt; true);  SumAll(numbers, n =&gt; n % 2 == 0);  SumAll(numbers, n =&gt; n &gt; 3); 



3、Consumer与Loan Pattern

比如我们有一个资源类Resource：
public class Resource {       public Resource() {          System.out.println("Opening resource");      }       public void operate() {          System.out.println("Operating on resource");      }       public void dispose() {          System.out.println("Disposing resource");      }  } 

我们必须这样调用：
Resource resource = new Resource();  try {      resource.operate();  } finally {      resource.dispose();  } 

因为对资源对象resource执行operate方法时可能抛出RuntimeException，所以需要在finally语句块中释放资源，防止可能的内存泄漏。

但是有一个问题，如果很多地方都要用到这个资源，那么就存在很多段类似这样的代码，这很明显违反了DRY（Don't Repeat Yourself）原则。而且如果某位程序员由于某些原因忘了用try/finally处理资源，那么很可能导致内存泄漏。那咋办呢？Java 8提供了一个Consumer接口，代码改写为如下：
public class Resource {       private Resource() {          System.out.println("Opening resource");      }       public void operate() {          System.out.println("Operating on resource");      }       public void dispose() {          System.out.println("Disposing resource");      }       public static void withResource(Consumer&lt;Resource&gt; consumer) {          Resource resource = new Resource();          try {              consumer.accept(resource);          } finally {              resource.dispose();          }      }  } 

调用代码如下：
Resource.withResource(resource -&gt; resource.operate()); 

外部要访问Resource不能通过它的构造函数了（private），只能通过withResource方法了，这样代码清爽多了，而且也完全杜绝了因人为疏忽而导致的潜在内存泄漏。



4、stream+laziness =&gt; efficiency

像之前一样先来一段非常简单的代码： 
List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5, 6);   for (int number : numbers) {      if (number % 2 == 0) {          int n2 = number * 2;          if (n2 &gt; 5) {              System.out.println(n2);              break;          }      }  } 

这段代码有什么问题？ 没错，可读性非常差。第一步，我们利用《重构》一书中的最基础的提取小函数重构手法来重构代码如下：
public boolean isEven(int number) {      return number % 2 == 0;  }   public int doubleIt(int number) {      return number * 2;  }   public boolean isGreaterThan5(int number) {      return number &gt; 5;  }   for (int number : numbers) {      if (isEven(number)) {          int n2 = doubleIt(number);          if (isGreaterThan5(n2)) {              System.out.println(n2);              break;          }      }  } 

OK，代码的意图清晰多了，但是可读性仍然欠佳，因为循环内嵌套一个if分支，if分支内又嵌套另外一个分支，于是继续重构代码如下：
public boolean isEven(int number) {      return number % 2 == 0;  }   public int doubleIt(int number) {      return number * 2;  }   public boolean isGreaterThan5(int number) {      return number &gt; 5;  }   List&lt;Integer&gt; l1 = new ArrayList&lt;Integer&gt;();  for (int n : numbers) {      if (isEven(n)) l1.add(n);  }   List&lt;Integer&gt; l2 = new ArrayList&lt;Integer&gt;();  for (int n : l1) {      l2.add(doubleIt(n));  }   List&lt;Integer&gt; l3 = new ArrayList&lt;Integer&gt;();  for (int n : l2) {      if (isGreaterThan5(n)) l3.add(n);  }   System.out.println(l3.get(0)); 

现在代码够清晰了，这是典型的“流水线”风格代码。但是等等，现在的代码执行会占用更多空间（三个List）和时间，我们来分析下。首先第二版代码的执行流程是这样的：
isEven: 1  isEven: 2  doubleIt: 2  isGreaterThan5: 2  isEven: 3  isEven: 4  doubleIt: 4  isGreaterThan5: 4  8 

而我们的第三版代码的执行流程是这样的：
isEven: 1 isEven: 2 isEven: 3 isEven: 4 isEven: 5 isEven: 6 doubleIt: 2 doubleIt: 4 doubleIt: 6 isGreaterThan5: 2 isGreaterThan5: 4 isGreaterThan5: 6 8 

步骤数是13:9，所以有时候重构得到可读性强的代码可能会牺牲一些运行效率（但是一切都得实际衡量之后才能确定）。那么有没有“三全其美”的实现方法呢？即：

1.代码可读性强

2.代码执行效率不比第一版代码差

3.空间消耗小

Streams come to rescue! Java 8提供了stream方法，我们可以通过对任何集合对象调用stream()方法获得Stream对象，Stream对象有别于Collections的几点如下：

1.不存储值：Streams不会存储值，它们从某个数据结构的流水线型操作中获取值（“酒肉穿肠过”）

2.天生的函数编程特性：对Stream对象操作能得到一个结果，但是不会修改原始数据结构

3.Laziness-seeking（延迟搜索）：Stream的很多操作如filter、map、sort和duplicate removal(去重）可以延迟实现，意思是我们只要检查到满足要求的元素就可以返回

4.可选边界：Streams允许Client取足够多的元素直到满足某个条件为止。而Collections不能这么做

上代码：
System.out.println(      numbers.stream()              .filter(Lazy::isEven)              .map(Lazy::doubleIt)              .filter(Lazy::isGreaterThan5)              .findFirst()  ); 

现在的执行流程是：
isEven: 1 isEven: 2 doubleIt: 2 isGreaterThan5: 4 isEven: 3 isEven: 4 doubleIt: 4 isGreaterThan5: 8 IntOptional[8] 

流程基本和第二版代码一致，这归功于Laziness-seeking特性。怎么理解呢？让我来构造下面这个场景：
Stream流对象要经过下面这种流水线式处理：  过滤出偶数 =&gt; 乘以2 =&gt; 过滤出大于5的数 =&gt; 取出第一个数   注意：=&gt; 左边的输出是右边的输入 

而Laziness-seeking意味着 我们在每一步只要一找到满足条件的数字，马上传递给下一步去处理并且暂停当前步骤。比如先判断1是否偶数，显然不是；继续判断2是否偶数，是偶数；好，暂停过滤偶数操作，将2传递给下一步乘以2，得到4；4继续传递给第三步，4不满足大于5，所以折回第一步；判断3是否偶数，不是；判断4是否偶数，是偶数；4传递给第二步，乘以2得到8；8传递给第三步，8大于5；所以传递给最后一步，直接取出得到 IntOptional[8]。

IntOptional[8]只是简单包装了下返回的结果，这样有什么好处呢？如果你接触过Null Object Pattern的话就知道了，这样可以避免无谓的null检测。


一：在JAVA中，有六个不同的地方可以存储数据：  

1. 寄存器（register）。 这是最快的存储区，因为它位于不同于其他存储区的地方——处理器内部。但是寄存器的数量极其有限，所以寄存器由编译器根据需求进行分配。你不能直接控制，也不能在程序中感觉到寄存器存在的任何迹象。    

------最快的存储区, 由编译器根据需求进行分配,我们在程序中无法控制.

2. 堆栈（stack）。位于通用RAM中，但通过它的“堆栈指针”可以从处理器哪里获得支持。堆栈指针若向下移动，则分配新的内存；若向上移动，则释放那些 内存。这是一种快速有效的分配存储方法，仅次于寄存器。创建程序时候，JAVA编译器必须知道存储在堆栈内所有数据的确切大小和生命周期，因为它必须生成 相应的代码，以便上下移动堆栈指针。这一约束限制了程序的灵活性，所以虽然某些JAVA数据存储在堆栈中——特别是对象引用，但是JAVA对象不存储其
 中。    

------存放基本类型的变量数据和对象，数组的引用，但对象本身不存放在栈中，而是存放在堆（new 出来的对象）或者常量池中（字符串常量对象存放在常量池中）

3. 堆（heap）。一种通用性的内存池（也存在于RAM中），用于存放所以的JAVA对象。堆不同于堆栈的好处是：编译器不需要知道要从堆里分配多少存储区 域，也不必知道存储的数据在堆里存活多长时间。因此，在堆里分配存储有很大的灵活性。当你需要创建一个对象的时候，只需要new写一行简单的代码，当执行 这行代码时，会自动在堆里进行存储分配。当然，为这种灵活性必须要付出相应的代码。用堆进行存储分配比用堆栈进行存储存储需要更多的时间。
  

------存放所有new出来的对象。

4. 静态存储（static storage）。这里的“静态”是指“在固定的位置”。静态存储里存放程序运行时一直存在的数据。你可用关键字static来标识一个对象的特定元素是静态的，但JAVA对象本身从来不会存放在静态存储空间里。  

------存放静态成员（static定义的）

5. 常量存储（constant storage）。常量值通常直接存放在程序代码内部，这样做是安全的，因为它们永远不会被改变。有时，在嵌入式系统中，常量本身会和其他部分分割离开，所以在这种情况下，可以选择将其放在ROM中  

------存放字符串常量和基本类型常量（public static final）

6. 非RAM存储。如果数据完全存活于程序之外，那么它可以不受程序的任何控制，在程序没有运行时也可以存在。  

------硬盘等永久存储空间 就速度来说，有如下关系：

    寄存器 &gt;堆栈 &gt; 堆 &gt; 其它

    这里我们主要关心栈，堆和常量池，对于栈和常量池中的对象可以共享，对于堆中的对象不可以共享。

     栈中的数据大小和生命周期是可以确定的，当没有引用指向数据时，这个数据就会消失。堆中的对象的由垃圾回收器负责回收，因此大小和生命周期不需要确定，具有很大的灵活性。    

    对于字符串：其对象的引用都是存储在栈中的，如果是编译期已经创建好(直接用双引号定义的)的就存储在常量池中，如果是运行期（new出来的）才能确定的就存储在堆中。对于equals相等的字符串，在常量池中永远只有一份，在堆中有多份。

     如以下代码： Java代码 

        String s1 = "china"; 

        String s2 = "china";

        String s3 = "china"; 

        String ss1 = new String("china"); 

        String ss2 = new String("china"); 

        String ss3 = new String("china");   




        这里解释一下，对于通过 new 产生一个字符串（假设为 ”china” ）时，会先去常量池中查找是否已经有了 ”china” 对象，如果没有则在常量池中创建一个此字符串对象，然后堆中再创建一个常量池中此 ”china” 对象的拷贝对象。

        也就是有道面试题： String s = new String(“xyz”); 产生几个对象？

         一个或两个。如果常量池中原来没有 ”xyz”, 就是两个。如果原来的常量池中存在“xyz”时，就是一个。

        对于基础类型的变量和常量：变量和引用存储在栈中，常量存储在常量池中。

        如以下代码： Java代码 

        int i1 = 9; 

        int i2 = 9; 

        int i3 = 9;  

        public static final int INT1 = 9; 

        public static final int INT2 = 9; 

        public static final int INT3 = 9;   




        对于成员变量和局部变量：成员变量就是方法外部，类的内部定义的变量；

     局部变量就是方法或语句块内部定义的变量。局部变量必须初始化。 形式参数是局部变量，局部变量的数据存在于栈内存中。栈内存中的局部变量随着方法的消失而消失。 成员变量存储在堆中的对象里面，由垃圾回收器负责回收。

     如以下代码： Java代码  

     class BirthDate {     

       private int day;     

       private int month;     

       private int year;         

       public BirthDate(int d, int m, int y) {         

                   day = d;          

                   month = m;          

                    year = y;     

                   }     

     // 省略get,set方法……… 

  }   

 

 public class Test{     

    public static void main(String args[]){ 

      int date = 9;         

      Test test = new Test();                  

      test.change(date);          

      BirthDate d1= new BirthDate(7,7,1970);            

    }         

  public void change1(int i){         

        i = 1234;     

    }   




  对于以上这段代码，date为局部变量，i,d,m,y都是形参为局部变量，day，month，year为成员变量。

  下面分析一下代码执行时候的变化：

  1. main方法开始执行：int date = 9; date局部变量，基础类型，引用和值都存在栈中。

  2. Test test = new Test(); test为对象引用，存在栈中，对象(new Test())存在堆中。

  3. test.change(date); i为局部变量，引用和值存在栈中。当方法change执行完成后，i就会从栈中消失。

  4. BirthDate d1= new BirthDate(7,7,1970);  d1 为对象引用，存在栈中，对象(new BirthDate())存在堆中，其中d，m，y为局部变量存储在栈中，且它们的类型为基础类型，因此它们的数据也存储在栈中。 day,month,year为成员变量，它们存储在堆中(new BirthDate()里面)。当BirthDate构造方法执行完之后，d,m,y将从栈中消失。

  5.main方法执行完之后，date变量，test，d1引用将从栈中消失，new Test(),new BirthDate()将等待垃圾回收。

 

Java堆、栈和常量池详解（二）

1. 栈(stack)与堆(heap)都是Java用来在RAM中存放数据的地方。与C++不同，Java自动管理栈和堆，程序员不能直接地设置栈或堆。

2. 栈的优势是，存取速度比堆要快，仅次于直接位于CPU中的寄存器。但缺点是，存在栈中的数据大小与生存期必须是确定的，缺乏灵活性。另外，栈数据可以共 享，详见第3点。    

    堆的优势是可以动态地分配内存大小，生存期也不必事先告诉编译器，Java的垃圾收集器会自动收走这些不再使用的数据。但缺点是，由于要 在运行时动态分配内存，存取速度较慢。

3. Java中的数据类型有两种。

 一种是基本类型(primitive types), 共有8种，即int, short, long, byte, float, double, boolean, char(注意，并没有string的基本类型)。这种类型的定义是通过诸如int a = 3; long b = 255L;的形式来定义的，称为自动变量。值得注意的是，自动变量存的是字面值，不是类的实例，即不是类的引用，这里并没有类的存在。如int a = 3;
 这里的a是一个指向int类型的引用，指向3这个字面值。这些字面值的数据，由于大小可知，生存期可知(这些字面值固定定义在某个程序块里面，程序块退出 后，字段值就消失了)，出于追求速度的原因，就存在于栈中。 另外，栈有一个很重要的特殊性，就是存在栈中的数据可以共享。假设我们同时定义   int a = 3;   int b = 3； 编 译器先处理int a = 3；首先它会在栈中创建一个变量为a的引用，然后查找有没有字面值为3的地址，没找到，就开辟一个存放3这个字面值的地址，然后将a指向3的地址。接着处 理int
 b = 3；在创建完b的引用变量后，由于在栈中已经有3这个字面值，便将b直接指向3的地址。这样，就出现了a与b同时均指向3的情况。 特 别注意的是，这种字面值的引用与类对象的引用不同。假定两个类对象的引用同时指向一个对象，如果一个对象引用变量修改了这个对象的内部状态，那么另一个对 象引用变量也即刻反映出这个变化。相反，通过字面值的引用来修改其值，不会导致另一个指向此字面值的引用的值也跟着改变的情况。如上例，我们定义完a与 b的值后，再令a=4；那么，b不会等于4，还是等于3。在编译器内部，遇到a=4；时，它就会重新搜索栈中是否有4的字面值，如果没有，重新开辟地址存
 放4的值；如果已经有了，则直接将a指向这个地址。因此a值的改变不会影响到b的值。

   另一种是包装类数据，如Integer, String, Double等将相应的基本数据类型包装起来的类。这些类数据全部存在于堆中，Java用new()语句来显示地告诉编译器，在运行时才根据需要动态创建，因此比较灵活，但缺点是要占用更多的时间。  

   举例如下： Java代码 

   public class Test {       

    public static void main(String[] args)       

    {   

        int a1=1;         

        int b1=1;         

        int c1=2;         

        int d1=a1+b1;         

        Integer a = 1;           

        Integer b = 2;           

        Integer c = 3;           

        Integer d = 3;           

        Integer e = 321;           

        Integer f = 321;

        Long g = 3L;  

       System.out.println(a1==b1);   //true  结果1           

       System.out.println(c1==d1);   //true  结果2         

       System.out.println(c==d);   //true  结果3            

       System.out.println(e==f);   //false  结果4          

      }  

  }   

 分析：

   结果1：a1==b1如上面所述,会在栈 中开辟存储空间存放数据。          

   结果2：首先它会在栈 中创建一个变量为c1的引用，然后查找有没有字面值为2的地址，没找到，就开辟一个存放2这个字面值的地址，然后将c1指向2的地址,d1为两个字面值相加也为2， 由于在栈中已经有2这个字面值，便将d1直接指向2的地址。这样，就出现了c1与d1同时均指向3的情况。           在分析下面结果以前让我们先对Java自动拆箱和装箱做个了结：在自动装箱时，把int变成Integer的时候，是有规则的，当你的int的值在-128-IntegerCache.high(127)
 时，返回的不是一个新new出来的Integer对象，而是一个已经缓存在堆 中的Integer对象，（我们可以这样理解，系统已经把-128到127之 间的Integer缓存到一个Integer数组中去了，如果你要把一个int变成一个Integer对象，首先去缓存中找，找到的话直接返回引用给你就 行了，不必再新new一个），如果不在-128-IntegerCache.high(127) 时会返回一个新new出来的Integer对象。           

  结果3：由于3是在范围内所以是从缓存中取数据的，c和d指向同一个对象，结果为true;         

  结果4：由于321不是在范围内所以不是从缓存中取数据的而是单独有new对象，e和f并没有指向同一个对象，结果为false;  

  4. String是一个特殊的包装类数据。即可以用String str = new String("abc");的形式来创建，也可以用String str = "abc"；的形式来创建(作为对比，在JDK 5.0之前，你从未见过Integer i = 3;的表达式，因为类与字面值是不能通用的，除了String。而在JDK 5.0中，这种表达式是可以的！因为编译器在后台进行Integer i = new Integer(3)的转换)。前者是规范的类的创建过程，即在Java中，一切都是对象，而对象是类的实例，全部通过new()的形式来创建。Java
 中的有些类，如DateFormat类，可以通过该类的getInstance()方法来返回一个新创建的类，似乎违反了此原则。其实不然。该类运用了单 例模式来返回类的实例，只不过这个实例是在该类内部通过new()来创建的，而getInstance()向外部隐藏了此细节。那为什么在String str = "abc"；中，并没有通过new()来创建实例，是不是违反了上述原则？其实没有。

   4(1)String str = "abc"创建对象的过程 1 首先在常量池中查找是否存在内容为"abc"字符串对象 2 如果不存在则在常量池中创建"abc"，并让str引用该对象 3 如果存在则直接让str引用该对象

至 于"abc"是怎么保存，保存在哪？常量池属于类信息的一部分，而类信息反映到JVM内存模型中是对应存在于JVM内存模型的方法区，也就是说这个类信息 中的常量池概念是存在于在方法区中，而方法区是在JVM内存模型中的堆中由JVM来分配的，所以"abc"可以说存在于堆中（而有些资料，为了把方法区的 堆区别于JVM的堆，把方法区称为栈）。一般这种情况下，"abc"在编译时就被写入字节码中，所以class被加载时，JVM就为"abc"在常量池中
 分配内存，所以和静态区差不多。  

   4(2)String str = new String("abc")创建实例的过程 1 首先在堆中（不是常量池）创建一个指定的对象"abc"，并让str引用指向该对象 2 在字符串常量池中查看，是否存在内容为"abc"字符串对象 3 若存在，则将new出来的字符串对象与字符串常量池中的对象联系起来 4 若不存在，则在字符串常量池中创建一个内容为"abc"的字符串对象，并将堆中的对象与之联系起来 intern 方法可以返回该字符串在常量池中的对象的引用，可以通过下面代码简单的测试
 Java代码 

  class StringTest {     

   public static void main(String[] args) {         

    String str1 = "abc";         

    String str2 = new String("abc").intern();         

    System.out.println(str1==str2);     

  } 

} 

  一个初始为空的字符串池，它由类 String 私有地维护。 当调用 intern 方法时，如果池已经包含一个等于此 String 对象的字符串（用 equals(Object) 方法确定），则返回池中的字符串。否则，将此 String 对象添加到池中，并返回此 String 对象的引用。 它遵循以下规则：对于任意两个字符串 s 和 t ，当且仅当  s.equals(t) 为 true 时，s.intern() ==
 t.intern() 才为 true 。   所以String str1 = "abc"，str1引用的是常量池（方法区）的对象，而String str2 = new String("abc")，str2引用的是堆中的对象，所以内存地址不一样，但是内容一样，所以==为false，而equals是true

4(3)String str1 = "abc"; String str2 = "ab" + "c"; str1==str2是ture 是因为String str2 = "ab" + "c"会查找常量池中时候存在内容为"abc"字符串对象，如存在则直接让str2引用该对象，显然String str1 = "abc"的时候，上面说了，会在常量池中创建"abc"对象，所以str1引用该对象，str2也引用该对象，所以str1==str2

4(4)String str1 = "abc"; String str2 = "ab"; String str3 = str2 + "c"; str1==str3是false 是因为String str3 = str2 + "c"涉及到变量（不全是常量）的相加，所以会生成新的对象，其内部实现是先new一个StringBuilder，然后 append(str2),append("c");然后让str3引用toString()返回的对象
 如果想了解更多的细节，可以自己查看反编译的代码，查看反编译代码可以用javap，

 即 javap -c -verbose 要查看的类文件(.class不要)

比如上面的代码的示例

javac StringTest.java //编译

javap -c -verbose StringTest //反编译

4(5)String str1 = "abc";

      String str2 = "abc";

     System.out.println(str1==str2);  //true 注意，

     我们这里并不用str1.equals(str2)；的方式，因为这将比较两个字符串的值是否相等。==号，根据JDK的说明，只有在两个引用都指向了同一个对象时才返回真值。而我们在这里要看的是，str1与str2是否都指向了同一个对象。 结果说明，JVM创建了两个引用str1和str2，但只创建了一个对象，而且两个引用都指向了这个对象。

4(6)String str1 = "abc";

      String str2 = "abc";

       str1 = "bcd";

       System.out.println(str1 + "," + str2);  //bcd, abc      

       System.out.println(str1==str2);  //false 这就是说，赋值的变化导致了类对象引用的变化，str1指向了另外一个新对象！而str2仍旧指向原来的对象。上例中，当我们将str1的值改为"bcd"时，JVM发现在 常量池中没有存放该值的地址，便开辟了这个地址，并创建了一个新的对象，其字符串的值指向这个地址。 事 实上，String类被设计成为不可改变(immutable)的类。如果你要改变其值，可以，但JVM在运行时根据新值悄悄创建了一个新对象，然后将这
 个对象的地址返回给原来类的引用。这个创建过程虽说是完全自动进行的，但它毕竟占用了更多的时间。在对时间要求比较敏感的环境中，会带有一定的不良影响。

 4(7)

     String str1 = "abc";

     String str2 = "abc";

               str1 = "bcd";      

     String str3 = str1;      

     System.out.println(str3);  //bcd      

     String str4 = "bcd";    

     System.out.println(str1 == str4);  //true str3 这个对象的引用直接指向str1所指向的对象(注意，str3并没有创建新对象)。当str1改完其值后，再创建一个String的引用str4，并指向 因str1修改值而创建的新的对象。可以发现，这回str4也没有创建新的对象，从而再次实现栈中数据的共享。

 4(8)

   我们再接着看以下的代码。  

  String str1 = new String("abc");

  String str2 = "abc";

  System.out.println(str1==str2);  //false 创建了两个引用。创建了两个对象。两个引用分别指向不同的两个对象。   String str1 = "abc";   String str2 = new String("abc");   System.out.println(str1==str2);  //false 创建了两个引用。创建了两个对象。两个引用分别指向不同的两个对象。 以上两段代码说明，只要是用new()来新建对象的，都会在堆中创建，而且其字符串是单独存值的，即使与栈中的数据相同，也不会与栈中的数据共享。

5. 数据类型包装类的值不可修改。不仅仅是String类的值不可修改，所有的数据类型包装类都不能更改其内部的值。

6. 结论与建议：

  (1) 我们在使用诸如String str = "abc"；的格式定义类时，总是想当然地认为，我们创建了String类的对象str。担心陷阱！对象可能并没有被创建！唯一可以肯定的是，指向 String类的引用被创建了。至于这个引用到底是否指向了一个新的对象，必须根据上下文来考虑，除非你通过new()方法来显要地创建一个新的对象。因 此，更为准确的说法是，我们创建了一个指向String类的对象的引用变量str，这个对象引用变量指向了某个值为"abc"的String类。清醒地认
 识到这一点对排除程序中难以发现的bug是很有帮助的。

(2)使用String str = "abc"；的方式，可以在一定程度上提高程序的运行速度，因为JVM会自动根据栈中数据的实际情况来决定是否有必要创建新对象。而对于String str = new String("abc")；的代码，则一概在堆中创建新对象，而不管其字符串值是否相等，是否有必要创建新对象，从而加重了程序的负担。这个思想应该是 享元模式的思想，但JDK的内部在这里实现是否应用了这个模式，不得而知。

(3)当比较包装类里面的数值是否相等时，用equals()方法；当测试两个包装类的引用是否指向同一个对象时，用==。

(4)由于String类的immutable性质，当String变量需要经常变换其值时，应该考虑使用StringBuilder类，以提高程序效率。


com.google.guava/guava 共有41个版本，总共被引用了20095次
被引用次数最多的版本是14.0.1 ，其被引用次数为3919 ，查看引用次数柱状图 。
Guava is a suite of core and expanded libraries that include utility classes, google's collections, io classes, and much much more. Guava has only one code dependency - javax.annotation, per the
 JSR-305 spec.

guava ? 19.0 最后更新于2015-12-09 被中央仓库Jar包引用79次guava ? 19.0-rc3 最后更新于2015-12-01 被中央仓库Jar包引用1次guava ? 19.0-rc2 最后更新于2015-09-17 被中央仓库Jar包引用4次guava ? 18.0-rc1 最后更新于2014-08-05 被中央仓库Jar包引用0次guava ? 17.0 最后更新于2014-04-22 被中央仓库Jar包引用438次guava ? 17.0-rc2 最后更新于2014-04-10 被中央仓库Jar包引用2次guava ? 17.0-rc1 最后更新于2014-04-08 被中央仓库Jar包引用1次guava ? 16.0.1 最后更新于2014-02-03 被中央仓库Jar包引用1359次guava ? 16.0 最后更新于2014-01-17 被中央仓库Jar包引用170次guava ? 16.0-rc1 最后更新于2013-12-19 被中央仓库Jar包引用34次guava ? 15.0 最后更新于2013-09-06 被中央仓库Jar包引用1700次
描述： Guava is a suite of core and expanded libraries that include utility classes, google's collections, io classes, and much much more. Guava has two code dependencies - javax.annotation per the JSR-305 spec and javax.inject
 per the JSR-330 spec.
guava ? 15.0-rc1 最后更新于2013-08-26 被中央仓库Jar包引用2次
描述： Guava is a suite of core and expanded libraries that include utility classes, google's collections, io classes, and much much more. Guava has two code dependencies - javax.annotation per the JSR-305 spec and javax.inject
 per the JSR-330 spec.
guava ? 14.0.1 最后更新于2013-03-14 被中央仓库Jar包引用3919次
描述： Guava is a suite of core and expanded libraries that include utility classes, google's collections, io classes, and much much more. Guava has two code dependencies - javax.annotation per the JSR-305 spec and javax.inject
 per the JSR-330 spec.
guava ? 14.0 最后更新于2013-02-25 被中央仓库Jar包引用481次
描述： Guava is a suite of core and expanded libraries that include utility classes, google's collections, io classes, and much much more. Guava has two code dependencies - javax.annotation per the JSR-305 spec and javax.inject
 per the JSR-330 spec.
guava ? 14.0-rc3 最后更新于2013-02-13 被中央仓库Jar包引用18次
描述： Guava is a suite of core and expanded libraries that include utility classes, google's collections, io classes, and much much more. Guava has two code dependencies - javax.annotation per the JSR-305 spec and javax.inject
 per the JSR-330 spec.
guava ? 14.0-rc2 最后更新于2013-01-17 被中央仓库Jar包引用30次
描述： Guava is a suite of core and expanded libraries that include utility classes, google's collections, io classes, and much much more. Guava has two code dependencies - javax.annotation per the JSR-305 spec and javax.inject
 per the JSR-330 spec.
guava ? 14.0-rc1 最后更新于2012-12-14 被中央仓库Jar包引用46次
描述： Guava is a suite of core and expanded libraries that include utility classes, google's collections, io classes, and much much more. Guava has two code dependencies - javax.annotation per the JSR-305 spec and javax.inject
 per the JSR-330 spec.
guava ? 13.0.1 最后更新于2012-08-28 被中央仓库Jar包引用1529次guava ? 13.0 最后更新于2012-08-02 被中央仓库Jar包引用747次guava ? 13.0-final 最后更新于2012-08-01 被中央仓库Jar包引用1次guava ? 13.0-rc2 最后更新于2012-07-20 被中央仓库Jar包引用4次guava ? 12.0.1 最后更新于2012-07-10 被中央仓库Jar包引用335次guava ? 13.0-rc1 最后更新于2012-06-26 被中央仓库Jar包引用9次guava ? 12.0 最后更新于2012-04-30 被中央仓库Jar包引用2054次guava ? 12.0-rc2 最后更新于2012-04-17 被中央仓库Jar包引用3次guava ? 12.0-rc1 最后更新于2012-03-30 被中央仓库Jar包引用7次
描述： Guava is a suite of core and expanded libraries that include utility classes, google's collections, io classes, and much much more. This project is a complete packaging of all the Guava libraries into a single jar.
 Individual portions of Guava can be used by downloading the appropriate module and its dependencies. Guava (complete) has only one code dependency - javax.annotation, per the JSR-305 spec.
guava ? 11.0.2 最后更新于2012-02-22 被中央仓库Jar包引用1324次
描述： Guava is a suite of core and expanded libraries that include utility classes, google's collections, io classes, and much much more. This project is a complete packaging of all the Guava libraries into a single jar.
 Individual portions of Guava can be used by downloading the appropriate module and its dependencies. Guava (complete) has only one code dependency - javax.annotation, per the JSR-305 spec.
guava ? 11.0.1 最后更新于2012-01-09 被中央仓库Jar包引用980次
描述： Guava is a suite of core and expanded libraries that include utility classes, google's collections, io classes, and much much more. This project is a complete packaging of all the Guava libraries into a single jar.
 Individual portions of Guava can be used by downloading the appropriate module and its dependencies. Guava (complete) has only one code dependency - javax.annotation, per the JSR-305 spec.
guava ? 11.0 最后更新于2011-12-18 被中央仓库Jar包引用546次
描述： Guava is a suite of core and expanded libraries that include utility classes, google's collections, io classes, and much much more. This project is a complete packaging of all the Guava libraries into a single jar.
 Individual portions of Guava can be used by downloading the appropriate module and its dependencies. Guava (complete) has only one code dependency - javax.annotation, per the JSR-305 spec.
guava ? 11.0-rc1 最后更新于2011-12-14 被中央仓库Jar包引用11次
描述： Guava is a suite of core and expanded libraries that include utility classes, google's collections, io classes, and much much more. This project is a complete packaging of all the Guava libraries into a single jar.
 Individual portions of Guava can be used by downloading the appropriate module and its dependencies. Guava (complete) has only one code dependency - javax.annotation, per the JSR-305 spec.
guava ? 10.0.1 最后更新于2011-10-10 被中央仓库Jar包引用1854次
描述： Guava is a suite of core and expanded libraries that include utility classes, google's collections, io classes, and much much more. This project is a complete packaging of all the Guava libraries into a single jar.
 Individual portions of Guava can be used by downloading the appropriate module and its dependencies. Guava (complete) has only one code dependency - javax.annotation, per the JSR-305 spec.
guava ? 10.0 最后更新于2011-09-28 被中央仓库Jar包引用381次
描述： Guava is a suite of core and expanded libraries that include utility classes, google's collections, io classes, and much much more. This project is a complete packaging of all the Guava libraries into a single jar.
 Individual portions of Guava can be used by downloading the appropriate module and its dependencies. Guava (complete) has only one code dependency - javax.annotation, per the JSR-305 spec.
guava ? 10.0-rc3 最后更新于2011-09-23 被中央仓库Jar包引用1次
描述： Guava is a suite of core and expanded libraries that include utility classes, google's collections, io classes, and much much more. This project is a complete packaging of all the Guava libraries into a single jar.
 Individual portions of Guava can be used by downloading the appropriate module and its dependencies. Guava (complete) has only one code dependency - javax.annotation, per the JSR-305 spec.
guava ? 10.0-rc2 最后更新于2011-09-19 被中央仓库Jar包引用1次
描述： Guava is a suite of core and expanded libraries that include utility classes, google's collections, io classes, and much much more. This project is a complete packaging of all the Guava libraries into a single jar.
 Individual portions of Guava can be used by downloading the appropriate module and its dependencies. Guava (complete) has only one code dependency - javax.annotation, per the JSR-305 spec.
guava ? 10.0-rc1 最后更新于2011-09-09 被中央仓库Jar包引用4次
描述： Guava is a suite of core and expanded libraries that include utility classes, google's collections, io classes, and much much more. This project is a complete packaging of all the Guava libraries into a single jar.
 Individual portions of Guava can be used by downloading the appropriate module and its dependencies. Guava (complete) has only one code dependency - javax.annotation, per the JSR-305 spec.
guava ? r09 最后更新于2011-04-08 被中央仓库Jar包引用989次
描述： Guava is a suite of core and expanded libraries that include utility classes, google's collections, io classes, and much much more. This project is a complete packaging of all the Guava libraries into a single jar.
 Individual portions of Guava can be used by downloading the appropriate module and its dependencies. Guava (complete) has only one code dependency - javax.annotation, per the JSR-305 spec.
guava ? r08 最后更新于2011-01-31 被中央仓库Jar包引用591次
描述： Guava is a suite of core and expanded libraries that include utility classes, google's collections, io classes, and much much more. This project is a complete packaging of all the Guava libraries into a single jar.
 Individual portions of Guava can be used by downloading the appropriate module and its dependencies. Guava (complete) has only one code dependency - javax.annotation, per the JSR-305 spec.
guava ? r07 最后更新于2010-09-24 被中央仓库Jar包引用241次
描述： Guava is a suite of core and expanded libraries that include utility classes, google's collections, io classes, and much much more. This project is a complete packaging of all the Guava libraries into a single jar.
 Individual portions of Guava can be used by downloading the appropriate module and its dependencies. Guava (complete) has only one code dependency - javax.annotation, per the JSR-305 spec.
guava ? r06 最后更新于2010-07-08 被中央仓库Jar包引用121次
描述： Guava is a suite of core and expanded libraries that include utility classes, google's collections, io classes, and much much more. This project is a complete packaging of all the Guava libraries into a single jar.
 Individual portions of Guava can be used by downloading the appropriate module and its dependencies. Guava (complete) has only one code dependency - javax.annotation, per the JSR-305 spec.
guava ? r05 最后更新于2010-06-01 被中央仓库Jar包引用69次
描述： Guava is a suite of core and expanded libraries that include utility classes, google's collections, io classes, and much much more. This project is a complete packaging of all the Guava libraries into a single jar.
 Individual portions of Guava can be used by downloading the appropriate module and its dependencies. Guava (complete) has only one code dependency - javax.annotation, per the JSR-305 spec.
guava ? r03 最后更新于2010-04-26 被中央仓库Jar包引用9次
描述： Guava is a suite of core and expanded libraries that include utility classes, google's collections, io classes, and much much more. This project is a complete packaging of all the Guava libraries into a single jar.
 Individual portions of Guava can be used by downloading the appropriate module and its dependencies. Guava (complete) has only one code dependency - javax.annotation, per the JSR-305 spec.


com.google.guava/guava-collections 共有1个版本，总共被引用了421次
被引用次数最多的版本是r03 ，其被引用次数为421 。
Guava Collections is a collections extension library with expanded collection types, implementations, and utility methods for dealing with aggregate data.

collections

guava-collections ? r03 最后更新于2010-04-26 被中央仓库Jar包引用421次

com.google.guava/guava-gwt 共有35个版本，总共被引用了191次
被引用次数最多的版本是12.0 ，其被引用次数为65 ，查看引用次数柱状图 。
Guava is a suite of core and expanded libraries that include utility classes, google's collections, io classes, and much much more. This project includes GWT-friendly sources.

gwt

guava-gwt ? 19.0 最后更新于2015-12-09 被中央仓库Jar包引用3次guava-gwt ? 19.0-rc3 最后更新于2015-12-01 被中央仓库Jar包引用0次guava-gwt ? 19.0-rc2 最后更新于2015-09-17 被中央仓库Jar包引用0次guava-gwt ? 19.0-rc1 最后更新于2015-07-23 被中央仓库Jar包引用0次guava-gwt ? 17.0 最后更新于2014-04-22 被中央仓库Jar包引用6次guava-gwt ? 17.0-rc2 最后更新于2014-04-10 被中央仓库Jar包引用0次guava-gwt ? 17.0-rc1 最后更新于2014-04-08 被中央仓库Jar包引用0次guava-gwt ? 16.0.1 最后更新于2014-02-03 被中央仓库Jar包引用3次guava-gwt ? 16.0 最后更新于2014-01-17 被中央仓库Jar包引用2次guava-gwt ? 16.0-rc1 最后更新于2013-12-19 被中央仓库Jar包引用0次guava-gwt ? 15.0 最后更新于2013-09-06 被中央仓库Jar包引用10次guava-gwt ? 15.0-rc1 最后更新于2013-08-26 被中央仓库Jar包引用0次guava-gwt ? 14.0.1 最后更新于2013-03-14 被中央仓库Jar包引用62次guava-gwt ? 14.0 最后更新于2013-02-25 被中央仓库Jar包引用0次guava-gwt ? 14.0-rc3 最后更新于2013-02-13 被中央仓库Jar包引用0次guava-gwt ? 14.0-rc2 最后更新于2013-01-17 被中央仓库Jar包引用0次guava-gwt ? 14.0-rc1 最后更新于2012-12-14 被中央仓库Jar包引用0次guava-gwt ? 13.0.1 最后更新于2012-08-28 被中央仓库Jar包引用15次guava-gwt ? 13.0 最后更新于2012-08-02 被中央仓库Jar包引用0次guava-gwt ? 13.0-final 最后更新于2012-08-01 被中央仓库Jar包引用0次guava-gwt ? 13.0-rc2 最后更新于2012-07-20 被中央仓库Jar包引用0次guava-gwt ? 12.0.1 最后更新于2012-07-10 被中央仓库Jar包引用0次guava-gwt ? 13.0-rc1 最后更新于2012-06-26 被中央仓库Jar包引用0次guava-gwt ? 12.0 最后更新于2012-04-30 被中央仓库Jar包引用65次guava-gwt ? 12.0-rc2 最后更新于2012-04-17 被中央仓库Jar包引用0次guava-gwt ? 12.0-rc1 最后更新于2012-03-30 被中央仓库Jar包引用0次guava-gwt ? 11.0.2 最后更新于2012-02-22 被中央仓库Jar包引用2次guava-gwt ? 11.0.1 最后更新于2012-01-09 被中央仓库Jar包引用0次guava-gwt ? 11.0 最后更新于2011-12-18 被中央仓库Jar包引用0次guava-gwt ? 11.0-rc1 最后更新于2011-12-14 被中央仓库Jar包引用0次guava-gwt ? 10.0.1 最后更新于2011-10-10 被中央仓库Jar包引用20次guava-gwt ? 10.0 最后更新于2011-09-28 被中央仓库Jar包引用3次guava-gwt ? 10.0-rc3 最后更新于2011-09-23 被中央仓库Jar包引用0次guava-gwt ? 10.0-rc2 最后更新于2011-09-19 被中央仓库Jar包引用0次guava-gwt ? 10.0-rc1 最后更新于2011-09-09 被中央仓库Jar包引用0次

com.google.guava/guava-jdk5 共有8个版本，总共被引用了139次
被引用次数最多的版本是13.0 ，其被引用次数为97 ，查看引用次数柱状图 。
Guava is a suite of core and expanded libraries that include utility classes, google's collections, io classes, and much much more. Guava has only one code dependency - javax.annotation, per the
 JSR-305 spec.

guava-jdk5 ? 17.0 最后更新于2014-04-22 被中央仓库Jar包引用8次guava-jdk5 ? 17.0-rc2 最后更新于2014-04-10 被中央仓库Jar包引用2次guava-jdk5 ? 17.0-rc1 最后更新于2014-04-08 被中央仓库Jar包引用0次guava-jdk5 ? 16.0 最后更新于2014-02-10 被中央仓库Jar包引用4次guava-jdk5 ? 16.0-rc1 最后更新于2014-01-31 被中央仓库Jar包引用2次guava-jdk5 ? 14.0.1 最后更新于2013-06-13 被中央仓库Jar包引用23次guava-jdk5 ? 14.0.1-rc1 最后更新于2013-04-24 被中央仓库Jar包引用3次guava-jdk5 ? 13.0 最后更新于2012-09-26 被中央仓库Jar包引用97次

com.google.guava/guava-io 共有1个版本，总共被引用了133次
被引用次数最多的版本是r03 ，其被引用次数为133 。
Guava IO contains a variety of types and utilities to ease IO handling in Java.

io

guava-io ? r03 最后更新于2010-04-26 被中央仓库Jar包引用133次

com.google.guava/guava-testlib 共有31个版本，总共被引用了104次
被引用次数最多的版本是16.0.1 ，其被引用次数为43 ，查看引用次数柱状图 。
Guava testlib is a set of java classes used for more convenient unit testing - particularly to assist the tests for Guava itself.

guava-testlib ? 17.0 最后更新于2014-04-22 被中央仓库Jar包引用8次guava-testlib ? 17.0-rc2 最后更新于2014-04-10 被中央仓库Jar包引用1次guava-testlib ? 17.0-rc1 最后更新于2014-04-08 被中央仓库Jar包引用1次guava-testlib ? 16.0.1 最后更新于2014-02-03 被中央仓库Jar包引用43次guava-testlib ? 16.0 最后更新于2014-01-17 被中央仓库Jar包引用2次guava-testlib ? 16.0-rc1 最后更新于2013-12-19 被中央仓库Jar包引用1次guava-testlib ? 15.0 最后更新于2013-09-06 被中央仓库Jar包引用10次guava-testlib ? 15.0-rc1 最后更新于2013-08-26 被中央仓库Jar包引用1次guava-testlib ? 14.0.1 最后更新于2013-03-14 被中央仓库Jar包引用25次guava-testlib ? 14.0 最后更新于2013-02-25 被中央仓库Jar包引用0次guava-testlib ? 14.0-rc3 最后更新于2013-02-13 被中央仓库Jar包引用0次guava-testlib ? 14.0-rc2 最后更新于2013-01-17 被中央仓库Jar包引用0次guava-testlib ? 14.0-rc1 最后更新于2012-12-14 被中央仓库Jar包引用0次guava-testlib ? 13.0.1 最后更新于2012-08-28 被中央仓库Jar包引用5次guava-testlib ? 13.0 最后更新于2012-08-02 被中央仓库Jar包引用3次guava-testlib ? 13.0-final 最后更新于2012-08-01 被中央仓库Jar包引用0次guava-testlib ? 13.0-rc2 最后更新于2012-07-20 被中央仓库Jar包引用0次guava-testlib ? 12.0.1 最后更新于2012-07-10 被中央仓库Jar包引用0次guava-testlib ? 13.0-rc1 最后更新于2012-06-26 被中央仓库Jar包引用0次guava-testlib ? 12.0 最后更新于2012-04-30 被中央仓库Jar包引用1次guava-testlib ? 12.0-rc2 最后更新于2012-04-17 被中央仓库Jar包引用0次guava-testlib ? 12.0-rc1 最后更新于2012-03-30 被中央仓库Jar包引用0次guava-testlib ? 11.0.2 最后更新于2012-02-22 被中央仓库Jar包引用1次guava-testlib ? 11.0.1 最后更新于2012-01-09 被中央仓库Jar包引用0次guava-testlib ? 11.0 最后更新于2011-12-18 被中央仓库Jar包引用0次guava-testlib ? 11.0-rc1 最后更新于2011-12-14 被中央仓库Jar包引用0次guava-testlib ? 10.0.1 最后更新于2011-10-10 被中央仓库Jar包引用0次guava-testlib ? 10.0 最后更新于2011-09-28 被中央仓库Jar包引用2次guava-testlib ? 10.0-rc3 最后更新于2011-09-23 被中央仓库Jar包引用0次guava-testlib ? 10.0-rc2 最后更新于2011-09-19 被中央仓库Jar包引用0次guava-testlib ? 10.0-rc1 最后更新于2011-09-09 被中央仓库Jar包引用0次

com.google.guava/guava-base 共有1个版本，总共被引用了17次
被引用次数最多的版本是r03 ，其被引用次数为17 。
Guava Base contains core classes, utility methods, and services used by other parts of the Guava libraries.

guava-base ? r03 最后更新于2010-04-26 被中央仓库Jar包引用17次

com.google.guava/guava-annotations 共有1个版本，总共被引用了2次
被引用次数最多的版本是r03 ，其被引用次数为2 。
Guava annotations are used throughout the Guava libraries.

annotations

guava-annotations ? r03 最后更新于2010-04-26 被中央仓库Jar包引用2次

com.google.guava/guava-testlib-jdk5 共有8个版本，总共被引用了0次
被引用次数最多的版本是17.0 ，其被引用次数为0 。
Guava testlib is a set of java classes used for more convenient unit testing - particularly to assist the tests for Guava itself.

guava-testlib-jdk5 ? 17.0 最后更新于2014-04-22 被中央仓库Jar包引用0次guava-testlib-jdk5 ? 17.0-rc2 最后更新于2014-04-10 被中央仓库Jar包引用0次guava-testlib-jdk5 ? 17.0-rc1 最后更新于2014-04-08 被中央仓库Jar包引用0次guava-testlib-jdk5 ? 16.0 最后更新于2014-02-10 被中央仓库Jar包引用0次guava-testlib-jdk5 ? 16.0-rc1 最后更新于2014-01-31 被中央仓库Jar包引用0次guava-testlib-jdk5 ? 14.0.1 最后更新于2013-06-13 被中央仓库Jar包引用0次guava-testlib-jdk5 ? 14.0.1-rc1 最后更新于2013-04-24 被中央仓库Jar包引用0次guava-testlib-jdk5 ? 13.0 最后更新于2012-09-26 被中央仓库Jar包引用0次

com.google.guava/guava-bootstrap 共有10个版本，总共被引用了0次
被引用次数最多的版本是12.0-rc1 ，其被引用次数为0 。
ExecutorService's type parameters changed between JDK5 and JDK6 in a way that makes it impossible for our invokeAll/invokeAny methods to match both at compile time. This project builds a JDK6-like
 copy of ExecutorService (but with JDK5 compiler settings to ensure that it will work with JRE5 at runtime). This project's is then used in the bootstrap class path of Guava proper.

guava-bootstrap ? 12.0-rc1 最后更新于2012-03-30 被中央仓库Jar包引用0次guava-bootstrap ? 11.0.2 最后更新于2012-02-22 被中央仓库Jar包引用0次guava-bootstrap ? 11.0.1 最后更新于2012-01-09 被中央仓库Jar包引用0次guava-bootstrap ? 11.0 最后更新于2011-12-18 被中央仓库Jar包引用0次guava-bootstrap ? 11.0-rc1 最后更新于2011-12-14 被中央仓库Jar包引用0次guava-bootstrap ? 10.0.1 最后更新于2011-10-10 被中央仓库Jar包引用0次guava-bootstrap ? 10.0 最后更新于2011-09-28 被中央仓库Jar包引用0次guava-bootstrap ? 10.0-rc3 最后更新于2011-09-23 被中央仓库Jar包引用0次guava-bootstrap ? 10.0-rc2 最后更新于2011-09-19 被中央仓库Jar包引用0次guava-bootstrap ? 10.0-rc1 最后更新于2011-09-09 被中央仓库Jar包引用0次

com.google.guava/guava-tests 共有31个版本，总共被引用了0次
被引用次数最多的版本是17.0 ，其被引用次数为0 。
The unit tests for the Guava libraries - separated into a separate artifact to allow for the testlibs to depend on guava itself.

guava-tests ? 17.0 最后更新于2014-04-22 被中央仓库Jar包引用0次guava-tests ? 17.0-rc2 最后更新于2014-04-10 被中央仓库Jar包引用0次guava-tests ? 17.0-rc1 最后更新于2014-04-08 被中央仓库Jar包引用0次guava-tests ? 16.0.1 最后更新于2014-02-03 被中央仓库Jar包引用0次guava-tests ? 16.0 最后更新于2014-01-17 被中央仓库Jar包引用0次guava-tests ? 16.0-rc1 最后更新于2013-12-19 被中央仓库Jar包引用0次guava-tests ? 15.0 最后更新于2013-09-06 被中央仓库Jar包引用0次guava-tests ? 15.0-rc1 最后更新于2013-08-26 被中央仓库Jar包引用0次guava-tests ? 14.0.1 最后更新于2013-03-15 被中央仓库Jar包引用0次guava-tests ? 14.0 最后更新于2013-02-25 被中央仓库Jar包引用0次guava-tests ? 14.0-rc3 最后更新于2013-02-13 被中央仓库Jar包引用0次guava-tests ? 14.0-rc2 最后更新于2013-01-17 被中央仓库Jar包引用0次guava-tests ? 14.0-rc1 最后更新于2012-12-14 被中央仓库Jar包引用0次guava-tests ? 13.0.1 最后更新于2012-08-28 被中央仓库Jar包引用0次guava-tests ? 13.0 最后更新于2012-08-02 被中央仓库Jar包引用0次guava-tests ? 13.0-final 最后更新于2012-08-01 被中央仓库Jar包引用0次guava-tests ? 13.0-rc2 最后更新于2012-07-20 被中央仓库Jar包引用0次guava-tests ? 12.0.1 最后更新于2012-07-10 被中央仓库Jar包引用0次
描述： The unit tests for the Guava libraries - separated into a separate artifact to allow for the testlibs to depend on guava itself.
guava-tests ? 13.0-rc1 最后更新于2012-06-26 被中央仓库Jar包引用0次guava-tests ? 12.0 最后更新于2012-04-30 被中央仓库Jar包引用0次
描述： The unit tests for the Guava libraries - separated into a separate artifact to allow for the testlibs to depend on guava itself.
guava-tests ? 12.0-rc2 最后更新于2012-04-17 被中央仓库Jar包引用0次
描述： The unit tests for the Guava libraries - separated into a separate artifact to allow for the testlibs to depend on guava itself.
guava-tests ? 12.0-rc1 最后更新于2012-03-30 被中央仓库Jar包引用0次
描述： The unit tests for the Guava libraries - separated into a separate artifact to allow for the testlibs to depend on guava itself.
guava-tests ? 11.0.2 最后更新于2012-02-22 被中央仓库Jar包引用0次
描述： The unit tests for the Guava libraries - separated into a separate artifact to allow for the testlibs to depend on guava itself.
guava-tests ? 11.0.1 最后更新于2012-01-09 被中央仓库Jar包引用0次
描述： The unit tests for the Guava libraries - separated into a separate artifact to allow for the testlibs to depend on guava itself.
guava-tests ? 11.0 最后更新于2011-12-18 被中央仓库Jar包引用0次
描述： The unit tests for the Guava libraries - separated into a separate artifact to allow for the testlibs to depend on guava itself.
guava-tests ? 11.0-rc1 最后更新于2011-12-14 被中央仓库Jar包引用0次
描述： The unit tests for the Guava libraries - separated into a separate artifact to allow for the testlibs to depend on guava itself.
guava-tests ? 10.0.1 最后更新于2011-10-10 被中央仓库Jar包引用0次
描述： The unit tests for the Guava libraries - separated into a separate artifact to allow for the testlibs to depend on guava itself.
guava-tests ? 10.0 最后更新于2011-09-28 被中央仓库Jar包引用0次
描述： The unit tests for the Guava libraries - separated into a separate artifact to allow for the testlibs to depend on guava itself.
guava-tests ? 10.0-rc3 最后更新于2011-09-23 被中央仓库Jar包引用0次
描述： The unit tests for the Guava libraries - separated into a separate artifact to allow for the testlibs to depend on guava itself.
guava-tests ? 10.0-rc2 最后更新于2011-09-19 被中央仓库Jar包引用0次
描述： The unit tests for the Guava libraries - separated into a separate artifact to allow for the testlibs to depend on guava itself.
guava-tests ? 10.0-rc1 最后更新于2011-09-09 被中央仓库Jar包引用0次
描述： The unit tests for the Guava libraries - separated into a separate artifact to allow for the testlibs to depend on guava itself.


com.google.guava/guava-bootstrap-jdk5 共有8个版本，总共被引用了0次
被引用次数最多的版本是17.0 ，其被引用次数为0 。
ExecutorService's type parameters changed between JDK5 and JDK6 in a way that makes it impossible for our invokeAll/invokeAny methods to match both at compile time. This project builds a JDK6-like
 copy of ExecutorService (but with JDK5 compiler settings to ensure that it will work with JRE5 at runtime). It also builds a version of AbstractExecutorService that is equivalent to a JDK5 version but using the JDK6 type parameters for the invokeAll/invokeAny
 methods just as with ExecutorService. This project's is then used in the bootstrap class path of Guava proper.

guava-bootstrap-jdk5 ? 17.0 最后更新于2014-04-22 被中央仓库Jar包引用0次guava-bootstrap-jdk5 ? 17.0-rc2 最后更新于2014-04-10 被中央仓库Jar包引用0次guava-bootstrap-jdk5 ? 17.0-rc1 最后更新于2014-04-08 被中央仓库Jar包引用0次guava-bootstrap-jdk5 ? 16.0 最后更新于2014-02-10 被中央仓库Jar包引用0次guava-bootstrap-jdk5 ? 16.0-rc1 最后更新于2014-01-31 被中央仓库Jar包引用0次guava-bootstrap-jdk5 ? 14.0.1 最后更新于2013-06-13 被中央仓库Jar包引用0次
描述： ExecutorService's type parameters changed between JDK5 and JDK6 in a way that makes it impossible for our invokeAll/invokeAny methods to match both at compile time. This project builds a JDK6-like copy of ExecutorService
 (but with JDK5 compiler settings to ensure that it will work with JRE5 at runtime). This project's is then used in the bootstrap class path of Guava proper.
guava-bootstrap-jdk5 ? 14.0.1-rc1 最后更新于2013-04-24 被中央仓库Jar包引用0次
描述： ExecutorService's type parameters changed between JDK5 and JDK6 in a way that makes it impossible for our invokeAll/invokeAny methods to match both at compile time. This project builds a JDK6-like copy of ExecutorService
 (but with JDK5 compiler settings to ensure that it will work with JRE5 at runtime). This project's is then used in the bootstrap class path of Guava proper.
guava-bootstrap-jdk5 ? 13.0 最后更新于2012-09-26 被中央仓库Jar包引用0次
描述： ExecutorService's type parameters changed between JDK5 and JDK6 in a way that makes it impossible for our invokeAll/invokeAny methods to match both at compile time. This project builds a JDK6-like copy of ExecutorService
 (but with JDK5 compiler settings to ensure that it will work with JRE5 at runtime). This project's is then used in the bootstrap class path of Guava proper.


com.google.guava/guava-concurrent 共有1个版本，总共被引用了0次
被引用次数最多的版本是r03 ，其被引用次数为0 。
Guava Concurrency Libraries are an expanded set of services and types supporting advanced concurrent programming in Java.

guava-concurrent ? r03 最后更新于2010-04-26 被中央仓库Jar包引用0次

com.google.guava/guava-tests-jdk5 共有8个版本，总共被引用了0次
被引用次数最多的版本是17.0 ，其被引用次数为0 。
The unit tests for the Guava libraries - separated into a separate artifact to allow for the testlibs to depend on guava itself.

guava-tests-jdk5 ? 17.0 最后更新于2014-04-22 被中央仓库Jar包引用0次guava-tests-jdk5 ? 17.0-rc2 最后更新于2014-04-10 被中央仓库Jar包引用0次guava-tests-jdk5 ? 17.0-rc1 最后更新于2014-04-08 被中央仓库Jar包引用0次guava-tests-jdk5 ? 16.0 最后更新于2014-02-10 被中央仓库Jar包引用0次guava-tests-jdk5 ? 16.0-rc1 最后更新于2014-01-31 被中央仓库Jar包引用0次guava-tests-jdk5 ? 14.0.1 最后更新于2013-06-13 被中央仓库Jar包引用0次guava-tests-jdk5 ? 14.0.1-rc1 最后更新于2013-04-24 被中央仓库Jar包引用0次guava-tests-jdk5 ? 13.0 最后更新于2012-09-26 被中央仓库Jar包引用0次

com.google.guava/guava-primitives 共有1个版本，总共被引用了0次
被引用次数最多的版本是r03 ，其被引用次数为0 。
Guava is a suite of core and expanded libraries that include utility classes, google's collections, io classes, and much much more.

guava-primitives ? r03 最后更新于2010-04-26 被中央仓库Jar包引用0次


1. 在Maven的porn.xml 文件中添加dependency如下





[html] view
 plain copy






&lt;dependency&gt;  
    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;  
    &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;  
    &lt;version&gt;1.7.2&lt;/version&gt;  
&lt;/dependency&gt;  


之后就会添加三个包，








2. 之后在项目下添加log4j.properties

项目路径为：src/main/resources



log4j.properties





[html] view
 plain copy






#config root logger  
log4j.rootLogger = INFO,system.out  
log4j.appender.system.out=org.apache.log4j.ConsoleAppender  
log4j.appender.system.out.layout=org.apache.log4j.PatternLayout  
log4j.appender.system.out.layout.ConversionPattern=LogTest Logger--&gt;%5p{%F:%L}-%m%n  
  
#config this Project.file logger  
log4j.logger.thisProject.file=INFO,thisProject.file.out  
log4j.appender.thisProject.file.out=org.apache.log4j.DailyRollingFileAppender  
log4j.appender.thisProject.file.out.File=logContentFile.log  
log4j.appender.thisProject.file.out.layout=org.apache.log4j.PatternLayout
  




3. 在代码中添加





[java] view
 plain copy






private static final Logger logger = LoggerFactory.getLogger(LogTest.class);
  



如果要输出logger文件：





[plain] view
 plain copy






log4j.rootLogger=INFO,R,stdout    
    
log4j.appender.stdout=org.apache.log4j.ConsoleAppender    
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout  
log4j.appender.stdout.layout.ConversionPattern=Logger--&gt;%5p{%F:%L}-%m%n   
    
log4j.appender.R=org.apache.log4j.DailyRollingFileAppender    
log4j.appender.R.File=../logs/log  
log4j.appender.R.layout=org.apache.log4j.PatternLayout  
log4j.appender.R.layout.ConversionPattern=Logger--&gt;%5p{%F:%L}-%m%n   


下面是log4j.properties的配置信息，在此要感谢前辈提供的资源

#输出格式
#%m 输出代码中指定的消息
#%p 输出优先级，即DEBUG，INFO，WARN，ERROR，FATAL
#%r 输出自应用启动到输出该log信息耗费的毫秒数
#%c 输出所属的类目，通常就是所在类的全名
#%t 输出产生该日志事件的线程名
#%n 输出一个回车换行符，Windows平台为“\r\n”，Unix平台为“\n”
#%d 输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，比如：%d{yyyy MMM dd HH:mm:ss,SSS}，输出类似：2002年10月18日 22：10：28，921
#%l 输出日志事件的发生位置，包括类目名、发生的线程，以及在代码中的行数。举例：Testlog4.main(TestLog4.Java:10)

格式化例子：
log4j.appender.thisProject.file.out.layout.ConversionPattern=log4j--&gt;%d{yyyy MMM dd HH:mm:ss,SSS}%5p{%F\:%L}-%m%n

注意：
1.信息格式化的小知识
    这些参数中间可能会参杂一些数字比如：%5p它的意思就是在输出此参数之前加入多少个空格，还有就是里面的“\”的作用是转义字符

2.log4j.properties文件放置位置
    (1)在java project项目中，它放置的位置是在项目的根目录下而不是在项目的src目录下。
    (2)在javaweb项目中它放置的位置是在src目录下，因为这个时候tomcat会去默认的加载它的，不需要我们去手动的加载log4j的配置文件，只需要根据配置获取自己需要的logger实例即可,由此我们可以知道如果我们使用的不是tomcat容器的话，是不是需要自己手动加载或者至少要配置一下呢？比如使用Websphere等非apache服务器。

3.对于Java Web项目里面的日志的位置配置
    (1)如果是要指定日志文件的位置为D盘下的log.txt文件。
    log4j.appender.thisProject.file.out.File=d:\\log.txt
    (2)如果指定日志文件的位置为当前的tomcat的工作目录下的某个文件
    log4j.appender.thisProject.file.out.File=${catalina.home}/logs/logs_tomcat.log

4.log4j的加载机制

    log4j.properties加载机制？其实log4j.properties只是log4j的配置文件。程序启动时，log4j组件去读log4j.properties，和读取普通配置文件没多大区别。获取用户配置的一些log4j的属性值，调用想应该的方法为log4j属性设置。

    把log4j.properties当作一个struts.xml或者一个hibernate-cfg.xml就可以了。但不同的是，log4j不像struts和hibernate，它不是一个独立的组件,没法自己完成初始化，一般都是什么组件需要它
 就去初始化。比如，hibernate默认的日志组件就是log4j，在hibernate初始化的时候它会去初始化log4j。如果你没配置log4j.properties,hibernate会抛出异常，但还是可以正常初始化。



在SQL Server 中经常出现N''的语句，大写字母N作前缀的 N'xxx' ，是将其内容xxx作为 Unicode字符常量（双字节）。而没有N的 'yyy'， 是将yyy 作为字符常量（单字节）。

 

　　为了容易理解，以下使用示例作为分析：

SELECT @PageCurrent=@TopN1,
@sql=N'SELECT @n=@n-1,@s=CASE WHEN @n&lt;'+@TopN
+N' THEN @s+N'',''+QUOTENAME(RTRIM(CAST('+@FieldKey
+N' as varchar(8000))),N'''''''') ELSE N'''' END FROM '+@tbname

 

　　分析其中后两句，而且为了区别起见，将配对的'使用不同颜色来表示：　

一 第1个  N' THEN @S+N'',''+QUOTENAME(RTRIM(CAST('+@FieldKey  的Unicode
 （最远匹配）的内容为：
　THEN @S+N'',''+QUOTENAME(RTRIM(CAST(

 

　　继续分析其中的内容：   N'',''
　　(1) N'','' ：
 有大N开头，开始和结束的' ，解释其内容为Unicode 字符：','
　　(2) ',' ：   无大N开头，开始和结束的' ，起引号作用，其内容为字符串：,
　　(3) 最终内容为 逗号：,


二 第2个 N' as varchar(8000) ) ), N'''''''') ELSE N'''' END  FROM' +@tbname 的Unicode
 （最远匹配）的内容为：
　as varchar(8000) ) ), N'''''''') ELSE N'''' END  FROM

 

　　继续分析其中的内容： 
　2.1 N''''''''   (有8个')
　　(1)N'''''''' ：
 有大N开头，开始和结束的'，解释其内容为Unicode 字符：''''''
　　(2)'''''' ：   无大N开头，开始和结束的'，起引号作用，其内容为字符串：''''
　　(3) 最终内容为 4个单引号 ： ''''

　2.2 N''''   (有4个')
　　(1)N'''' ： 有大N开头，开始和结束的'，解释其内容为Unicode
 字符：''
　　(2)'' ：   无大N开头，开始和结束的'，起引号作用，其内容为字符串：空：
　　(3) 最终内容为 空 ：空

 

三 总结 SQL Server字符串，要从外向内(从开始和结尾的两端，向里分析)剥离分析：
　　有大N的'，解释其内容为Unicode 字符（双字节）。
　　无大N的'，起引号作用，其内容为字符串（单字节）。

　或者简单地说：
　　有大N的'，要去掉4个'(开始和结尾各2个')为其最终内容。
　　无大N的'，要去掉2个'(开始和结尾各1个')为其最终内容。


我们先回顾一下主流Java的垃圾回收器(HotSpot JVM)。本文是针对堆的垃圾回收展开讨论的。

堆被分解为较小的三个部分。具体分为：新生代、老年代、持久代。



绝大部分新生成的对象都放在Eden区，当Eden区将满，JVM会因申请不到内存，而触发Young GC ,进行Eden区+有对象的Survivor区(设为S0区)垃圾回收，把存活的对象用复制算法拷贝到一个空的Survivor(S1)中，此时Eden区被清空，另外一个Survivor S0也为空。下次触发Young GC回收Eden+S0，将存活对象拷贝到S1中。新生代垃圾回收简单、粗暴、高效。若发现Survivor区满了，则将这些对象拷贝到old区或者Survivor没满但某些对象足够Old,也拷贝到Old区(每次Young GC都会使Survivor区存活对象值+1，直到阈值)。 3.Old区也会进行垃圾收集(Young GC),发生一次 Major GC 至少伴随一次Young GC，一般比Young GC慢十倍以上。JVM在Old区申请不到内存，会进行Full GC。Old区使用一般采用Concurrent-Mark–Sweep策略回收内存。

总结：Java垃圾回收器是一种“自适应的、分代的、停止—复制、标记-清扫”式的垃圾回收器。

缺点：

GC过程中会出现STW(Stop-The-World)，若Old区对象太多，STW耗费大量时间。CMS收集器对CPU资源很敏感。CMS收集器无法处理浮动垃圾，可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生。CMS导致内存碎片问题。

G1收集器

在G1中，堆被划分成 许多个连续的区域(region)。每个区域大小相等，在1M~32M之间。JVM最多支持2000个区域，可推算G1能支持的最大内存为2000*32M=62.5G。区域(region)的大小在JVM初始化的时候决定，也可以用-XX:G1HeapReginSize设置。

在G1中没有物理上的Yong(Eden/Survivor)/Old Generation，它们是逻辑的，使用一些非连续的区域(Region)组成的。

新生代收集

G1的新生代收集跟ParNew类似，当新生代占用达到一定比例的时候，开始出发收集。





被圈起的绿色部分为新生代的区域(region)，经过Young GC后存活的对象被复制到一个或者多个区域空闲中，这些被填充的区域将是新的新生代；当新生代对象的年龄(逃逸过一次Young GC年龄增加１)已经达到某个阈值(ParNew默认15)，被复制到老年代的区域中。

回收过程是停顿的(STW,Stop-The-Word);回收完成之后根据Young GC的统计信息调整Eden和Survivor的大小，有助于合理利用内存，提高回收效率。

回收的过程多个回收线程并发收集。

老年代收集

和CMS类似，G1收集器收集老年代对象会有短暂停顿。

标记阶段，首先初始标记(Initial-Mark),这个阶段是停顿的(Stop the World Event)，并且会触发一次普通Mintor GC。对应GC log:GC pause (young) (inital-mark)Root Region Scanning，程序运行过程中会回收survivor区(存活到老年代)，这一过程必须在young GC之前完成。Concurrent Marking，在整个堆中进行并发标记(和应用程序并发执行)，此过程可能被young GC中断。在并发标记阶段，若发现区域对象中的所有对象都是垃圾，那个这个区域会被立即回收(图中打X)。同时，并发标记过程中，会计算每个区域的对象活性(区域中存活对象的比例)。Remark, 再标记，会有短暂停顿(STW)。再标记阶段是用来收集 并发标记阶段 产生新的垃圾(并发阶段和应用程序一同运行)；G1中采用了比CMS更快的初始快照算法:snapshot-at-the-beginning (SATB)。Copy/Clean up，多线程清除失活对象，会有STW。G1将回收区域的存活对象拷贝到新区域，清除Remember Sets，并发清空回收区域并把它返回到空闲区域链表中。复制/清除过程后。回收区域的活性对象已经被集中回收到深蓝色和深绿色区域。



关于Remembered Set概念：G1收集器中，Region之间的对象引用以及其他收集器中的新生代和老年代之间的对象引用是使用Remembered Set来避免扫描全堆。G1中每个Region都有一个与之对应的Remembered Set，虚拟机发现程序对Reference类型数据进行写操作时，会产生一个Write Barrier暂时中断写操作，检查Reference引用的对象是否处于不同的Region之间(在分代中例子中就是检查是否老年代中的对象引用了新生代的对象)，如果是便通过CardTable把相关引用信息记录到被引用对象所属的Region的Remembered
 Set中。当内存回收时，在GC根节点的枚举范围加入Remembered Set即可保证不对全局堆扫描也不会有遗漏。

G1虽然保留了CMS关于代的概念，但是代已经不是物理上连续区域，而是一个逻辑的概念。在标记过程中，每个区域的对象活性都被计算，在回收时候，就可以根据用户设置的停顿时间，选择活性较低的区域收集，这样既能保证垃圾回收，又能保证停顿时间，而且也不会降低太多的吞吐量。Remark阶段新算法的运用，以及收集过程中的压缩，都弥补了CMS不足。引用Oracle官网的一句话：“G1 is planned as the long term replacement for the Concurrent Mark-Sweep Collector
 (CMS)”。


1. HotSpot历史

    SUN的JDK版本从1.3.1开始运用HotSpot虚拟机， 2006年底开源，主要使用C++实现，JNI接口部分用C实现。
    HotSpot是较新的Java虚拟机，用来代替JIT(Just in Time)，可以大大提高Java运行的性能。 
    Java原先是把源代码编译为字节码在虚拟机执行，这样执行速度较慢。而HotSpot将常用的部分代码编译为本地(原生，native)代码，这样显着提高了性能。 
    HotSpot JVM 参数可以分为规则参数(standard options)和非规则参数(non-standard options)。 
    规则参数相对稳定，在JDK未来的版本里不会有太大的改动。 
    非规则参数则有因升级JDK而改动的可能。

    规则和非规则参数这里不做介绍了，网上资料很多。

 

2.HotSpot基础知识

    HotSpot包括一个解释器和两个编译器（client 和 server，二选一的），解释与编译混合执行模式，默认启动解释执行。

    编译器：java源代码被编译器编译成class文件（字节码），java字节码在运行时可以被动态编译（JIT）成本地代码(前提是解释与编译混合执行模式且虚拟机不是刚启动时)。

    解释器： 解释器用来解释class文件（字节码），java是解释语言（书上这么说的）。

    server启动慢，占用内存多，执行效率高，适用于服务器端应用；

    client启动快，占用内存小，执行效率没有server快，默认情况下不进行动态编译，适用于桌面应用程序。

    由-XX:+RewriteFrequentPairs参数控制  client模式默认关闭，server模式默认开启

    在jre安装目录下的lib/i386/jvm.cfg 文件下。

   

   java -version

   Java HotSpot(TM) Client VM (build 14.3-b01, mixed mode, sharing)

   mixed mode 解释与编译 混合的执行模式 默认使用这种模式

 

   java -Xint -version

   Java HotSpot(TM) Client VM (build 14.3-b01, interpreted mode, sharing)

   interpreted  纯解释模式 禁用JIT编译

 

   java -Xcomp -version

   Java HotSpot(TM) Client VM (build 14.3-b01, compiled mode, sharing)

   compiled  纯编译模式（如果方法无法编译，则回退到解释模式执行无法编译的方法）

   

3.动态编译

      动态编译(compile during run-time)，英文称Dynamic compilation；Just In Time也是这个意思。

      HotSpot对bytecode的编译不是在程序运行前编译的，而是在程序运行过程中编译的。
      HotSpot里运行着一个监视器（Profile Monitor），用来监视程序的运行状况。

      java字节码（class文件）是以解释的方式被加载到虚拟机中(默认启动时解释执行)。 程序运行过程中，那一部分运用频率大，那些对程序的性能影响重要。对程序运行效率影响大的代码，称为热点（hotspot），HotSpot会把这些热点动态地编译成机器码（native
 code），同时对机器码进行优化，从而提高运行效率。对那些较少运行的代码，HotSpot就不会把他们编译。

      HotSpot对字节码有三层处理：不编译(字节码加载到虚拟机中时的状态。也就是当虚拟机执行的时候再编译)，编译(把字节码编译成本地代码。虚拟机执行的时候已经编译好了，不要再编译了)，编译并优化（不但把字节码编译成本地代码，而且还进行了优化）。

       至于那些程序那些不编译，那些编译，那些优化，则是由监视器（Profile Monitor）决定。

 

4.为什么不静态编译？

    为什么字节码在装载到虚拟机之前就编译成本地代码？ 

    动态编译器也在许多方面比静态编译器优越。静态编译器通常很难准确预知程序运行过程中究竟什么部分最需要优化。

    函数调用都是很浪费系统时间的，因为有许多进栈出栈操作。因此有一种优化办法，就是把原来的函数调用，通过编译器的编译，改成非函数调用，把函数代码直接嵌到调用处，变成顺序执行。

    面向对象的语言支持多态，静态编译无效确定程序调用哪个方法，因为多态是在程序运行中确定调用哪个方法。


DBCC DROPCLEANBUFFERS:从缓冲池中删除所有缓存，清除缓冲区

在进行测试时，使用这个命令可以从SQLSERVER的数据缓存data cache(buffer)清除所有的测试数据，以保证测试的公正性。

需要注意的是这个命令只移走干净的缓存，不移走脏缓存。由于这个原因，在执行这个命令前，应该先执行CheckPoint，将所有脏的缓存写入磁盘，

这样在运行DBCC RROPCLEANBUFFERS 时，可以保证所有的数据缓存被清理，而不是其中的一部分。

 

DBCC CacheStats:显示存在于当前buffer Cache中的对象的信息，例如：hit rates，编译的对象和执行计划

 

DBCC ErrorLog :如果很少重启mssqlserver服务，那么服务器的日志(不是数据库事务日志)会增长得很快，而且打开和查看日志的速度也会很慢

使用这个命令，可以截断当前的服务器日志，主要是生成一个新的日志。可以考虑设置一个调度任务，每周执行这个命令自动截断服务器日志。

使用存储过程sp_cycle_errorlog也可以达到同样的目的


 

一、DBCC 帮助类命令

DBCC HELP('?') ：查询所有的DBCC命令  

DBCC HELP('命令') ：查询指定的DBCC命令的语法说明 

DBCC USEROPTIONS ：返回当前连接的活动(设置)的SET选项


 

二、DBCC 检查验证类命令 

DBCC CHECKALLOC('数据库名称') ：检查指定数据库的磁盘空间分配结构的一致性

DBCC CHECKCATALOG ('数据库名称') ：检查指定数据库的系统表内和系统表间的一致性

DBCC CHECKCONSTRAINTS ('tablename') ：检查指定表上的指定约束或所有约束的完整性

DBCC CHECKDB ：检查数据库中的所有对象的分配和结构完整性 

DBCC CHECKFILEGROUP ：检查指定文件组中所有表在当前数据库中的分配和结构完整性

DBCC CHECKTABLE ：检查指定表或索引视图的数据、索引及test、ntest和image页的完整性

DBCC CHECKIDENT ：如果存在大量数据删除，考虑在删除后，使用 dbcc checkident 重置一下自增值

http://social.msdn.microsoft.com/Forums/zh-CN/sqlserverzhchs/thread/8fa3e3a8-2ff2-4a68-be3e-92e76c380ef9/

检查指定的当前标识值

DBCC SQLPERF(UMSSTATS)：最关键的一个参考数据num runnable：表明当前有多少个线程再等待运行，如果大于等于2,考虑CPU达到瓶颈

Scheduler ID:当前机器有多少个逻辑CPU就有多少个Scheduler ID，具体怎麽看可以看一下我的这篇文章

SQLSERVER独特的任务调度算法"SQLOS"


 

三、DBCC 维护类命令 

DBCC CLEANTABLE ('db_name','table_name') ：回收Alter table drop column语句删除可变长度列或text

DBCC DBREINDEX ：重建指定数据库的一个或多个索引 跟ALTER INDEX REBUILD差不多

DBCC INDEXDEFRAG：对表或视图上的索引和非聚集索引进行碎片整理

DBCC PINTABLE (db_id,object_id) ：将表数据驻留在内存中

查看哪些表驻留在内存的方法是：0：没有驻留 ，1：驻留

1 USE [GPOSDB]
2 GO
3 SELECT  OBJECTPROPERTY(OBJECT_ID('dbo.SystemPara'), 'tableispinned') 


DBCC UNPINTABLE (db_id,object_id) ：撤消驻留在内存中的表

DBCC SHRINKDATABASE(db_id,int) ：收缩指定数据库的数据文件和日志文件大小 

DBCC SHRINKFILE(file_name,int)：收缩相关数据库的指定数据文件和日志文件大小


 

四、DBCC 性能调节命令

DBCC dllname(FREE) ：在内存中卸载指定的扩展过程动态链接库（dll)

sp_helpextendedproc 查看加载的扩展PROC 

DBCC DROPCLEANBUFFERS ：从缓冲池中删除所有缓冲区

DBCC FREEPROCCACHE ：从执行计划缓冲区删除所有缓存的执行计划

DBCC INPUTBUFFER ：显示从客户机发送到服务器的最后一个语句

DBCC OPENTRAN (db_name) ：查询某个数据库执行时间最久的事务，由哪个程序拥有

DBCC SHOW_STATISTICS ：显示指定表上的指定目标的当前统计信息分布

DBCC SHOWCONTIG ：显示指定表的数据和索引的碎片信息

DBCC SQLPERF (logspace) ：查看各个DB的日志情况

(iostats) 查看IO情况

(threads) 查看线程消耗情况

返回多种有用的统计信息 

DBCC CACHESTATS ：显示SQL Server 2000内存的统计信息

DBCC CURSORSTATS ：显示SQL Server 2000游标的统计信息

DBCC MEMORYSTATS ：显示SQL Server 2000内存是如何细分的

DBCC SQLMGRSTATS ：显示缓冲区中先读和预读准备的SQL语句


 

五、DBCC 未公开的命令

DBCC ERRLOG ：初始化SQL Server 2000的错误日志文件

DBCC FLUSHPROCINDB (db_id) ：清除SQL Server 2005服务器内存中的某个数据库的存储过程缓存内容 

DBCC BUFFER (db_name,object_name,int(缓冲区个数)) ：显示缓冲区的头部信息和页面信息

DBCC DBINFO (db_name) ：显示数据库的结构信息 

DBCC DBTABLE ：显示管理数据的表(数据字典)信息 

DBCC IND (db_name,table_name,index_id) ：查看某个索引使用的页面信息 

DBCC REBUILDLOG ：重建SQL Server 2000事务日志文件

DBCC LOG (db_name,3) (-1~4) ：查看某个数据库的事物日志信息 显示格式可以为：-1，0，1，2，3，4 每个数字代表不同的格式

DBCC PAGE ：查看某个数据库数据页面信息

DBCC PROCBUF ：显示过程缓冲池中的缓冲区头和存储过程头

DBCC PRTIPAGE ：查看某个索引页面的每行指向的页面号

DBCC PSS (user,spid,1) ：显示当前连接到SQL Server 2000服务器的进程信息

DBCC RESOURCE ：显示服务器当前使用的资源情况

DBCC TAB (db_id,object_id) ：显示数据页面的结构





六、DBCC跟踪标记

跟踪标记用于临时设置服务器的特定特征或关闭特定行为，常用于诊断性能问题或调试存储过程或复杂的系统

DBCC TRACEON (3604) ：打开跟踪标记

DBCC TRACEOFF ：关闭跟踪标记

DBCC TRACESTATS ：查看跟踪标记状态





七、官方使用DBCC的建议

1、在系统使用率较低时运行 CHECKDB。

2、请确保未同时执行其它磁盘 I/O 操作，例如磁盘备份。

3、将 tempdb 放到单独的磁盘系统或快速磁盘子系统中。

4、允许 tempdb 在驱动器上有足够的扩展空间。 使用带有 ESTIMATE ONLY 的 DBCC 估计 tempdb 将需要多少空间。

5、避免运行占用大量 CPU 的查询或批处理作业。

6、在 DBCC 命令运行时，减少活动事务。

7、使用 NO_INFOMSGS 选项减少一些信息的输出。

8、考虑使用带有 PHYSICAL_ONLY 选项的 DBCC CHECKDB 来检查页和记录的物理结构。

PHYSICAL_ONLY 选项：只检查物理错误，不检查逻辑错误

物理错误比逻辑出更严重，因为物理错误一般SQLSERVER都不能修复的，而逻辑错误大部分SQLSERVER都可以修复


Git常用操作命令：

1) 远程仓库相关命令

检出仓库：$ git clone git://github.com/xx/xx.git

查看远程仓库：$ git remote -v

添加远程仓库：$ git remote add [name] [url]

删除远程仓库：$ git remote rm [name]

修改远程仓库：$ git remote set-url --push[name][newUrl]

拉取远程仓库：$ git pull [remoteName] [localBranchName]

推送远程仓库：$ git push [remoteName] [localBranchName]

 

2）分支(branch)操作相关命令

查看本地分支：$ git branch

查看远程分支：$ git branch -r

创建本地分支：$ git branch [name] ----注意新分支创建后不会自动切换为当前分支

切换分支：$ git checkout [name]

创建新分支并立即切换到新分支：$ git checkout -b [name]

删除分支：$ git branch -d [name] ---- -d选项只能删除已经参与了合并的分支，对于未有合并的分支是无法删除的。如果想强制删除一个分支，可以使用-D选项

合并分支：$ git merge [name] ----将名称为[name]的分支与当前分支合并

创建远程分支(本地分支push到远程)：$ git
 push origin [name]

删除远程分支：$ git push origin :heads/[name]

我从master分支创建了一个issue5560分支，做了一些修改后，使用git push origin master提交，但是显示的结果却是'Everything up-to-date'，发生问题的原因是git
 push origin master 在没有track远程分支的本地分支中默认提交的master分支，因为master分支默认指向了origin master 分支，这里要使用git push origin issue5560：master 就可以把issue5560推送到远程的master分支了。
    如果想把本地的某个分支test提交到远程仓库，并作为远程仓库的master分支，或者作为另外一个名叫test的分支，那么可以这么做。

$ git push origin test:master         // 提交本地test分支作为远程的master分支 //好像只写这一句，远程的github就会自动创建一个test分支
$ git push origin test:test              // 提交本地test分支作为远程的test分支

如果想删除远程的分支呢？类似于上面，如果:左边的分支为空，那么将删除:右边的远程的分支。

$ git push origin :test              // 刚提交到远程的test将被删除，但是本地还会保存的，不用担心

3）版本(tag)操作相关命令

查看版本：$ git tag

创建版本：$ git tag [name]

删除版本：$ git tag -d [name]

查看远程版本：$ git tag -r

创建远程版本(本地版本push到远程)：$ git
 push origin [name]

删除远程版本：$ git push origin :refs/tags/[name]

 

4) 子模块(submodule)相关操作命令

添加子模块：$ git submodule add [url] [path]

如：$ git submodule add git://github.com/soberh/ui-libs.git src/main/webapp/ui-libs

初始化子模块：$ git submodule init ----只在首次检出仓库时运行一次就行

更新子模块：$ git submodule update ----每次更新或切换分支后都需要运行一下

删除子模块：（分4步走哦）

1)$ git rm --cached [path]

2) 编辑“.gitmodules”文件，将子模块的相关配置节点删除掉

3) 编辑“.git/config”文件，将子模块的相关配置节点删除掉

4) 手动删除子模块残留的目录

 

5）忽略一些文件、文件夹不提交

在仓库根目录下创建名称为“.gitignore”的文件，写入不需要的文件夹名或文件，每个元素占一行即可，如

target

bin

*.db

 

 


git操作-删除文件



git删除文件
rm add2.txt
git rm add2.txt
git commit -m "rm test"
git push web
 
-----------at server
cd /var/www/foo.git;sudo
 git update-server-info
 
------------检查删除效果
cd;rm foo3 -rf;git clone http://[某ip]/foo.git foo3
 
------------更新已经存在的local code
cd;cd foo2
git remote add web [某user]@[某ip]:/var/www/foo.git/
git pull web master




DBCC PAGE命令用于查询一个页面的内部存储结构信息,该命令有4个参数，前3个参数必须指定，语法如下：
DBCC PAGE ({dbid | dbname}, filenum, pagenum[, printopt])

需要说明的是必须打开3604跟踪标志，否则DBCC PAGE命名不返还信息到客户端。第一个参数是数据库名或数据库ID
第二个参数指定文件号
第二个参数指定页号
Printopt参数可选; 可以使用以下值:
0 默认值; 输出buffer header 和 page header信息
1 输出 buffer header, page header, 分别输出每行信息, 行偏移表
2 输出 buffer header, page header, 整页数据,  行偏移表
3 输出 buffer header, page header, 别输出每行信息, 行偏移表; 分别列出每列的值


DBCC IND 命令用于查询一个存储对象的内部存储结构信息，该命令有4个参数, 前3个参数必须指定。语法如下：

DBCC IND ( { 'dbname' | dbid }, { 'objname' | objid },{ nonclustered indid | 1 | 0 | -1 | -2 } [, partition_number] )

第一个参数是数据库名或数据库ID。
第二个参数是数据库中的对象名或对象ID，对象可以是表或者索引视图。
第三个参数是一个非聚集索引ID或者 1, 0, 1, or 2. 值的含义：
 0: 只显示对象的in-row data页和 in-row IAM 页。
 1: 显示对象的全部页, 包含IAM 页, in-row数据页, LOB 数据页row-overflow 数据页 . 如果请求的对象含有聚集所以则索引页也包括。
 -1: 显示全部IAM页,数据页, 索引页 也包括 LOB 和row-overflow 数据页。
 -2: 显示全部IAM页。
 Nonclustered index ID:显示索引的全部 IAM页, data页和索引页，包含LOB和 row-overflow数据页。

为了兼容sql server 2000,第四个参数是可选的,该参数用于指定一个分区号.如果不给定值或者给定0, 则显示全部分区数据。

和DBCC PAGE不同的是, SQL Server运行DBCC IND不需要开启3604跟踪标志.

DBCC IND命令输出列的含义：
PageFID: 文件ID
PagePID: PageID
IAMFID: IAM页所在的文件ID
IAMPID: IAM页所在的PageID
ObjectID: 对象ID
IndexID: 索引ID
PartitionNumber: 表或索引的分区号
PartitionID ID: 数据库范围内唯一的表或索引的分区ID
iam_chain_type： 页面所属的分配单元类型: in-row data, row-overflow data, or LOB data
PageType: 1 = data page, 2 = index page, 3 = LOB_MIXED_PAGE, 4 =LOB_TREE_PAGE, 10 = IAM page
IndexLevel:索引级别; 0 表示叶级
NextPageFID 当前级别的后一页的文件ID
NextPagePID 当前级别的后一页的PageID
PrevPageFID 当前级别的前一页的文件ID
PrevPagePID 当前级别的前一页的PageID


以前我们在写sql的时候，最怕的一件事情就是sql莫名奇妙的超级慢，慢的是出去转一圈回来，那个小球还在一直转。。。这个着急也只有当事人才明白，后来听说有个什么“评估执行计划“，后来的后来才明白应该避免表扫描。。。

一：表扫描

1.现象

　　”表扫描“听起来很简单，不就是一行一行的扫嘛，你要说”执行计划”的话，我也会玩，为了更可观，我build一个表，再插入三行数据，如下图：



 

上面的Person我是一个索引都没建，然后where一下，看看表扫描是啥样的？？？

 

 

   果然是看到了万恶的“表扫描”三个字，既然是万恶的东西，我们一定要深刻了解下，然后我们才可以怎么去想办法避免它。。。所以我们一定要理解到本

质，那问题来了，它到底是怎么扫的呢？？？怎么破呢？这个还必须得从数据页说起。。。

 

二： 深刻理解表扫描

1：数据页

　   这个学sqlserver的没有理由说不知道，我们的记录都是以数据页形式存储的，而且还应该知道数据页的大小是8k。。。。那数据页在哪里？我可以

让你眼见为实。



乍一看我画了好多，千万不要怕，不要以为画的多，就以为高深了。。。我简单的剖析下。

&lt;1&gt;:dbcc ind 命令

　你要是想看数据页的相关情况，sqlserver还真提供了专用命令dbcc 满足你，你可能会问sqlserver中有提供ind命令的参数吗？告诉你吧，还真有

的，不过这个要开启2588跟踪，就像下面这样。



  &lt;2&gt;：PageFID,PagePID,IAMFID

　　刚才也说了，数据页有很多种，默认说的都是表数据页，其实还有IAM数据页，没什么稀奇的，IAM就是用来跟踪表数据页的，所以上面的图中，

IAMFID字段为Null的记录就是IAM页，下面的PagePID=78的，就是表数据页。

 

2.查看数据页

  为避免大家糊涂了，我先还是说说数据页内部结构大概是个什么样子，好让大家有个整体印象。



　从图中可以看到，在数据页的尾部是有很多槽位的，这些槽位指向了Data区域中一条条实际记录的地址，所以说表扫描，其实就是扫这些Slot槽位，

还是拿上面的Person表中的三条记录来说，他们都是保存在78号数据页中，现在出于好奇心把78号数据页导出来，说干就干。。。。很简单，你需

要做两件事情：

&lt;1&gt;开启3604跟踪： dbcc traceon(3604)

&lt;2&gt;使用dbcc page 命令导出1号文件下面的78号数据页（pageFID:pagePID）=(1:78)，就像下面这样。。。

 

数据页头（PAGE HEADER）：

 

数据内容（Page Data)： 

 

数据槽位(Page Slot)：

 

 

有没有看到上面（0,1,2）三个槽位，并且都有相应的偏移地址(0x7e,0x92,0xba），这个地址就指向了Data区域实际记录的偏移地址。


一：那些系统视图

1. 系统视图是干什么呢？

　　从名字上看就知道，系统视图嘛？猜的不错的话，就是存放一些sqlserver系统的一些信息，很好，恭喜你，答对了。

 

2. 都定义在哪呢？

　  为了让你眼见为实，下面截图看看，从截图中你可以看到，不管是“系统数据库”还是“用户数据库”都是有这些系统视图的，而且一眼扫下去发

现连名字都一样。





 

3.看看这些系统视图都能带给我什么福利？

   Q1：我在维护一个系统的时候，我只知道有一个数据库中，有一个表的字段叫 “state”，但我忘了是定义在那张表中？我该如

         何找出来？

　A1： 这个简单，在sqlserver里面提供了一个系统视图叫“INFORMATION_SCHEMA.COLUMNS”，下面我们截图看看。



　   从这个系统视图名字中的这个SCHEMA这个单词可知，原来是一个保存表架构的视图，而且还有这个字段的“排位”，“默认值”这些特性，泥煤，

是不是有一种很爽的感觉？？？

 

  Q2:我在C#代码中看到了一个存储过程名"CategoryInsert",我想看它的源码，但是我的table中存储过程有几千个，总不能让我

　　 一个个的去找吧，，，拜托在系统视图中可有快捷的方法查看？

  A2：so easy。。。告诉你吧，只有你想不到的，没有系统视图做不到，不就一个简简单单的看存储过程代码么？

　　  sys.sql_modules就可以帮你实现。



 

Q3：这种方法好是好，但是copy的definition字段是没有格式化的。。。。大哥，上千行的sql哦。。。我特别想格式化的输

　　 出怎么办呀？谢谢了。

A3：确实如你所说，格式化输出的话，系统View只能帮你到这了，不过天无绝人之路，你可以使用系统存储过程，里面有一个

　　神奇的sp_helptext，可以祝你实现梦想，不用谢。

　　

　　

二：对系统视图的一些思考

　　在上面的代码中，我演示了两个系统view，一个proc给我们带来的福利，那么仔细看一看，你就会有两个疑惑。。。。

 

1：系统View在哪定义的？

　　这个问题问的真好，从文章开头我们就知道，我的用户库MYPETSHOP是有很多系统view的，但是我真的没有定义这些view呀，老天可以

给我作证，那问题就很神秘了，system view到底从何而来？这个问题你也只有问sqlserver团队了，他们将system view都放入了一个隐藏

的resource数据库，那这个数据库在哪呢？我给你找到。



 

找到了之后，我现在继续附加进来，如果你够聪明的话，你不能直接加载它，否则会报进程正在使用中，原因我想你也知道。

 



 

解决方法也很简单，我们做一份copy到E盘。然后附加这个copy就好了。



 

既然附加进来了，我现在的感觉就是迫不及待的去看一看，细心的你通过下面的截图，我想你应该明白了些什么，这些view并不是在”系统视图“

文件夹下面的，而是正真的作为用户视图。。。对不对。。。

 



 

2：系统view的数据源在何处？

    这个也是很经典的问题，既然是view，我想大家都明白，其实它就是虚表的意思，既然是虚表，那基础表在何处？带着这个问题我来翻一下

我的MYPETSHOP数据库。



 

可以看到，上面的系统基表空空如也，黄鹤一去不复返，白云千载空悠悠。。。那更大的疑问来了，如果连基础表都没有，那在这个DB中的

system view到底是查谁呢？这不是大忽悠么？？？但是事实是真的没有吗？因为你没看到不代表真的没有，可以继续用system view来祝我

们一臂之力，接下来用sys.objects一探究竟。。。



此处以sqlserver为示例做演示。


大多教科书和前辈们都说状态少的字段不要建索引，由此带来的开销还不如不建索引，但是这句话有多少人真的知道，或者说有多少人真的对此有比较深刻的理解，而不是听别人道听途说。这样记得快，忘记的也不慢。这篇我来分析一下这句话到底有几个意思。

 

一：现象

　 首先我们还是用测试数据来发现问题，我先建立一个Person，有5个字段，建表sql如下：


DROP TABLE dbo.Person

CREATE TABLE Person(ID INT PRIMARY KEY IDENTITY,NAME VARCHAR(900),Age INT,Email VARCHAR(20),isMan INT )

-- 在isMan字段创建非聚集索引（0：女 1：男）
CREATE INDEX idx_isMan ON dbo.Person(isMan)

DECLARE @ch AS INT=0

WHILE @ch&lt;=100000
BEGIN
    INSERT INTO dbo.Person(NAME,Age,Email,isMan) 
    VALUES
    (
      REPLICATE(CHAR(@ch),50),
      @ch,
      CAST(CAST(RAND()*1000000000 AS INT) AS VARCHAR(10))+'qq.com',
      @ch%2
    )
    SET @ch=@ch+1
END



通过上面的sql可以发现表中有5个字段，ID为聚集索引，isMan为非聚集索引，isMan也就是两种状态（0,1），并且插入10w条记录，截图如下：



 

 

sql都做完了，接下来要做的事情就是查询下： isMan=1的记录，如下图：



 

    哥明明是在isMan上做数据检索的，怎么就变成 “聚集索引扫描”了？这他么的什么意思嘛，居然不走我的“idx_isMan”索引，

却走他么的“聚集索引(PK__Person__3214EC276EF57B66)”。。同时也看到上面的”逻辑读取”为521。。说明在内存中走了521个数据页。

但是我不服呀。。。我一定要让执行计划走我的索引。。。办法就是强制指定。。。如下图。





看到上面的图，你是不是已经疯了。。。老子才捞5w的数据，你给我走了10w多次数据页。。。这么说1条记录要走两个数据页。。。而扫描聚集

索引才走521个数据页，相差200倍。。。难怪执行计划打死也不走“idx_isMan”这条索引。。。要是这样走了人家还不拿刀捅了sqlserver么？？？

 

二：分析原因

　　现在很生气，整个人都不好了，为什么会这样？为了找出问题，我们还得看数据页。

1 DBCC TRACEON(3604,2588)
2 DBCC IND(Ctrip,Person,-1)




通过上面的三个图，大概可以看到，10w条数据用了697数据页，其中聚集索引有521个，非聚集索引为176个，这也说明了上面的”聚集索引扫描“走

遍了它自己所有的数据页来才捞出数据，同时还发现这两个索引都有一个共同特征就是，只有一个根节点(indexLevel=1）和无数个（indexLevel=0）

叶子节点，然后我脑子里面就有一幅图出来了。。。

 



上面就是我构思出来的图，这个专业一点的名字叫做书签查找。。。我们通过建立”idx_isMan“索引后，就会构建右半图的B树结构，其中索引记录

会存放两个值，一个是索引值isMan和一个聚集索引值ID，如果你不相信的话，可以通过DBCC Page去探索"idx_isMan"的索引页，你也可以通过

DBCC SHOW_STATISTICS 去查看，如图：



然后引擎通过“idx_isMan“扫描后，拿到了key值，但是非常可惜，我是select * 的，所以必须还要喷出记录中的Name，Emai等l字段，但是

”index_isMan"中并没有保存这几个字段，所以必须通过key去”聚集索引“的B树中去找。。。最后通过”聚集索引“的B树找到了目标记录，这也

就是所谓的执行计划中的”键查找“，然后喷出”Name，Email“等字段。。。。问题就在这里。。。因为我这样来回的蹦跶蹦跶。。。造成了找出

完整的一个记录，需要蹦跶2-3次数据页。。。具体的寻找记录，可参考图中的”紫色线条“，最后也就造成了10w多次蹦跶。。。

 

三：启示

     那这个例子给我们什么启示呢？？？仔细想想你就知道。。。使用非聚集索引，千万不要捞取过多的数据。。。因为过多的数据会造成在多个

B树中来回的蹦跶。。。想要做到捞取数据较少，就必须在高唯一性的字段上建立索引，这样的话在非聚集索引B树中符合的数据相对较少，也就

减少了我蹦跶到”主键索引“的B树次数。。。这样的话来回蹦跶的次数远远比”聚集索引“扫描来的实惠，对不对。。。

 

所以结论出来了：必须在唯一性较高的字段上建立非聚集索引。


量子组合器是我们设计量子处理器的图形用户界面。那些熟悉量子计算的人可能用定义良好的逻辑门和测量值库作为一个工具构建量子电路来识别这个组合器。对于不熟悉的人，我们将会解释其中一些关键部分。
当你第一次点击上面的“组合器”按钮时，你将要求决定你是愿意运行一个理想的量子处理器还是一个真实的量子处理器。这是指系统的拓扑结构。在理想处理器中，逻辑门将放置在任何位置，然而在真实处理器中，设定的拓扑是当前运行在我们实验室的物理装置（是为了约束一些双量子开关电路的可用性）。

一旦你在“组合器”键上，你就可以开始制造你自己的量子电路。我们这样描述量子积分，因为它某些方面类似于乐谱。时间的推移从左至右，每一行代表一个量子位（以及随着时间的推移发生在量子位上的变化）。每个量子位有不同的频率，就像一个不同的音符。量子逻辑门为代表的方盒子，扮演一个频率不同的持续时间，振幅和相位表示。这些被称为单量子比特门。用竖线将两个量子位连接在一起的逻辑门叫做CNOT逻辑门；这两个量子比特门的功能类似于常规数字逻辑的异或门。量子位的固点把CNOT逻辑门控制反转量子位在结束状态的时候的逻辑门(因此控制NOT或CNOT)。一些逻辑门，就如CNOT，有硬件限制。允许连接设置下面的示意图中定义设备位于量子组合器,以及最近校准设备参数。

量子组合器库（位于量子位下面的穿孔）包含四种类的逻辑门，各由自己的颜色表示。点击右边栏的帮助按钮提供所有不同逻辑门的快速概括。第一类逻辑门（黄色）代表量子位空闲操作一段时间等于单量子位逻辑门持续时间。第二类逻辑门（绿色）代表一组称为圣保利运营商，代表跳位相位（是一个典型的NOT），翻转一组和组合为翻转和相位翻转。第三类（蓝色）表示克利福逻辑门，其中包括H,S，和产生量子叠加的逻辑门，与所有重要的CNOT双量子比特门纠缠的必要条件。最后一类（橙色）代表普遍控制所需的逻辑门。

量子算法（电路）开始于准备定义良好的量子位状态（这里的基态|0&gt;，是我们为您自动完成的），然后一次执行一系列一和二量子位，后跟一个量子位元的量具。量具被一个粉红色的盒子装饰着。有两种可选择的量具：标准的量具是一个简单的Z轴投影，另一种是布洛赫量具，是布洛赫球体投影显示最后一个量子位状态被投射在X、Y和Z轴。测量后，量子位回归传统态（为0或1，但不会有量子叠加态），这是由测量操作之后出现的双线。所有这些元素将变得更清楚当你看完这个用户指南后。
为了使用这个组合器，简单的将逻辑盒子放进量子位穿孔的地方。双击框删除,或者将他们拖到垃圾桶。对于CNOT逻辑门，拖到穿孔处,首先表明目标量子位,然后再次单击控制量子位。请注意,一旦你标注量具,你不能按照随后的逻辑门,因为信息在那时候已经成为传统的信息了。
加载量子得分并尝试模拟它,看看它是怎样的,或开始创作自己的量子组合器!







一：从数据页角度看问题

1. 做两个表，插入两条数据，在test1上做复合索引，在test2上做include索引，如下图：


 1 -- 在test1表中插入2条记录
 2 CREATE TABLE test1(ID int,Name CHAR(5),Email CHAR(10))
 3 INSERT INTO test1 VALUES(1,'aaaaa','111@qq.com')
 4 INSERT INTO test1 VALUES(2,'bbbbb','222@qq.com')
 5 CREATE INDEX idx_test1 ON dbo.test1(Name,Email)
 6 
 7 -- 在test2表中插入2条记录
 8 CREATE TABLE test2(ID int,Name CHAR(5),Email CHAR(10))
 9 INSERT INTO test2 VALUES(1,'aaaaa','111@qq.com')
10 INSERT INTO test2 VALUES(2,'bbbbb','222@qq.com')
11 CREATE INDEX idx_test2 ON dbo.test2(Name) INCLUDE(Email)



 

2. 然后通过DBCC 命令查看数据页记录

&lt;1&gt; 先来看看test1表中各个槽位的信息

1 DBCC TRACEON(2588,3604)
2 DBCC IND(Ctrip,test1,-1)
3 DBCC PAGE(Ctrip,1,194,1) 



 1 Slot 0, Offset 0x60, Length 27, DumpStyle BYTE
 2 
 3 Record Type = INDEX_RECORD           Record Attributes =  NULL_BITMAP     Record Size = 27
 4 
 5 Memory Dump @0x000000000FB0A060
 6 
 7 0000000000000000:   16616161 61613131 31407171 2e636f6d ?.aaaaa111@qq.com 
 8 0000000000000010:   c0000000 01000000 030000?????????????...........      
 9 
10 Slot 1, Offset 0x7b, Length 27, DumpStyle BYTE
11 
12 Record Type = INDEX_RECORD           Record Attributes =  NULL_BITMAP     Record Size = 27
13 
14 Memory Dump @0x000000000FB0A07B
15 
16 0000000000000000:   16626262 62623232 32407171 2e636f6d ?.bbbbb222@qq.com 
17 0000000000000010:   c0000000 01000100 030000?????????????...........      
18 
19 OFFSET TABLE:
20 
21 Row - Offset                         
22 1 (0x1) - 123 (0x7b)                 
23 0 (0x0) - 96 (0x60)            



 

&lt;2&gt; 再来看看test2表中各个槽位信息

1 DBCC TRACEON(2588,3604)
2 DBCC IND(Ctrip,test2,-1)
3 DBCC PAGE(Ctrip,1,207,1)



 1 Slot 0, Offset 0x60, Length 27, DumpStyle BYTE
 2 
 3 Record Type = INDEX_RECORD           Record Attributes =  NULL_BITMAP     Record Size = 27
 4 
 5 Memory Dump @0x000000000DFCA060
 6 
 7 0000000000000000:   16616161 6161c400 00000100 00003131 ?.aaaaa........11 
 8 0000000000000010:   31407171 2e636f6d 030000?????????????1@qq.com...      
 9 
10 Slot 1, Offset 0x7b, Length 27, DumpStyle BYTE
11 
12 Record Type = INDEX_RECORD           Record Attributes =  NULL_BITMAP     Record Size = 27
13 
14 Memory Dump @0x000000000DFCA07B
15 
16 0000000000000000:   16626262 6262c400 00000100 01003232 ?.bbbbb........22 
17 0000000000000010:   32407171 2e636f6d 030000?????????????2@qq.com...      
18 
19 OFFSET TABLE:
20 
21 Row - Offset                         
22 1 (0x1) - 123 (0x7b)                 
23 0 (0x0) - 96 (0x60) 



 

&lt;3&gt; 从test1和test2的数据页来看，都是有两个slot槽位，然后我们把test1和test2的slot0槽位拿出来对比下，是不是就知道两者大概有什么区别了。

test1のslot0 

1 0000000000000000:   16616161 61613131 31407171 2e636f6d ?.aaaaa111@qq.com 
2 0000000000000010:   c0000000 01000000 030000?????????????...........    


test2のslot0 

1 0000000000000000:   16616161 6161c400 00000100 00003131 ?.aaaaa........11 
2 0000000000000010:   31407171 2e636f6d 030000?????????????1@qq.com...     


下面我仔细解剖下两表中的slot内容：

 16   6161616161   3131314071712e636f6d  c0000000 0100 0000  0300    00

16:                            　　这个是索引记录的系统头数据。

6161616161:             　　转换成十进制就是9797979797,也就是字符的aaaaa。

3131314071712e636f6d:  这个我想你也懂，也就是111@qq.com。

c000000010000000:        因为我们是堆表，所以这个就是表的RowID，转化为十进制就是： 192:1:0。

0300：                            这个表示表中的记录数，也就是3条记录。

 

如果你对上面的讲解明白了，那我们继续看看test2のslot0，如果你仔细的话，你会看到在test2中，111qq.com是在记录的最后。。。那这说明什

么问题呢？？？如果你对记录比较熟悉的话，你就知道，其实记录中的变长字段值一般都是放在记录的尾部。。。好处就是可以做到“行溢出”。也就是

可以超过索引的900长度限制。。。而复合索引却无法做到。。。如果你不信我可以做个例子，将name和email的长度设为定长500。



 

而include索引却可以顺利通过。。。。。



微软的Windows 10一经发布便获得外界盛赞。这款操作系统几乎解决了Windows 8身上的所有大问题，它不仅速度更快、运行更流畅、用户界面也更加友好。但Windows 10同时也存在一个和每一位用户息息相关的问题：它基本上会监视你在计算机上的一举一动。


虽说谁在装系统的时候都不会去阅读微软那好几万字的服务协议，但他们的隐私声明其实并没有那么晦涩难懂：

“最后，本着诚信原则在以下情况下，我们可能访问、披露和保存个人数据，包括您的内容（比如您的电子邮件内容、其他私人通信或私人文件夹中的文件）：

1.遵循适用法律或响应有效法律程序，包括执法机关或者其他政府机关；

2.保护我们的客户，例如防止垃圾邮件或欺诈服务用户的企图，或帮助防止死亡或严重人身伤害；

3.运行和维护服务的安全，包括防止或阻止攻击我们的计算机系统或网络；

4.保护Microsoft的权利或财产，包括履行约束服务使用条款 - 但是，如果我们收到信息，表明有人正使用我们的服务交易盗取的 Microsoft 知识或物理财产，我们不会亲自检查客户的私密内容，而可能会交由执法部门处理。”

这些条款看上去可能有点渗人，不过你也不必惊慌。微软允许Windows 10用户关闭那些他们认为可能侵犯到自身隐私的功能，不过这些功能在默认状况下都是开启的。如果你想要重新夺回自己个人数据的控制权，不妨遵照下面这些步骤。

首先，你需要开启设置菜单并点击“隐私”。这里虽然有13个之多的二级设置菜单，但你只需要对当中的一部分进行调整。在这些设置当中，“常规”一栏是最为重要的，当中默认开启的功能会让微软了解到你的位置和打字习惯等信息。此外，你还应该点击窗口当中的“管理我的Microsoft广告和其他个性化设置系信息”超链接来在网页上更改自己的个性化广告偏好。关闭当中的功能选项之后，你就可以避免被广告追踪功能所侵扰。

Cortana也是应该格外关注的对象，虽然她能带来不少便捷的功能，但在提供服务的过程当中，你的不少私人数据和信息也会被她所获取。如果你不想让她这样做，可以在“语音、墨迹书写和键入”一栏当中点击“停止收集有关我的信息”按钮。

如果你懒得进行这些复杂的设置，还有一个简单直接的方法可以一劳永逸地保护自己的隐私，那就是从Windows 10当中移除微软账户，并新建一个本地账户。这样做之后，微软就不会获取到你的数据，并将其同步到其他设备上。如果你并不需要同步功能，这将会是个不错的方法。



C

你必须懂C。为哈? 因为出于所有现实的理由，这个世界上你过去，现在，将来会用到的每一台计算机都是一台冯·诺曼机器，而C是一种轻量级的，很有表达力的语法，能很好的展现冯·诺曼机器的能力。

冯·诺曼架构就是你每天都用的计算机的架构的标准：一个 CPU，内存，硬盘，一条总线。多核计算机并没有带来本质上的变化。冯·诺曼机是一个很方便，很便宜，上世纪五十年代的实现图灵机的技术，图灵机是执行计算的最知名的抽象模型。

世 上还有其他的计算的机器。比如，Lisp 机器，是上世纪 50 年代对 Lisp 计算模型的实现。Lisp 模型是基于 lambda 代数的一种计算语言表示法，后者是与图灵机同构的一种模型。不像图灵机，lambda 代数能被人类读和写。但是这二者是同等能力的。它们同样精确的表示了计算机能干什么。

Lisp 机现在不是很流行了，除了在跳蚤市场里。从谁更受欢迎来说，冯·诺曼机器赢了。还有一些其他的计算机，比如神经网络计算机，译者也不知道怎么翻的计算机(cellular automata)，但是这些都不够大众化，至少现在是这样的。

所以你必须知道C。

还 有一个你必须知道C的原因是，Unix 是用C写的。巧的是，Windows 也是。基本上所有的其他操作系统都是用C写的。因为这些操作系统都是冯·诺曼机的操作系统，你还能用别的吗? 任何跟C很不一样的东西都会跟硬件的实际能力相差太远而导致无法满足性能上的需要，至少对一个操作系统来说是这样—至少在上个世纪是这样，碰巧这些系统都 是上个世纪的。

你还应该知道 Lisp。你不必用它来干实际工作，虽然它在很多 GNU 的软件里都会很用得着。尤其是，你应该学会 Scheme，Lisp 的一种小巧化的，纯洁的方言。GNU 的版本叫 Guile。

他们在麻省理工和加州伯克利教新学生一到两个学期的 Scheme，这些学生都对他们为哈要学这么奇怪的语言抓破脑袋。实话实说，作为第一门学习的语言，这是一个很烂的选择，第二门也是很烂。你应该学会它，最终，但不是作为第一门或第二门语言。

这是很难的哦。这是很大的一步。学会怎么用 Lisp 写出像C语言的程序是不够的，那没有意义。C 和 Lisp 一个就像红外线，一个就像紫外线，它们分布在光谱的最两端。它俩一个牛逼的地方刚好是另一个傻逼了的地方。

如 果说，C是最靠近计算机是如何工作的语言模型，Lisp 就是最能反映计算(注意，这里没有了“机”字，计算机和计算是很不同的！译者注)是如何工作的模型。你不需要懂很多 Lisp，真的。紧咬 Scheme 就哦了，因为它是最简单最干净的。其他的 Lisp 已经发展成了很大，很复杂(很好很强大? 译者：-)的编程环境，就像 C++ 和 Java，要有很多库啊，工具啊等等之类。那些，你不需要知道。但是你应该能用 Scheme 写程序。如果你能够做出 The Little Schemer 和 The Seasoned
 Schemer 这两本书里的所有习题，你懂得就够多了，我认为。

但是对于你天天要做的编程工作，你应该基于以下条款选择你的语言：库，文档，工具支持，操作系统集成，资源，和一堆其他的东西。这些条款跟计算机如何工作关系很小，但是跟人类如何工作关系甚大。

人们还在用很直白的C语言写东西。很多东西。你应该懂C！

C++

C++ 是地球上最蠢的语言，即使是从蠢这个字的真正意义上出发。C++很无厘头。它不知道自己是什么东西。它没有自省(introspective，面向对象里 的一个概念，译者注)。C也没有，但是C不是“面向对象”的，而面向对象很大程度上是关于要让你的程序知道它自己。对象就像演员。所以面向对象语言应该有 运行时的自省机制，知道自己是个什么类的对象。C++不是这样的，真的，你不会那样用它。

关于C：写一个C的编译器是那么的简单，以至于你 可以用C写一个关于C的工具，用起来就像是有内省机制。而 C++ 呢，基本上是不可解析的，所以如果你想写一个很牛逼的工具用来 —— 比如，告诉你你的虚函数的原型，或者帮你重构你的代码，你将不得不依赖别人的工具集，因为你自己在除非脑子进屎的情况下是根本不会去写一个 C++ 的解析器的。而市面上所有的 C++ 的解析器都很傻逼。

C++很蠢，你不能用蠢语言创造一个好系统。语言决定世界，蠢语言决定蠢世界。

所有的计算都基于抽象。你用低级的东西创造出高级的东西。但是你不能用分子创造出一个城市。尝试使用太低级别的抽象只会给你带来麻烦。

我们就惹上麻烦了 (是指亚马逊的员工，还是所有 C++ 的程序员? 我也不知道，译者注)。

理智的情况下，你用C写的最大的东东就是一个操作系统。而操作系统其实不是很大的，真的。它们看起来很大，但那是因为它们有很多应用软件，操作系统本身的内核是蛮小的。

你 用 C++ 能写的最大的东东是…也是操作系统。好吧，或许稍微再大点儿。让我们说，再大三倍吧。或者 10 倍吧。但是操作系统内核最多也就，那啥，一百万行代码? 所以我说你能用 C++ 写的最大的系统大概也就是一千万行代码吧，再大的话就开始不行了，这玩意儿你没法控制了，就像恐怖片里的…

我说的一千万行是指如果你那时候还能让你的系统编译通过的话。

我们(在亚马逊，译者注)有五千万行 C++ 代码。不，现在还要更多了。我已经不知道有多少行了。上个圣诞节是五千万行，那是九个月前，而它以每季度八百万行的规模增长。增长率本身也增长，妈呀。

我们想在这个系统里干点啥好像要一万年。一个亚马逊工程师有一次这样描述我们的代码库：“一座很大的屎山，你见过的最大的山，每次你想修正一个 bug，你的工作就是爬到屎山的正中心去。”

伙计们，那哥们可是在四年前说的这话。他现在已经到更环保绿色的牧场上去了。真是太可惜了，他可是个实实在在的高手啊。

这 都是 C++ 的错。别跟我争论。就是的。我们用的是世上最蠢的语言。这简直有点老板级的蠢，你说呢? (译者注，meta 在计算机术语里通常表示更高一个层次，比如，meta-language，比普通的 language 高一个层次，意思是关于语言的语言。哲学里应该会经常用到这个词。我不懂哲学，但是我觉得老板们总是比我们高一级，所以 meta-dump 我就翻译成老板级的蠢喽。：-)

说了以上这些难听的话，话得说回来了。用 C++ 写出漂亮的代码显然是可以的，我的意思是说，这样的代码应该大部分还是C，偶尔很有品味的，很有节制的用一点C++。但是这种代码几乎从来不会被写出来。 C++是个很好玩的游乐场，而如果你把它玩儿得门儿清的话你会觉得自己特牛，所以你总是被诱惑把你知道的所有的东西都用上。但是那是很难做好的，因为从一 开始这个语言就太狗屎了，最终，你会弄得一塌糊涂，即使你很能干。

我知道，我说的都是异端邪说，该被钉到十字架上的。随便吧。我在大学里的 时候老喜欢 C++ 了，因为我那时候就只知道这一门语言。当我听到我的语言教授，Craig Chambers，绝对的厌憎C++，我想：“为啥呢? 我觉得它挺好的啊”。而当我听到 STL (标准模板库)的发明者被采访时说他恨 OOP (面向对象编程)时，我更是认为他肯定是磕药了。怎么会有人恨 OOP 呢，而这个人竟然还是 STL 的发明者?

亲不敬，熟生厌(语出圣经，译者注)。说的是在大多数情况下，跟一件事物熟悉了之后你就失去对它的膜拜尊敬了; 在计算机语言里情况不是这样的。光对一门语言熟悉不会导致你看轻这门语言。你必须成为另一门更优秀的语言的专家(才能让你明白原来那门语言有多么多的问题)。

所 以如果你不喜欢我针对 C++ 大放厥词，请你去学另一门语言并成为一个专家(我推荐 Lisp)，只有那时你才有足够的武器与我争论。然而，那时你将不会跟我争了。你上了我的当了。你也会跟我一样变得不喜欢 C++ 了，你或许会觉得我这个人很恶心，把你骗得不喜欢自己曾经的最爱了。所以或许你应该把我说的一切都忘了。C++挺好的其实，真的。它就是很棒棒(译者注， 作者在这里用了 ducky，这是一个女性喜欢用的夸某物好的词，近来也为玻璃们喜爱)。忘了我说的话。C++不错的。

Lisp

(我打赌这一节会让你觉得惊讶，即使你已经关注我的博客有一阵了[译者注，作者也可能是说，即使你成为亚马逊的员工有一阵了])

亚马逊创业之初，我们有很多明星级的工程师。我不认识他们所有人，但是我认识几个。

比如？Shel Kaphan, 大拿。Greg Linden, 大拿。Eric Benson。即使在他加入亚马逊之前就已经有自己响亮的名气了。也是大拿。

他 们写了 Obidos 服务器。是 Obidos 让亚马逊成功的。只是后来那些生产大便很拿手的工程师，网页开发者，搞前端的人 —— 这些人因为生产大便很拿手而总是能让经理们满意 —— 只是在后来这些人把 Obidos 搞糟了。(他们的大便)把整条河都堵了，打个比方说的话。但是 Obidos 是亚马逊最初的成功的一块关键的基石。

这些最早的牛人们在亚马逊神圣的代码库里只允许两种语言：C 和 Lisp。

你自己去想吧。

当 然，他们所有人都使用 Emacs。靠，Eric Benson 是 XEmacs 的作者之一。这个世界上所有伟大的工程师都在用 Emacs[注1]。那种世界因你而不同级别的伟大。不是坐在你旁边的格子里的那哥们那种伟大。也不是 Fred，走廊尽头那哥们。我说的是我们这个行业里最伟大的软件开发者，那些能改变这个工业的面貌的人。像 James Gosling 们(Java 语言设计者)，Donald Knuth 们(这个人没有听说过的话赶紧改行吧，别搞计算机了)，Paul Graham 们[注2]，Jamie Zawinski
 们，Eric Benson 们。真正的工程师用 Emacs。你必须很有点聪明才能把 Emacs 用好，而如果你能成为一个 Emacs 大师的话它会给你难以置信的牛力。有机会的话你应该站到 Paul Nordstrom 的肩后看看他是怎么工作的，如果你不相信我的话。对那些一辈子都在用烂 Visual Studio 之类的集成开发环境的人来说，一定会大开眼界的。

Emacs 是那种你可以用 100 年的编辑器。

Shel, Eric, Greg，和其他像他们那样的人，我没有足够幸运能跟他们直接一起工作：他们禁止在这里使用C++，他们禁止使用 Perl(或者 Java，为完整起见)。他们是明白人。

现在我们都在用C++，Java 和 Perl 了，所有的代码都用这些语言。我们的前辈们已经到更环保的牧场上去了 (指没有大便的牧场，译者注)。

Shel 用 C 写了 Mailman，客服部的人把它用 Lisp 封装了一下。Emacs-Lisp。你不需要知道 Mailman 是什么东西。除非你是个 Amazon 的老员工，或许不是搞技术的，而且你曾经不得不让客户哈皮 (只有在这种情况下你才需要知道 Mailman，译者注)。不是间接的，因为你用 C++ 写的一个狗屎功能跑不起来了，让客户很生气，于是你不得不去搞定它以恢复客户的哈皮度。不，我是说直接的，意思是，你必须跟他们聊。我们可爱的，不识字 的，呱呱其谈的，心地善良的，充满希望的，困惑的，能帮点小忙的，愤怒的，哈皮的客户们，真正的客户们，那些从咱们这里买东西的人，我们的客户们。(如果
 你必须跟他们打交道的话，)那你就会知道 Mailman 这个东西。

Mailman 是客服部的客户电子邮件处理软件，我们用了它有…四，五年? 反正是很长时间。它是用 Emacs 写的，所有人都爱死它了。

人 们现在还很爱它。直到今天，我依旧不得不听我们一些非技术员工跟我长篇大论的叨叨他们是多么的怀念 Mailman。我可绝不是满嘴喷粪。上个圣诞节我参加了一个 Amazon 的派对，一个我不知道自己怎么会被邀请的派对，里面全是些西装笔挺的商务人士，谁都长得比我帅，比我光鲜。以及一些我在公司里曾经打过交道的人(这句不知 道怎么译)。四个美女认出了我是在客服部里干的，把我包围了，跟我说了十五分钟她们是多么的怀念 Mailman 和 Emacs，而现在的亚马逊(我们用 JSP 花了好多年准备换掉 Mailman 的那一套软件)是怎么的不能满足她们，让她们觉得跟以前一样爽。

这一切都太梦幻了，我觉得她们可能是喝多了。

Shel 是个天才。Emacs 是天才。连非技术人员都爱 Emacs。我现在就是在 Emacs 里打这些文字。我绝不情愿在任何其他地方打字。这不只是关于让你的效率得到飞跃，通过那些地球上其他地方找不到的快捷键和文本编辑功能。我每分钟打一百三 到一百四十个英文单词，在 Emacs 里，当我在写没有格式要求的文本的时候。我测过这个时间速度。自己写了一个测打字速度的 Emacs 应用。但我想跟你说的不只是这个。

Emacs 有的是一种你叫不出名字来的品质。

我们现在不用 Mailman 了。那是因为我们有一种叫得出名字的品质 —— 就是，烂。我们很烂。我们(当时)找不到 Emacs-Lisp 足够牛的人把 Mailman 继续搞下去。今天这应该不难了; 亚马逊现在到处都是 Emacs Lisp 的黑客。但是在那时候，客服部的人没法从别人那里得到帮助。于是他们就用他们当时手头有的资源去搞这件事。他们当时没有足够多的 Emacs-Lisp 的人。有一段时间，他们甚至找来 Bob Glickstein 当合同工，那个给 O’Reilly 写了那本 Gnu Emacs
 扩展的书的家伙，坐在一个小办公室里给 Emacs 写 Mailman 的扩展。

客服应用部是 Amazon 的第一个两块比萨饼的团队(代表团队人数的增加，编者注)。这个团队是完全自立的。不管是那时还是现在。没人跟他们说话，没人帮他们。没有枪，没有炮，他 们自己造。他们没有网页工程师，没有支持工程师。屁也没有。有的只是一堆骨灰级的工程师和一个能带新人的文化。这就是他们需要的一切了。

但他们最终不得不让 Mailman 光荣退休。妈哎。而我呢今天还听到人们说他们是多么的怀念它。甚至在派对上。

我 想今天按人头比例来说，客服部仍然拥有比亚马逊任何其他团队更多的 Lisp 黑客。可能他们用到 Lisp 的机会不多了，但是 Eric Raymond 说过，即使你很少用 Lisp 写程序，学习 Lisp 会是意义深远的一个经历，能让你下辈子都成为一个更好的工程师。

卡尔，宗教现在已经不是大众的精神鸦片了。现在鸦片是集成开发环境了。(卡尔·马克思。这个人不知道的话应该打屁屁)。

Java

Java 是过去的 10 年中计算行业里发生过的最好的同时也是最坏的事。

一 方面，Java 把你从 C++ 编程的很多枯燥易错的细节中解救出来了。没有数组越界了，没有 core dump 了。抛出来的异常能让你精确定位到出错的那一行代码，而且 99% 的时候都是正确的那一行出错了的代码。对象们在需要的时候能智能地把它们自己打印出来。等等等等。

另一方面，除了是一种语言，一个虚拟机，一个巨无霸的类库，一个安全模型，一个可移植的字节码格式，Java 还是一个宗教。邪教。所以你不能太相信对它太虔诚的人。想要招一个好的 Java 工程师是一项很有技术挑战的活。

但是总的来说，Java 是软件工程史上的一大进步。

从 C++ 到 Java 不只是语法上的改变。这是一种需要一段时间去好好体会的一种震撼性的世界观的转变。这有点像突然你被配了一个执行助理。你知道老总们为什么总是好像有时间 去开会，总是知道公司现在运行的情况，总是写出很酷酷的文档吗? 老总们常常忘记其实他们不是一个人在战斗，他们都是两个全职的人，他们和他们的执行助理们。有一个执行助理把你从琐事中解救出来让你有时间去思考那些真的 需要你去解决的问题; 没有的话你将不得不花一半的时间在那些无聊的世俗的事情上。切换到 Java 编程语言就把你变成了两个程序员 ——
 一个处理那些你不需要关心的东西，另一个可以集中精力在问题本身上。这是一个很震人的改变，一个你应该很快就能习惯能喜欢上的改变。

就像 Jamie Zawinski (Netscape 牛人，开发 Mozilla 浏览器，好像学历是高中毕业?)在他著名的“Java 真烂(java sucks)”那篇文章里说的：“先说那些好东西：Java 没有 free() 函数。我必须一开始就承认，其他的东西都没什么了不起。(没有 free)是能让我原谅其他所有东西的特性，不管其他东西有多烂。讲完这一点后，我的文章里其他一切几乎都完全没有重要性了。”

Jamie 的文章写在 1997 年，按 Java 年来算的话是很早以前了，跟他写这篇文章时比，Java 已经有很大的改善; 一些他抱怨的东西甚至已经被 fix 了。

但是大多数还是没有被 fix。Java 作为一门语言还是有点烂。但就如 Jamie 指出的，Java“是今天为止最好的语言。我的意思是说，它是今天市面上那些烂得底儿掉地一堆语言比起来有那么一点能被我接受。”

真的，你应该读读他那篇文章。

Java 几乎每一方面都很好，除了它的语言本身，而这是 JWZ 抱怨的主要对象。但那是一个很大的抱怨。再好的库也救不了一个烂语言。相信我：你可能比我知道多得多的东西，但是我知道好兵救不了烂将。在 Geoworks 搞了五年汇编语言都会了我这个道理。

跟 C++ 比，Java 作为一个语言还过得去。好吧，别扯了，Java 要好很多。因为它有(内建)的字符串。哥们，你说一个没有内建的字符串的语言是人用的吗。

但是 Java 跟 C++ 比少了一些好东西，比如(函数调用时)传引用，栈上的对象，typedef，宏，以及运算符重载。一些时不时地会很称手的东西。

哦， 还有多重继承，我现在老了，反而挺欣赏了的多重继承。如果你认为我这个观点僵硬不灵活的家伙是多态教义很好的反例的话，我倒是可以给你举几个为什么你需要 多态继承的好例子，或者至少像 Ruby 那样的 mixin 或者自动的派遣。下次问问我白龙马的事情。今天我要告诉你为什么 Java 的 interface 是个烂货。

几年前 Gosling 自己都说，如果一切都能重来的话，他不会搞出个 interface 的概念。

但是那正是 Java 的问题。当 James 说出那句话的时候，人们被雷到了。我甚至能感觉到那股雷劲儿，能感觉到 Sun 公司市场部和法务部的鸟人是多么想把 James 灭口，然后告诉大家他没那么说过。

Java 的问题就是人们都被那帮人搞的广告效应蒙住了眼。C++，Perl，任何流行语言都有这个问题。这是很严重的，因为如果没有一些说大话吹牛逼的广告，一个 语言是不会流行起来的。所以如果一个语言的设计者说他的语言没有被设计得很完美的话，就是赶紧用麻醉枪射击这胡说八道的家伙并关闭会议的时候了。

语言们需要放点儿卫星才能活，我只希望人们不要被卫星耀瞎了眼。

我 学了面向对象编程， 我自己也对此大吹大擂。当我加入亚马逊时，我不能告诉你我有什么智慧或者经验，但我可以给你背诵出所有关于 OOP 的魔咒。多重继承是邪恶的，因为大家都这么说; 运算符重载是邪恶的，诸如此类。我甚至有点模糊地知道为什么是邪恶的，但实际上不知道。后来我明白了，这些都不邪恶，不是烂玩意儿，烂的是开发者，是我。 我现在还是烂，但是希望每年都不烂一点起来。

上礼拜我碰到一个来面试的，他告诉我多继是邪恶的，因为，比如，你可以从头，胳膊，腿，躯干多 重继承出一个人来。他既是对的，又是错的。那样的多继情形当然邪恶，但那都是因为他自己太邪恶了。那样继承出来的“东西”远远就能看见有多蠢，如果他还把 这玩意儿弄进门来那就更邪恶了。

不良开发者，占了这世上开发者的大多数，他们能用你扔给他们随便什么语言写出不良的代码。

说 了这些，还是得说回来，多继不是请客吃饭那么轻松的事儿; mixin 看起来是更好的解决方案，但是还没人完美的解决这个问题。但我还是认为 Java 比 C++ 好，即使它没有多继。因为我知道不管我的出发点是多么好，某一天我还是会被一堆不懂怎么写好代码的人包围，让他们用 Java 比用 C++ 会带来更少的伤害。

此外，Java 除了语言本身外还有老多其他的重要有用的东西。且 Java 语言本身也在进化，虽然像冰川一样慢，所以我们还是能看到希望。Java 正是我们应该在亚马逊推荐使用的语言。

你就是得小心点儿，因为和其他任何语言一样，你能很容易找出一堆人，他们很懂一门语言及其编程环境，但对品味，计算或者其他任何重要的东西却一无所知。

当你有怀疑时，还是雇那种会好几门语言的 Java 程序员，那种厌憎 J2EE/EJB 之类松松跨跨的所谓框架的，那种使用 Emacs 的。这都是一些实战经验。

Perl

Perl，怎么说呢?

Perl 是个老朋友。老老朋友。我开始写 Perl 代码的时候，可能是 1995 年。而它为我很好的服务了差不多 10 年的时间。

它就像你骑了十万二十万英里的老自行车，你心里永远有一块地方装着它，虽然现在你已经换了一辆更加现代化的只有五磅重的自行车，而且这一辆也不像老的那辆顶得你屁眼疼了。

Perl 受欢迎原因有仨：

用 Perl 你很快就能搞定你的问题。而这是最终的衡量标准。

Perl 有世上最好的市场推广。你可以写一本介绍他们市场推广有多绝的书。Sun 公司砸大笔钱给 Java 推市场，Perl 在受欢迎程度来说能跟 Java 齐头并进，但 Perl 纯粹是依靠 Larry Wall 和他那帮哥们的三寸不烂之舌做市场。哈佛商学院的人应该去研究 Perl 的市场是怎么做出来的。真的让人瞠目结舌。

直到差不多，呃，现在，Perl 没有真正的竞争者。

有比 Perl “好”的语言。操，有很多比 Perl 好的语言，如果你定义“好”为“不是给疯子用的”的话。Lisp, Smalltalk, Python，妈呀，我可能可以列出二三十种比 Perl “好”的语言。从这些语言不像这个夏天在台湾街头爆了肚皮的抹香鲸这个角度来说。鲸鱼肠子到处都是，汽车上，机车上，行人身上。这就是 Perl。让人着迷，真的。

但是 Perl 有很多很多好的特性，直到最近，都是其他语言没有的。它们弥补了 Perl 肠子在外的不足。你可以从爆了肚皮的鲸鱼可以做很多有用的东西出来，比如香水。这很有用。Perl 也是这样。

当其他的那些语言(尤其是 Lisp 和 Smalltalk)都想假装操作系统并不存在，列表(Lisp 的)和对象(Smalltalk 的)就是把屎搞出来的唯一存在，Perl 却走了截然相反的路子。Larry 说：Unix 和字符串是搞出屎来的唯一存在。

对很多任务来说，他绝对是正确的。所以 Perl 绝对是 Unix 系统管理和字符串处理的史上最强语言，除了一个，刚出来的一个，从哥斯拉(电影哥斯拉看过没)之地出来的一个。我一会儿会讲到那一个。

可 惜，Larry 太太太太在意 Unix 系统管理和字符串处理以致他压根忘了列表和对象，等他明白过来想改正的时候已经晚了。实际上，在 Perl 早期的…好吧，对鲸鱼肠子我实在不想用“设计”这个词，就说生命周期中吧，他犯的几个关键错误让把列表和对象加进来变得如此尴尬，以致 Perl 已经进化成一个真正的 Rube Goldberg 机器，至少当你想在 Perl 里用列表和对象的时候。(Rube Goldberg 是一漫画家，常画一些很复杂的机器，但只完成简单的工作，比如一个小球滚过很多关卡，最后把门打开。译者注)。

列表和对象也他妈的是很重要的，Larry！(farging 应该是作者不想说 fucking 那么直白，译者注)

Perl 没法表达列表因为 Larry 一早犯了一个悲剧性的愚蠢的错误，把列表全抹平。于是(1, 2, (3, 4))魔术般地变成(1, 2, 3, 4)。不是说你会想让它这样工作，而是 Larry 刚好那天在搞一个这样会更方便的问题。于是 Perl 的数据结构从此就变得爆炸了的鲸鱼了。

今 天你看 Perl 的书，小教程或 PPT 的时候，不花三分之一的时间在“引用”上是不可能的。这就是 Larry 可怜的，坏了的，Goldberg (漫画家，想起来没? 译者注)式的对他那抹平列表的疯狂错误的解决方案。但是 Perl 的市场宣传做得那么难以置信地好以致它让你觉得这是你身上发生过的最好的东西。你可以对任何东西取它的引用。这很有趣！闻起来也很香（说肠子呢，译者注， 呵呵）！

Perl 不能支持面向对象编程因为 Larry 压根不相信这玩意儿。这可能没什么大不了; 我也不是很确定我是不是信这个 OOP。但是那么为啥他又要试着把对象加进 Perl 呢? Perl 的面向对象是个半成品，且在 Perl 社区里没多少人重视。它就是不像字符串处理或 Unix 集成那样充满灵感。

当然了，Perl 还有其他很多怪怪的特性。比如它的“上下文”，这是 Larry 要有N个变量名字空间的喜剧式决定的一个恐怖片式的产物。这些空间由 sigil 来区分(就是 Perl 里变量名前面的‘$’，‘@’，‘%’字符)，看着像是从 shell 脚本里拷贝来的。在 Perl 里，所有的运算符，所有的函数，所有的操作其行为都是六取一的随机的，取决于当前的“上下文”。没有一些规则或助记法能帮你搞定这些特定操作在特定上下文 里的特定行为。你得把它们全记在脑子里。

想要个例子? 这儿有一个：在一个值量(scalar，对应于 vector，向量)上下文里对一个哈希取值你得到一个字符串，里面是个分数，分子是目前已分配的键，分母是总共有多少个桶。鲸鱼肠子，我告诉你。

但就像我说的—直到最近，没啥能像 Perl 那样把屎搞定。

Ruby

每 过 15 年左右，一门语言就会被更好的代替。C被 C++ 代替，至少对大应用开发而又需要性能和数据类型的人们来说。C++ 被 Java 代替，而 Java 无疑在 7 年后又会被更好的东西代替—好吧，我说的是完全代替 C++ 的 7 年后，这到目前为止还没有发生，主要是因为微软能在 Java 霸占桌面系统之前狙击它。但是在服务器上的应用而言，C++ 的阵地已经慢慢让给 Java 了。

Perl 有一天也会消逝。那是因为一门新的语言 Ruby 刚刚终于被翻译成英语了。没错，它是在日本发明的，这么多地儿，没想到日本人搞出来了，还以为他们只是硬件和制造上占有名气，而不是他们的软件业，所以大 家都跟你一样惊奇。为什么呢，大家可能都在想。但是我认为这都是跟打字有关。我根本不能想象他们以前能打字打得足够快，英文字母只有 26 个，他们却有上万个字。但是 Emacs 几年前支持多字节字符了，所以我猜他们现在打字速度他妈的快多了。(所以能搞出 Ruby 来了，译者猜作者是这个意思) (是的，他们也用 Emacs
 —— 事实上日本人负责了 Emacs 多字节支持的大部工作，而且搞得坚不可摧。)

不 管怎么样，Ruby 从 Perl 那里偷师了所有的好东西; 实际上，Matz, Ruby 的作者(Yukihiro Matsumoto，如果我没记错的话，但是他外号“Matz”)，觉得他从 Perl 那里偷的有点太多了，他的鞋上也粘了些鲸鱼肠子。但是只是一丢丢。

最重要的是，Ruby 拿来了 Perl 的串处理和 Unix 集成，一点没改，就是说语法都是一样的，于是乎啥也不说了，你就拥有了 Perl 最好的那部分。这是个不错的开局，特别是如果你不把 Perl 剩下的东西也拿进来的话。

但是之后 Matz 还从 Lisp 那里拿来的最好的列表处理，Smalltalk 和其他语言那里拿来了最好的面向对象，CLU 那里拿来了最好的迭代器，以及基本上是每个人每个事的最好的东西。

而 他让这些东西全部都跑起来，跑得那么顺，你都不会注意到这些东西在那儿。我比其他任何语言都快就学会了 Ruby，我总共会三十到四十门语言; 而我花了大概三天时间就能用 Ruby 比 Perl 还流畅地工作了，当了八年的 Perl 黑客后。这些东西是这么的和谐你都能自己猜它们是怎么工作的，而且大多数时候你都能猜对。漂亮。有趣。靠谱。

如果把语言比成自行车，那么 AWK 就是一辆粉系的儿童自行车，前面有个白色小框，还插块小旗，Perl 就是沙滩车(还记得那有多酷吧? 唉。)，而 Ruby 则是一辆七千五美金的钛合金山地自行车。从 Perl 飞跃到 Ruby 意义不下于从 C++ 到 Java 的飞跃。却没有任何缺陷，因为 Ruby 几乎是 Perl 功能的一个超集，而 Java 却拿掉了一些人们想要的东西，且没有真正的提供一个替代品。

下次我会写更多关于 Ruby 的东西。我先需要灵感。去读读 Lucky Stiff 的(poignant) guide to Ruby 吧。那本书是一本有灵感的书。真的，读一下。超赞。我不理解产生它的那种头脑，但它很有趣，很犀利，且全是关于 Ruby 的。好像。你会看到的。

Python

啊，Python 怎么说呢，一个不错的语言，这么多年来一直旁边在等待它的机会? Python 社区很长时间以来是那些勇敢地吞下红药片从 Perl 骇客帝国中醒来的人的避难营。

啊，有点像 Smalltalk 的人们，他们永远在等待替代C++，没想到半路杀出 Java 一下把它们操翻了，漂亮地，永久地。哎哟。Ruby 正在对 Python 做着同样的事，现在，今天。可能会在一夜之间吧。

Python 本来可以统治世界，可惜它有两个致命缺陷：空格，和冷淡。

空 格很简单，就是说 Python 是用缩进来表达代码块之间的嵌套。它强制你必须按一定格式把所有的东西缩进，他们这样做是为了让所有人写的代码看上去一样。不料蛮多程序员讨厌这点，因为 他们觉得自己的自由被拿走了; 感觉就像 Python 侵犯了宪法赋予他们的可以随便缩进格式和全写在一行上的权利。

Python 的作者，Guido Van Rossum，也在早期犯过一些很傻的技术错误 —— 没有像 Larry 的失误那么严重，但是还是有几个。比如，最早 Python 没有字面变量范围，但它同时也没有动态变量范围，而动态变量范围可能会有它一些问题，但它还是有用的。Python 却没有这些，只有全局的和本地(函数)的两种范围。所以即使它是一个真正的 OO 系统，类甚至不能访问它们自己的动态成员变量。你必须给成员函数传“self”参数，一大堆 self 参数很快就会把你搞疯掉，即使你不在意空格问题。

等等之类。

但在我看来，Python 不行其实是因为冷淡。这阻止了它成为首选脚本语言，或者首选一切语言。靠，人们现在还在用 Tcl 作嵌入解释执行器，虽然 Python 比 Tcl 好得不要太多 —— 除了，我说，这个冷淡问题

根据《2015
 H1绿盟科技DDoS威胁报告》指出，如今大流量网络攻击正逐渐呈现增长趋势，前不久锤子科技的发布会以及9月12日苹果官网宕机的案例就印证了这一点。那什么是DDoS攻击？如何才能抵御DDoS攻击呢？本文作者通过一系列漫画图片为大家做了生动演示。


伤感的发布会

2015年8月25日晚，锤子手机可谓迎来了有史以来最伤感的发布会。除了所有产品资料提前遭到泄密外，就连发布会当天的电商网站也遭到了DDoS攻击，致使客户无法下单数小时。 据悉，此次DDoS攻击流量为数十G，当晚工作人员一直在奋力抢修……




无独有偶，9月12日苹果开放预购iPhone
 6s时更是伤感，甚至有些惊心动魄。



因为他的商城，被准备抢购的果粉刷爆了！！！生生失联了104分钟！！！效果相当于一次有规模的DDoS攻击。而相应的CDN服务商对此竟然一时间束手无策，只能强行限制了访问。这可是要影响到数以亿计的生意！



这些大流量的DDoS攻击行为，也印证了《2015 H1绿盟科技DDoS威胁报告》中的观点：大流量攻击呈现增长趋势。



那到底DDoS是个啥玩意？




让我们来举个栗子，假设你开了一家店，生意还不错哦！



此时隔壁家生意萧条的老王盯上了你（好吧，别介意，他也可以不姓王的），



于是他雇佣来了一群闹事的小子。



紧接着，你就发现突然店里来了一大波客人。你完全应接不暇，而且他们老找你问这问那，东看西看，就是不买东西，更可恶，赖着不走了！



而真正的顾客连进店的地方都没有了！这就是所谓的DDoS攻击——一群“恶意访问”、“堵店门”、“占空间”、还“调戏店员”的非法流量。他们是黑客通过网络上事先留了木马后门的僵尸主机发动的，只不过他们装的和正常访问的数据几乎一样，使得NF或其他防护设备根本无法识别哪些是非法的数据流量。






那么，这时候的解决办法就是，需要一个“明眼人”帮忙清理现场了。具体来说，就是利用某种抗DDoS攻击的工具来精准识别这些非法流量，比如绿盟科技的ADS。



这个工具是如何实现精准识别非法流量的？

1、反欺骗：他会对数据包的地址及端口的正确性进行验证，同时进行反向探测。





2、协议栈行为模式分析：每个数据包类型需要符合RFC规定，这就好像每个数据包都要有完整规范的着装，只要不符合规范，ADS会自动识别并过滤。



3、特定应用防护：非法流量总是有一些特定特征的，这就好比即便你混进了顾客群中，但你的行为还是会暴露出你的动机，比如老重复问店员同一个问题，老做同样的动作，这样，你仍然还是会被发现的。





4、用户行为模式分析：真是的数据是随机访问的，这就好比顾客进店后的行为是随机的，或看看商品，或询询价，或来回比对，或和店员攀谈，而非法流量会大规模地，步调一致地去访问某一个点，这样一来，也是会被ADS识别。



5、动态指纹识别:合法的流量数据，都会有相应的加密算法，这就好比每个数据进入服务器前，都要通过私下分配的口令验证，如果你说不出口令或这口令不对，那么，ADS就直接把你OUT了。









6、带宽控制：而真实的访问数据过大时，ADS可以限制其最大输出的流量，以减少下游网络系统的压力，有了这个功能，苹果公司就可以不用这么手忙脚乱了。



后记

随着DDoS攻击工具越来越普遍和强大，Internet上的安全隐患随之增多，客户业务系统对网络依赖程度也越来越高。可以预见的是，DDoS 攻击事件数量会持续增长，而攻击规模也会更大，损失严重程度也会更高。那么关于“DDos 攻击”，你看懂了吗？




因为他的商城，被准备抢购的果粉刷爆了！！！生生失联了104分钟！！！效果相当于一次有规模的DDoS攻击。而相应的CDN服务商对此竟然一时间束手无策，只能强行限制了访问。这可是要影响到数以亿计的生意！



这些大流量的DDoS攻击行为，也印证了《2015 H1绿盟科技DDoS威胁报告》中的观点：大流量攻击呈现增长趋势。



那到底DDoS是个啥玩意？




CSRF（Cross Site Request Forgery, 跨站域请求伪造）是一种网络的攻击方式，该攻击可以在受害者毫不知情的情况下以受害者名义伪造请求发送给受攻击站点，从而在并未授权的情况下执行在权限保护之下的操作，有很大的危害性。然而，该攻击方式并不为大家所熟知，很多网站都有
 CSRF 的安全漏洞。本文首先介绍 CSRF 的基本原理与其危害性，然后就目前常用的几种防御方法进行分析，比较其优劣。最后，本文将以实例展示如何在网站中防御 CSRF 的攻击，并分享一些开发过程中的最佳实践。




CSRF 背景与介绍


CSRF（Cross Site Request Forgery, 跨站域请求伪造）是一种网络的攻击方式，它在 2007 年曾被列为互联网 20 大安全隐患之一。其他安全隐患，比如 SQL 脚本注入，跨站域脚本攻击等在近年来已经逐渐为众人熟知，很多网站也都针对他们进行了防御。然而，对于大多数人来说，CSRF 却依然是一个陌生的概念。即便是大名鼎鼎的 Gmail, 在 2007 年底也存在着 CSRF 漏洞，从而被黑客攻击而使 Gmail 的用户造成巨大的损失。



CSRF 攻击实例


CSRF 攻击可以在受害者毫不知情的情况下以受害者名义伪造请求发送给受攻击站点，从而在并未授权的情况下执行在权限保护之下的操作。比如说，受害者 Bob 在银行有一笔存款，通过对银行的网站发送请求 http://bank.example/withdraw?account=bob&amp;amount=1000000&amp;for=bob2 可以使 Bob 把 1000000 的存款转到 bob2 的账号下。通常情况下，该请求发送到网站后，服务器会先验证该请求是否来自一个合法的 session，并且该 session 的用户
 Bob 已经成功登陆。黑客 Mallory 自己在该银行也有账户，他知道上文中的 URL 可以把钱进行转帐操作。Mallory 可以自己发送一个请求给银行：http://bank.example/withdraw?account=bob&amp;amount=1000000&amp;for=Mallory。但是这个请求来自 Mallory 而非 Bob，他不能通过安全认证，因此该请求不会起作用。这时，Mallory 想到使用 CSRF 的攻击方式，他先自己做一个网站，在网站中放入如下代码： src=”http://bank.example/withdraw?account=bob&amp;amount=1000000&amp;for=Mallory
 ”，并且通过广告等诱使 Bob 来访问他的网站。当 Bob 访问该网站时，上述 url 就会从 Bob 的浏览器发向银行，而这个请求会附带 Bob 浏览器中的 cookie 一起发向银行服务器。大多数情况下，该请求会失败，因为他要求 Bob 的认证信息。但是，如果 Bob 当时恰巧刚访问他的银行后不久，他的浏览器与银行网站之间的 session 尚未过期，浏览器的 cookie 之中含有 Bob 的认证信息。这时，悲剧发生了，这个 url 请求就会得到响应，钱将从 Bob 的账号转移到 Mallory 的账号，而
 Bob 当时毫不知情。等以后 Bob 发现账户钱少了，即使他去银行查询日志，他也只能发现确实有一个来自于他本人的合法请求转移了资金，没有任何被攻击的痕迹。而 Mallory 则可以拿到钱后逍遥法外。

CSRF 攻击的对象

在讨论如何抵御 CSRF 之前，先要明确 CSRF 攻击的对象，也就是要保护的对象。从以上的例子可知，CSRF 攻击是黑客借助受害者的 cookie 骗取服务器的信任，但是黑客并不能拿到 cookie，也看不到 cookie 的内容。另外，对于服务器返回的结果，由于浏览器同源策略的限制，黑客也无法进行解析。因此，黑客无法从返回的结果中得到任何东西，他所能做的就是给服务器发送请求，以执行请求中所描述的命令，在服务器端直接改变数据的值，而非窃取服务器中的数据。所以，我们要保护的对象是那些可以直接产生数据改变的服务，而对于读取数据的服务，则不需要进行
 CSRF 的保护。比如银行系统中转账的请求会直接改变账户的金额，会遭到 CSRF 攻击，需要保护。而查询余额是对金额的读取操作，不会改变数据，CSRF 攻击无法解析服务器返回的结果，无需保护。



当前防御 CSRF 的几种策略


在业界目前防御 CSRF 攻击主要有三种策略：验证 HTTP Referer 字段；在请求地址中添加 token 并验证；在 HTTP 头中自定义属性并验证。下面就分别对这三种策略进行详细介绍。

验证 HTTP Referer 字段

根据 HTTP 协议，在 HTTP 头中有一个字段叫 Referer，它记录了该 HTTP 请求的来源地址。在通常情况下，访问一个安全受限页面的请求来自于同一个网站，比如需要访问 http://bank.example/withdraw?account=bob&amp;amount=1000000&amp;for=Mallory，用户必须先登陆 bank.example，然后通过点击页面上的按钮来触发转账事件。这时，该转帐请求的 Referer 值就会是转账按钮所在的页面的 URL，通常是以 bank.example 域名开头的地址。而如果黑客要对银行网站实施
 CSRF 攻击，他只能在他自己的网站构造请求，当用户通过黑客的网站发送请求到银行时，该请求的 Referer 是指向黑客自己的网站。因此，要防御 CSRF 攻击，银行网站只需要对于每一个转账请求验证其 Referer 值，如果是以 bank.example 开头的域名，则说明该请求是来自银行网站自己的请求，是合法的。如果 Referer 是其他网站的话，则有可能是黑客的 CSRF 攻击，拒绝该请求。

这种方法的显而易见的好处就是简单易行，网站的普通开发人员不需要操心 CSRF 的漏洞，只需要在最后给所有安全敏感的请求统一增加一个拦截器来检查 Referer 的值就可以。特别是对于当前现有的系统，不需要改变当前系统的任何已有代码和逻辑，没有风险，非常便捷。

然而，这种方法并非万无一失。Referer 的值是由浏览器提供的，虽然 HTTP 协议上有明确的要求，但是每个浏览器对于 Referer 的具体实现可能有差别，并不能保证浏览器自身没有安全漏洞。使用验证 Referer 值的方法，就是把安全性都依赖于第三方（即浏览器）来保障，从理论上来讲，这样并不安全。事实上，对于某些浏览器，比如 IE6 或 FF2，目前已经有一些方法可以篡改 Referer 值。如果 bank.example 网站支持 IE6 浏览器，黑客完全可以把用户浏览器的 Referer 值设为以
 bank.example 域名开头的地址，这样就可以通过验证，从而进行 CSRF 攻击。

即便是使用最新的浏览器，黑客无法篡改 Referer 值，这种方法仍然有问题。因为 Referer 值会记录下用户的访问来源，有些用户认为这样会侵犯到他们自己的隐私权，特别是有些组织担心 Referer 值会把组织内网中的某些信息泄露到外网中。因此，用户自己可以设置浏览器使其在发送请求时不再提供 Referer。当他们正常访问银行网站时，网站会因为请求没有 Referer 值而认为是 CSRF 攻击，拒绝合法用户的访问。

在请求地址中添加 token 并验证

CSRF 攻击之所以能够成功，是因为黑客可以完全伪造用户的请求，该请求中所有的用户验证信息都是存在于 cookie 中，因此黑客可以在不知道这些验证信息的情况下直接利用用户自己的 cookie 来通过安全验证。要抵御 CSRF，关键在于在请求中放入黑客所不能伪造的信息，并且该信息不存在于 cookie 之中。可以在 HTTP 请求中以参数的形式加入一个随机产生的 token，并在服务器端建立一个拦截器来验证这个 token，如果请求中没有 token 或者 token 内容不正确，则认为可能是 CSRF 攻击而拒绝该请求。

这种方法要比检查 Referer 要安全一些，token 可以在用户登陆后产生并放于 session 之中，然后在每次请求时把 token 从 session 中拿出，与请求中的 token 进行比对，但这种方法的难点在于如何把 token 以参数的形式加入请求。对于 GET 请求，token 将附在请求地址之后，这样 URL 就变成 http://url?csrftoken=tokenvalue。 而对于 POST 请求来说，要在 form 的最后加上 &lt;input type=”hidden” name=”csrftoken”
 value=”tokenvalue”/&gt;，这样就把 token 以参数的形式加入请求了。但是，在一个网站中，可以接受请求的地方非常多，要对于每一个请求都加上 token 是很麻烦的，并且很容易漏掉，通常使用的方法就是在每次页面加载时，使用 javascript 遍历整个 dom 树，对于 dom 中所有的 a 和 form 标签后加入 token。这样可以解决大部分的请求，但是对于在页面加载之后动态生成的 html 代码，这种方法就没有作用，还需要程序员在编码时手动添加 token。

该方法还有一个缺点是难以保证 token 本身的安全。特别是在一些论坛之类支持用户自己发表内容的网站，黑客可以在上面发布自己个人网站的地址。由于系统也会在这个地址后面加上 token，黑客可以在自己的网站上得到这个 token，并马上就可以发动 CSRF 攻击。为了避免这一点，系统可以在添加 token 的时候增加一个判断，如果这个链接是链到自己本站的，就在后面添加 token，如果是通向外网则不加。不过，即使这个 csrftoken 不以参数的形式附加在请求之中，黑客的网站也同样可以通过 Referer 来得到这个
 token 值以发动 CSRF 攻击。这也是一些用户喜欢手动关闭浏览器 Referer 功能的原因。

在 HTTP 头中自定义属性并验证

这种方法也是使用 token 并进行验证，和上一种方法不同的是，这里并不是把 token 以参数的形式置于 HTTP 请求之中，而是把它放到 HTTP 头中自定义的属性里。通过 XMLHttpRequest 这个类，可以一次性给所有该类请求加上 csrftoken 这个 HTTP 头属性，并把 token 值放入其中。这样解决了上种方法在请求中加入 token 的不便，同时，通过 XMLHttpRequest 请求的地址不会被记录到浏览器的地址栏，也不用担心 token 会透过 Referer 泄露到其他网站中去。

然而这种方法的局限性非常大。XMLHttpRequest 请求通常用于 Ajax 方法中对于页面局部的异步刷新，并非所有的请求都适合用这个类来发起，而且通过该类请求得到的页面不能被浏览器所记录下，从而进行前进，后退，刷新，收藏等操作，给用户带来不便。另外，对于没有进行 CSRF 防护的遗留系统来说，要采用这种方法来进行防护，要把所有请求都改为 XMLHttpRequest 请求，这样几乎是要重写整个网站，这代价无疑是不能接受的。



Java 代码示例


下文将以 Java 为例，对上述三种方法分别用代码进行示例。无论使用何种方法，在服务器端的拦截器必不可少，它将负责检查到来的请求是否符合要求，然后视结果而决定是否继续请求或者丢弃。在 Java 中，拦截器是由 Filter 来实现的。我们可以编写一个 Filter，并在 web.xml 中对其进行配置，使其对于访问所有需要 CSRF 保护的资源的请求进行拦截。

在 filter 中对请求的 Referer 验证代码如下

清单 1. 在 Filter 中验证 Referer
// 从 HTTP 头中取得 Referer 值
 String referer=request.getHeader("Referer"); 
 // 判断 Referer 是否以 bank.example 开头
 if((referer!=null) &amp;&amp;(referer.trim().startsWith(“bank.example”))){ 
    chain.doFilter(request, response); 
 }else{ 
    request.getRequestDispatcher(“error.jsp”).forward(request,response); 
 }

以上代码先取得 Referer 值，然后进行判断，当其非空并以 bank.example 开头时，则继续请求，否则的话可能是 CSRF 攻击，转到 error.jsp 页面。

如果要进一步验证请求中的 token 值，代码如下

清单 2. 在 filter 中验证请求中的 token
HttpServletRequest req = (HttpServletRequest)request; 
 HttpSession s = req.getSession(); 

 // 从 session 中得到 csrftoken 属性
 String sToken = (String)s.getAttribute(“csrftoken”); 
 if(sToken == null){ 

    // 产生新的 token 放入 session 中
    sToken = generateToken(); 
    s.setAttribute(“csrftoken”,sToken); 
    chain.doFilter(request, response); 
 } else{ 

    // 从 HTTP 头中取得 csrftoken 
    String xhrToken = req.getHeader(“csrftoken”); 

    // 从请求参数中取得 csrftoken 
    String pToken = req.getParameter(“csrftoken”); 
    if(sToken != null &amp;&amp; xhrToken != null &amp;&amp; sToken.equals(xhrToken)){ 
        chain.doFilter(request, response); 
    }else if(sToken != null &amp;&amp; pToken != null &amp;&amp; sToken.equals(pToken)){ 
        chain.doFilter(request, response); 
    }else{ 
        request.getRequestDispatcher(“error.jsp”).forward(request,response); 
    } 
 }

首先判断 session 中有没有 csrftoken，如果没有，则认为是第一次访问，session 是新建立的，这时生成一个新的 token，放于 session 之中，并继续执行请求。如果 session 中已经有 csrftoken，则说明用户已经与服务器之间建立了一个活跃的 session，这时要看这个请求中有没有同时附带这个 token，由于请求可能来自于常规的访问或是 XMLHttpRequest 异步访问，我们分别尝试从请求中获取 csrftoken 参数以及从 HTTP 头中获取 csrftoken
 自定义属性并与 session 中的值进行比较，只要有一个地方带有有效 token，就判定请求合法，可以继续执行，否则就转到错误页面。生成 token 有很多种方法，任何的随机算法都可以使用，Java 的 UUID 类也是一个不错的选择。

除了在服务器端利用 filter 来验证 token 的值以外，我们还需要在客户端给每个请求附加上这个 token，这是利用 js 来给 html 中的链接和表单请求地址附加 csrftoken 代码，其中已定义 token 为全局变量，其值可以从 session 中得到。

清单 3. 在客户端对于请求附加 token
function appendToken(){ 
    updateForms(); 
    updateTags(); 
 } 

 function updateForms() { 
    // 得到页面中所有的 form 元素
    var forms = document.getElementsByTagName('form'); 
    for(i=0; i&lt;forms.length; i++) { 
        var url = forms[i].action; 

        // 如果这个 form 的 action 值为空，则不附加 csrftoken 
        if(url == null || url == "" ) continue; 

        // 动态生成 input 元素，加入到 form 之后
        var e = document.createElement("input"); 
        e.name = "csrftoken"; 
        e.value = token; 
        e.type="hidden"; 
        forms[i].appendChild(e); 
    } 
 } 

 function updateTags() { 
    var all = document.getElementsByTagName('a'); 
    var len = all.length; 

    // 遍历所有 a 元素
    for(var i=0; i&lt;len; i++) { 
        var e = all[i]; 
        updateTag(e, 'href', token); 
    } 
 } 

 function updateTag(element, attr, token) { 
    var location = element.getAttribute(attr); 
    if(location != null &amp;&amp; location != '' '' ) { 
        var fragmentIndex = location.indexOf('#'); 
        var fragment = null; 
        if(fragmentIndex != -1){ 

            //url 中含有只相当页的锚标记
            fragment = location.substring(fragmentIndex); 
            location = location.substring(0,fragmentIndex); 
        } 
		
        var index = location.indexOf('?'); 

        if(index != -1) { 
            //url 中已含有其他参数
            location = location + '&amp;csrftoken=' + token; 
        } else { 
            //url 中没有其他参数
            location = location + '?csrftoken=' + token; 
        } 
        if(fragment != null){ 
            location += fragment; 
        } 
		
        element.setAttribute(attr, location); 
    } 
 }

在客户端 html 中，主要是有两个地方需要加上 token，一个是表单 form，另一个就是链接 a。这段代码首先遍历所有的 form，在 form 最后添加一隐藏字段，把 csrftoken 放入其中。然后，代码遍历所有的链接标记 a，在其 href 属性中加入 csrftoken 参数。注意对于 a.href 来说，可能该属性已经有参数，或者有锚标记。因此需要分情况讨论，以不同的格式把 csrftoken 加入其中。

如果你的网站使用 XMLHttpRequest，那么还需要在 HTTP 头中自定义 csrftoken 属性，利用 dojo.xhr 给 XMLHttpRequest 加上自定义属性代码如下：

清单 4. 在 HTTP 头中自定义属性
var plainXhr = dojo.xhr; 

 // 重写 dojo.xhr 方法
 dojo.xhr = function(method,args,hasBody) { 
    // 确保 header 对象存在
    args.headers = args.header || {}; 
		
    tokenValue = '&lt;%=request.getSession(false).getAttribute("csrftoken")%&gt;'; 
    var token = dojo.getObject("tokenValue"); 
    
    // 把 csrftoken 属性放到头中
    args.headers["csrftoken"] = (token) ? token : "  "; 
    return plainXhr(method,args,hasBody); 
 };这里改写了 dojo.xhr 的方法，首先确保 dojo.xhr 中存在 HTTP 头，然后在 args.headers 中添加 csrftoken 字段，并把 token 值从 session 里拿出放入字段中。




CSRF 防御方法选择之道


通过上文讨论可知，目前业界应对 CSRF 攻击有一些克制方法，但是每种方法都有利弊，没有一种方法是完美的。如何选择合适的方法非常重要。如果网站是一个现有系统，想要在最短时间内获得一定程度的 CSRF 的保护，那么验证 Referer 的方法是最方便的，要想增加安全性的话，可以选择不支持低版本浏览器，毕竟就目前来说，IE7+, FF3+ 这类高版本浏览器的 Referer 值还无法被篡改。

如果系统必须支持 IE6，并且仍然需要高安全性。那么就要使用 token 来进行验证，在大部分情况下，使用 XmlHttpRequest 并不合适，token 只能以参数的形式放于请求之中，若你的系统不支持用户自己发布信息，那这种程度的防护已经足够，否则的话，你仍然难以防范 token 被黑客窃取并发动攻击。在这种情况下，你需要小心规划你网站提供的各种服务，从中间找出那些允许用户自己发布信息的部分，把它们与其他服务分开，使用不同的 token 进行保护，这样可以有效抵御黑客对于你关键服务的攻击，把危害降到最低。毕竟，删除别人一个帖子比直接从别人账号中转走大笔存款严重程度要轻的多。

如果是开发一个全新的系统，则抵御 CSRF 的选择要大得多。笔者建议对于重要的服务，可以尽量使用 XMLHttpRequest 来访问，这样增加 token 要容易很多。另外尽量避免在 js 代码中使用复杂逻辑来构造常规的同步请求来访问需要 CSRF 保护的资源，比如 window.location 和 document.createElement(“a”) 之类，这样也可以减少在附加 token 时产生的不必要的麻烦。

最后，要记住 CSRF 不是黑客唯一的攻击手段，无论你 CSRF 防范有多么严密，如果你系统有其他安全漏洞，比如跨站域脚本攻击 XSS，那么黑客就可以绕过你的安全防护，展开包括 CSRF 在内的各种攻击，你的防线将如同虚设。




总结与展望

可见，CSRF 是一种危害非常大的攻击，又很难以防范。目前几种防御策略虽然可以很大程度上抵御 CSRF 的攻击，但并没有一种完美的解决方案。一些新的方案正在研究之中，比如对于每次请求都使用不同的动态口令，把 Referer 和 token 方案结合起来，甚至尝试修改 HTTP 规范，但是这些新的方案尚不成熟，要正式投入使用并被业界广为接受还需时日。在这之前，我们只有充分重视 CSRF，根据系统的实际情况选择最合适的策略，这样才能把 CSRF 的危害降到最低。

核心容器改进

核心容器额外提供了更丰富的元数据来改进编程。默认 Java 8 的方法检测为 bean 属性的 getter/setter 方法。如果目标 bean 只定义了一个构造函数,则它无需要指定@Autowired注解@Configuration类支持构造函数注入。任何 SpEL 表达式用于指定@EventListener的 condition 引用到 bean（例如@beanName.method()）。组成注解现在可以用一个包含元注解中的数组属性的数组组件类型的元素来覆盖。例如，@RequestMapping的的String[] path 可以在组成注解用 String path 覆盖。@Scheduled和@Schedules现在是作为元注解用来通过属性覆盖来创建自定义的组成注解。@Scheduled适当支持任何范围内的 bean。

数据访问改进
jdbc:initialize-database 和 jdbc:embedded-database 支持可配置的分离器被应用到每个脚本。

缓存改进
Spring 4.3 允许在一个给定的 key 并发调用时实现要同步，使得相应的值只计算一次。这是一个可选的功能，通过设置@Cacheable的新的 sync 属性来启用。此功能引入了Cache接口的一个重大更改，即get(Object key, Callable&lt;T&gt; valueLoader)方法已添加。
Spring 4.3 还改进了缓存抽象如下：

SpEL 表达式对于缓存相关的注解，现在可以引用 bean（即@beanName.method())）。ConcurrentMapCacheManager和ConcurrentMapCache现在通过一个新的storeByValue属性支持缓存实体的序列化。 @Cacheable，@CacheEvict，@CachePut和@Caching现在是作为元注解用来通过属性覆盖来创建自定义的组成注解。

JMS 改进

@SendTo现在可以在类级别指定一个共同回复目标。@JmsListener 和 @JmsListeners现在是作为元注解用来通过属性覆盖来创建自定义的组成注解。

Web 改进

内建支持 HTTP HEAD 和 HTTP OPTIONS.新的组合注解 @GetMapping, @PostMapping, @PutMapping, @DeleteMapping, 和 @PatchMapping 用于@RequestMapping。

详见 @RequestMapping 组合变种
新的@RequestScope, @SessionScope, 和 @ApplicationScope用于 web 范围的组合注解

Request scope, Session
 scope, 和 Application scope
新的 @RestControllerAdvice 注解是 @ControllerAdvice 和 @ResponseBody 的语义结合@ResponseStatus现在在类级别被支持，并被所有方法继承新的 @SessionAttribute 注解用于访问 session 属性 (见例子)新的 @RequestAttribute 注解用于访问请求属性 (见例子)@ModelAttribute 允许通过 binding=false 来避免数据绑定(见引用)错误和自定义抛出，将被统一到 MVC 异常处理器中处理HTTP 消息转换编码一致处理，包括默认 UTF-8 用于多部分文本内容静态资源处理使用配置的ContentNegotiationManager用于媒体类型计算RestTemplate 和 AsyncRestTemplate 支持通过DefaultUriTemplateHandler 来实现严格的URI变量编码AsyncRestTemplate支持请求拦截

WebSocket 消息改进
@SendTo和@SendToUser现在可以在类级被指定为共享共同的目的地。

测试改进

为了支持 Spring TestContext Framework ，现在需要 JUnit 4.12 或者更高的版本新的SpringRunner 关联于 SpringJUnit4ClassRunner测试相关的注解，现在可以在接口上声明了。例如，基于 Java 8 的接口上使用测试接口空声明的 @ContextConfiguration 现在将会完全忽略，如果检测到默认的 XML 文件, Groovy 脚本, 或@Configuration 类型@Transactional 测试方法不再需要public (如, 在 TestNG 和 JUnit 5)@BeforeTransaction 和 @AfterTransaction不再需要public，并且在 基于 Java 8 的接口的默认方法上声明在Spring TestContext Framework 的ApplicationContext的缓存现在有界为32默认最大规模和最近最少使用驱逐策略。最大的大小可以通过设置称为spring.test.context.cache.maxSize 一个 JVM 系统属性或 Spring 配置。ContextCustomizer API 用于自定义测试 ApplicationContext 在 bean 定义加载到上下文后但在上下文被刷新前。定制工具可以在全球范围由第三方进行注册，而无需要实现一个自定义的 ContextLoader。@Sql 和 @SqlGroup 现在作为元注解通过覆盖属性来创建自定义组合注解ReflectionTestUtils现在在 set 或 get 一个字段时，会自动解开代理。服务器端的 Spring MVC 测试支持具有多个值的响应头。服务器端的 Spring MVC 测试解析表单数据的请求内容和填充请求参数。服务器端的 Spring MVC 测试支持 mock 式的断言来调用处理程序方法。客户端 REST 测试支持允许指定多少次预期的请求以及期望的声明顺序是否应该被忽略（参见15.6.3，“客户端REST测试”）。客户端 REST 测试支持请求主体表单数据的预期。

支持新的类库和服务器

Hibernate ORM 5.2 (同样很好的支持 4.2/4.3 和 5.0/5.1，不推荐 3.6 )Jackson 2.8 (在Spring 4.3，最低至 Jackson 2.6+ )OkHttp 3.x (仍然并行支持 OkHttp 2.x)Netty 4.1Undertow 1.4Tomcat 8.5.2 以及 9.0 M6

参考引用

中文的 《Spring Framework 4.x参考文档》


语法：
CREATE [索引类型] INDEX 索引名称
ON 表名(列名)
WITH FILLFACTOR = 填充因子值0~100
GO


/*实例*/
USE 库名
GO
IF EXISTS (SELECT * FROM SYSINDEXES WHERE NAME='IX_TEST_TNAME')--检测是否已经存在IX_TEST_TNAME索引
DROP INDEX TEST.IX_TEST_TNAME--如果存在则删除

--创建索引
CREATE NONCLUSTERED INDEX IX_TEST_TNAME --创建一个非聚集索引
ON TEST(TNAME)  --为TEST表的TNAME字段创建索引
WITH FILLFACTOR = 30 --填充因子为30%
GO

SELECT * FROM TEST(INDEX = IX_TEST_TNAME) WHERE TNAME = 'A' --指定按‘IX_TEST_TNAME’索引查询

总结：
      1.什么是索引：数据库中的索引是某个表中一列或多列值的集合和相应的指向表中物理标识这些值的数据页的逻辑指针清单。
  2.分类：
     唯一索引(UNIQUE)：不允许两行具有相同的索引值（创建了唯一约束，系统将自动创建唯一索引）
     主键索引：主键索引要求主键中的每个值是唯一的，（创建主键自动创建主键索引）
     聚集索引(CLUSTERED)：表中各行的物理顺序与键值的逻辑（索引）顺序相同，表中只能包含一个聚集索引，主键列默认为聚集索引
     非聚集索引(NONCLUSTERED)：表中各行的物理顺序与键值的逻辑（索引）顺序不匹配，表中可以有249个非聚集索引
    3.创建索引的标准：用语频繁搜索的列；用语对数据进行排序的列
注意：如果表中仅有几行，或列中只包含几个不同的值，不推荐创建索引，因为SQL Server 在小型表中用索引搜索数据所花的时间比逐行搜索更长。

 
CREATE INDEX (SQL Server Compact Edition)
   http://msdn.microsoft.com/zh-cn/library/ms345331(SQL.90).aspx


新增： 2006 年 4 月 14 日

在指定的表上创建索引。可以在表中输入数据之前创建索引。

 语法






 


CREATE [UNIQUE] [NONCLUSTERED] INDEX index_name ON table_name (column_name [ASC|DESC][,…n])
WITH (STATISTICS_NORECOMPUTE = { ON | OFF })]








 参数





术语
定义




UNIQUE



在表上创建唯一索引。唯一索引是不允许其中任意两行具有相同索引值的索引。

SQL Server 2005 Compact Edition (SQL Server Compact Edition) 在创建索引后将检查是否存在重复的值（如果数据已存在），并在每次使用 INSERT 或 UPDATE 语句添加数据时执行该检查操作。必须先消除重复值，然后才可对列创建唯一索引。如果存在重复的键值，则将取消 CREATE INDEX 语句并返回错误。只能对定义为 NOT NULL 的列创建唯一索引。

如果存在唯一索引，则可能生成重复键值的 UPDATE 或 INSERT 语句将回滚，且 SQL Server Compact Edition 返回错误。即使 UPDATE 或 INSERT 语句更改许多行，但只要存在一个重复，上面这一点也将成立。





NONCLUSTERED



创建指定表的逻辑排序的索引。使用非聚集索引，数据行的物理顺序将独立于其索引顺序。这是唯一支持的索引类型。（默认值为 NONCLUSTERED）





index_name



指定索引的名称。索引名称在表中必须是唯一的，但是在数据库中不必是唯一的。





table_name



指定要对其创建索引的表的名称。

此表包含要建立索引的一个或多个列。





column name



要应用索引的列。指定两个或两个以上的列的名称，以对指定列中的组合值创建组合索引。在表后面的括号中，按排序优先级顺序列出要包含在组合索引中的列。




注意：


不能将包含 ntext 或 image 数据类型的列指定为要建立索引的列。

 










ASC | DESC ]



为特定的索引列确定升序 (ASC) 或降序 (DSC) 排序方向。默认值为 ASC。





n



指示可以为任何特定索引指定多列的占位符。索引中可以包含的最大列数为 16。





STATISTICS_NORECOMPUTE



指定是否重新计算分发统计信息。默认值为 OFF。

ON 
不自动重新计算过期的统计信息。OFF 
启用自动统计信息更新

若要还原自动统计信息更新，请将 STATISTICS_NORECOMPUTE 设置为 OFF，或执行不带 NORECOMPUTE 子句的 UPDATE STATISTICS。




重要事项：


禁用分发统计信息的自动重新计算功能可能会阻止查询优化器为涉及此表的查询选取最佳执行计划。

 










示例

以下示例对 MyCustomers 表创建了唯一索引：





 复制代码




CREATE TABLE MyCustomers (CustID int, CompanyName nvarchar(50))
CREATE UNIQUE INDEX idxCustId ON MyCustomers (CustId)





Anomaly：见异常值词条。  
Apache Software Foundation（ASF）：专门为支持开源软件项目而办的一个非盈利性组织。 
ARPU（Average revenue per user）：每个用户的平均收入。 
Artificial neural network:人工神经网络，通常简称神经网络。  
Avro：一个在Hadoop上的数据序列化系统，设计用于支持大批量数据交换应用。 
贝叶斯分析方法（Bayesian Analysis）：提供了一种计算假设概率的方法，这种方法是基于假设的先验概率、给定假设下观察到不同数据的概率以及观察到的数据本身而得出的。 
bounce rate：见跳出率词条。  
B2C：英文Business-to-Consumer的缩写，其中文含义为企业对消费者。
CART：Classification and Regression Trees的英文首字母缩写，或者称分类与回归树，是一种决策树分类算法。  
CBL（China Black List）：中国垃圾邮件黑名单。 
Cluster（类或簇的英文）：是一个数据对象的集合。  
Cookie: 指的是指网站为了辨别用户身份而储存在用户本地终端浏览器上的一类数据。 
CRM（用户关系管理，Customer Relationship Management）指的是公司对客户和潜在客户的管理模式。  
Direct Marketing：见直效行销词条。 Discriminant analysis：见判别分析词条。
DSS(Decision Support System)：决策支持系统的缩写，是辅助决策者通过数据、模型和知识，进行半结构化或非结构化决策的计算机应用系统。
独立访客：指在一天之内（00:00-24:00）访问网站的上网电脑数量（以cookie为依据）。 
EB：计算机存储单位，1 EB = 1,024 PB = 1,048,576 TB = 1,152,921,504,606,846,976 Bytes（字节），或是2的60次方字节。 
EDM（Email Direct Marketing）：用电子邮件进行营销的方式。  
EIS（Executive Information Systems的缩写，高级管理人员信息系统)：为高级管理人员设计的系统，用于深层次管理数据分析和运营趋势分析等。 
Entropy：见熵。  
二跳率：当网站页面展开后，用户在页面上产生的首次点击被称为“二跳”，二跳的次数即为“二跳量”，而二跳量与浏览量的比值称为页面的二跳率。 
ETL：(Extract Transform Load)的缩写，是指数据的提取、转换、加载。  
分布式数据库（Distributed Database）：用计算机网络将物理上分散的多个数据库单元连接起来组成一个逻辑统一的数据库。  
关联规则(Association rules)：是形如X→Y的蕴涵式,其中X和Y分别称为关联规则的先导(antecedent或left-hand-side, LHS)和后继(consequent或right-hand-side, RHS) 。 根节点：决策树最上面的节点。在它上面没有其他节点，其他所有的属性都是它的后续节点。 
购物篮分析（market basket analysis）：就是关联规则算法。在市场上关联规则算法经常作为商品购物车的分析，所以在应用领域又被称为购物篮分析。 
Granularity：见“粒度”。  
HBase ：一个在HDFS上搭建大规模结构化存储集群分布式存储系统，具有高可靠性、高性能、面向列，可伸缩特性。  HDFS：部署在廉价硬件上提供高吞吐量和高容错性的分布式文件系统，适合有超大数据集的应用程序。  Hive：基于Hadoop的数据仓库工具，可以将结构化的数据映射成数据表并提供类SQL数据库查询管理功能，适合于数据仓库的统计分析。  
后验概率(Posterior Probability)：当根据经验及有关材料推测出主观概率后，对其是否准确没有充分把握时，可采用概率论中的贝叶斯公式进行修正，修正前的概率称为先验概率，
修正后的概率称为后验概率。  
回归分析（regression analysis)是确定两种或两种以上变数间相互依赖的定量关系的一种统计分析方法。  计量经济学（Econometrics）是以经济学和数理统计学为方法论作为基础，对于经济问题试图用数量和经验两者进行综合的经济学分支。  基于互联网的挖掘（Web挖掘）是利用数据挖掘技术从Web文档及Web服务中自动发现并提取人们感兴趣的信息。  交叉验证(Cross-validation)：主要用于建模应用中，在给定的建模样本中，拿出大部分样本进行建模型，留小部分样本用刚建立的模型进行预报，并求这小部分样本的预报误差，记录它们的平方加和。
  
机器学习(Machine Learning)：研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。  
监督式学习（Supervised learning）：机器学习中的一类，可以由训练资料中学到或建立一个模式（函数），并依此模式推测新的样本归类或者属性。 聚类(Clustering)：将物理或抽象对象的集合分成由类似的对象组成的多个类的过程。由聚类所生成的簇是一组数据对象的集合，这些对象与同一个簇中的对象彼此相似，与其他簇中的对象相异。  
决策树（Decision Tree）：一般都是自上而下的来生成的。每个决策或事件（即自然状态）都可能引出两个或多个事件，导致不同的结果，把这种决策分支画成图形很像一棵树的枝干，
故称决策树。  
决策树剪枝（Decision tree pruning）：由于在决策树生成过程中，会过度拟合训练数据，而且易受噪声数据的影响，所以剪枝操作是决策树生成过程中的一个重要步骤。  决策支持系统(decision support system)：辅助决策者通过数据、模型和知识，以人机交互方式进行半结构化或非结构化决策的计算机应用系统。  
KDD(Knowledge discovery in database)：泛指所有从源数据中发掘模式或联系的方法 
k近邻(k nearest):一个理论上比较成熟的方法，也是最简单的机器学习算法之一。该方法的思路是：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大
多数属于某一个类别，则该样本也属于这个类别。  
LAMP：Linux，Apache，MySQL和PHP，四种web技术的缩写，是一些web2.0公司使用的主要技术组合。  
landing page：见着陆页词条。  
LBS（Location-based service）是与位置相关的软件服务的英文缩写，指的是一类利用和控制与位置及时间相关的计算机软件服务。  粒度（Granularity）：指数据仓库的数据单位中保存数据的细化或综合程度的级别。 
Lift：使用分类器相对于不使用分类器产生的正类的比例。  联机事务处理系统(OLTP)：实时采集处理与事务相连的数据以及共享数据库和其它文件的地位的变化。在联机事务处理中，事务是被立即执行的，这与批处理相反，一批事务被存储一段时间，然后再被执行。  
联机分析处理(OLAP)：使分析人员，管理人员或执行人员能够从多角度对信息进行快速一致，交互地存取，从而获得对数据的更深入了解的一类软件技术。  流量（traffic）：是指网站的访问量，是用来描述访问一个网站或是网店的用户数量以及用户所浏览的网页数量等一系列指标，这些指标主要包括：独立访客数量（unique visitors）、 ·页面浏览数（page views）、每个访客的页面浏览数（Page Views per user）。 
六度分隔理论（Six Degrees of Separation）：是个假设，在人际关系脉络方面您可以通过不超出六位中间人直接与世上任意人认识。 LNMP：Linux，Nginx，MySQL和PHP，四种web技术的缩写，是一些web2.0公司使用的主要技术组合。  
Metadata：见元数据。  
MapReduce：HDFS上处理大数据集的并行计算框架。 
MongoDB: 是一个基于分布式文件存储的数据库。 
Nginx：开源的高性能HTTP服务器。 
Outlier: 见异常点词条。 
PAM：见围绕中心点的划分聚类算法。
判别分析(Discriminant analysis)：是在分类确定的条件下，根据某一研究对象的各种特征值判别其类型归属问题的一种多变量统计分析方法。 
PB：计算机存储单位，1 PB = 1,024 TB = 1,048,576 GB = 1，125，899，906，842，624 Bytes（字节），或是2的50次方字节。 
PU学习：正例和无标记样本学习（Learning from Positive and Unlabeled examples）一般称为LPU或PU学习，是一种半监督学习方法。  Pig：在HDFS和MapReduce上处理大规模数据集的脚本语言，它提供更高层次的抽象并转化为优化处理的MapReduce运算。  
频繁集（frequent itemset）：是大于最小支持度的项目集。  
强关联规则：如果某条规则同时满足最小支持度（min-support）和最小置信度（min-confidence），则称它为强关联规则。 R语言：R是属于GNU系统的一个自由、免费、源代码开放的软件，是一个用于统计计算和统计制图的工具。  
REST（Representational State Transfer，表现状态转移）：是Roy Fielding博士在2000年他的博士论文中提出来的一种软件架构风格，在此风格中，每个资源是由全球唯一的URI来指定，
资源本身和其表现方式是完全独立的；当一个用户拿到资源的表现方式时，他有足够的信息可以修改或者删除服务器上相应的资源而且每条消息都包含了足够的信息可以描述消息的处理。  热图（heat map）：热图或热力图是数据的一种二维呈现，其中的数值都用颜色表示。一个简单的热图提供信息的即时可见概况。  
人工神经网络（Artificial Neural Networks）：一种模范动物神经网络行为特征，进行分布式并行信息处理的算法数学模型。这种网络依靠系统的复杂程度，通过调整内部
大量节点之间相互连接的关系，从而达到处理信息的目的。  
人工智能(Artificial Intelligence)：研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门新的技术科学。它企图了解智能的实质，
并生产出一种新的能以人类智能相似的方式做出反应的智能机器。  
3C产品：3C产品指的是通讯产品（Communication），消费类电子产品（Consumer Electronics）和电脑产品（Computer），三类产品的首字母都是C，所以称3C SEMMA是数据挖掘过程(Sample, Explore, Modify, Model,and Assess)的英文缩写，意思是抽样，检查，修改，设立模型和评估。  熵（entropy）:指的是体系的混乱的程度，它在控制论、概率论、数论、天体物理、生命科学等领域都有重要应用，在不同的学科中也有引申出的更为具体的定义，是各领域十分重要的参量。熵由鲁道夫·克劳修斯（Rudolf
 Clausius）提出，并应用在热力学中。后来在，克劳德·艾尔伍德·香农（Claude Elwood Shannon）第一次将熵的概念引入到信息论中来。 商业智能（Business Intelligence）：采用数据库或数据仓库技术进行商业信息的收集，集成，分析和报告以帮助做决策的应用与实践系统。  
时间序列（Time Series）：是指将某种现象某一个统计指标在不同时间上的各个数值，按时间先后顺序排列而形成的序列。时间序列法是一种定量预测方法，亦称简单外延方法。 
事务数据库(Transaction Database)：由文件构成，每条记录代表一个事务。典型的事务包含唯一的事务标记，多个项目组成一个事务  
数据结构（data structure)：各种数据之间的逻辑关系，用来支持特定的数据处理功能，比如树、列表和链接表。  
数据可视化(Data Visualization)：关于数据的视觉表现形式的研究，这种数据的视觉表现形式被定义为一种以某种概要形式抽提出来的信息，包括相应信息单位的各种属性和变量。  数据挖掘(Data Mining)：从存放在数据库，数据仓库或其他信息库中的大量的数据中获取有效的、新颖的、潜在有用的、最终可理解的模式的过程。  
数据可视化（Data Visualization）：多维度数据通过图形的方式来做的展现  数据仓库：是决策支持系统（DSS）和联机分析应用数据源的结构化数据环境。数据仓库研究和解决从数据库中获取信息的问题。数据仓库的特征在于面向主题、集成性、稳定性和时变性。  数据清洗(data cleaning)：过滤那些不符合要求的数据，将过滤的结果交给业务主管部门，确认是否过滤掉还是由业务单位修正之后再进行抽取。 数据库（Database）：是按照数据结构来组织、存储和管理数据的仓库。  属性(attribute)：属性是实体的描述性性质或特征，具有数据类型、域、默认值三种性质。属性也往往用于对控件特性的描述。对于按钮控件的名称、显示的文字、背景色，背景图片等等。SNS：是社会化服务网络，Social
 Services Networks的英文首字母缩写。 
spatio-temporal data mining：时间和空间数据的挖掘。  
Sqoop：一个用来将Hadoop和关系型数据库中的数据相互转移的工具。 
索引（Index）：在数据库中，用来对记录提供有效访问的标记。  
特征选择（Feature Selection ) ：是指从已有的M个特征(Feature)中选择N个特征使得系统的特定指标最优化。  统计学（statistics）：是应用数学的一个分支，主要通过利用概率论建立数学模型，收集所观察系统的数据，进行量化的分析、总结，并进而进行推断和预测，为相关决策提供依据和参考。它被广泛的应用在各门学科之上，从物理和社会科学到人文科学，甚至被用来工商业及政府的情报决策之上。  
跳出率（bounce rate）是互联网上的一个常用指标，指的是进入某一个网站之后不再继续浏览，而直接离开网站的访客比例。通常来说，跳出率越高，网站的粘性就越低。 Traffic：见流量词条。  
UGC：User Generated Content的缩写，即用户生成内容。  
Web log项（日志项）：网络上的服务器记录所有访问该Web服务器的数据流的信息。 
Web挖掘(Web Mining): Web挖掘是数据挖掘在Web上的应用，它利用数据挖掘技术从与WWW相关的资源和行为中抽取感兴趣的、有用的模式和隐含信息，涉及Web技术、数据挖掘、
计算机语言学、信息学等多个领域，是一项综合技术。  
围绕中心点的划分聚类算法（PAM）：通过反复地用非代表对象来代替代表对象，提高聚类的质量的算法。  唯一浏览量：是指网站来源是搜索引擎下的广告主网站的唯一浏览量，即在浏览量的基础上，不被记作重复的浏览量，刷新的浏览量不被记作唯一浏览量。  
无监督学习（unsupervised learning）：机器学习的一种，指从无标记的数据中找出隐藏结构信息的方法。 
先验概率:见后验概率词条。  
线性模型(linear model) ：是一种分析模型，它假定考虑的各变化因素是线性的关系。
协作推荐：是利用用户访问行为的相似性来相互推荐用户可能感兴趣的资源。  
文本挖掘（text mining）:指从文本数据中抽取有价值的信息和知识的计算机处理技术。即从文本中进行数据挖掘。从这个意义上讲，文本挖掘是数据挖掘的一个分支,由机器学习、
数理统计、自然语言处理等多种学科交叉形成。  
信息检索（Information Retrieval）：指信息按一定的方式组织起来，并根据信息用户的需要找出有关的信息的过程和技术。  
信息增益（Information Gain）是衡量一个属性区分数据样本的能力。信息增益量越大，对信息分类的能力就越强。而用来计算信息增益的公式就需要用到熵（Entropy）。 相关分析（correlation analysis），相关分析是研究现象之间是否存在某种依存关系，并对具体有依存关系的现象探讨其相关方向以及相关程度，是研究随机变量之间的相关关系的
一种统计方法。  
序列算法：在数据挖掘中的序列算法是对于一个序列（sequence）中的数据找出统计规律的算法。  
异常点(Outlier): 在大规模数据集中，通常存在着不遵循数据模型的普遍行为的样本。这些样本和其他部分数据有很大不问或不一致，叫作异常点(Outlier)，也有翻译成局外者的。 异常值（anomaly）的定义是基于某种度量而言，异常值是指样本中的个别值，其数值明显偏离它（或他们）所属样本的其余观测值。  
遗传算法（Genetic Algorithm）是模拟达尔文生物进化论的自然选择和遗传学机理的生物进化过程的计算模型，是一种通过模拟自然进化过程搜索最优解的方法。  元数据（Metadata）：是指描述数据仓库内数据的结构和建立方法的数据，是关于数据的数据， 是对数据的结构、内容、键码、索引等的一中描述。 
ZB：计算机存储单位。1 ZB = 1,024 EB = 1,180,591,620,717,411,303,424 Bytes（字节） ，或者是2的70次方字节。  
召回率(Recall Rate,也叫查全率)：是检索出的相关文档数和文档库中所有的相关文档数的比率。 
直效行销（Direct Marketing）：又名零阶通路，是指制造商或零售商，直接将产品出售给消费者，使通路阶层降至零阶或一阶，减少中间费用，为消费者取得较低价格的销售方式。 知识工程（Knowledge Engineering）：人工智能的原理和方法，对那些需要专家知识才能解决的应用难题提供求解的手段。  
知识发现（KDD：Knowledge Discovery in Databases）：从数据集中识别出有效的、新颖的、潜在有用的，以及最终可理解的模式的非平凡过程。  支持度（support）：描述关联规则的阈值，反映符合关联规则模式的任务相关的元组（或事务）所占的百分比。  
支持向量机(Support Vector Machine,SVM):Corinna Cortes和Vapnik8等于1995年首先提出的，它在解决小样本、非线性及高维模式识别中表现出许多特有的优势，
并能够推广应用到函数拟合等其他机器学习问题中。  
主成分分析（Principal Component Analysis，PCA）： 将多个变量通过线性变换以选出较少个数重要变量的一种多元统计分析方法。 
转化率(Conversion Rate)指的是产生实际消费的用户和来到用户网页的总用户数量的比值，是将流量转化为实际的销售额的一种衡量方式。 置信度(Confidence):衡量关联规则的可信程度。  
着陆页（landing page），指的是网站中的一个市场营销专用页面，通常是搜索引擎或是其他广告所指向的页面。 
自助法(bootstrap)：非参数统计中一种重要的估计统计量，采用重抽样技术从原始样本中抽取一定数量（自己给定）的样本。  Zookeeper：一个针对大型分布式系统的可靠协调系统，提供功能包括：配置维护、名字服务、分布式同步、组服务等。  
最大频繁项集（Maximal Frequent Itemsets，MFI）:频繁地出现在数据集中的最大子集。 
最大似然估计:是用来求一个样本集的相关概率函数的参数的一种统计方法。
   

JMM：Java Memory Model(Java内存模型)，围绕着在并发过程中如何处理可见性、原子性、有序性这三个特性而建立的模型。


可见性：JMM提供了volatile变量定义、final、synchronized块来保证可见性。
例如：线程a在将共享变量x=1写入主内存的时候，如何保证线程b读取共享变量x的值为1，这就是JMM做的事情。JMM通过控制主内存与每个线程的本地内存之间的交互，来为java程序员提供内存可见性保证。

原子性：JMM提供保证了访问基本数据类型的原子性（其实在写一个工作内存变量到主内存要两步：store、write），但是实际业务处理场景往往是需要更大的范围的原子性保证，所以模型也提供了synchronized块来保证

有序性：这个概念是相对而言的，如果在本线程内，所有的操作都是有序的，如果在一个线程观察另一个线程，所有的操作都是无序的，前句是“线程内表现为串行行为”，后句是“指令的重排序”和“工作内存和主内存同步延迟”现象，模型提供了volatile和synchronized来保证线程之间操作的有序性。

重排序：在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序(编译器、处理器)，就是因为这些重排序，所以可能会导致多线程程序出现内存可见性问题(数据安全问题)和有序性问题。
JMM是如何处理的呢？
对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排序。
对于处理器重排序，JMM的处理器重排序规则会要求java编译器在生成指令序列时，插入特定类型的内存屏障（memory barriers，intel称之为memory fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序。
总之一句话，JMM是通过禁止特定类型的编译器重排序和处理器重排序来为程序员提供一致的内存可见性保证。

A线程具体什么时候刷新共享数据到主内存是不确定的，假设我们使用了同步原语(synchronized，volatile和final),那么刷新的时间是确定的，例如：线程A释放锁后会同步到主内存，线程B获取锁后会同步主内存数据。
即“A线程释放锁--B线程获取锁”可以实现A，B线程之间的通信。




JMM有以下主要的规则： 


An Unlock operation on a monitor synchronizes-with later lock operations. 当针对一个监控对象执行解锁操作时，首先synchronizes-with随后的锁操作。即当要解锁时，首先此操作会把它范围内的对象与主存同步，然后解锁，之后才会执行随后其他的锁操作。A write to a volatile variable synchronizes-with later reads of the variable. 当写一个volatile变量时，首先synchronizes-with随后的读此变量的操作。即当写完一个volatile变量后，JVM会首先将此变量与主存同步，然后才执行随后的读volatile变量操作。当然也从主存读了。If an action A synchronizes-with action B, then A happens-before B. 如果时行为A synchronizes-with 行为B，那么行为A happens-before B。If A comes before B in program order within a thread, then A happens-before B. 在同一个线程中如果程序中A在B之前，那么A也一定发生在B之前。The completion of a constructor happens-before the finalizer for that object starts to run. 完成构造函数会发生在此对象的finalizer启动之前，即在对一个对象回收前，此对象必须已经构造完毕。An action which starts a Thread synchronizes-with the first action of the new Thread. 创建了一个新线程的行为synchronizes-with这个线程的第一个操作。即创建完新线程后，JVM首先要把这个线程的信息同步给主存，然后才可以执行这个线程内部的其他操作。Thread.join() synchronizes-with the last (and all other) actions in the thread being joined. Thread.join()函数synchronizes-with被join的线程内部的所有其他操作。即执行Thread.join()之后JVM首先会把信息跟主存同步，然后才会继续执行被join线程内部的其他操作。(Transitivity) If X happens-before Y, and Y happens-before Z, then X happens-before Z. 传递性，即X在Y之前执行，Y在Z之前执行，那么X会在Z之前执行。
前面的两条规则是说：“releases happen before acquires;” （解锁发生在获取锁之前）即：一个线程拿着锁，当写操作完毕后首先释放锁，然后这个锁才能被其他线程获得 。

以上的这些规则是JMM所做的基本保证，在真正的JVM实现中会有更多更好的规则。




Java有哪四个核心技术？首先，我们要了解一下java核心技术的重要性，它可以帮助我们举一反三、触类旁通，有助于提升我们对整个Java平台的理解力。





一：Java虚拟机    
Java虚拟机的主要任务是装载class文件并且执行其中的字节码。Java虚拟机包含一个类装载器，它可以从程序和API中装载class文件。Java
 API中只有程序执行时需要的那些类才会被装载。字节码由执行引擎来执行。不同的Java虚拟机中，执行引擎可能实现得非常不同。在由软件实现的虚拟机中，最简单的执行引擎就是一次性解释字节码。另一种执行引擎更快，但是也更消耗内存，叫做"即时编译器(just-in-time compiler)"。在这种情况下，第一次被执行的字节码会被编译成本地机器代码。编译出的本地机器代码会被缓存，当方法以后被调用的时候可以重用。第三种执行引擎是自适应优化器。在这种方法里，虚拟机开始的时候解释字节码，但是会监视运行中程序的活动，并且记录下使用最频繁的代码段。程序运行的时候，虚拟机只把那些活动最频繁的代码编译成本地代码，其他的代码由于使用得不是很频繁，继续保留为字节码-由虚拟机继续解释它们。一个自适应的优化器可以使得Java虚拟机在80%~90%的时间里执行被优化过的本地代码，而只需要编译10%~20%的对性能有影响的代码。

当Java虚拟机是由主机操作系统上的软件实现的时候，Java程序通过调用本地方法(native
 method)和主机交互。Java中有两种方法: Java方法和本地方法。Java方法是由Java语言编写，编译成字节码文件，存储在class文件中的。本地方法是由其他语言(比如c,c++或汇编语言)编写的，编译成和处理器相关的机器代码。本地方法保存在动态链接库中,格式是各个平台专有的。运行中Java程序调用本地方法时，虚拟机装载包含这个本地方法的动态库，并调用这个方法。本地方法是联系Java程序和底层主机操作系统的连接方法。



二：类装载器的体系结构

一个Java应用程序可以使用两种类装载器："启动(bootstrap)"类装载器和用户定义的类装载器。启动类装载器(这是系统中唯一的)是Java虚拟机实现的一部分。启动类装载器通常使用某种默认方式从本地磁盘中装载类，包括Java
 API类(启动类装载器也被称为原始类装载器、系统类装载器或者默认类装载器)。

Java应用程序能够在运行时安装用户定义的类装载器，这种类装载器能够使用自定义的方式来装载类。例如，从网络下载class文件。尽管启动类装载器是虚拟机实现的本质部分，而用户定义的类装载器不是，但用户定义的类装载器能够用Java来编写,能够被编译成class文件，能够被虚拟机装载，还能够像其它对象一样实例化。

由于由用户定义类装载器，所以不必在编译的时候就知道运行中的Java应用程序中最终会加入的所有的类。用户定义的类装载器使得运行扩展Java应用程序成为可能。当它运行时，应用程序能够解决它需要哪些额外的类，能够决定是使用一个或是更多的用户定义的类装载器来装载。由于类装载器是用Java编写的，所以可用任何在Java代码中表述的风格来进行类装载。这些类可以通过网络下载，可以从某些数据库中获取，甚至可以动态生成。

每一个类被装载的时候，Java虚拟机都监视这个类，看到它到底是被启动类装载器还是被用户定义类装载器装载。当被装载的类引用了另外一个类时，虚拟机就会使用装载第一个类的类装载器装载引用的类。例如，如果虚拟机使用一个特定的类装载器装载Volcano这个类，它就会使用这个类装载器装载Volcano类使用的所有类。

由于Java虚拟机采取这种方式进行类的装载，所以被装载的类默认情况下只能看到被同一个类装载器装载的别的类。通过这种方法，Java的体系结构允许在一个Java应用程序中建立多个命名空间。运行时的Java程序中的每一个类装载器都有自己的命名空间。

Java应用程序可以创建多少个(或多种)被不同的类装载器装载的类存放在不同的命名空间中，它们不能相互访问，除非应用程序显示地允许这么做。当编写一个Java应用程序的时候，从不同源文件装载的类可以分隔在不同的命名空间中。通过这种方法，就能够使用Java类装载器的体系结构来控制任何不同源文件中装载的代码之间的相互影响，特别是能够阻止恶意代码获取访问或破坏善意代码的权限。

Web浏览器是一个动态扩展的例子，Web浏览器使用用户定义的类装载器从网络下载用于Java
 applet的class文件。Web浏览器使用一个用来安装用户定义类装载器的Java应用程序。这个用户定义的类装载器通常被称为Java Applet类装载器，它知道如何向HTTP服务器请求class文件。Java Applet可以作为动态扩展的例子，因为Java应用程序并不知道它什么时候会开始从网络下载浏览器请求的class文件。只有当浏览器遇到有Java applet的页面时，才决定是否需要下载class文件。

Web浏览器启动的Java应用程序通常为每个提供class文件的网络地址分别创建不同的用户定义类装载器，因此，不同的用户定义类装载器装载不同来源的class文件。这就可以把它们分别放置在Java主机应用程序的不同命名空间之下。由于不同来源的Java
 applet文件放置在不同的命名空间中，恶意的Java applet代码就不会直接访问从别的地方下载的class文件。这就能够限制或阻止不同来源的代码之间的相互访问。



三：Java class文件 

Java
 class文件主要在平台无关性和网络移动性方面使Java更适合网络。它在平台无关性方面的任务是：为Java程序提供独立于底层主机平台的二进制形式的服务。这种途径途径打破了C或者C++等语言所遵循的传统，使用这些传统语言写的程序通常首先被编译，然后被连接成单独的、专门支持特定硬件平台和操作系统的二进制文件。通常情况下，一个平台上的二进制可执行文件不能在其他平台上工作。而Java class文件时可以运行在任何支持Java虚拟机的硬件平台和操作系统上的二进制文件。

当编译和连接一个C++程序时，所获得的可执行二进制文件只能在指定的硬件平台和操作系统上运行，因为这个二进制文件包含了对目标处理器的机器语言。而Java编译器把Java源文件的指令翻译成字节码，这种字节码就是Java虚拟机的"机器语言"。class文件设计得紧凑，因此它们可以快速地在网络上传送。其次，由于Java程序是动态连接和动态扩展的，class文件可以在需要的时候才下载。这个特点使得Java应用程序能够安排从网络上下载class文件的时间，从而可以最大限度地减少终端用户的等待时间。


四：Java
 API 

Java
 API通过支持平台无关性和安全性，使得Java适应于网络应用。Java API是运行库的集合，它提供了一套访问主机系统资源的标准方法。运行Java程序时，虚拟机装载程序的class文件所使用的Java API class文件。所有被装载的class文件(包括从应用程序中和从Java API中提取的)和所有已经装载的动态库(包含本地方法)共同组成了在Java虚拟机上运行的整个程序。

在一个平台能够支持Java程序以前，必须在这个特定平台上明确地实现API的功能。为访问主机上的本地资源，Java API调用了本地方法。由于Java
 API class文件调用了本地方法，Java程序就不需要再调用它们了。通过这种方法，Java API class文件为底层主机提供了具有平台无关性、标准接口的Java程序。对Java程序而言，无论平台内部如何，Java API都会有同样的表现和可预测的行为。正是由于在每个特定的主机平台上明确地实现了Java虚拟机和Java API,因此，Java程序自身就能够成为具有平台无关性的程序。

Java
 API在Java安全性模型方面也有贡献。当Java API的方法进行任何有潜在危险的操作(比如进行本地磁盘写操作)之前，都会通过查询访问控制器来检验是否得到了授权。访问控制器是一个类，该类用来执行栈检验，已决定是否允许某种操作。





1. 查看docker信息（version、info）
# 查看docker版本  
$docker version  
# 显示docker系统的信息  
$docker info  

2. 对image的操作（search、pull、images、rmi、history）
# 检索image  
$docker search image_name  
# 下载image  
$docker pull image_name  
# 列出镜像列表; -a, --all=false Show all images; --no-trunc=false Don't truncate output; -q, --quiet=false Only show numeric IDs  
$docker images  
# 删除一个或者多个镜像; -f, --force=false Force; --no-prune=false Do not delete untagged parents  
$docker rmi image_name  
# 显示一个镜像的历史; --no-trunc=false Don't truncate output; -q, --quiet=false Only show numeric IDs  
$docker history image_name  

3. 启动容器（run）
docker容器可以理解为在沙盒中运行的进程。这个沙盒包含了该进程运行所必须的资源，包括文件系统、系统类库、shell 环境等等。但这个沙盒默认是不会运行任何程序的。你需要在沙盒中运行一个进程来启动某一个容器。这个进程是该容器的唯一进程，所以当该进程结束的时候，容器也会完全的停止。

# 在容器中运行"echo"命令，输出"hello word"  
$docker run image_name echo "hello word"  
# 交互式进入容器中  
$docker run -i -t image_name /bin/bash  
# 在容器中安装新的程序  
$docker run image_name apt-get install -y app_name  

Note：  在执行apt-get 命令的时候，要带上-y参数。如果不指定-y参数的话，apt-get命令会进入交互模式，需要用户输入命令来进行确认，但在docker环境中是无法响应这种交互的。apt-get 命令执行完毕之后，容器就会停止，但对容器的改动不会丢失。

4. 查看容器（ps）
# 列出当前所有正在运行的container  
$docker ps  
# 列出所有的container  
$docker ps -a  
# 列出最近一次启动的container  
$docker ps -l  

5. 保存对容器的修改（commit）
当你对某一个容器做了修改之后（通过在容器中运行某一个命令），可以把对容器的修改保存下来，这样下次可以从保存后的最新状态运行该容器。

# 保存对容器的修改; -a, --author="" Author; -m, --message="" Commit message  
$docker commit ID new_image_name  

Note：  image相当于类，container相当于实例，不过可以动态给实例安装新软件，然后把这个container用commit命令固化成一个image。

6. 对容器的操作（rm、stop、start、kill、logs、diff、top、cp、restart、attach）
# 删除所有容器  
$docker rm `docker ps -a -q`  
# 删除单个容器; -f, --force=false; -l, --link=false Remove the specified link and not the underlying container; -v, --volumes=false Remove the volumes associated to the container  
$docker rm Name/ID  
# 停止、启动、杀死一个容器  
$docker stop Name/ID  
$docker start Name/ID  
$docker kill Name/ID  
# 从一个容器中取日志; -f, --follow=false Follow log output; -t, --timestamps=false Show timestamps  
$docker logs Name/ID  
# 列出一个容器里面被改变的文件或者目录，list列表会显示出三种事件，A 增加的，D 删除的，C 被改变的  
$docker diff Name/ID  
# 显示一个运行的容器里面的进程信息  
$docker top Name/ID  
# 从容器里面拷贝文件/目录到本地一个路径  
$docker cp Name:/container_path to_path  
$docker cp ID:/container_path to_path  
# 重启一个正在运行的容器; -t, --time=10 Number of seconds to try to stop for before killing the container, Default=10  
$docker restart Name/ID  
# 附加到一个运行的容器上面; --no-stdin=false Do not attach stdin; --sig-proxy=true Proxify all received signal to the process  
$docker attach ID  

Note： attach命令允许你查看或者影响一个运行的容器。你可以在同一时间attach同一个容器。你也可以从一个容器中脱离出来，是从CTRL-C。

7. 保存和加载镜像（save、load）
当需要把一台机器上的镜像迁移到另一台机器的时候，需要保存镜像与加载镜像。

# 保存镜像到一个tar包; -o, --output="" Write to an file  
$docker save image_name -o file_path  
# 加载一个tar包格式的镜像; -i, --input="" Read from a tar archive file  
$docker load -i file_path  
# 机器a  
$docker save image_name &gt; /home/save.tar  
# 使用scp将save.tar拷到机器b上，然后：  
$docker load &lt; /home/save.tar  

8、 登录registry server（login）
# 登陆registry server; -e, --email="" Email; -p, --password="" Password; -u, --username="" Username  
$docker login  

9. 发布image（push）

# 发布docker镜像  
$docker push new_image_name  

10.  根据Dockerfile 构建出一个容器

#build  
      --no-cache=false Do not use cache when building the image  
      -q, --quiet=false Suppress the verbose output generated by the containers  
      --rm=true Remove intermediate containers after a successful build  
      -t, --tag="" Repository name (and optionally a tag) to be applied to the resulting image in case of success  
$docker build -t image_name Dockerfile_path
   


对于SQL Server的优化来说，优化查询可能是很常见的事情。由于数据库的优化，本身也是一个涉及面比较的广的话题， 因此本文只谈优化查询时如何看懂SQL Server查询计划。毕竟我对SQL Server的认识有限，如有错误，也恳请您在发现后及时批评指正。

首先，打开【SQL Server Management Studio】，输入一个查询语句看看SQL Server是如何显示查询计划的吧。
说明：本文所演示的数据库，是我为一个演示程序专用准备的数据库， 可以在此网页中下载。
select v.OrderID, v.CustomerID, v.CustomerName, v.OrderDate, v.SumMoney, v.Finished
from   OrdersView as v
where v.OrderDate &gt;= '2010-12-1' and v.OrderDate &lt; '2011-12-1';


其中，OrdersView是一个视图，其定义如下：
SELECT     dbo.Orders.OrderID, dbo.Orders.CustomerID, dbo.Orders.OrderDate, 
            dbo.Orders.SumMoney, dbo.Orders.Finished, 
            ISNULL(dbo.Customers.CustomerName, N'') AS CustomerName
FROM         dbo.Orders LEFT OUTER JOIN
                dbo.Customers ON dbo.Orders.CustomerID = dbo.Customers.CustomerID


对于前一句查询，SQL Server给出的查询计划如下（点击工具栏上的【显示估计的执行计划】按钮）：



从这个图中，我们至少可以得到3个有用的信息：
1. 哪些执行步骤花费的成本比较高。显然，最右边的二个步骤的成本是比较高的。
2. 哪些执行步骤产生的数据量比较多。对于每个步骤所产生的数据量， SQL Server的执行计划是用【线条粗细】来表示的，因此也很容易地从分辨出来。
3. 每一步执行了什么样的动作。

对于一个比较慢的查询来说，我们通常要知道哪些步骤的成本比较高，进而，可以尝试一些改进的方法。 一般来说，如果您不能通过：提高硬件性能或者调整OS,SQL Server的设置之类的方式来解决问题，那么剩下的可选方法通常也只有以下这些了：
1. 为【scan】这类操作增加相应字段的索引。
2. 有时重建索引或许也是有效的，具体情形请参考后文。
3. 调整语句结构，引导SQL Server采用其它的查询方案去执行。
4. 调整表结构（分表或者分区）。

下面再来说说一些很重要的理论知识，这些内容对于执行计划的理解是很有帮助的。

回到顶部

SQL Server 查找记录的方法

说到这里，不得不说SQL Server的索引了。SQL Server有二种索引：聚集索引和非聚集索引。二者的差别在于：【聚集索引】直接决定了记录的存放位置， 或者说：根据聚集索引可以直接获取到记录。【非聚集索引】保存了二个信息：1.相应索引字段的值，2.记录对应聚集索引的位置（如果表没有聚集索引则保存记录指针）。 因此，如果能通过【聚集索引】来查找记录，显然也是最快的。

SQL Server 会有以下方法来查找您需要的数据记录：
1. 【Table Scan】：遍历整个表，查找所有匹配的记录行。这个操作将会一行一行的检查，当然，效率也是最差的。
2. 【Index Scan】：根据索引，从表中过滤出来一部分记录，再查找所有匹配的记录行，显然比第一种方式的查找范围要小，因此比【Table Scan】要快。
3. 【Index Seek】：根据索引，定位（获取）记录的存放位置，然后取得记录，因此，比起前二种方式会更快。
4. 【Clustered Index Scan】：和【Table Scan】一样。注意：不要以为这里有个Index，就认为不一样了。 其实它的意思是说：按聚集索引来逐行扫描每一行记录，因为记录就是按聚集索引来顺序存放的。 而【Table Scan】只是说：要扫描的表没有聚集索引而已，因此这二个操作本质上也是一样的。
5. 【Clustered Index Seek】：直接根据聚集索引获取记录，最快！

所以，当发现某个查询比较慢时，可以首先检查哪些操作的成本比较高，再看看那些操作在查找记录时， 是不是【Table Scan】或者【Clustered Index Scan】，如果确实和这二种操作类型有关，则要考虑增加索引来解决了。 不过，增加索引后，也会影响数据表的修改动作，因为修改数据表时，要更新相应字段的索引。所以索引过多，也会影响性能。 还有一种情况是不适合增加索引的：某个字段用0或1表示的状态。例如可能有绝大多数是1，那么此时加索引根本就没有意义。 这时只能考虑为0或者1这二种情况分开来保存了，分表或者分区都是不错的选择。

如果不能通过增加索引和调整表来解决，那么可以试试调整语句结构，引导SQL Server采用其它的查询方案去执行。 这种方法要求： 1.对语句所要完成的功能很清楚， 2.对要查询的数据表结构很清楚， 3.对相关的业务背景知识很清楚。 如果能通过这种方法去解决，当然也是很好的解决方法了。不过，有时SQL Server比较智能，即使你调整语句结构，也不会影响它的执行计划。

如何比较二个相同功能的SQL语句的性能好坏呢，我建议采用二种方法： 1. 直接把二个查询语句放在【SQL Server Management Studio】，然后去看它们的【执行计划】，SQL Server会以百分比的方式告诉你二个查询的【查询开销】。 这种方法简单，通常也是可以参考的，不过，有时也会不准，具体原因请接着往下看(可能索引统计信息过旧)。
2. 根据真实的程序调用，写相应的测试代码去调用：这种方法就麻烦一些，但是它更能代表现实调用情况， 得到的结果也是更具有参考价值的，因此也是值得的。

回到顶部

SQL Server Join 方式

在SQL Server中，每个join命令，都会在内部执行时采用三种更具体的方式来运行：

1. 【Nested Loops join】，如果一个联接输入很小，而另一个联接输入很大而且已在其联接列上创建了索引， 则索引 Nested Loops 连接是最快的联接操作，因为它们需要的 I/O 和比较都最少。

嵌套循环联接也称为“嵌套迭代”，它将一个联接输入用作外部输入表（显示为图形执行计划中的顶端输入），将另一个联接输入用作内部（底端）输入表。外部循环逐行处理外部输入表。内部循环会针对每个外部行执行，在内部输入表中搜索匹配行。可以用下面的伪码来理解：
foreach(row r1 in outer table)
    foreach(row r2 in inner table)
        if( r1, r2 符合匹配条件 )
            output(r1, r2);


最简单的情况是，搜索时扫描整个表或索引；这称为“单纯嵌套循环联接”。如果搜索时使用索引，则称为“索引嵌套循环联接”。如果将索引生成为查询计划的一部分（并在查询完成后立即将索引破坏），则称为“临时索引嵌套循环联接”。查询优化器考虑了所有这些不同情况。

如果外部输入较小而内部输入较大且预先创建了索引，则嵌套循环联接尤其有效。在许多小事务中（如那些只影响较小的一组行的事务），索引嵌套循环联接优于合并联接和哈希联接。但在大型查询中，嵌套循环联接通常不是最佳选择。

2. 【Merge Join】，如果两个联接输入并不小但已在二者联接列上排序（例如，如果它们是通过扫描已排序的索引获得的），则合并联接是最快的联接操作。如果两个联接输入都很大，而且这两个输入的大小差不多，则预先排序的合并联接提供的性能与哈希联接相近。但是，如果这两个输入的大小相差很大，则哈希联接操作通常快得多。

合并联接要求两个输入都在合并列上排序，而合并列由联接谓词的等效 (ON) 子句定义。通常，查询优化器扫描索引（如果在适当的一组列上存在索引），或在合并联接的下面放一个排序运算符。在极少数情况下，虽然可能有多个等效子句，但只用其中一些可用的等效子句获得合并列。

由于每个输入都已排序，因此 Merge Join 运算符将从每个输入获取一行并将其进行比较。例如，对于内联接操作，如果行相等则返回。如果行不相等，则废弃值较小的行并从该输入获得另一行。这一过程将重复进行，直到处理完所有的行为止。

合并联接操作可以是常规操作，也可以是多对多操作。多对多合并联接使用临时表存储行（会影响效率）。如果每个输入中有重复值，则在处理其中一个输入中的每个重复项时，另一个输入必须重绕到重复项的开始位置。 可以创建唯一索引告诉SQL Server不会有重复值。

如果存在驻留谓词，则所有满足合并谓词的行都将对该驻留谓词取值，而只返回那些满足该驻留谓词的行。

合并联接本身的速度很快，但如果需要排序操作，选择合并联接就会非常费时。然而，如果数据量很大且能够从现有 B 树索引中获得预排序的所需数据，则合并联接通常是最快的可用联接算法。

3. 【Hash Join】，哈希联接可以有效处理未排序的大型非索引输入。它们对复杂查询的中间结果很有用，因为： 1. 中间结果未经索引（除非已经显式保存到磁盘上然后创建索引），而且通常不为查询计划中的下一个操作进行适当的排序。 2. 查询优化器只估计中间结果的大小。由于对于复杂查询，估计可能有很大的误差，因此如果中间结果比预期的大得多，则处理中间结果的算法不仅必须有效而且必须适度弱化。

哈希联接可以减少使用非规范化。非规范化一般通过减少联接操作获得更好的性能，尽管这样做有冗余之险（如不一致的更新）。哈希联接则减少使用非规范化的需要。哈希联接使垂直分区（用单独的文件或索引代表单个表中的几组列）得以成为物理数据库设计的可行选项。

哈希联接有两种输入：生成输入和探测输入。查询优化器指派这些角色，使两个输入中较小的那个作为生成输入。

哈希联接用于多种设置匹配操作：内部联接；左外部联接、右外部联接和完全外部联接；左半联接和右半联接；交集；联合和差异。此外，哈希联接的某种变形可以进行重复删除和分组，例如 SUM(salary) GROUP BY department。这些修改对生成和探测角色只使用一个输入。

哈希联接又分为3个类型：内存中的哈希联接、Grace 哈希联接和递归哈希联接。

内存中的哈希联接：哈希联接先扫描或计算整个生成输入，然后在内存中生成哈希表。根据计算得出的哈希键的哈希值，将每行插入哈希存储桶。如果整个生成输入小于可用内存，则可以将所有行都插入哈希表中。生成阶段之后是探测阶段。一次一行地对整个探测输入进行扫描或计算，并为每个探测行计算哈希键的值，扫描相应的哈希存储桶并生成匹配项。

Grace 哈希联接：如果生成输入大于内存，哈希联接将分为几步进行。这称为“Grace 哈希联接”。每一步都分为生成阶段和探测阶段。首先，消耗整个生成和探测输入并将其分区（使用哈希键上的哈希函数）为多个文件。对哈希键使用哈希函数可以保证任意两个联接记录一定位于相同的文件对中。因此，联接两个大输入的任务简化为相同任务的多个较小的实例。然后将哈希联接应用于每对分区文件。

递归哈希联接：如果生成输入非常大，以至于标准外部合并的输入需要多个合并级别，则需要多个分区步骤和多个分区级别。如果只有某些分区较大，则只需对那些分区使用附加的分区步骤。为了使所有分区步骤尽可能快，将使用大的异步 I/O 操作以便单个线程就能使多个磁盘驱动器繁忙工作。

在优化过程中不能始终确定使用哪种哈希联接。因此，SQL Server 开始时使用内存中的哈希联接，然后根据生成输入的大小逐渐转换到 Grace 哈希联接和递归哈希联接。 
如果优化器错误地预计两个输入中哪个较小并由此确定哪个作为生成输入，生成角色和探测角色将动态反转。哈希联接确保使用较小的溢出文件作为生成输入。这一技术称为“角色反转”。至少一个文件溢出到磁盘后，哈希联接中才会发生角色反转。

说明：您也可以显式的指定联接方式，SQL Server会尽量尊重您的选择。比如你可以这样写：inner loop join, left outer merge join, inner hash join 
但是，我还是建议您不要这样做，因为SQL Server的选择基本上都是正确的，不信您可以试一下。

好了，说了一大堆理论东西，再来个实际的例子解释一下吧。

回到顶部

更具体执行过程

前面，我给出一张图片，它反映了SQL Server在执行某个查询的执行计划，但它反映的信息可能不太细致，当然，您可以把鼠标指标移动某个节点上，会有以下信息出现：



刚好，我装的是中文版的，上面都是汉字，我也不多说了。我要说的是另一种方式的执行过程，比这个包含更多的执行信息， 而且是实际的执行情况。（当然，您也可以继续使用图形方式，在运行查询前点击工具栏上的【包括实际的执行计划】按钮）

让我们再次回到【SQL Server Management Studio】，输入以下语句，然后执行。
set statistics profile on 

select v.OrderID, v.CustomerID, v.CustomerName, v.OrderDate, v.SumMoney, v.Finished
from   OrdersView as v
where v.OrderDate &gt;= '2010-12-1' and v.OrderDate &lt; '2011-12-1';


注意：现在加了一句，【set statistics profile on 】，得到的结果如下：



可以从图片上看到，执行查询后，得到二个表格，上面的表格显示了查询的结果，下面的表格显示了查询的执行过程。相比本文的第一张图片， 这张图片可能在直观上不太友好，但是，它能反映更多的信息，而且尤其在比较复杂的查询时，可能看起来更容易，因为对于复杂的查询，【执行计划】的步骤太多，图形方式会造成图形过大，不容易观察。 而且这张执行过程表格能反映2个很有价值的数据（前二列）。

还是来看看这个【执行过程表格】吧。我来挑几个重要的说一下。
【Rows】：表示在一个执行步骤中，所产生的记录条数。（真实数据，非预期）
【Executes】：表示某个执行步骤被执行的次数。（真实数据，非预期）
【Stmt Text】：表示要执行的步骤的描述。
【EstimateRows】：表示要预期返回多少行数据。

在这个【执行过程表格】中，对于优化查询来说，我认为前三列是比较重要的。对于前二列，我上面也解释了，意思也很清楚。 前二列的数字也大致反映了那些步骤所花的成本，对于比较慢的查询中，应该留意它们。 【Stmt Text】会告诉你每个步骤做了什么事情。对于这种表格，它所要表达的其实是一种树型信息（一行就表示在图形方式下的一个节点）， 所以，我建议从最内层开始去读它们。做为示例，我来解释一下这张表格它所表达的执行过程。

第5行：【Clustered Index Seek(OBJECT:([MyNorthwind].[dbo].[Customers].[PK_Customers]), SEEK:([MyNorthwind].[dbo].[Customers].[CustomerID]=[MyNorthwind].[dbo].[Orders].[CustomerID]) ORDERED FORWARD)】， 意思是说，SQL Server在对表Customers做Seek操作，而且是按照【Clustered Index Seek】的方式，对应的索引是【PK_Customers】，seek的值来源于[Orders].[CustomerID]

第4行：【Clustered Index Scan(OBJECT:([MyNorthwind].[dbo].[Orders].[PK_Orders]), WHERE:([MyNorthwind].[dbo].[Orders].[OrderDate]&gt;='2010-12-01 00:00:00.000' AND [MyNorthwind].[dbo].[Orders].[OrderDate]&lt;'2011-12-01 00:00:00.000'))】， 意思是说，SQL Server在对表Customers做Scan操作，即：最差的【表扫描】的方式，原因是，OrderDate列上没有索引，所以只能这样了。

第3行：【Nested Loops(Left Outer Join, OUTER REFERENCES:([MyNorthwind].[dbo].[Orders].[CustomerID]))】， 意思是说，SQL Server把第5行和第4行产生的数据用【Nested Loops】的方式联接起来，其中Outer表是Orders，要联接的匹配操作也在第5行中指出了。

第2行：【Compute Scalar(DEFINE:([Expr1006]=isnull([MyNorthwind].[dbo].[Customers].[CustomerName],N'')))】， 意思是说，要执行一个isnull()函数的调用。具体原因请参考本文前部分中给出视图定义代码。

第1行：【SELECT [v].[OrderID],[v].[CustomerID],[v].[CustomerName],[v].[OrderDate],[v].[SumMoney],[v].[Finished] FROM [OrdersView] [v] WHERE [v].[OrderDate]&gt;=@1 AND [v].[OrderDate]&lt;@2】， 通常第1行就是整个查询，表示它的返回值。

回到顶部

索引统计信息：查询计划的选择依据

前面一直说到【执行计划】，既然是计划，就表示要在具体执行前就能确定下来的操作方案。那么SQL Server是如何选择一个执行计划的呢？ SQL Server怎么知道什么时候该用索引或者用哪个索引呢？ 对于SQL Server来说，每当要执行一个查询时，都要首先检查这个查询的执行计划是否存在缓存中，如果没有，就要生成一个执行计划， 具体在产生执行计划时，并不是看有哪些索引可用（随机选择），而是会参考一种被称为【索引统计信息】的数据。 如果您仔细地看一下前面的执行计划或者执行过程表格，会发现SQL Server能预估每个步骤所产生的数据量，
 正是因为SQL Server能预估这些数据量，SQL Server才能选择一个它认为最合适的方法去执行查询过程， 此时【索引统计信息】就能告诉SQL Server这些信息。 说到这里，您是不是有点好奇呢，为了让您对【索引统计信息】有个感性的认识，我们来看看【索引统计信息】是个什么样子的。 请在【SQL Server Management Studio】，输入以下语句，然后执行。
dbcc show_statistics (Products, IX_CategoryID)



得到的结果如下图：



首先，还是解释一下命令：【dbcc show_statistics】这个命令可以显示我们想知道的【索引统计信息】，它需要二个参数，1. 表名，2. 索引名

再来看看命令的结果，它有三个表格组成：
1. 第一个表格，它列出了这个索引统计信息的主要信息。



列名
说明


Name
统计信息的名称。


Updated
上一次更新统计信息的日期和时间。


Rows
表中的行数。


Rows Sampled
统计信息的抽样行数。


Steps
数据可分成多少个组，与第三个表对应。


Density
第一个索引列前缀的选择性（不包括 EQ_ROWS）。


Average key length
所有索引列的平均长度。


String Index
如果为“是”，则统计信息中包含字符串摘要索引，以支持为 LIKE 条件估算结果集大小。仅适用于 char、varchar、nchar 和 nvarchar、varchar(max)、nvarchar(max)、text 以及 ntext 数据类型的前导列。




2. 第二个表格，它列出各种字段组合的选择性，数据越小表示重复越性越小，当然选择性也就越高。



列名
说明


All density
索引列前缀集的选择性（包括 EQ_ROWS）。注意：这个值越小就表示选择性越高。
如果这个值小于0.1，这个索引的选择性就比较高，反之，则表示选择性就不高了。


Average length
索引列前缀集的平均长度。


Columns
为其显示 All density 和 Average length 的索引列前缀的名称。




3. 第三个表格，数据分布的直方图，SQL Server就是靠它预估一些执行步骤的数据量。



列名
说明


RANGE_HI_KEY
每个组中的最大值。


RANGE_ROWS
每组数据组的估算行数，不包含最大值。


EQ_ROWS
每组数据组中与最大值相等的行的估算数目。


DISTINCT_RANGE_ROWS
每组数据组中的非重复值的估算数目，不包含最大值。


AVG_RANGE_ROWS
每组数据组中的重复值的平均数目，不包含最大值，计算公式：RANGE_ROWS / DISTINCT_RANGE_ROWS for DISTINCT_RANGE_ROWS &gt; 0




为了能让您更好的理解这些数据，尤其是第三组，请看下图：



当时我在填充测试数据时，故意把CategoryId分为1到8（10是后来临时加的），每组填充了78条数据。所以【索引统计信息】的第三个表格的数据也都是正确的， 也正是根据这些统计信息，SQL Server才能对每个执行步骤预估相应的数据量，从而影响Join之类的选择。当然了，在选择Join方式时， 也要参考第二个表格中字段的选择性。SQL Server在为查询生成执行计划时， 查询优化器将使用这些统计信息并结合相关的索引来评估每种方案的开销来选择最佳的查询计划。

再来个例子说明一下统计信息对于查询计划的重要性。首先多加点数据，请看以下代码：
declare @newCategoryId int;
insert into dbo.Categories (CategoryName) values(N'Test statistics');
set @newCategoryId = scope_identity();

declare @count int;
set @count = 0;

while( @count &lt; 100000 )
begin
    insert into Products (ProductName, CategoryID, Unit, UnitPrice, Quantity, Remark) 
    values( cast(newid() as nvarchar(50)), @newCategoryId, N'个', 100, @count +1, N'');

    set @count = @count + 1;
end
go

update statistics Products;
go



再来看看索引统计信息：



再来看看同一个查询，但因为查询参数值不同时，SQL Server选择的执行计划：
select p.ProductId, t.Quantity 
from Products as p left outer join [Order Details] as t on p.ProductId = t.ProductId 
where p.CategoryId = 26;    -- 26 就是最新产生的CategoryId，因此这个查询会返回10W条记录

select p.ProductId, t.Quantity 
from Products as p left outer join [Order Details] as t on p.ProductId = t.ProductId 
where p.CategoryId = 6;    -- 这个查询会返回95条记录




从上图可以看出，由于CategoryId的参数值不同，SQL Server会选择完全不同的执行计划。统计信息重要性在这里体现的很清楚吧。

创建统计信息后，数据库引擎对列值（根据这些值创建统计信息）进行排序， 并根据这些值（最多 200 个，按间隔分隔开）创建一个“直方图”。直方图指定有多少行精确匹配每个间隔值， 有多少行在间隔范围内，以及间隔中值的密度大小或重复值的发生率。

SQL Server 2005 引入了对 char、varchar、varchar(max)、nchar、nvarchar、nvarchar(max)、text 和 ntext 列创建的统计信息收集的其他信息。这些信息称为“字符串摘要”，可以帮助查询优化器估计字符串模式中查询谓词的选择性。 查询中有 LIKE 条件时，使用字符串摘要可以更准确地估计结果集大小，并不断优化查询计划。 这些条件包括诸如 WHERE ProductName LIKE '%Bike' 和 WHERE Name LIKE '[CS]heryl'
 之类的条件。

既然【索引统计信息】这么重要，那么它会在什么时候生成或者更新呢？事实上，【索引统计信息】是不用我们手工去维护的， SQL Server会自动去维护它们。而且在SQL Server中也有个参数来控制这个更新方式：



统计信息自动功能工作方式

创建索引时，查询优化器自动存储有关索引列的统计信息。另外，当 AUTO_CREATE_STATISTICS 数据库选项设置为 ON（默认值）时， 数据库引擎自动为没有用于谓词的索引的列创建统计信息。

随着列中数据发生变化，索引和列的统计信息可能会过时，从而导致查询优化器选择的查询处理方法不是最佳的。 例如，如果创建一个包含一个索引列和 1,000 行数据的表，每一行在索引列中的值都是唯一的， 则查询优化器将把该索引列视为收集查询数据的好方法。如果更新列中的数据后存在许多重复值， 则该列不再是用于查询的理想候选列。但是，查询优化器仍然根据索引的过时分布统计信息（基于更新前的数据），将其视为好的候选列。

当 AUTO_UPDATE_STATISTICS 数据库选项设置为 ON（默认值）时，查询优化器会在表中的数据发生变化时自动定期更新这些统计信息。 每当查询执行计划中使用的统计信息没有通过针对当前统计信息的测试时就会启动统计信息更新。 采样是在各个数据页上随机进行的，取自表或统计信息所需列的最小非聚集索引。 从磁盘读取一个数据页后，该数据页上的所有行都被用来更新统计信息。 常规情况是：在大约有 20% 的数据行发生变化时更新统计信息。但是，查询优化器始终确保采样的行数尽量少。 对于小于 8 MB 的表，则始终进行完整扫描来收集统计信息。

采样数据（而不是分析所有数据）可以将统计信息自动更新的开销降至最低。 在某些情况下，统计采样无法获得表中数据的精确特征。可以使用 UPDATE STATISTICS 语句的 SAMPLE 子句和 FULLSCAN 子句， 控制按逐个表的方式手动更新统计信息时采样的数据量。FULLSCAN 子句指定扫描表中的所有数据来收集统计信息， 而 SAMPLE 子句用来指定采样的行数百分比或采样的行数

在 SQL Server 2005 中，数据库选项 AUTO_UPDATE_STATISTICS_ASYNC 提供了统计信息异步更新功能。 当此选项设置为 ON 时，查询不等待统计信息更新，即可进行编译。而过期的统计信息置于队列中， 由后台进程中的工作线程来更新。查询和任何其他并发查询都通过使用现有的过期统计信息立即编译。 由于不存在等待更新后的统计信息的延迟，因此查询响应时间可预测；但是过期的统计信息可能导致查询优化器选择低效的查询计划。 在更新后的统计信息就绪后启动的查询将使用那些统计信息。这可能会导致重新编译缓存的计划（取决于较旧的统计信息版本）。
 如果在同一个显式用户事务中出现某些数据定义语言 (DDL) 语句（例如，CREATE、ALTER 和 DROP 语句），则无法更新异步统计信息。

AUTO_UPDATE_STATISTICS_ASYNC 选项设置于数据库级别，并确定用于数据库中所有统计信息的更新方法。 它只适用于统计信息更新，而无法用于以异步方式创建统计信息。只有将 AUTO_UPDATE_STATISTICS 设置为 ON 时， 将此选项设置为 ON 才有效。默认情况下，AUTO_UPDATE_STATISTICS_ASYNC 选项设置为 OFF。

从以上说明中，我们可以看出，对于大表，还是有可能存在统计信息更新不及时的时候，这时，就可能会影响查询优化器的判断了。
有些人可能有个经验：对于一些慢的查询，他们会想到重建索引来尝试解决。其实这样做是有道理的。 因为，在某些时候一个查询突然变慢了，可能和统计信息更新不及时有关，进而会影响查询优化器的判断。 如果此时重建索引，就可以让查询优化器知道最新的数据分布，自然就可以避开这个问题。 还记得我前面用【set statistics profile on】显示的执行过程表格吗？注意哦，那个表格就显示每个步骤的实际数据量和预估的数据量。要不要重建索引，其实我们可以用【set statistics profile on】来看一下，如果实际数据量和预估的数据量的差值比较大，
 那么我们可以考虑手工去更新统计信息，然后再去试试。

回到顶部

优化视图查询

再来说说优化视图查询，虽然视图也是由一个查询语句定义的，本质上也是一个查询，但它和一般的查询语句在优化时，还是有所区别的。 这里主要的区别在于，视图虽然是由一个查询语句定义的，但如果只去分析这个查询定义，可能得到的意义不大，因为视图多数时候就不是直接使用， 而是在使用前，会加上where语句，或者放在其它语句中供from子句所使用。下面还是举个例子吧，在我的演示数据库中有个视图OrdersView，定义代码前面有。 我们来看看，如果直接使用这个视图，会有什么样的执行计划出来：



从这个视图可以看出，SQL Server会对表Orders做全表扫描，应该是很低效的。再来看看下面这个查询：



从这个执行计划可以看出，与上面那个就不一样了。前一个查询中对Orders表的查找是使用【Clustered Index Scan】的方式， 而现在在使用【Clustered Index Seek】的方式了，最右边二个步骤的成本的百分比也发生了改变。这样就足以说明，优化视图时， 最好能根据实际需求，应用不同的过滤条件，再来决定如何去优化。

再来一个由三个查询组成的情况来看看这个视图的执行计划。
select * from dbo.OrdersView where OrderId = 1;
select * from dbo.OrdersView where CustomerId = 1;
select * from dbo.OrdersView where OrderDate &gt;= '2010-12-1' and OrderDate &lt; '2011-12-1';




很明显，对于同一个视图，在不同的过滤条件下，执行计划的差别很明显。

回到顶部

       大数据的出现带来了许多新的术语，但这些术语往往比较难以理解。因此，我们通过本文给出一个常用的大数据术语表，抛砖引玉，供大家深入了解。其中部分定义参考了相应的博客文章。当然，这份术语表并没有100%包含所有的术语。


A

聚合(Aggregation) – 搜索、合并、显示数据的过程。

算法(Algorithms) – 可以完成某种数据分析的数学公式。

分析法(Analytics) – 用于发现数据的内在涵义。

异常检测(Anomaly detection) – 在数据集中搜索与预期模式或行为不匹配的数据项。除了“Anomalies”,用来表示异常的词有以下几种：outliers, exceptions, surprises, contaminants.他们通常可提供关键的可执行信息。

匿名化(Anonymization) – 使数据匿名，即移除所有与个人隐私相关的数据。

应用(Application) – 实现某种特定功能的计算机软件。

人工智能(Artificial Intelligence) – 研发智能机器和智能软件，这些智能设备能够感知周遭的环境，并根据要求作出相应的反应，甚至能自我学习。

B

行为分析法(Behavioural Analytics) – 这种分析法是根据用户的行为如“怎么做”，“为什么这么做”，以及“做了什么”来得出结论，而不是仅仅针对人物和时间的一门分析学科，它着眼于数据中的人性化模式。

大数据科学家(Big Data Scientist) – 能够设计大数据算法使得大数据变得有用的人。

大数据创业公司(Big data startup) – 指研发最新大数据技术的新兴公司。

生物测定术(Biometrics) – 根据个人的特征进行身份识别。

B字节 (BB: Brontobytes) – 约等于1000 YB(Yottabytes)，相当于未来数字化宇宙的大小。1 B字节包含了27个0。

商业智能(Business Intelligence) – 是一系列理论、方法学和过程，使得数据更容易被理解。



C

分类分析(Classification analysis) – 从数据中获得重要的相关性信息的系统化过程; 这类数据也被称为元数据(meta data),是描述数据的数据。

云计算(Cloud computing) – 构建在网络上的分布式计算系统，数据是存储于机房外的(即云端)。

聚类分析(Clustering analysis) – 它是将相似的对象聚合在一起，每类相似的对象组合成一个聚类(也叫作簇)的过程。这种分析方法的目的在于分析数据间的差异和相似性。

冷数据存储(Cold data storage) – 在低功耗服务器上存储那些几乎不被使用的旧数据。但这些数据检索起来将会很耗时。

对比分析(Comparative analysis) – 在非常大的数据集中进行模式匹配时，进行一步步的对比和计算过程得到分析结果。

复杂结构的数据(Complex structured data) – 由两个或多个复杂而相互关联部分组成的数据，这类数据不能简单地由结构化查询语言或工具(SQL)解析。

计算机产生的数据(Computer generated data) – 如日志文件这类由计算机生成的数据。

并发(Concurrency) – 同时执行多个任务或运行多个进程。

相关性分析(Correlation analysis) – 是一种数据分析方法，用于分析变量之间是否存在正相关，或者负相关。

客户关系管理(CRM: Customer Relationship Management) – 用于管理销售、业务过程的一种技术，大数据将影响公司的客户关系管理的策略。

D



仪表板(Dashboard) – 使用算法分析数据，并将结果用图表方式显示于仪表板中。

数据聚合工具(Data aggregation tools) – 将分散于众多数据源的数据转化成一个全新数据源的过程。

数据分析师(Data analyst) – 从事数据分析、建模、清理、处理的专业人员。

数据库(Database) – 一个以某种特定的技术来存储数据集合的仓库。

数据库即服务(Database-as-a-Service) – 部署在云端的数据库，即用即付，例如亚马逊云服务(AWS: Amazon Web Services)。

数据库管理系统(DBMS: Database Management System) – 收集、存储数据，并提供数据的访问。

数据中心(Data centre) – 一个实体地点，放置了用来存储数据的服务器。

数据清洗(Data cleansing) – 对数据进行重新审查和校验的过程，目的在于删除重复信息、纠正存在的错误，并提供数据一致性。

数据管理员(Data custodian) – 负责维护数据存储所需技术环境的专业技术人员。

数据道德准则(Data ethical guidelines) – 这些准则有助于组织机构使其数据透明化，保证数据的简洁、安全及隐私。

数据订阅(Data feed) – 一种数据流，例如Twitter订阅和RSS。

数据集市(Data marketplace) – 进行数据集买卖的在线交易场所。

数据挖掘(Data mining) – 从数据集中发掘特定模式或信息的过程。

数据建模(Data modelling) – 使用数据建模技术来分析数据对象，以此洞悉数据的内在涵义。

数据集(Data set) – 大量数据的集合。

数据虚拟化(Data virtualization) – 数据整合的过程，以此获得更多的数据信息，这个过程通常会引入其他技术，例如数据库，应用程序，文件系统，网页技术，大数据技术等等。

去身份识别(De-identification) – 也称为匿名化(anonymization)，确保个人不会通过数据被识别。

判别分析(Discriminant analysis) – 将数据分类;按不同的分类方式，可将数据分配到不同的群组，类别或者目录。是一种统计分析法，可以对数据中某些群组或集群的已知信息进行分析，并从中获取分类规则。

分布式文件系统(Distributed File System) – 提供简化的，高可用的方式来存储、分析、处理数据的系统。

文件存贮数据库(Document Store Databases) – 又称为文档数据库(document-oriented database), 为存储、管理、恢复文档数据而专门设计的数据库，这类文档数据也称为半结构化数据。

E

探索性分析(Exploratory analysis) – 在没有标准的流程或方法的情况下从数据中发掘模式。是一种发掘数据和数据集主要特性的一种方法。

E字节(EB: Exabytes) – 约等于1000 PB(petabytes), 约等于1百万 GB。如今全球每天所制造的新信息量大约为1 EB。

提取-转换-加载(ETL: Extract, Transform and Load) – 是一种用于数据库或者数据仓库的处理过程。即从各种不同的数据源提取(E)数据，并转换(T)成能满足业务需要的数据，最后将其加载(L)到数据库。

F

故障切换(Failover) – 当系统中某个服务器发生故障时，能自动地将运行任务切换到另一个可用服务器或节点上。

容错设计(Fault-tolerant design) – 一个支持容错设计的系统应该能够做到当某一部分出现故障也能继续运行。

G

游戏化(Gamification) – 在其他非游戏领域中运用游戏的思维和机制，这种方法可以以一种十分友好的方式进行数据的创建和侦测，非常有效。

图形数据库(Graph Databases) – 运用图形结构(例如，一组有限的有序对，或者某种实体)来存储数据，这种图形存储结构包括边缘、属性和节点。它提供了相邻节点间的自由索引功能，也就是说，数据库中每个元素间都与其他相邻元素直接关联。

网格计算(Grid computing) – 将许多分布在不同地点的计算机连接在一起，用以处理某个特定问题，通常是通过云将计算机相连在一起。

H

Hadoop – 一个开源的分布式系统基础框架，可用于开发分布式程序，进行大数据的运算与存储。

Hadoop数据库(HBase) – 一个开源的、非关系型、分布式数据库，与Hadoop框架共同使用。

HDFS – Hadoop分布式文件系统(Hadoop Distributed File System);是一个被设计成适合运行在通用硬件(commodity hardware)上的分布式文件系统。

高性能计算(HPC: High-Performance-Computing) – 使用超级计算机来解决极其复杂的计算问题。

I

内存数据库(IMDB: In-memory) – 一种数据库管理系统，与普通数据库管理系统不同之处在于，它用主存来存储数据，而非硬盘。其特点在于能高速地进行数据的处理和存取。

物联网(Internet of Things) – 在普通的设备中装上传感器，使这些设备能够在任何时间任何地点与网络相连。

J

法律上的数据一致性(Juridical data compliance) – 当你使用的云计算解决方案，将你的数据存储于不同的国家或不同的大陆时，就会与这个概念扯上关系了。你需要留意这些存储在不同国家的数据是否符合当地的法律。

K

键值数据库(KeyValue Databases) – 数据的存储方式是使用一个特定的键，指向一个特定的数据记录，这种方式使得数据的查找更加方便快捷。键值数据库中所存的数据通常为编程语言中基本数据类型的数据。

L

延迟(Latency) – 表示系统时间的延迟。

遗留系统(Legacy system) – 是一种旧的应用程序，或是旧的技术，或是旧的计算系统，现在已经不再支持了。

负载均衡(Load balancing) – 将工作量分配到多台电脑或服务器上，以获得最优结果和最大的系统利用率。

位置信息(Location data) – GPS信息，即地理位置信息。

日志文件(Log file) – 由计算机系统自动生成的文件，记录系统的运行过程。

M

M2M数据(Machine2Machine data) – 两台或多台机器间交流与传输的内容。

机器数据(Machine data) – 由传感器或算法在机器上产生的数据。

机器学习(Machine learning) – 人工智能的一部分，指的是机器能够从它们所完成的任务中进行自我学习，通过长期的累积实现自我改进。

MapReduce – 是处理大规模数据的一种软件框架(Map: 映射，Reduce: 归纳)。

大规模并行处理(MPP: Massively Parallel Processing) – 同时使用多个处理器(或多台计算机)处理同一个计算任务。

元数据(Metadata) – 被称为描述数据的数据，即描述数据数据属性(数据是什么)的信息。

MongoDB – 一种开源的非关系型数据库(NoSQL database)。

多维数据库(Multi-Dimensional Databases) – 用于优化数据联机分析处理(OLAP)程序，优化数据仓库的一种数据库。

多值数据库(MultiValue Databases) – 是一种非关系型数据库(NoSQL), 一种特殊的多维数据库：能处理3个维度的数据。主要针对非常长的字符串，能够完美地处理HTML和XML中的字串。

N

自然语言处理(Natural Language Processing) – 是计算机科学的一个分支领域，它研究如何实现计算机与人类语言之间的交互。

网络分析(Network analysis) – 分析网络或图论中节点间的关系，即分析网络中节点间的连接和强度关系。

NewSQL – 一个优雅的、定义良好的数据库系统，比SQL更易学习和使用，比NoSQL更晚提出的新型数据库。

NoSQL – 顾名思义，就是“不使用SQL”的数据库。这类数据库泛指传统关系型数据库以外的其他类型的数据库。这类数据库有更强的一致性，能处理超大规模和高并发的数据。
O

对象数据库(Object Databases) – (也称为面象对象数据库)以对象的形式存储数据，用于面向对象编程。它不同于关系型数据库和图形数据库，大部分对象数据库都提供一种查询语言，允许使用声明式编程(declarative programming)访问对象。

基于对象图像分析(Object-based Image Analysis) – 数字图像分析方法是对每一个像素的数据进行分析，而基于对象的图像分析方法则只分析相关像素的数据，这些相关像素被称为对象或图像对象。

操作型数据库(Operational Databases) – 这类数据库可以完成一个组织机构的常规操作，对商业运营非常重要，一般使用在线事务处理，允许用户访问 、收集、检索公司内部的具体信息。

优化分析(Optimization analysis) – 在产品设计周期依靠算法来实现的优化过程，在这一过程中，公司可以设计各种各样的产品并测试这些产品是否满足预设值。

本体论(Ontology) – 表示知识本体，用于定义一个领域中的概念集及概念之间的关系的一种哲学思想。(译者注: 数据被提高到哲学的高度，被赋予了世界本体的意义，成为一个独立的客观数据世界)。

异常值检测(Outlier detection) – 异常值是指严重偏离一个数据集或一个数据组合总平均值的对象，该对象与数据集中的其他它相去甚远，因此，异常值的出现意味着系统发生问题，需要对此另加分析。

P

模式识别(Pattern Recognition) – 通过算法来识别数据中的模式，并对同一数据源中的新数据作出预测。

P字节(PB: Petabytes) – 约等于1000 TB(terabytes), 约等于1百万 GB (gigabytes)。欧洲核子研究中心(CERN)大型强子对撞机每秒产生的粒子个数就约为1 PB。

平台即服务(PaaS: Platform-as-a-Service) – 为云计算解决方案提供所有必需的基础平台的一种服务。

预测分析(Predictive analysis) – 大数据分析方法中最有价值的一种分析方法，这种方法有助于预测个人未来(近期)的行为，例如某人很可能会买某些商品，可能会访问某些网站，做某些事情或者产生某种行为。通过使用各种不同的数据集，例如历史数据，事务数据，社交数据，或者客户的个人信息数据，来识别风险和机遇。

隐私(Privacy) – 把具有可识别出个人信息的数据与其他数据分离开，以确保用户隐私。

公共数据(Public data) – 由公共基金创建的公共信息或公共数据集。

Q

数字化自我(Quantified Self) – 使用应用程序跟踪用户一天的一举一动，从而更好地理解其相关的行为。

查询(Query) – 查找某个问题答案的相关信息。

R

再识别(Re-identification) – 将多个数据集合并在一起，从匿名化的数据中识别出个人信息。

回归分析(Regression analysis) – 确定两个变量间的依赖关系。这种方法假设两个变量之间存在单向的因果关系(译者注：自变量，因变量，二者不可互换)。

RFID – 射频识别; 这种识别技术使用一种无线非接触式射频电磁场传感器来传输数据。

实时数据(Real-time data) – 指在几毫秒内被创建、处理、存储、分析并显示的数据。

推荐引擎(Recommendation engine) – 推荐引擎算法根据用户之前的购买行为或其他购买行为向用户推荐某种产品。

路径分析(Routing analysis) – 针对某种运输方法通过使用多种不同的变量分析从而找到一条最优路径，以达到降低燃料费用，提高效率的目的。

S

半结构化数据(Semi-structured data) – 半结构化数据并不具有结构化数据严格的存储结构，但它可以使用标签或其他形式的标记方式以保证数据的层次结构。

情感分析(Sentiment Analysis) – 通过算法分析出人们是如何看待某些话题。

信号分析(Signal analysis) – 指通过度量随时间或空间变化的物理量来分析产品的性能。特别是使用传感器数据。

相似性搜索(Similarity searches) – 在数据库中查询最相似的对象，这里所说的数据对象可以是任意类型的数据。

仿真分析(Simulation analysis) – 仿真是指模拟真实环境中进程或系统的操作。仿真分析可以在仿真时考虑多种不同的变量，确保产品性能达到最优。

智能网格(Smart grid) – 是指在能源网中使用传感器实时监控其运行状态，有助于提高效率。

软件即服务(SaaS: Software-as-a-Service) – 基于Web的通过浏览器使用的一种应用软件。

空间分析(Spatial analysis) – 空间分析法分析地理信息或拓扑信息这类空间数据，从中得出分布在地理空间中的数据的模式和规律。

SQL – 在关系型数据库中，用于检索数据的一种编程语言。

结构化数据(Structured data) -可以组织成行列结构，可识别的数据。这类数据通常是一条记录，或者一个文件，或者是被正确标记过的数据中的某一个字段，并且可以被精确地定位到。

T

T字节(TB: Terabytes) – 约等于1000 GB(gigabytes)。1 TB容量可以存储约300小时的高清视频。

时序分析(Time series analysis) – 分析在重复测量时间里获得的定义良好的数据。分析的数据必须是良好定义的，并且要取自相同时间间隔的连续时间点。

拓扑数据分析(Topological Data Analysis) – 拓扑数据分析主要关注三点：复合数据模型、集群的识别、以及数据的统计学意义。

交易数据(Transactional data) – 随时间变化的动态数据。

透明性(Transparency) – 消费者想要知道他们的数据有什么作用、被作何处理，而组织机构则把这些信息都透明化了。

U

非结构化数据(Un-structured data) – 非结构化数据一般被认为是大量纯文本数据，其中还可能包含日期，数字和实例。

V

价值(Value) – (译者注：大数据4V特点之一) 所有可用的数据，能为组织机构、社会、消费者创造出巨大的价值。这意味着各大企业及整个产业都将从大数据中获益。

可变性(Variability) – 也就是说，数据的含义总是在(快速)变化的。例如，一个词在相同的推文中可以有完全不同的意思。

多样(Variety) – (译者注：大数据4V特点之一) 数据总是以各种不同的形式呈现，如结构化数据，半结构化数据，非结构化数据，甚至还有复杂结构化数据。

高速(Velocity) – (译者注：大数据4V特点之一) 在大数据时代，数据的创建、存储、分析、虚拟化都要求被高速处理。

真实性(Veracity) – 组织机构需要确保数据的真实性，才能保证数据分析的正确性。因此，真实性(Veracity)是指数据的正确性。

可视化(Visualization) – 只有正确的可视化，原始数据才可被投入使用。这里的“可视化”并非普通的图型或饼图，可视化指是的复杂的图表，图表中包含大量的数据信息，但可以被很容易地理解和阅读。

大量(Volume) – (译者注：大数据4V特点之一) 指数据量，范围从Megabytes至Brontobytes。

W

天气数据(Weather data) – 是一种重要的开放公共数据来源，如果与其他数据来源合成在一起，可以为相关组织机构提供深入分析的依据。

X

XML数据库(XML Databases) – XML数据库是一种以XML格式存储数据的数据库。XML数据库通常与面向文档型数据库相关联，开发人员可以对XML数据库的数据进行查询，导出以及按指定的格式序列化。

Y

Y字节 (Yottabytes) – 约等于1000 ZB (Zettabytes), 约等于250万亿张DVD的数据容量。现今，整个数字化宇宙的数据量为1 YB, 并且将每18年翻一番。

Z

Z字节 (ZB: Zettabytes) – 约等于1000 EB (Exabytes), 约等于1百万 TB。据预测，到2016年全球范围内每天网络上通过的信息大约能达到1 ZB。

附：存储容量单位换算表：

1 Bit(比特) = Binary Digit

8 Bits = 1 Byte(字节)

1,024 Bytes = 1 Kilobyte

1,024 Kilobytes = 1 Megabyte

1,024 Megabytes = 1 Gigabyte

1,024 Gigabytes = 1 Terabyte

1,024 Terabytes = 1 Petabyte

1,024 Petabytes = 1 Exabyte

1,024 Exabytes = 1 Zettabyte

1,024 Zettabytes = 1 Yottabyte

1,024 Yottabytes = 1 Brontobyte

1,024 Brontobytes = 1 
NonaByte

1,024 NonaBytes = 1 DoggaByte

1,024 DoggaBytes
 = 1 CorydonByte


创建索引是一个经久不衰的话题，网上关于索引的使用方式与建议的资料比比皆是，其表述的意思在一定程度上也是大同小异。当然，作为这么一个经典的话题，要确切说清楚怎样用才是好的，那是不容易的，此处就本人一些使用过程中的积累做一些概述，有不足之处，还望多多指正。

1、较频繁的作为查询条件的字段应该创建索引.

2、唯一性太差的字段不适合单独创建索引，即使频繁作为查询条件：

唯一性太差的字段：如状态字段，类型字段等。这些字段即使创建了单独的索引，MySQL Query
 Optimizer大多数也不会选择使用，如果什么时候选择了这种索引，可能会带来极大的性能问题。由于索引字段中每个值都含有大量的记录，那么存储引擎在根据索引访问数据的时候会带来大量的随机IO，甚至有时候可能还好出现大量的重复IO

       3、更新非常频繁的字段不适合创建索引：

更新字段数据，同时还要更新索引的数据，以确保索引信息是准确的，这会增加IO访问量较大的增加，不仅仅影响更新query的响应时间，还会影响真个存储系统的资源消耗，加大存储系统的负责。




单一索引还是复合索引

对于多个where条件的数据，组合索引会比单一索引的查询效率要高，因为通过单一索引所能过滤的数据并不完整，和通过组合索引相比，存储引擎需要访问更多的记录。但是组合索引在多个字段中存在，更新的频率会带来一定性能消耗。

       对于建立多个单键索引，MYSQL Query  Optimizer大多数时候只会选择一个单键值的索引，然后放弃其他索引。即使他选择了同时利用两个或者更多的索引通过INDEX_MERGE来优化查询，可能所收到的效果并不会比选择其中某一个单键值索引高效。

因为如果选择了INDEX_MERGE来优化查询，就需要访问多个索引，同时还要将通过访问到的几个索引进行merge操作，所带来的成本可能反而会比选择其中一个最有效的索引来完成查询更高。

在创建组合索引并不是说将查询条件中所有字段放在一个索引中，我们还应该尽量让一个索引被多个query语句使用，尽量减少同一个表上面索引的数量，减少因为数据更新所带来的索引更新成本。同时还可以减少因为索引所带来的存储空间的消耗。




大多数场景下比较适合：

1、对于单键索引，尽量选择针对当前query过滤性更好的索引；

2、在选择组合索引的时候，当前query中过滤性最好的字段在索引字段顺序中排列越靠前越好；

3、在选择组合索引的时候，尽量选择可以能够包含当前query的where子句中更多字段索引；

4、尽可能通过分析统计信息和调整query的写法来达到选择合适索引的目的而减少通过使用Hint人为控制索引的选择，因为这会是后期的维护成本增加，同时增加维护所带来的潜在风险。




建议：

1、表的主键、外键必须有索引；
2、数据量超过300的表应该有索引；
3、经常与其他表进行连接的表，在连接字段上应该建立索引；
4、经常出现在Where子句中的字段，特别是大表的字段，应该建立索引；
5、索引应该建在选择性高的字段上；
6、索引应该建在小字段上，对于大的文本字段甚至超长字段，不要建索引；
7、复合索引的建立需要进行仔细分析；尽量考虑用单字段索引代替：
A、正确选择复合索引中的主列字段，一般是选择性较好的字段；
B、复合索引的几个字段是否经常同时以AND方式出现在Where子句中？单字段查询是否极少甚至没有？如果是，则可以建立复合索引；否则考虑单字段索引；
C、如果复合索引中包含的字段经常单独出现在Where子句中，则分解为多个单字段索引；
D、如果复合索引所包含的字段超过3个，那么仔细考虑其必要性，考虑减少复合的字段；
E、如果既有单字段索引，又有这几个字段上的复合索引，一般可以删除复合索引；
8、频繁进行数据操作的表，不要建立太多的索引；
9、删除无用的索引，避免对执行计划造成负面影响；


以下搜集了一些在云计算中会比较常遇到的一些术语，提供中英对照信息：
1. 自由计算      free computing 
2. 弹性可伸缩    elastic and scalable 
3. 主机          host / instance 
4. 硬盘          hard disk/ volume 
5. 密钥          key 
6. 公开密钥      public key 
7. 映像          image / mapping 
8. 负载均衡      load balancing 
9. 对象存储      object storage 
10. 弹性计算      elastic computing 
11. 按秒计费      charged by seconds 
12. 多重实时副本  multiple real-time copy 
13. 安全隔离      security isolation 
14. 异地副本      long-distance copy 
15. 后端系统      back-end system 
16. 前端系统      front-end system 
17. 写时拷贝技术  copy-on-write technique 
18. 控制台        console 
19. 监控台        dashboard 
20. 远程终端      remote terminal 
21. 服务端口      service port  
22. 模拟主机显示器      simulation host display    
23. 路由器        router  
24. 多路万兆光纤  multiple 10000MB optical fiber 
25. 密码验证登录  password authentication login 
26. 静态IP        static IP 
27. 动态IP        dynamic IP 
28. 混合云        hybrid cloud  
29. SLA服务级别协议          Service Level Agreement 
30. 分布式存储    distributed storage 
31. 存储柜        locker

32. 云计算加速器    cloud computing accelerator 

33.  NIST           National Institute of Standards and Technology  美国国家标准技术研究所 
34.  智能电网       smart gird 
35.  智慧城市       smart city 
36.  物联网         Internet of Things (IOT) 
37.  集成电路       Integrated Circuit 
38.  嵌套虚拟化     nested virtualization 
39.  内存           memory 
40.  千兆           Gigabyte 
41.  网卡           network card 
42.  单线程测试     single thread test 
43.  最大素数测试   largest prime test 
44.  单核CPU       single-core CPU 
45.  双核CPU       dual-core CPU 
46.  磁盘吞吐量     disk throughput 
47.  BGP           边界网关协议Border Gateway Protocol

48.  语音控制       voice control 
49.  湿度           humidity 
50.  智能分析       intelligent analysis 
51.  SOA           Service Oriented Architecture面向服务的架构 
52.  开源操作系统   Open Source Operating System 
53.  虚拟机         virtual machine 
54.  源代码         source code 
55.  文档           document 
56.  全媒体         omni-media 
57.  API接口       API interface 
58.  快照           snapshot 
59.  工单系统       ticket system 
60.  堡垒机         fortress machine 
61.  单点登录       SSO  single sign on 
62.  脚本管理       script management 
63.  拓扑管理       topology management

64.  ETL            Extraction-Transformation-Loading 数据提取、转换和加载 
65.  网络流量        network traffic 
66.  域名绑定        domain banding  
67.  文件外链        external document linking 
68.  防篡改          tamper-proofing  
69.  防抵赖          non-repudiation 
70.  端到端          end-to-end  
71.  全景透视        panoramic perspective  
72.  多维度特征识别      multidimensional characteristic identification    
73.  检索            retrieval  
74.  存储矩阵        storage matrix 
75.  示例代码        sample code 
76.  可执行代码      executable code 
77.  远程擦除        remote wipe 
78.  底层固件        bottom firmware 
79.  存储分级        storage tiering 
80.  回写式高速缓存  Write-back Cache 
81.  软件定义存储    software defined storage 
82.  横向可扩展存储  transverse extensible storage 
83.  模块化数据中心  Modular Data Center  
84.  DNS域名系统            Domain Name System  
85.  封顶            capping 
86.  芯片            chip  
87.  ISV             Independent Software Vendor第三方软件开发商
88.  特征向量        Feature Vector    
89. 远程异地备份    remote backup 
90. 虚拟显示技术    visual vision 
91. 虚拟现实        Visual Reality (VR) 
92. 数据记录器      Data Recorder   
93. 业务连续性管理  Business Continuity Management (BCM)
94. 钢筋砼框架        reinforced concrete frame 
95. 防爆墙            blast wall 
96. 入侵检测探测器    intrusion detector 
97. 弱电间            low voltage room 
98. 门禁系统          access control system 
99. 网络接入商        web portal provider 
100. 审计日志          audit logs  
101. UPS               Uninterrupted Power Supply 不间断电源 
102. 柴油发电机         diesel generator 
103. 地下储油罐         underground petrol tank 
104. 多节点集群     multi-node cluster 
105. 预案           emergency response plan 
106. 高速复制链路   high-speed copying link 
107. 容错级         fault tolerance 
108. 里程表         milestone 
109. 制冷密度       cooling density 
110. 千瓦           kilowatt  
111. 灭火方式       fire extinguishing method 
112. 防渗漏等级     anti-leakage level 
113. 机房均布荷载   computer room even load 
114. 全冗余         full redundancy  
115. 两路市电       two-way electricity  
116. 一路自卑应急   one-way self-prepared emergency power 
117. 9度烈度       9 degree seismic intensity
118. 密文           ciphertext 
119. 专属机柜       exclusive rack  
120. 设备上下电支持 upper and lower electricity support 
121. 网络布线       network cabling 
122. 实时热备份     real time thermal backup 
123. 桌面演练       desktop practice 
124.  模拟切换演练   simulated switch practice
125. 园区占地面积   floor area of the park 
126. 规划建设面积   planning construction area 
127. 高速链路复制   high-speed copying link 
128. 7※24hours     7 multiply 24 hours  
129. 安全和访问控制 security and visiting control （物理环境）     
130. 银监会       China Banking Regulatory Commission (CBRC) 
131. 发改委       National Development and Reform Commission (NDRC) 
132. 中国信息安全测评中心 China Information Technology Evaluation Center   
133. 工信部       Ministry of Industry and Information Technology  
134. 住建部       Ministry of Housing and Urban-Rural Development 
135. DRII         国际灾难恢复协会Disaster Recovery Institute International 
136. BCI          业务持续协会 Business Continuity Institute  
137. TCO         Total Cost of Ownship 总拥有成本 
138. HCI          Human Computer Interaction 人机交互 
139. OCR         Optical Character Recognition 文字识别  
140. SOA         Service Oriented Architecture  面向服务的体系结构 
141. NoSQL       非关系型数据库  
142.  Hadoop       一个分布式系统基础架构，由Apache基金会所开发。（用户可以在不了解分布式底层细节的情况下，开发分布式程序。利用集群的优势高速运转和储存。 
143. 操作型数据库  operational database  
144. CTI      Computer Telecommunication Integration 计算机电信集成技术             
145. ITIL      Information Technology Infrastructural Library IT基础架构库






32.
 
云计算加速器
 
 
 
 










cloud computing accelerator 




首先挑几个大家听得或看到比较多的热热身：
CEO(Chief executive officer)首席执行官 
CTO(Chief technology officer)首席技术官 
CIO(Chief information officer)首席信息官 
CFO(Chief financial officer)首席财务官 
COO(Chief operating officer)首席运营官

对各个简称的更详尽解释如下：
CEO(Chief Executive Officer)，即首席执行官，是美国人在20世纪60年代进行公司治理结构改革创新时的产物。

由于市场风云变幻，决策的速度和执行的力度比以往任何时候都更加重要。
 传统的“董事会决策、经理层执行”的公司体制已经难以满足决策的需要。而且， 决策层和执行层之间存在的信息传递时滞和沟通障碍、决策成本的增加，已经严 重影响经理层对企业重大决 策的快速反应和执行能力。而解决这一问题的首要一 点，就是让经理人拥有更多自主决策的权力，让经理人更多为自己的决策奋斗、对 自己的行为负责。CEO就是这种变革的产物。CEO在某种意义上代表着将原来董事会 手中的一些决策权过渡到经营层手中。 
CEO与总经理，形式上都是企业的“一把手”，CEO既是行政一把手，又是股东 权益代言人————大多数情况下，CEO是作为董事会成员出现的，总经理则不一定 是董事会成员。从这个意义上讲，CEO代表着企业，并对企业经营负责。 由于国外没有类似的上级主管和来自四面八方的牵制，CEO的权威比国内的总经理们更绝对，但他们绝不会像总经理那样过多介入公司的具体事务。CEO作出总体决
 策后，具体执行权力就会下放。所以有人说，CEO就像我国50%的董事长加上50%的总经理。 
一般来讲，CEO的主要职责有三方面：①对公司所有重大事务和人事任免进行决 策，决策后，权力就下放给具体主管，CEO具体干预的较少；②营造一种促使员工愿 意为公司服务的企业文化；③把公司的整体形象推销出去。

CTO是个技术主管，CIO是个具有技术背景或对技术有些了解地公司高层。

通常CIO向CEO汇报，或向CFO汇报。CIO不需要是个技术大拿，但对技术必须非常敏感，并能发掘技术带给公司地潜力。随着IT在各公司地重要性日渐提高，CIO地地位也渐高，有时能进入公司地最高决策层。CIO是个桥梁，把公司地商业模式和技术连接起来。基本上CTO就是一个技术大拿，熟练掌握公司地核心技术，并可以带领团队开发或使用新技术来帮助公司达到目标。基本上CTO不会是公司地最高层。 
企业CIO和CTO有着明显地区别，但是最大地区别不是在于他们对技术地掌握程度和深度，而是在于他们对企业战略地驾驭能力和适应能力。 
CTO有时候也会成为公司地最高层，特别是一些以技术为核心竞争力地企业来说。首先，我们来解读一下什么是CTO。其实，CTO（首席技术官）作为一个外来名词，在中国还不多见，随着网络热潮传进中国地CXO系列中地一员，CTO给人留下地印象只是技术人员所能达到地最高职位。“但当技术日益成为影响企业发展地决定因素时，CTO也就成为对企业发展起着决定性作用地人群之一。 
在美国，CTO除了负责技术支持和技术改良等日常工作外，其主要职责是设计公司地未来工作。从某种意义上说，CTO地首要工作是提出公司未来两三年内地产品和服务地技术发展方向。 
尽管CTO这个名词是引进来了，但在角色职能定义方面同国外还存在一定差距。作为一个高科技公司地CTO，其更多地工作应该是前瞻性地，也就是制定下一代产品地策略和进行研究工作，属于技术战略地重要执行者。 
在国内来看，大部分地企业里地“CTO”都是过去地“工程师”摇身一变而成地，因此带着很强地技术色彩。在一些通过技术安身立命地高科技企业，这些工程师出身地CTO也往往能够占据核心领导地位。但是在其他地行业中，例如一些传统地行业，一些把市场营销能力作为核心竞争力地企业，CTO地作用就大打折扣，CIO就逐渐浮出水面了。 
“CIO”即信息总监，他通过组织和利用企业地IT资源，为企业创造效益。通过信息化掌握了企业地业务命脉以及战略方向地CIO，很可能向决策管理层地地位继续上升，直到达到权力地顶峰—CEO。 
一家美国主导企业地首席执行官和一群首席信息官进行了一次谈话，讨论首席信息官在现代公司中地作用。在谈话进行到一半地时候，他直截了当地说：“首席信息官也许是我最重要地经理人。没有他们，我不知道我地公司会是怎样。”由此可见CIO在企业中地重要作用了。 
在CIO成功地基本素质中，其中有一项是要精通企业以及相关行业地知识。要搞信息化，一个CIO至少要熟悉企业地研发、生产、计划、营销、市场、物流等核心业务流程，熟悉企业地财务管理、组织结构、行政程序、人力资源管理等基础资源，以及企业发展地远景、价值观等企业地文化范畴。在这基础上，CIO才能对企业地IT建设和信息资源做出正确地规划。 
因此如果你想成为一个成功地CIO，那么最好远离电脑，去积极培养作为企业管理者应该具备地各种能力。对500名CIO所做地调查发现，70%地人认为通往成功地关键是有效地沟通；58%地人选择谙熟商业流程和运作；而46%地人则认为战略性地思想和计划能力很重要。而此前被认为很重要地IT技能，只获得了10%地认可。这不能不说是一个巨大地观念改变。

CFO(Chief
 Financial Officer)意指公司首席财政官或财务总监，是现代公司中最重要、最有价值的顶尖管理职位之一，是掌握着企业的神经系统(财务信息)和血液系统(现金资源)灵魂人物。



做一名成功的CFO需要具备丰富的金融理论知识和实务经验。公司理财与金融市场交互、项目估价、风险管理、产品研发、战略规划、企业核心竞争力的识别与建立以及洞悉信息技术及电子商务对企业的冲击等自然都是CFO职责范围内的事。

在一个大型公司运作中，CFO是一个穿插在金融市场操作和公司内部财务管理之间的角色。担当CFO的人才大多是拥有多年在金融市场驰骋经验的人。在美国，优秀的CFO常常在华尔街做过成功的基金经理人。
COO（chief Operation
 officer） 的职责主要是负责公司的日常营运，辅助CEO的工作。
一般来讲，COO负责公司职能管理组织体系的建设，并代表CEO处理企业的日常职能事务。如果公司未设有总裁职务，则COO还要承担整体业务管理的职能，主管企业营销与综合业务拓展，负责建立公司整个的销售策略与政策，组织生产经营，协助CEO制定公司的业务发展计划，并对公司的经营绩效进行考核。

其他一些为各个岗位才较为常见的简称：


首席品牌官【CBO】 chief brand officer

首席文化官【CCO】 Chief Cultural Officer

开发总监【CDO】 chief Development officer

人事总监 【CHO】 Chief Human resource officer

首席知识官【CKO】 chief knowledge officer

首席市场官【CMO】 chief Marketing officer

首席谈判官【CNO】 chief Negotiation officer

公关总监【CPO】 chief Public relation officer

质量总监【CQO】 chief Quality officer

销售总监【CSO】 chief Sales officer

评估总监【CVO】 chief Valuation officer 
CAO：Answerer 首席答辩人，专门负责解答媒体、债权人和用户等有关网站倒闭问题的询问。

CBO：Business Plan 首席商业计划官，是首席财务官的助理之一，专门针对不同的投资人制订相应的BP。

CCO：Cost Control 首席成本控制官，凡超过100元以上的支出必须由CC0批准。

CDO：Domain name 首席域名官，负责公司域名注册、网站清盘时域名的拍卖、域名法律纠纷等相关问题。

CGO：Guideline 首席方针制订官，规划公司的宏伟蓝图，一般是5年以后的目标。

CHO：Harmony 首席协调官，调解投资者和经营者之间的冲突，并确保公司内部矛盾不要泄露。

CJO：Judge 首席执法官，解决内部劳资纠纷，包括员工对降薪、辞退补偿等所引起的问题。

CKO：Keep connecting，网络连接专员，最繁忙的岗位之一，当中国电信的网络连接中断时及时向员工通报。

CLO：Lawer 首席律师，负责公司被控侵权时的应诉以及各种合同文本的审核。

CMO：Media 首席媒体官，保持和媒体之间的友好关系，为公司随时发布新闻做准备。

CNO：News 首席新闻官，向媒体披露公司网站被黑、裁员、被收购等重大新闻。

CPO：Privacy 首席隐私官，负责公司内部员工Email、ICQ、OICQ等通信内容的监控。

CQO：Quantity Making，数量指标编造专家，负责注册用户数量、页面浏览、营业收入等指标的编造。

CRO：Reduce the stafftrimmer 首席裁员官，负责所有与裁员有关的事务，直接向股东大会负责，包括董事长在内都不得干预其工作。

CSO：Strategy 首席战略官，由已经退位的公司主要创建人担任，在政府机关一般称为调研员或顾问。

CTO：Testing 首席测试官，是公司唯一负责网站建设的专家，由于技术开发不成熟，需要一直测试下去。

CUO：Union 首席联盟官，以战略联盟的名义，专门寻找有收购自己意向的网站。

CVO：VC reception 风险投资商接待专员，首席财务官的另一重要助理。

CWO：Writer 首席网络写手，负责将小事扩大化，通过炒作达到扩大网站知名度的目的，其下属为COO。

CXO：Xingxiang（因为中国特有，所以只能用汉语拼音表示） 网站形象代言人，一般由学历不高且没有任何网络知识的年轻人担任。

CYO：Yearly 公司元老，这是一个荣誉称号，授予在同一网站工作满一年的员工（这个职位通常空缺）。

CZO：Zero 最后离开公司的一个人，负责关好门窗，将公司大门钥匙交给物业管理处，可以由CAO兼任。

计算机/互联网/通讯 Technology/Internet
首席技术执行官 CTO/VP Engineering
技术总监/经理 Technical Director/Manager
信息技术经理 IT Manager
信息技术主管 IT Supervisor
信息技术专员 IT Specialist
项目经理/主管 Project Manager/Supervisor
项目执行/协调人员 Project Specialist / Coordinator
系统分析员 System Analyst
高级软件工程师 Senior Software Engineer
软件工程师 Software Engineer
系统工程师 System Engineer
高级硬件工程师 Senior Hardware Engineer
硬件工程师 Hardware Engineer
通信技术工程师 Communications Engineer
ERP技术/应用顾问 ERP Technical/Application Consultant

数据库工程师 Database Engineer
技术支持经理 Technical Support Manager
技术支持工程师 Technical Support Engineer
品质经理 QA Manager
信息安全工程师 Information Security Engineer
软件测试工程师 Software QA Engineer
硬件测试工程师 Hardware QA Engineer
测试员 Test Engineer
网站营运经理/主管 Web Operations Manager/Supervisor
网络工程师 Network Engineer
系统管理员/网管 System Manager/Webmaster
网页设计/制作 Web Designer/Production
技术文员/助理 Technical Clerk/Assistant

销售 Sales
销售总监 Sales Director
销售经理 Sales Manager
区域销售经理 Regional Sales Manager
客户经理 Sales Account Manager
渠道/分销经理 Channel/Distribution Manager
渠道主管 Channel Supervisor
销售主管 Sales Supervisor
销售代表 Sales Representative / Executive
销售工程师 Sales Engineer
医药代表 Pharmaceutical Sales Representative
保险代理 Insurance Agent
销售助理 Sales Assistant / Trainee
商务经理 Business Manager
商务专员/助理 Business Executive/Assistant
销售行政经理 Sales Admin. Manager
销售行政主管 Sales Admin. Supervisor
售前/售后技术服务经理 Technical Service Manager
售前/售后技术服务主管 Technical Service Supervisor
售前/售后技术服务工程师 Technical Service Engineer
售后/客户服务（非技术）经理 Customer Service Manager
售后/客户服务（非技术）主管 Customer Service Supervisor
售后/客户服务（非技术）专员 Customer Service Executive
经销商 Distributor

市场/公关/广告 Marketing/PR/Advertising
市场/广告总监 Marketing/Advertising Director/VP
市场/营销经理 Marketing Manager
市场/营销主管 Marketing Supervisor
市场/营销专员 Marketing Executive/Communication
市场助理 Marketing Assistant / Trainee
产品/品牌经理 Product/Brand Manager
产品/品牌主管 Product/Brand Supervisor
市场通路经理 Trade Marketing Manager
市场通路主管 Trade Marketing Supervisor
促销经理 Promotions Manager
促销主管 Promotions Supervisor
促销员 Promotions Specialist
市场分析/调研人员 Market Analyst/ Research Analyst
公关/会务经理 Public Relations Manager
公关/会务主管 Public Relations Supervisor
公关/会务专员 Public Relations Executive
媒介经理 Media Manager
媒介人员 Media Specialist
企业/业务发展经理 Business Development Manager
企业策划人员 Corporate Planning
广告策划/设计/文案 Advertising Creative/Design/Copy writer


GM（General Manager）总经理 
VP（Vice President）副总裁
FVP（First Vice President）第一副总裁 
AVP（Assistant Vice President）副总裁助理 
HRD（Human Resource Director）人力资源总监 
OD（Operations Director）运营总监 
MD（Marketing Director）市场总监 
OM（Operations Manager）运作经理 
PM（Production Manager生产经理、Product Manager产品经理、Project Manager项目经理) 注：这里面变化比较多，要结合谈话时的背景来判断究竟是指哪种身份） 
BM（Branch Manager）部门经理 
DM（District Manager）区域经理 
RM（Regional Manager）区域经理 
======================= 
下面总结了CAO~CZO中间的字母从A到Z的各种简称： 
CAO: Art 艺术总监 
CBO: Business 商务总监 
CCO: Content 内容总监 
CDO: Development 开发总监 
CEO: Executive 首席执行官 
CFO: Finance 财务总监 
CGO: Gonverment 政府关系 
CHO: Human resource 人事总监 
CIO: Information 技术总监 
CJO: Jet 把营运指标都加一个或多个零使公司市值像火箭般上升的人 
CKO: Knowledge 知识总监 
CLO: Labour 工会主席 
CMO: Marketing 市场总监 
CNO: Negotiation 首席谈判代表 
COO: Operation 首席营运官 
CPO: Public relation 公关总监 
CQO: Quality control 质控总监 
CRO: Research 研究总监 
CSO: Sales 销售总监 
CTO: Technology 首席技术官 
CUO: User 客户总监 
CVO: Valuation 评估总监 
CWO: Women 妇联主席 
CXO: 什么都可以管的不管部部长 
CYO: Yes 什么都点头的老好人 
CZO: 现在排最后,等待接班的太子部分主要职位的职能： CEO(Chief executive officer)首席执行官 类似总经理、总裁，是企业的法人代表。 




       CLI（command-line interface，命令行界面）是指可在用户提示符下键入可执行指令的界面，它通常不支持鼠标，用户通过键盘输入指令，计算机接收到指令后，予以执行。
CLI在汇编指令中也有关闭中断的意思。
CLI是Command
 Line Interface的缩写，即命令行界面。CLI界面是所有路由器、TM（Termination
 Multiplexer，终端复用器）、CM（Cable
 Modem，
电缆调制解调器）等产品提供的界面，如CISCO，
 LUCENT，Arris， 华为等。它是路由器产品的标准。使用CLI具有使用要求低（只需要串行口），容易
使用，功能扩充方便等优点，特别是当有很多（如10台）台路由器设备需要配置的时候，可以通过COPY/PASTE功能很快完成所有路由器的配置。不需要
通过IE一台台配置。

通常认为，命令行界面（CLI）没有图形用户界面（GUI）那么方便用户操作。因为，命令行界面的软件通常需要用户记忆操作的命令，但是，由于其
本身的特点，命令行界面要较图形用户界面节约计算机系统的资源。在熟记命令的前提下，使用命令行界面往往要较使用图形用户界面的操作速度要快。
所以，在的图形用户界面的操作系统中，通常都保留着可选的命令行界面。
传统的Unix环境是 CLI（命令行界面），即在命令行下键入命令，执行想要的操作。相比之下，这种方式执行起来更快，功能也更强，不足之处是用
户需要了解相关操作的命令。早期的计算机操作系统都只有命令行操作模式，没有使用非常流行的“图形用户界面（GUI）。
虽然许多计算机系统都提供了图形化的操作方式，但是却都没有因而停止提供文字模式的命令行操作方式，相反的，许多系统反而更加强这部份的功
能，例如Windows就不只加强了操作命令的功能和数量，也一直在改善Shell
 Programming的方式。而之所以要加强、改善，自然是因为不够好；操作系
统的图形化操作方式对单一客户端计算机的操作，已经相当方便，但如果是一群客户端计算机，或者是24小时运作的服务器计算机，图形化操作方式有
时会力有未逮，所以需要不断增强命令行界面的脚本语言和宏语言来提供丰富的控制与自动化的系统管理能力，例如Linux系统的Bash或是Windows系
统的Windows
 PowerShell。
相关扩展
CLI（Common
 Language Infrastructure）

通用语言基础结构（Common
 Language Infrastructure，CLI）是CLR的一个子集，也就是.NET中最终对编译成MSIL代码的应用
程序的运行环境进行管理的那一部分。在CLR结构图中CLI位于下半部分，主要包括类加载器(Class
 Loader)、实时编译器(IL
 To 
Native Compilers)和一个运行时环境的垃圾收集器(Garbage
 Collector)。CLI是.Net和CLR的灵魂，CLI为IL代码提供运行的环境，你可
以将使用任何语言编写的代码通过其特定的编译器转换为MSIL代码之后运行其上，甚至还可以自己写MSIL代码在CLI上面运行。
欧洲计算机制造商协会（ECMA）已经于2001年10月13日批准C#语言规范（ECMA-334）成为一种新诞生的计算机产业标准。同时国际标准组织
ISO也同意该标准进入该组织的审批阶段。并且，作为.Net与CLR的核心部分，CLI与C#也同时获得了ECMA的批准（ECMA-335）。拥有了C#与CLI这
两项标准，你可以自己写出能够运行于任何操作系统上的.Net平台(只要你愿意)。如前所述，著名的Mono项目就是这么干的，Mono项目包括三个核心的
部分：一个C#语言的编译器，一个CLI和一个类库。在Java的世界中，这项工作是由SUN公司完成的，SUN针对不同的操作系统开发出相应的Java虚拟
机以便让一个由Java开发的应用程序运行在不同的操作系统上，但是迄今为止还没听说过微软有这方面打算(为用户提供非Windows系统的.Net平台)。


我们用Eclipse创建Maven结构的web项目的时候选择了Artifact Id为maven-artchetype-webapp，由于这个catalog比较老，用的servlet还是2.3的，而一般现在至少都是2.5，在Project Facets里面修改Dynamic web module为2.5的时候就会出现Cannot change version of project facet Dynamic web module to 2.5，如图：




其实在右边可以看到改到2.5需要的条件以及有冲突的facets，解决这个问题的步骤如下：

1.把Servlet改成3.0，打开项目的web.xml，改之前：





[html] view
 plain copy


 print?



&lt;!DOCTYPE web-app PUBLIC  
 "-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN"  
 "http://java.sun.com/dtd/web-app_2_3.dtd" &gt;  
  
&lt;web-app&gt;  
  &lt;display-name&gt;Archetype Created Web Application&lt;/display-name&gt;  
&lt;/web-app&gt;  






改后：





[html] view
 plain copy


 print?



&lt;?xml version="1.0" encoding="UTF-8"?&gt;  
&lt;web-app version="3.0"  
    xmlns="http://java.sun.com/xml/ns/javaee"  
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"  
    xsi:schemaLocation="http://java.sun.com/xml/ns/javaee  
    http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd"&gt;  
      
  &lt;display-name&gt;Archetype Created Web Application&lt;/display-name&gt;  
&lt;/web-app&gt;  






2.修改项目的设置，在Navigator下打开项目.settings目录下的org.eclipse.jdt.core.prefs





[html] view
 plain copy


 print?



eclipse.preferences.version=1  
org.eclipse.jdt.core.compiler.codegen.inlineJsrBytecode=enabled  
org.eclipse.jdt.core.compiler.codegen.targetPlatform=1.5  
org.eclipse.jdt.core.compiler.compliance=1.5  
org.eclipse.jdt.core.compiler.problem.assertIdentifier=error  
org.eclipse.jdt.core.compiler.problem.enumIdentifier=error  
org.eclipse.jdt.core.compiler.problem.forbiddenReference=warning  
org.eclipse.jdt.core.compiler.source=1.5  


把1.5改成1.8







[html] view
 plain copy


 print?



eclipse.preferences.version=1  
org.eclipse.jdt.core.compiler.codegen.inlineJsrBytecode=enabled  
org.eclipse.jdt.core.compiler.codegen.targetPlatform=1.8
  
org.eclipse.jdt.core.compiler.compliance=1.8
  
org.eclipse.jdt.core.compiler.problem.assertIdentifier=error  
org.eclipse.jdt.core.compiler.problem.enumIdentifier=error  
org.eclipse.jdt.core.compiler.problem.forbiddenReference=warning  
org.eclipse.jdt.core.compiler.source=1.8
  


打开org.eclipse.wst.common.component







[html] view
 plain copy


 print?



&lt;?xml version="1.0" encoding="UTF-8"?&gt;  
&lt;project-modules id="moduleCoreId" project-version="1.5.0"&gt;  
    &lt;wb-module deploy-name="test"&gt;  
        &lt;wb-resource deploy-path="/" source-path="/target/m2e-wtp/web-resources"/&gt;  
        &lt;wb-resource deploy-path="/" source-path="/src/main/webapp" tag="defaultRootSource"/&gt;  
        &lt;wb-resource deploy-path="/WEB-INF/classes" source-path="/src/main/java"/&gt;  
        &lt;wb-resource deploy-path="/WEB-INF/classes" source-path="/src/main/resources"/&gt;  
        &lt;property name="context-root" value="test"/&gt;  
        &lt;property name="java-output-path" value="/test/target/classes"/&gt;  
    &lt;/wb-module&gt;  
&lt;/project-modules&gt;  


把project-version="1.5.0"改成project-version="1.8.0"




[html] view
 plain copy


 print?



&lt;?xml version="1.0" encoding="UTF-8"?&gt;  
&lt;project-modules id="moduleCoreId" project-version="1.8.0"&gt;  
    &lt;wb-module deploy-name="test"&gt;  
        &lt;wb-resource deploy-path="/" source-path="/target/m2e-wtp/web-resources"/&gt;  
        &lt;wb-resource deploy-path="/" source-path="/src/main/webapp" tag="defaultRootSource"/&gt;  
        &lt;wb-resource deploy-path="/WEB-INF/classes" source-path="/src/main/java"/&gt;  
        &lt;wb-resource deploy-path="/WEB-INF/classes" source-path="/src/main/resources"/&gt;  
        &lt;property name="context-root" value="test"/&gt;  
        &lt;property name="java-output-path" value="/test/target/classes"/&gt;  
    &lt;/wb-module&gt;  
&lt;/project-modules&gt;  


打开org.eclipse.wst.common.project.facet.core.xml







[html] view
 plain copy


 print?



&lt;?xml version="1.0" encoding="UTF-8"?&gt;  
&lt;faceted-project&gt;  
  &lt;fixed facet="wst.jsdt.web"/&gt;  
  &lt;installed facet="java" version="1.5"/&gt;  
  &lt;installed facet="jst.web" version="2.3"/&gt;  
  &lt;installed facet="wst.jsdt.web" version="1.0"/&gt;  
&lt;/faceted-project&gt;  


把&lt;installed facet="java" version="1.5"/&gt;改成&lt;installed facet="java" version="1.8"/&gt;，把  &lt;installed facet="jst.web" version="2.3"/&gt;改成  &lt;installed facet="jst.web" version="3.0"/&gt;







[html] view
 plain copy


 print?



&lt;?xml version="1.0" encoding="UTF-8"?&gt;  
&lt;faceted-project&gt;  
  &lt;fixed facet="wst.jsdt.web"/&gt;  
  &lt;installed facet="java" version="1.8"/&gt;  
  &lt;installed facet="jst.web" version="3.0"/&gt;  
  &lt;installed facet="wst.jsdt.web" version="1.0"/&gt;  
&lt;/faceted-project&gt;  


都改好之后在打开看看，已经把Dynamic web module改成了3.0






好了，大功搞成，这是一种解决办法，但是治标不治本，更高级的就是自定义catalog，然后安装到本地，再创建的时候啥都有了，比如把现在流行的s(struts2)sh，ssi，s(springmvc)sh 创建catalog，包括包结构，部分代码啥的都有。


MySQL解压版安装与设置，有需要的朋友可以参考下。

首先，介绍一下Mysql的基本情况： 

1、Mysql版本：mysql-5.6.24-win32
2、官方下载地址：http://dev.mysql.com/downloads/mysql/；分账户登录和非账户登录下载，读者可根据自身情况进行下载。
其次，描述配置和安装MySQL服务： 

1、解压MySQL到按照目录：D:\java\mysql-5.6.24-win32

2、设置环境变量
增加环境变量： MYSQL_HOME=D:\java\mysql-5.6.24-win32
1)修改环境变脸： 在path后面增加%MYSQL_HOME%\bin;
2)配置my.ini

3、配置
将D:\java\mysql-5.6.24-win32\my-default.ini 拷贝一份并修改为my.ini


修改：
[mysqld]
#绑定IPv4和3306端口
bind-address = 0.0.0.0
port = 3306

# 设置mysql的安装目录
basedir=D:\java\mysql-5.6.24-win32

# 设置mysql数据库的数据的存放目录
datadir=D:\java\mysql-5.6.24-win32\data

# 允许最大连接数
max_connections=200

4、安装MYSQL服务
1）打开cmd.exe；
2）进入目录：D:\java\mysql-5.6.24-win32\bin；
3）运行： mysqld -install （你会看到服务安装成功）

5、MySQL服务开启与关闭
1）启动服务
net start mysql
2）停止服务
net stop mysql

6、配置root用户登录
1）打开cmd.exe；
2）进入目录：D:\java\mysql-5.6.24-win32\bin；
3）输入：mysql -u root -p，提示输入密码时，直接回车即可以root身份进入管理MySQL了
4）修改root密码，运行：d:\mysql-5.6.13\bin\mysqladmin -u root -p password &lt;新密码&gt;



其他，my.ini的配置 

关于my.ini里面更多更复杂的参数配置，需要对MySQL进行优化的兄弟们可以参照MySQL官网的手册来操作。


这篇文章主要介绍了Windows下使用批处理实现启动关闭mysql，其主要核心思想是将mysql注册成为windows下的服务，推荐给大家。
将绿色版的mysql注册成Windows下的服务，或者安装版的mysql的Windows服务均可使用。

创建一个文件，并以.bat为后缀，如mysql.bat，打开编辑，输入如下内容。输入后以管理员身份运行。（前提要mysql已经安装或配置成功）
cls 
@echo off
:设置窗口字体颜色
color 0a 
:设置窗口标题
TITLE MySQL管理程序
  
call :checkAdmin
  
goto menu
:菜单
:menu
cls
echo. 
echo.=-=-=-=-请选择您要对MySQL的操作-=-=-=-=-
echo.
echo.1: 启动MySQL
echo.
echo.2: 关闭MySQL
echo. 
echo.3: 重启MySQL
echo. 
echo.4: 退 出
echo.
echo.=-=-=-=-请输入您要选择的项目序号↓-=-=-=-
set /p id=
if "%id%"=="1" goto startup
if "%id%"=="2" goto shutdown
if "%id%"=="3" goto reboot
if "%id%"=="4" exit
pause
  
:启动
:startup
echo.
call :checkMySQL 1
echo.启动MySQL......
net start "MySQL"
echo.启动MySQL成功！
pause 
goto menu 
  
:停止
:shutdown
echo.
call :checkMySQL 2
echo.关闭MySQL......
net stop "MySQL"
echo.关闭MySQL成功！
pause 
goto menu
  
:重启
:reboot
echo.
call :checkMySQL 2
echo.关闭MySQL......
net stop "MySQL"
echo.关闭MySQL成功！
goto startup
goto menu
  
:退出
:goout
pause
goto menu
  
:检查MySQL进程是否存在
:checkMySQL
set /a count=0
for /f "tokens=1 delims= " %%i in ('tasklist /nh ^| find /i "MySQL"') do (set /a count+=1)
if %count% neq 0 if "%1" equ "1" (
  echo 警告：MySQL已启动
  goto goout
)
if %count% equ 0 if "%1" equ "2" (
  echo 警告：MySQL未启动
  goto goout
)
  
:检查是否是以管理员身份运行
:checkAdmin
echo test am i admin? &gt; %SystemRoot%\System32\test.sunhao
if not exist %SystemRoot%\System32\test.sunhao (
  echo 警告：请以管理员身份运行！
  pause
  exit
)
del %SystemRoot%\System32\test.sunhao



1、什么是FindBugs
FindBugs 是一个静态分析工具，它检查类或者 JAR 文件，将字节码与一组缺陷模式进行对比以发现可能的问题。有了静态分析工具，就可以在不实际运行程序的情况对软件进行分析。不是通过分析类文件的形式或结构来确定程序的意图，而是通常使用 Visitor 模式来鉴别代码是否符合一些固定的规范。
2、如何安装FindBugs?
作为Eclipse的一个插件，可以将Findbugs集成到Eclipse中使用。
第一种是在线安装：在Eclipse的插件安装地址中输入http://findbugs.cs.umd.edu/eclipse并一路“next”就可安装成功。
第二种方式是下载Findbugs插件，将它放入Eclipse下的plusin文件夹，然后重启Eclipse即可。
3、如何使用FindBugs
安装了Findbugs插件后。右击点击你要检查的项目选择【Find Bugs】-&gt;【Find Bugs】进行检查。要查看Findbugs检查出了哪些Bug，可以选择Windows菜单-&gt;Show View-&gt;Bug Explorer，打开Bug Explorer面板。如果想要查看某个Bug详细的信息，则可以选择Windows菜单-&gt;Open Perspective，然后选择FindBugs就可以打开FindBugs的Properties面板，在这个面板里面可以看到最详尽的Bugs信息。
4、FindBugs能发现的所有Bug类型
FindBugs 网站http://findbugs.sourceforge.net/bugDescriptions.html提供了完整的类型清单。

To install the FindBugs plugin:


In Eclipse, click on Help -&gt; Software Update -&gt; Find and Install...Choose the Search for new features to install option, and click Next.Click New Remote Site.Enter the following:

Name: FindBugs update siteURL: one of the following (note: no final slash on the url)

http://findbugs.cs.umd.edu/eclipse for official releaseshttp://findbugs.cs.umd.edu/eclipse-candidate for candidate releases and official releaseshttp://findbugs.cs.umd.edu/eclipse-daily for all releases, including developmental ones

and click OK."FindBugs update site" should appear under Sites to include in search. 
Click the checkbox next to it to select it, and click Finish.You should see FindBugs Feature under Select features to install. 
(You may have to click on one or two triangles to make it visible in the tree.)
Select the checkbox next to it and click next.Select the I accept option to accept the license and click Next.Make sure the location is correct where you're installing it. The default (your workspace) should be fine. Click Finish.The plugin is not digitally signed. Go ahead and install it anyway.Click Yes to make Eclipse restart itself.


它是干嘛的？
findbugs是一个开源的eclipse 代码检查工具；它可以简单高效全面地帮助我们发现程序代码中存在的bug，bad smell，以及潜在隐患。针对各种问题，它并且提供了简单的修改意见供我们重构时进行参考； 通过使用它，可以一定程度上降低我们code review的工作量，并且会提高review效率。 通过findbugs找到bug，再由我们自己重构代码，可以培养我们的编码意识及水平，形成好的习惯提高开发编码能力。
哪里下载？
下载地址：
http://downloads.sourceforge.net/project/findbugs/findbugs%20eclipse%20plugin/1.3.9/edu.umd.cs.findbugs.plugin.eclipse_1.3.9.20090821.zip?use_mirror=ncu
如何安装？
1、把下载的压缩包解压后，把 

copy到eclipse的plugin目录中去；
2、重新启动eclipse
3、打开eclipse-&gt;window-&gt;Preferences，搜索关键字findbugs,如果能找到配置项，那么表示安装成功，如图：




怎么用？
findbugs 简单易用，按照下图操作即可；
1、在eclipse package Explorer 右键选择目标工程-&gt; build project



2、选择指定的包或者类进行findbug



此时findbugs会遍历指定的包或者类，进行分析，找出代码bug，然后集中显示在 find bugs的bugs explorer 中，下面我们添加bugs explorer。
3、添加findbugs explorer 
（eclipse 左下角）









4、bugs explorer 添加完毕后，我们就可以查看刚刚找到的bugs了，如图：



找出的bug有3中颜色， 黑色的臭虫标志是分类， 红色的臭虫表示严重bug发现后必须修改代码，橘黄色的臭虫表示潜在警告性bug 尽量修改。（附录是各种bug的解释及修改方案，请大家按附表参考修改）
双击bug项目就可以在右边编辑窗口自动打开相关代码文件并连接到代码片段。 点击行号旁边的小臭虫图标后再eclipse下方输出区将提供详细的bug描述，以及修改建议等信息。我们可以根据此信息进行修改。
参考资料
suorceforge 地址：http://findbugs.sourceforge.net/
官方的文档 ：http://findbugs.sourceforge.net/manual
http://hi.baidu.com/seejava/blog/item/bbbd02382c7ea5f5b311c742.html
转载自：http://tidus2005.iteye.com/blog/462212
有的时候MyEclipse8.5不可以在线更新插件，也就是说明明你添加插件后，却不可以应用更改（不知道为什么，谁知道可以告诉我)。那就只有采用离线安装方式，下载插件包，然后安装。
而MyEclipse在7.0版之后的目录结构发生了变化，而且是很大的变化，你再也找不到eclipse这个文件夹了，而以前安装插件的时候是都要在这个文件夹里做手脚的。在网上找了好多文章，有各种说法，这样那样的，都不管用，后来终于找到了几个有用的，知道了两种离线插件的安装方法。
在一般情况下，下载回来的插件解压后只有这两种目录结构
eclipse目录，下面有两个文件夹：features、plugins。
插件名目录（如edu.umd.cs.findbugs.plugin.eclipse_1.3.9.20090821），下面有这样的结构
第一种结构的插件应该是老版本的Eclipse离线安装目录结构，后者应该是比较新的结构，当然这些都是我猜测的。
下面说如何安装，那就是在MyEclipse8.5里有一个插件配置的文件，这个是很必要的，位置在：MyEclipse安装根目录/configuration/org.eclipse.equinox.simpleconfigurator/bundles.info
所有插件都必须配置在这个文件里才可以使用，这个文件的格式是
包名，版本号，文件路经，4，false
要安装插件最必要的步骤就是照猫画虎的把插件信息添加到这里就OK了。
安装步骤：
一、Copy文件
如果是第一种目录结构，就要把features、plugins里面的内容 分别copy到 MyEclipse安装根目录/Common/features与 MyEclipse安装根目录/Common/plugins目录下。
如果是第二种目录结构，就要把解压出来的那一整个目录copy到 MyEclipse安装根目录/Common/plugins目录下。
二、配置bundles.info文件
如果是第一种目录结构，在bundles.info末尾追加类似如下信息：
jp.gr.java_conf.ussiy.app.propedit,5.3.3,file:/D:/MyEclipse 8.5/Common/plugins/jp.gr.java_conf.ussiy.app.propedit_5.3.3.jar/,4,false
如果是第二种目录结构，在bundles.info末尾追加类似如下信息：
edu.umd.cs.findbugs.plugin.eclipse,1.3.9.20090821,file:/D:/MyEclipse 8.5/Common/plugins/edu.umd.cs.findbugs.plugin.eclipse_1.3.9.20090821/,4,false
所不同的就是第一种目录结构的要指定到具体的jar文件，而第二种目录结构只需要指定到目录就可以了。
三、重启MyEclipse。



下面是20个非常有用的Java程序片段，希望能对你有用。
1.
 字符串与整型的相互转换
String a = String.valueOf(2);   //integer to numeric string   
int i = Integer.parseInt(a); //numeric string to an int 

2. 向文件末尾添加内容

BufferedWriter out = null;   
try {   
    out = new BufferedWriter(new FileWriter(”filename”, true));   
    out.write(”aString”);   
} catch (IOException e) {   
    // error processing code   
} finally {   
    if (out != null) {   
        out.close();   
    }   
}
3. 得到当前方法的名字

String methodName = Thread.currentThread().getStackTrace()[1].getMethodName();
4. 转字符串到日期java.util.Date = java.text.DateFormat.getDateInstance().parse(dateString); 或者是：
SimpleDateFormat format = new SimpleDateFormat( "yyyy-MM-dd" );   
Date date = format.parse( myString ); 5. 使用JDBC链接Oracle
public class OracleJdbcTest   
{   
    String driverClass = "oracle.jdbc.driver.OracleDriver";   
   
    Connection con;   
   
    public void init(FileInputStream fs) throws ClassNotFoundException, SQLException, FileNotFoundException, IOException   
    {   
        Properties props = new Properties();   
        props.load(fs);   
        String url = props.getProperty("db.url");   
        String userName = props.getProperty("db.user");   
        String password = props.getProperty("db.password");   
        Class.forName(driverClass);   
   
        con=DriverManager.getConnection(url, userName, password);   
    }   
   
    public void fetch() throws SQLException, IOException   
    {   
        PreparedStatement ps = con.prepareStatement("select SYSDATE from dual");   
        ResultSet rs = ps.executeQuery();   
   
        while (rs.next())   
        {   
            // do the thing you do   
        }   
        rs.close();   
        ps.close();   
    }   
   
    public static void main(String[] args)   
    {   
        OracleJdbcTest test = new OracleJdbcTest();   
        test.init();   
        test.fetch();   
    }   
}
6. 把 Java util.Date 转成 sql.Date

java.util.Date utilDate = new java.util.Date();   
java.sql.Date sqlDate = new java.sql.Date(utilDate.getTime());
7. 使用NIO进行快速的文件拷贝

public static void fileCopy( File in, File out )   
            throws IOException   
    {   
        FileChannel inChannel = new FileInputStream( in ).getChannel();   
        FileChannel outChannel = new FileOutputStream( out ).getChannel();   
        try  
        {   
//          inChannel.transferTo(0, inChannel.size(), outChannel);      // original -- apparently has trouble copying large files on Windows   
   
            // magic number for Windows, 64Mb - 32Kb)   
            int maxCount = (64 * 1024 * 1024) - (32 * 1024);   
            long size = inChannel.size();   
            long position = 0;   
            while ( position &lt; size )   
            {   
               position += inChannel.transferTo( position, maxCount, outChannel );   
            }   
        }   
        finally  
        {   
            if ( inChannel != null )   
            {   
               inChannel.close();   
            }   
            if ( outChannel != null )   
            {   
                outChannel.close();   
            }   
        }   
    }
8. 创建图片的缩略图

private void createThumbnail(String filename, int thumbWidth, int thumbHeight, int quality, String outFilename)   
        throws InterruptedException, FileNotFoundException, IOException   
    {   
        // load image from filename   
        Image image = Toolkit.getDefaultToolkit().getImage(filename);   
        MediaTracker mediaTracker = new MediaTracker(new Container());   
        mediaTracker.addImage(image, 0);   
        mediaTracker.waitForID(0);   
        // use this to test for errors at this point: System.out.println(mediaTracker.isErrorAny());   
   
        // determine thumbnail size from WIDTH and HEIGHT   
        double thumbRatio = (double)thumbWidth / (double)thumbHeight;   
        int imageWidth = image.getWidth(null);   
        int imageHeight = image.getHeight(null);   
        double imageRatio = (double)imageWidth / (double)imageHeight;   
        if (thumbRatio &lt; imageRatio) {   
            thumbHeight = (int)(thumbWidth / imageRatio);   
        } else {   
            thumbWidth = (int)(thumbHeight * imageRatio);   
        }   
   
        // draw original image to thumbnail image object and   
        // scale it to the new size on-the-fly   
        BufferedImage thumbImage = new BufferedImage(thumbWidth, thumbHeight, BufferedImage.TYPE_INT_RGB);   
        Graphics2D graphics2D = thumbImage.createGraphics();   
        graphics2D.setRenderingHint(RenderingHints.KEY_INTERPOLATION, RenderingHints.VALUE_INTERPOLATION_BILINEAR);   
        graphics2D.drawImage(image, 0, 0, thumbWidth, thumbHeight, null);   
   
        // save thumbnail image to outFilename   
        BufferedOutputStream out = new BufferedOutputStream(new FileOutputStream(outFilename));   
        JPEGImageEncoder encoder = JPEGCodec.createJPEGEncoder(out);   
        JPEGEncodeParam param = encoder.getDefaultJPEGEncodeParam(thumbImage);   
        quality = Math.max(0, Math.min(quality, 100));   
        param.setQuality((float)quality / 100.0f, false);   
        encoder.setJPEGEncodeParam(param);   
        encoder.encode(thumbImage);   
        out.close();   
    }9. 创建 JSON 格式的数据
import org.json.JSONObject;   
...   
...   
JSONObject json = new JSONObject();   
json.put("city", "Mumbai");   
json.put("country", "India");   
...   
String output = json.toString();   
...10. 使用iText JAR生成PDF
import java.io.File;   
import java.io.FileOutputStream;   
import java.io.OutputStream;   
import java.util.Date;   
   
import com.lowagie.text.Document;   
import com.lowagie.text.Paragraph;   
import com.lowagie.text.pdf.PdfWriter;   
   
public class GeneratePDF {   
   
    public static void main(String[] args) {   
        try {   
            OutputStream file = new FileOutputStream(new File("C:\\Test.pdf"));   
   
            Document document = new Document();   
            PdfWriter.getInstance(document, file);   
            document.open();   
            document.add(new Paragraph("Hello Kiran"));   
            document.add(new Paragraph(new Date().toString()));   
   
            document.close();   
            file.close();   
   
        } catch (Exception e) {   
            e.printStackTrace();   
        }   
    }   
}11. HTTP 代理设置
System.getProperties().put("http.proxyHost", "someProxyURL");   
System.getProperties().put("http.proxyPort", "someProxyPort");   
System.getProperties().put("http.proxyUser", "someUserName");   
System.getProperties().put("http.proxyPassword", "somePassword");12. 单实例Singleton 示例
public class SimpleSingleton {   
    private static SimpleSingleton singleInstance =  new SimpleSingleton();   
   
    //Marking default constructor private   
    //to avoid direct instantiation.   
    private SimpleSingleton() {   
    }   
   
    //Get instance for class SimpleSingleton   
    public static SimpleSingleton getInstance() {   
   
        return singleInstance;   
    }   
}另一种实现
public enum SimpleSingleton {   
    INSTANCE;   
    public void doSomething() {   
    }   
}   
   
//Call the method from Singleton:   
SimpleSingleton.INSTANCE.doSomething();关于单例的详情可以查看单例设计模式。


13. 抓屏程序

import java.awt.Dimension;   
import java.awt.Rectangle;   
import java.awt.Robot;   
import java.awt.Toolkit;   
import java.awt.image.BufferedImage;   
import javax.imageio.ImageIO;   
import java.io.File;   
   
...   
   
public void captureScreen(String fileName) throws Exception {   
   
   Dimension screenSize = Toolkit.getDefaultToolkit().getScreenSize();   
   Rectangle screenRectangle = new Rectangle(screenSize);   
   Robot robot = new Robot();   
   BufferedImage image = robot.createScreenCapture(screenRectangle);   
   ImageIO.write(image, "png", new File(fileName));   
   
}   
...14. 列出文件和目录
File dir = new File("directoryName");   
  String[] children = dir.list();   
  if (children == null) {   
      // Either dir does not exist or is not a directory   
  } else {   
      for (int i=0; i &lt; children.length; i++) {   
          // Get filename of file or directory   
          String filename = children[i];   
      }   
  }   
   
  // It is also possible to filter the list of returned files.   
  // This example does not return any files that start with `.'.   
  FilenameFilter filter = new FilenameFilter() {   
      public boolean accept(File dir, String name) {   
          return !name.startsWith(".");   
      }   
  };   
  children = dir.list(filter);   
   
  // The list of files can also be retrieved as File objects   
  File[] files = dir.listFiles();   
   
  // This filter only returns directories   
  FileFilter fileFilter = new FileFilter() {   
      public boolean accept(File file) {   
          return file.isDirectory();   
      }   
  };   
  files = dir.listFiles(fileFilter);15. 创建ZIP和JAR文件
import java.util.zip.*;   
import java.io.*;   
   
public class ZipIt {   
    public static void main(String args[]) throws IOException {   
        if (args.length &lt; 2) {   
            System.err.println("usage: java ZipIt Zip.zip file1 file2 file3");   
            System.exit(-1);   
        }   
        File zipFile = new File(args[0]);   
        if (zipFile.exists()) {   
            System.err.println("Zip file already exists, please try another");   
            System.exit(-2);   
        }   
        FileOutputStream fos = new FileOutputStream(zipFile);   
        ZipOutputStream zos = new ZipOutputStream(fos);   
        int bytesRead;   
        byte[] buffer = new byte[1024];   
        CRC32 crc = new CRC32();   
        for (int i=1, n=args.length; i &lt; n; i++) {   
            String name = args[i];   
            File file = new File(name);   
            if (!file.exists()) {   
                System.err.println("Skipping: " + name);   
                continue;   
            }   
            BufferedInputStream bis = new BufferedInputStream(   
                new FileInputStream(file));   
            crc.reset();   
            while ((bytesRead = bis.read(buffer)) != -1) {   
                crc.update(buffer, 0, bytesRead);   
            }   
            bis.close();   
            // Reset to beginning of input stream   
            bis = new BufferedInputStream(   
                new FileInputStream(file));   
            ZipEntry entry = new ZipEntry(name);   
            entry.setMethod(ZipEntry.STORED);   
            entry.setCompressedSize(file.length());   
            entry.setSize(file.length());   
            entry.setCrc(crc.getValue());   
            zos.putNextEntry(entry);   
            while ((bytesRead = bis.read(buffer)) != -1) {   
                zos.write(buffer, 0, bytesRead);   
            }   
            bis.close();   
        }   
        zos.close();   
    }   
}16. 解析/读取XML 文件
xml文件
&lt;?xml version="1.0"?&gt;  
&lt;students&gt;  
    &lt;student&gt;  
        &lt;name&gt;John&lt;/name&gt;  
        &lt;grade&gt;B&lt;/grade&gt;  
        &lt;age&gt;12&lt;/age&gt;  
    &lt;/student&gt;  
    &lt;student&gt;  
        &lt;name&gt;Mary&lt;/name&gt;  
        &lt;grade&gt;A&lt;/grade&gt;  
        &lt;age&gt;11&lt;/age&gt;  
    &lt;/student&gt;  
    &lt;student&gt;  
        &lt;name&gt;Simon&lt;/name&gt;  
        &lt;grade&gt;A&lt;/grade&gt;  
        &lt;age&gt;18&lt;/age&gt;  
    &lt;/student&gt;  
&lt;/students&gt;java代码：
import java.io.File;   
import javax.xml.parsers.DocumentBuilder;   
import javax.xml.parsers.DocumentBuilderFactory;   
   
import org.w3c.dom.Document;   
import org.w3c.dom.Element;   
import org.w3c.dom.Node;   
import org.w3c.dom.NodeList;   
   
public class XMLParser {   
   
    public void getAllUserNames(String fileName) {   
        try {   
            DocumentBuilderFactory dbf = DocumentBuilderFactory.newInstance();   
            DocumentBuilder db = dbf.newDocumentBuilder();   
            File file = new File(fileName);   
            if (file.exists()) {   
                Document doc = db.parse(file);   
                Element docEle = doc.getDocumentElement();   
   
                // Print root element of the document   
                System.out.println("Root element of the document: "  
                        + docEle.getNodeName());   
   
                NodeList studentList = docEle.getElementsByTagName("student");   
   
                // Print total student elements in document   
                System.out   
                        .println("Total students: " + studentList.getLength());   
   
                if (studentList != null &amp;&amp; studentList.getLength() &gt; 0) {   
                    for (int i = 0; i &lt; studentList.getLength(); i++) {   
   
                        Node node = studentList.item(i);   
   
                        if (node.getNodeType() == Node.ELEMENT_NODE) {   
   
                            System.out   
                                    .println("=====================");   
   
                            Element e = (Element) node;   
                            NodeList nodeList = e.getElementsByTagName("name");   
                            System.out.println("Name: "  
                                    + nodeList.item(0).getChildNodes().item(0)   
                                            .getNodeValue());   
   
                            nodeList = e.getElementsByTagName("grade");   
                            System.out.println("Grade: "  
                                    + nodeList.item(0).getChildNodes().item(0)   
                                            .getNodeValue());   
   
                            nodeList = e.getElementsByTagName("age");   
                            System.out.println("Age: "  
                                    + nodeList.item(0).getChildNodes().item(0)   
                                            .getNodeValue());   
                        }   
                    }   
                } else {   
                    System.exit(1);   
                }   
            }   
        } catch (Exception e) {   
            System.out.println(e);   
        }   
    }   
    public static void main(String[] args) {   
   
        XMLParser parser = new XMLParser();   
        parser.getAllUserNames("c:\\test.xml");   
    }   
}17.把Array转换成Map
import java.util.Map;   
import org.apache.commons.lang.ArrayUtils;   
   
public class Main {   
   
  public static void main(String[] args) {   
    String[][] countries = { { "United States", "New York" }, { "United Kingdom", "London" },   
        { "Netherland", "Amsterdam" }, { "Japan", "Tokyo" }, { "France", "Paris" } };   
   
    Map countryCapitals = ArrayUtils.toMap(countries);   
   
    System.out.println("Capital of Japan is " + countryCapitals.get("Japan"));   
    System.out.println("Capital of France is " + countryCapitals.get("France"));   
  }   
}18. 发送邮件
import javax.mail.*;   
import javax.mail.internet.*;   
import java.util.*;   
   
public void postMail( String recipients[ ], String subject, String message , String from) throws MessagingException   
{   
    boolean debug = false;   
   
     //Set the host smtp address   
     Properties props = new Properties();   
     props.put("mail.smtp.host", "smtp.example.com");   
   
    // create some properties and get the default Session   
    Session session = Session.getDefaultInstance(props, null);   
    session.setDebug(debug);   
   
    // create a message   
    Message msg = new MimeMessage(session);   
   
    // set the from and to address   
    InternetAddress addressFrom = new InternetAddress(from);   
    msg.setFrom(addressFrom);   
   
    InternetAddress[] addressTo = new InternetAddress[recipients.length];   
    for (int i = 0; i &lt; recipients.length; i++)   
    {   
        addressTo[i] = new InternetAddress(recipients[i]);   
    }   
    msg.setRecipients(Message.RecipientType.TO, addressTo);   
   
    // Optional : You can also set your custom headers in the Email if you Want   
    msg.addHeader("MyHeaderName", "myHeaderValue");   
   
    // Setting the Subject and Content Type   
    msg.setSubject(subject);   
    msg.setContent(message, "text/plain");   
    Transport.send(msg);   
}19.发送带数据的HTTP请求
import java.io.BufferedReader;   
import java.io.InputStreamReader;   
import java.net.URL;   
   
public class Main {   
    public static void main(String[] args)  {   
        try {   
            URL my_url = new URL("http://coolshell.cn/");   
            BufferedReader br = new BufferedReader(new InputStreamReader(my_url.openStream()));   
            String strTemp = "";   
            while(null != (strTemp = br.readLine())){   
            System.out.println(strTemp);   
        }   
        } catch (Exception ex) {   
            ex.printStackTrace();   
        }   
    }   
}20. 改变数组的大小
/**  
* Reallocates an array with a new size, and copies the contents  
* of the old array to the new array.  
* @param oldArray  the old array, to be reallocated.  
* @param newSize   the new array size.  
* @return          A new array with the same contents.  
*/  
private static Object resizeArray (Object oldArray, int newSize) {   
   int oldSize = java.lang.reflect.Array.getLength(oldArray);   
   Class elementType = oldArray.getClass().getComponentType();   
   Object newArray = java.lang.reflect.Array.newInstance(   
         elementType,newSize);   
   int preserveLength = Math.min(oldSize,newSize);   
   if (preserveLength &gt; 0)   
      System.arraycopy (oldArray,0,newArray,0,preserveLength);   
   return newArray;   
}   
   
// Test routine for resizeArray().   
public static void main (String[] args) {   
   int[] a = {1,2,3};   
   a = (int[])resizeArray(a,5);   
   a[3] = 4;   
   a[4] = 5;   
   for (int i=0; i&lt;a.length; i++)   
      System.out.println (a[i]);   
}


单例模式（Singleton Pattern）是Java中最简单的设计模式之一。这种设计模式属于创建型模式，它提供了一种创建对象的最佳方式。
这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。
注意：
（1）单例类只能有一个实例。
（2）单例类必须自己创建自己的唯一实例。
（3）单例类必须给所有其他对象提供这一实例。


单例介绍
意图：保证一个类只有一个实例，并提供一个访问它的全局访问点。
主要解决：一个全局使用的类频繁的创建与销毁。
何时使用：想控制实例数目，节省系统资源的时候。
如何解决：判断系统是否已经有这个实例，有则返回，没有则创建。
关键代码：构造函数私有。
应用实例：1、一个党只能有一个主席；
                 2、windows是多进程多线程的，在操作一个文件时，会不可避免地出现多个进程或线程同时操作一个文件的现象，所以所有文件的处理必须通过唯一                         的实例来进行。
                 3、一些设备管理器常常设计为单例模式，比如打印时，就要避免多台打印机打印同一个文件的现象。
优点：1、减少了内存的开销，尤其是频繁的创建和销毁实例。2、避免对资源的多重占用。
缺点：没有接口，不能继承，与单一职责原则冲突，一个类应该只关心内部逻辑，而不关心外面怎么样来实例化。
适用场景：1、要求生产唯一序列号。2、web中的计数器，不用每次刷新都在数据库里加一次，用单例缓存起来。3、创建的一个对象要消耗的资源过多，比如I/O与数据库的连接等。
注意事项：getInstance()方法中需要使用同步锁synchronized(Singleton.class)防止多线程同时进入造成instance被多次实例化。


实现


我们将创建一个 SingleObject 类。SingleObject 类有它的私有构造函数和本身的一个静态实例。

SingleObject 类提供了一个静态方法，供外界获取它的静态实例。SingletonPatternDemo，我们的演示类使用 SingleObject 类来获取SingleObject 对象。


步骤 1

创建一个 Singleton 类。

SingleObject.java
public class SingleObject {
	// 创建 SingleObject 的一个对象
	private static SingleObject instance = new SingleObject();

	// 让构造函数为 private，这样该类就不会被实例化
	private SingleObject() {
	}

	// 获取唯一可用的对象
	public static SingleObject getInstance() {
		return instance;
	}

	public void showMessage() {
		System.out.println("Hello World.");
	}
}


步骤 2


从 singleton 类获取唯一的对象。

SingletonPatternDemo.java
public class SingletonPatternDemo {
	public static void main(String[] args) {
		// 不合法的构造函数
		// 编译时错误：构造函数 SingleObject() 是不可见的
		// SingleObject singleObject = new SingleObject();

		// 获取唯一可用的对象
		SingleObject singleObject = SingleObject.getInstance();
		// 显示消息
		singleObject.showMessage();
	}
}
验证输出。

Hello World.


单例模式的几种实现方式


单例模式的实现有多种方式，如下所示：

1、懒汉式，线程不安全
是否lazy初始化：是
是否线程安全：否
实现难易度：易
描述：这种方式是最基本的实现方式，这种方式实现的最大问题就是不支持多线程。因为没有加锁synchronized，所以严格意义上它并不算单例模式。
这种方式lazy loading很明显，不要求线程安全，多线程不能正常工作。
代码实例：
public class SingletonCase1 {

	private static SingletonCase1 instance;

	private SingletonCase1() {

	}

	public static SingletonCase1 getInstance() {
		if (instance == null) {
			instance = new SingletonCase1();
		}

		return instance;
	}
}

2、懒汉式，线程安全
是否lazy初始化：是

是否多线程安全：是
实现难易程度：易
描述：这种方式具备很好的lazy loading，能够在多线程中很好的工作，但是，效率很低，99%情况下不要同步。
优点：第一次调用才初始化，避免内存浪费。
缺点：必须加锁synchronized才能保证单例，但加锁会影响效率。
getInstance() 的性能对应用程序不是很关键（该方法使用不太频繁）。
代码实例：
public class SingletonCase2 {
	private static SingletonCase2 instance;

	private SingletonCase2() {

	}

	public static synchronized SingletonCase2 getInstance() {
		if (instance == null) {
			instance = new SingletonCase2();
		}
		return instance;
	}
}


3、饿汉式
是否 Lazy 初始化：否

是否多线程安全：是
实现难度：易
描述：这种方式比较常用，但容易产生垃圾对象。
优点：没有加锁，执行效率会提高。
缺点：类加载时就初始化，浪费内存。
它基于
 classloder 机制避免了多线程的同步问题，不过，instance 在类装载时就实例化，虽然导致类装载的原因有很多种，在单例模式中大多数都是调用 getInstance 方法， 但是也不能确定有其他的方式（或者其他的静态方法）导致类装载，这时候初始化 instance 显然没有达到 lazy loading 的效果。
代码实例：
public class SingletonCase3 {
	private static SingletonCase3 instance = new SingletonCase3();

	private SingletonCase3() {

	}

	public static SingletonCase3 getInstance() {
		return instance;
	}
}&lt;h3 style="border: 0px; margin: 8px 0px; padding: 0px; font-size: 1.4em; color: rgb(51, 51, 51); font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, STHeiti, 'Microsoft Yahei', sans-serif;"&gt;6、枚举&lt;/h3&gt;




4、双检锁/双重校验锁（DCL，即 double-checked locking）
JDK 版本：JDK1.5
 起

是否
 Lazy 初始化：是



是否多线程安全：是

实现难度：较复杂
描述：这种方式采用双锁机制，安全且在多线程情况下能保持高性能。
getInstance()
 的性能对应用程序很关键

代码实例：
public class SingletonCase4 {
	private volatile static SingletonCase4 instance;

	private SingletonCase4() {

	}

	public static SingletonCase4 getInstance() {
		if (instance == null) {
			synchronized (SingletonCase4.class) {
				if (instance == null) {
					instance = new SingletonCase4();
				}
			}
		}
		return instance;
	}
}


5、登记式/静态内部类
是否 Lazy 初始化：是

是否多线程安全：是

实现难度：一般

描述：这种方式能达到双检锁方式一样的功效，但实现更简单。对静态域使用延迟初始化，应使用这种方式而不是双检锁方式。这种方式只适用于静态域的情况，双检锁方式可在实例域需要延迟初始化时使用。
这种方式同样利用了 classloder 机制来保证初始化 instance 时只有一个线程，它跟第 3 种方式不同的是：第 3 种方式只要 Singleton 类被装载了，那么 instance 就会被实例化（没有达到 lazy loading 效果），而这种方式是
 Singleton 类被装载了，instance 不一定被初始化。因为 SingletonHolder 类没有被主动使用，只有显示通过调用 getInstance 方法时，才会显示装载 SingletonHolder 类，从而实例化 instance。想象一下，如果实例化 instance 很消耗资源，所以想让它延迟加载，另外一方面，又不希望在 Singleton 类加载时就实例化，因为不能确保 Singleton 类还可能在其他的地方被主动使用从而被加载，那么这个时候实例化 instance 显然是不合适的。这个时候，这种方式相比第
 3 种方式就显得很合理。

代码实例：
public class SingletonCase5 {
	private static class SingletonHolder {
		private static final SingletonCase5 INSTANCE = new SingletonCase5();
	}

	private SingletonCase5() {

	}

	public static final SingletonCase5 getInstance() {
		return SingletonHolder.INSTANCE;
	}
}


6、枚举
JDK 版本：JDK1.5
 起

是否 Lazy 初始化：否

是否多线程安全：是
实现难度：易
描述：这种实现方式还没有被广泛采用，但这是实现单例模式的最佳方法。它更简洁，自动支持序列化机制，绝对防止多次实例化。
这种方式是 Effective Java 作者 Josh Bloch 提倡的方式，它不仅能避免多线程同步问题，而且还自动支持序列化机制，防止反序列化重新创建新的对象，绝对防止多次实例化。不过，由于 JDK1.5 之后才加入 enum 特性，用这种方式写不免让人感觉生疏，在实际工作中，也很少用。
不能通过 reflection attack 来调用私有构造方法。

代码实例：
public enum Singleton {
	INSTANCE;

	// 此处方法可以任自己定义
	public void anyMethod() {

	}
}

经验之谈：一般情况下，不建议使用第
 1 种和第 2 种懒汉方式，建议使用第 3 种饿汉方式。只有在要明确实现 lazy loading 效果时，才会使用第 5 种登记方式。如果涉及到反序列化创建对象时，可以尝试使用第 6 种枚举方式。如果有其他特殊的需求，可以考虑使用第 4 种双检锁方式。





本文将Java8的新特新逐一列出，并将使用简单的代码示例来指导你如何使用默认接口方法，lambda表达式，方法引用以及多重Annotation，之后你将会学到最新的API上的改进，比如流，函数式接口，Map以及全新的日期API





“Java is still not dead—and people are starting to figure that out.”

本文将用带注释的简单代码来描述新特性，你将看不到大片吓人的文字。

一、接口的默认方法

Java 8允许我们给接口添加一个非抽象的方法实现，只需要使用 default关键字即可，这个特征又叫做扩展方法，示例如下：


复制代码代码如下:


interface Formula {
    double calculate(int a);



    default double sqrt(int a) {
        return Math.sqrt(a);
    }
}


Formula接口在拥有calculate方法之外同时还定义了sqrt方法，实现了Formula接口的子类只需要实现一个calculate方法，默认方法sqrt将在子类上可以直接使用。

复制代码代码如下:


Formula formula = new Formula() {
    @Override
    public double calculate(int a) {
        return sqrt(a * 100);
    }
};



formula.calculate(100);     // 100.0
formula.sqrt(16);           // 4.0


文中的formula被实现为一个匿名类的实例，该代码非常容易理解，6行代码实现了计算 sqrt(a * 100)。在下一节中，我们将会看到实现单方法接口的更简单的做法。



译者注： 在Java中只有单继承，如果要让一个类赋予新的特性，通常是使用接口来实现，在C++中支持多继承，允许一个子类同时具有多个父类的接口与功能，在其他语言中，让一个类同时具有其他的可复用代码的方法叫做mixin。新的Java 8 的这个特新在编译器实现的角度上来说更加接近Scala的trait。 在C#中也有名为扩展方法的概念，允许给已存在的类型扩展方法，和Java 8的这个在语义上有差别。

二、Lambda 表达式

首先看看在老版本的Java中是如何排列字符串的：


复制代码代码如下:


List&lt;String&gt; names = Arrays.asList("peter", "anna", "mike", "xenia");



Collections.sort(names, new Comparator&lt;String&gt;() {
    @Override
    public int compare(String a, String b) {
        return b.compareTo(a);
    }
});


只需要给静态方法 Collections.sort 传入一个List对象以及一个比较器来按指定顺序排列。通常做法都是创建一个匿名的比较器对象然后将其传递给sort方法。



在Java 8 中你就没必要使用这种传统的匿名对象的方式了，Java 8提供了更简洁的语法，lambda表达式：


复制代码代码如下:


Collections.sort(names, (String a, String b) -&gt; {
    return b.compareTo(a);
});

看到了吧，代码变得更段且更具有可读性，但是实际上还可以写得更短：

复制代码代码如下:


Collections.sort(names, (String a, String b) -&gt; b.compareTo(a));

对于函数体只有一行代码的，你可以去掉大括号{}以及return关键字，但是你还可以写得更短点：

复制代码代码如下:


Collections.sort(names, (a, b) -&gt; b.compareTo(a));

Java编译器可以自动推导出参数类型，所以你可以不用再写一次类型。接下来我们看看lambda表达式还能作出什么更方便的东西来：

三、函数式接口

Lambda表达式是如何在java的类型系统中表示的呢？每一个lambda表达式都对应一个类型，通常是接口类型。而“函数式接口”是指仅仅只包含一个抽象方法的接口，每一个该类型的lambda表达式都会被匹配到这个抽象方法。因为 默认方法 不算抽象方法，所以你也可以给你的函数式接口添加默认方法。



我们可以将lambda表达式当作任意只包含一个抽象方法的接口类型，确保你的接口一定达到这个要求，你只需要给你的接口添加 @FunctionalInterface 注解，编译器如果发现你标注了这个注解的接口有多于一个抽象方法的时候会报错的。

示例如下：


复制代码代码如下:


@FunctionalInterface
interface Converter&lt;F, T&gt; {
    T convert(F from);
}
Converter&lt;String, Integer&gt; converter = (from) -&gt; Integer.valueOf(from);
Integer converted = converter.convert("123");
System.out.println(converted);    // 123

需要注意如果@FunctionalInterface如果没有指定，上面的代码也是对的。



译者注 将lambda表达式映射到一个单方法的接口上，这种做法在Java 8之前就有别的语言实现，比如Rhino JavaScript解释器，如果一个函数参数接收一个单方法的接口而你传递的是一个function，Rhino 解释器会自动做一个单接口的实例到function的适配器，典型的应用场景有 org.w3c.dom.events.EventTarget 的addEventListener 第二个参数 EventListener。

四、方法与构造函数引用

前一节中的代码还可以通过静态方法引用来表示：


复制代码代码如下:


Converter&lt;String, Integer&gt; converter = Integer::valueOf;
Integer converted = converter.convert("123");
System.out.println(converted);   // 123

Java 8 允许你使用 :: 关键字来传递方法或者构造函数引用，上面的代码展示了如何引用一个静态方法，我们也可以引用一个对象的方法：

复制代码代码如下:


 converter = something::startsWith;
String converted = converter.convert("Java");
System.out.println(converted);    // "J"

接下来看看构造函数是如何使用::关键字来引用的，首先我们定义一个包含多个构造函数的简单类：

复制代码代码如下:


class Person {
    String firstName;
    String lastName;



    Person() {}

    Person(String firstName, String lastName) {
        this.firstName = firstName;
        this.lastName = lastName;
    }
}


接下来我们指定一个用来创建Person对象的对象工厂接口：

复制代码代码如下:


interface PersonFactory&lt;P extends Person&gt; {
    P create(String firstName, String lastName);
}

这里我们使用构造函数引用来将他们关联起来，而不是实现一个完整的工厂：

复制代码代码如下:


PersonFactory&lt;Person&gt; personFactory = Person::new;
Person person = personFactory.create("Peter", "Parker");

我们只需要使用 Person::new 来获取Person类构造函数的引用，Java编译器会自动根据PersonFactory.create方法的签名来选择合适的构造函数。



五、Lambda 作用域

在lambda表达式中访问外层作用域和老版本的匿名对象中的方式很相似。你可以直接访问标记了final的外层局部变量，或者实例的字段以及静态变量。

六、访问局部变量

我们可以直接在lambda表达式中访问外层的局部变量：


复制代码代码如下:


final int num = 1;
Converter&lt;Integer, String&gt; stringConverter =
        (from) -&gt; String.valueOf(from + num);



stringConverter.convert(2);     // 3


但是和匿名对象不同的是，这里的变量num可以不用声明为final，该代码同样正确：

复制代码代码如下:


int num = 1;
Converter&lt;Integer, String&gt; stringConverter =
        (from) -&gt; String.valueOf(from + num);



stringConverter.convert(2);     // 3


不过这里的num必须不可被后面的代码修改（即隐性的具有final的语义），例如下面的就无法编译：

复制代码代码如下:


int num = 1;
Converter&lt;Integer, String&gt; stringConverter =
        (from) -&gt; String.valueOf(from + num);
num = 3;

在lambda表达式中试图修改num同样是不允许的。

七、访问对象字段与静态变量



和本地变量不同的是，lambda内部对于实例的字段以及静态变量是即可读又可写。该行为和匿名对象是一致的：


复制代码代码如下:

class Lambda4 {
    static int outerStaticNum;
    int outerNum;



    void testScopes() {
        Converter&lt;Integer, String&gt; stringConverter1 = (from) -&gt; {
            outerNum = 23;
            return String.valueOf(from);
        };

        Converter&lt;Integer, String&gt; stringConverter2 = (from) -&gt; {
            outerStaticNum = 72;
            return String.valueOf(from);
        };
    }
}



八、访问接口的默认方法

还记得第一节中的formula例子么，接口Formula定义了一个默认方法sqrt可以直接被formula的实例包括匿名对象访问到，但是在lambda表达式中这个是不行的。
Lambda表达式中是无法访问到默认方法的，以下代码将无法编译：

复制代码代码如下:


Formula formula = (a) -&gt; sqrt( a * 100);
Built-in Functional Interfaces

JDK 1.8 API包含了很多内建的函数式接口，在老Java中常用到的比如Comparator或者Runnable接口，这些接口都增加了@FunctionalInterface注解以便能用在lambda上。
Java 8 API同样还提供了很多全新的函数式接口来让工作更加方便，有一些接口是来自Google Guava库里的，即便你对这些很熟悉了，还是有必要看看这些是如何扩展到lambda上使用的。

Predicate接口



Predicate 接口只有一个参数，返回boolean类型。该接口包含多种默认方法来将Predicate组合成其他复杂的逻辑（比如：与，或，非）：


复制代码代码如下:


Predicate&lt;String&gt; predicate = (s) -&gt; s.length() &gt; 0;



predicate.test("foo");              // true
predicate.negate().test("foo");     // false

Predicate&lt;Boolean&gt; nonNull = Objects::nonNull;
Predicate&lt;Boolean&gt; isNull = Objects::isNull;

Predicate&lt;String&gt; isEmpty = String::isEmpty;
Predicate&lt;String&gt; isNotEmpty = isEmpty.negate();



Function 接口



Function 接口有一个参数并且返回一个结果，并附带了一些可以和其他函数组合的默认方法（compose, andThen）：


复制代码代码如下:


Function&lt;String, Integer&gt; toInteger = Integer::valueOf;
Function&lt;String, String&gt; backToString = toInteger.andThen(String::valueOf);



backToString.apply("123");     // "123"



Supplier 接口

Supplier 接口返回一个任意范型的值，和Function接口不同的是该接口没有任何参数

复制代码代码如下:


Supplier&lt;Person&gt; personSupplier = Person::new;
personSupplier.get();   // new Person


Consumer 接口

Consumer 接口表示执行在单个参数上的操作。

复制代码代码如下:


Consumer&lt;Person&gt; greeter = (p) -&gt; System.out.println("Hello, " + p.firstName);
greeter.accept(new Person("Luke", "Skywalker"));


Comparator 接口

Comparator 是老Java中的经典接口， Java 8在此之上添加了多种默认方法：

复制代码代码如下:


Comparator&lt;Person&gt; comparator = (p1, p2) -&gt; p1.firstName.compareTo(p2.firstName);



Person p1 = new Person("John", "Doe");
Person p2 = new Person("Alice", "Wonderland");

comparator.compare(p1, p2);             // &gt; 0
comparator.reversed().compare(p1, p2);  // &lt; 0



Optional 接口



Optional 不是函数是接口，这是个用来防止NullPointerException异常的辅助类型，这是下一届中将要用到的重要概念，现在先简单的看看这个接口能干什么：

Optional 被定义为一个简单的容器，其值可能是null或者不是null。在Java 8之前一般某个函数应该返回非空对象但是偶尔却可能返回了null，而在Java 8中，不推荐你返回null而是返回Optional。


复制代码代码如下:


Optional&lt;String&gt; optional = Optional.of("bam");



optional.isPresent();           // true
optional.get();                 // "bam"
optional.orElse("fallback");    // "bam"

optional.ifPresent((s) -&gt; System.out.println(s.charAt(0)));     // "b"



Stream 接口



java.util.Stream 表示能应用在一组元素上一次执行的操作序列。Stream 操作分为中间操作或者最终操作两种，最终操作返回一特定类型的计算结果，而中间操作返回Stream本身，这样你就可以将多个操作依次串起来。Stream 的创建需要指定一个数据源，比如 java.util.Collection的子类，List或者Set， Map不支持。Stream的操作可以串行执行或者并行执行。

首先看看Stream是怎么用，首先创建实例代码的用到的数据List：


复制代码代码如下:


List&lt;String&gt; stringCollection = new ArrayList&lt;&gt;();
stringCollection.add("ddd2");
stringCollection.add("aaa2");
stringCollection.add("bbb1");
stringCollection.add("aaa1");
stringCollection.add("bbb3");
stringCollection.add("ccc");
stringCollection.add("bbb2");
stringCollection.add("ddd1");

Java 8扩展了集合类，可以通过 Collection.stream() 或者 Collection.parallelStream() 来创建一个Stream。下面几节将详细解释常用的Stream操作：



Filter 过滤

过滤通过一个predicate接口来过滤并只保留符合条件的元素，该操作属于中间操作，所以我们可以在过滤后的结果来应用其他Stream操作（比如forEach）。forEach需要一个函数来对过滤后的元素依次执行。forEach是一个最终操作，所以我们不能在forEach之后来执行其他Stream操作。


复制代码代码如下:


stringCollection
    .stream()
    .filter((s) -&gt; s.startsWith("a"))
    .forEach(System.out::println);



// "aaa2", "aaa1"



Sort 排序



排序是一个中间操作，返回的是排序好后的Stream。如果你不指定一个自定义的Comparator则会使用默认排序。


复制代码代码如下:


stringCollection
    .stream()
    .sorted()
    .filter((s) -&gt; s.startsWith("a"))
    .forEach(System.out::println);



// "aaa1", "aaa2"


需要注意的是，排序只创建了一个排列好后的Stream，而不会影响原有的数据源，排序之后原数据stringCollection是不会被修改的：

复制代码代码如下:


System.out.println(stringCollection);
// ddd2, aaa2, bbb1, aaa1, bbb3, ccc, bbb2, ddd1


Map 映射

中间操作map会将元素根据指定的Function接口来依次将元素转成另外的对象，下面的示例展示了将字符串转换为大写字符串。你也可以通过map来讲对象转换成其他类型，map返回的Stream类型是根据你map传递进去的函数的返回值决定的。

复制代码代码如下:


stringCollection
    .stream()
    .map(String::toUpperCase)
    .sorted((a, b) -&gt; b.compareTo(a))
    .forEach(System.out::println);



// "DDD2", "DDD1", "CCC", "BBB3", "BBB2", "AAA2", "AAA1"



Match 匹配



Stream提供了多种匹配操作，允许检测指定的Predicate是否匹配整个Stream。所有的匹配操作都是最终操作，并返回一个boolean类型的值。


复制代码代码如下:


boolean anyStartsWithA = 
    stringCollection
        .stream()
        .anyMatch((s) -&gt; s.startsWith("a"));



System.out.println(anyStartsWithA);      // true

boolean allStartsWithA = 
    stringCollection
        .stream()
        .allMatch((s) -&gt; s.startsWith("a"));

System.out.println(allStartsWithA);      // false

boolean noneStartsWithZ = 
    stringCollection
        .stream()
        .noneMatch((s) -&gt; s.startsWith("z"));

System.out.println(noneStartsWithZ);      // true




Count 计数

计数是一个最终操作，返回Stream中元素的个数，返回值类型是long。


复制代码代码如下:


long startsWithB = 
    stringCollection
        .stream()
        .filter((s) -&gt; s.startsWith("b"))
        .count();



System.out.println(startsWithB);    // 3



Reduce 规约



这是一个最终操作，允许通过指定的函数来讲stream中的多个元素规约为一个元素，规越后的结果是通过Optional接口表示的：


复制代码代码如下:


Optional&lt;String&gt; reduced =
    stringCollection
        .stream()
        .sorted()
        .reduce((s1, s2) -&gt; s1 + "#" + s2);



reduced.ifPresent(System.out::println);
// "aaa1#aaa2#bbb1#bbb2#bbb3#ccc#ddd1#ddd2"



并行Streams



前面提到过Stream有串行和并行两种，串行Stream上的操作是在一个线程中依次完成，而并行Stream则是在多个线程上同时执行。

下面的例子展示了是如何通过并行Stream来提升性能：

首先我们创建一个没有重复元素的大表：


复制代码代码如下:


int max = 1000000;
List&lt;String&gt; values = new ArrayList&lt;&gt;(max);
for (int i = 0; i &lt; max; i++) {
    UUID uuid = UUID.randomUUID();
    values.add(uuid.toString());
}

然后我们计算一下排序这个Stream要耗时多久，
串行排序：

复制代码代码如下:


long t0 = System.nanoTime();



long count = values.stream().sorted().count();
System.out.println(count);

long t1 = System.nanoTime();

long millis = TimeUnit.NANOSECONDS.toMillis(t1 - t0);
System.out.println(String.format("sequential sort took: %d ms", millis));




// 串行耗时: 899 ms
并行排序：


复制代码代码如下:


long t0 = System.nanoTime();



long count = values.parallelStream().sorted().count();
System.out.println(count);

long t1 = System.nanoTime();

long millis = TimeUnit.NANOSECONDS.toMillis(t1 - t0);
System.out.println(String.format("parallel sort took: %d ms", millis));




// 并行排序耗时: 472 ms
上面两个代码几乎是一样的，但是并行版的快了50%之多，唯一需要做的改动就是将stream()改为parallelStream()。

Map

前面提到过，Map类型不支持stream，不过Map提供了一些新的有用的方法来处理一些日常任务。


复制代码代码如下:


Map&lt;Integer, String&gt; map = new HashMap&lt;&gt;();



for (int i = 0; i &lt; 10; i++) {
    map.putIfAbsent(i, "val" + i);
}




map.forEach((id, val) -&gt; System.out.println(val));
以上代码很容易理解， putIfAbsent 不需要我们做额外的存在性检查，而forEach则接收一个Consumer接口来对map里的每一个键值对进行操作。

下面的例子展示了map上的其他有用的函数：


复制代码代码如下:


map.computeIfPresent(3, (num, val) -&gt; val + num);
map.get(3);             // val33



map.computeIfPresent(9, (num, val) -&gt; null);
map.containsKey(9);     // false

map.computeIfAbsent(23, num -&gt; "val" + num);
map.containsKey(23);    // true

map.computeIfAbsent(3, num -&gt; "bam");
map.get(3);             // val33


接下来展示如何在Map里删除一个键值全都匹配的项：

复制代码代码如下:


map.remove(3, "val3");
map.get(3);             // val33



map.remove(3, "val33");
map.get(3);             // null


另外一个有用的方法：

复制代码代码如下:


map.getOrDefault(42, "not found");  // not found

对Map的元素做合并也变得很容易了：

复制代码代码如下:


map.merge(9, "val9", (value, newValue) -&gt; value.concat(newValue));
map.get(9);             // val9



map.merge(9, "concat", (value, newValue) -&gt; value.concat(newValue));
map.get(9);             // val9concat


Merge做的事情是如果键名不存在则插入，否则则对原键对应的值做合并操作并重新插入到map中。



九、Date API

Java 8 在包java.time下包含了一组全新的时间日期API。新的日期API和开源的Joda-Time库差不多，但又不完全一样，下面的例子展示了这组新API里最重要的一些部分：

Clock 时钟

Clock类提供了访问当前日期和时间的方法，Clock是时区敏感的，可以用来取代 System.currentTimeMillis() 来获取当前的微秒数。某一个特定的时间点也可以使用Instant类来表示，Instant类也可以用来创建老的java.util.Date对象。


复制代码代码如下:


Clock clock = Clock.systemDefaultZone();
long millis = clock.millis();



Instant instant = clock.instant();
Date legacyDate = Date.from(instant);   // legacy java.util.Date



Timezones 时区



在新API中时区使用ZoneId来表示。时区可以很方便的使用静态方法of来获取到。 时区定义了到UTS时间的时间差，在Instant时间点对象到本地日期对象之间转换的时候是极其重要的。


复制代码代码如下:


System.out.println(ZoneId.getAvailableZoneIds());
// prints all available timezone ids



ZoneId zone1 = ZoneId.of("Europe/Berlin");
ZoneId zone2 = ZoneId.of("Brazil/East");
System.out.println(zone1.getRules());
System.out.println(zone2.getRules());

// ZoneRules[currentStandardOffset=+01:00]
// ZoneRules[currentStandardOffset=-03:00]



LocalTime 本地时间



LocalTime 定义了一个没有时区信息的时间，例如 晚上10点，或者 17:30:15。下面的例子使用前面代码创建的时区创建了两个本地时间。之后比较时间并以小时和分钟为单位计算两个时间的时间差：


复制代码代码如下:


LocalTime now1 = LocalTime.now(zone1);
LocalTime now2 = LocalTime.now(zone2);



System.out.println(now1.isBefore(now2));  // false

long hoursBetween = ChronoUnit.HOURS.between(now1, now2);
long minutesBetween = ChronoUnit.MINUTES.between(now1, now2);

System.out.println(hoursBetween);       // -3
System.out.println(minutesBetween);     // -239


LocalTime 提供了多种工厂方法来简化对象的创建，包括解析时间字符串。

复制代码代码如下:


LocalTime late = LocalTime.of(23, 59, 59);
System.out.println(late);       // 23:59:59



DateTimeFormatter germanFormatter =
    DateTimeFormatter
        .ofLocalizedTime(FormatStyle.SHORT)
        .withLocale(Locale.GERMAN);

LocalTime leetTime = LocalTime.parse("13:37", germanFormatter);
System.out.println(leetTime);   // 13:37





LocalDate 本地日期

LocalDate 表示了一个确切的日期，比如 2014-03-11。该对象值是不可变的，用起来和LocalTime基本一致。下面的例子展示了如何给Date对象加减天/月/年。另外要注意的是这些对象是不可变的，操作返回的总是一个新实例。


复制代码代码如下:


LocalDate today = LocalDate.now();
LocalDate tomorrow = today.plus(1, ChronoUnit.DAYS);
LocalDate yesterday = tomorrow.minusDays(2);



LocalDate independenceDay = LocalDate.of(2014, Month.JULY, 4);
DayOfWeek dayOfWeek = independenceDay.getDayOfWeek();


System.out.println(dayOfWeek);    // FRIDAY
从字符串解析一个LocalDate类型和解析LocalTime一样简单：

复制代码代码如下:


DateTimeFormatter germanFormatter =
    DateTimeFormatter
        .ofLocalizedDate(FormatStyle.MEDIUM)
        .withLocale(Locale.GERMAN);



LocalDate xmas = LocalDate.parse("24.12.2014", germanFormatter);
System.out.println(xmas);   // 2014-12-24



LocalDateTime 本地日期时间



LocalDateTime 同时表示了时间和日期，相当于前两节内容合并到一个对象上了。LocalDateTime和LocalTime还有LocalDate一样，都是不可变的。LocalDateTime提供了一些能访问具体字段的方法。


复制代码代码如下:


LocalDateTime sylvester = LocalDateTime.of(2014, Month.DECEMBER, 31, 23, 59, 59);



DayOfWeek dayOfWeek = sylvester.getDayOfWeek();
System.out.println(dayOfWeek);      // WEDNESDAY

Month month = sylvester.getMonth();
System.out.println(month);          // DECEMBER

long minuteOfDay = sylvester.getLong(ChronoField.MINUTE_OF_DAY);
System.out.println(minuteOfDay);    // 1439


只要附加上时区信息，就可以将其转换为一个时间点Instant对象，Instant时间点对象可以很容易的转换为老式的java.util.Date。

复制代码代码如下:


Instant instant = sylvester
        .atZone(ZoneId.systemDefault())
        .toInstant();



Date legacyDate = Date.from(instant);
System.out.println(legacyDate);     // Wed Dec 31 23:59:59 CET 2014


格式化LocalDateTime和格式化时间和日期一样的，除了使用预定义好的格式外，我们也可以自己定义格式：

复制代码代码如下:


DateTimeFormatter formatter =
    DateTimeFormatter
        .ofPattern("MMM dd, yyyy - HH:mm");



LocalDateTime parsed = LocalDateTime.parse("Nov 03, 2014 - 07:13", formatter);
String string = formatter.format(parsed);
System.out.println(string);     // Nov 03, 2014 - 07:13


和java.text.NumberFormat不一样的是新版的DateTimeFormatter是不可变的，所以它是线程安全的。
关于时间日期格式的详细信息：http://download.java.net/jdk8/docs/api/java/time/format/DateTimeFormatter.html



十、Annotation 注解

在Java 8中支持多重注解了，先看个例子来理解一下是什么意思。
首先定义一个包装类Hints注解用来放置一组具体的Hint注解：


复制代码代码如下:


@interface Hints {
    Hint[] value();
}



@Repeatable(Hints.class)
@interface Hint {
    String value();
}


Java 8允许我们把同一个类型的注解使用多次，只需要给该注解标注一下@Repeatable即可。



例 1: 使用包装类当容器来存多个注解（老方法）


复制代码代码如下:


@Hints({@Hint("hint1"), @Hint("hint2")})
class Person {}

例 2：使用多重注解（新方法）

复制代码代码如下:


@Hint("hint1")
@Hint("hint2")
class Person {}

第二个例子里java编译器会隐性的帮你定义好@Hints注解，了解这一点有助于你用反射来获取这些信息：

复制代码代码如下:


Hint hint = Person.class.getAnnotation(Hint.class);
System.out.println(hint);                   // null



Hints hints1 = Person.class.getAnnotation(Hints.class);
System.out.println(hints1.value().length);  // 2

Hint[] hints2 = Person.class.getAnnotationsByType(Hint.class);
System.out.println(hints2.length);          // 2


即便我们没有在Person类上定义@Hints注解，我们还是可以通过 getAnnotation(Hints.class) 来获取 @Hints注解，更加方便的方法是使用 getAnnotationsByType 可以直接获取到所有的@Hint注解。
另外Java 8的注解还增加到两种新的target上了：

复制代码代码如下:


@Target({ElementType.TYPE_PARAMETER, ElementType.TYPE_USE})
@interface MyAnnotation {}

关于Java 8的新特性就写到这了，肯定还有更多的特性等待发掘。JDK 1.8里还有很多很有用的东西，比如Arrays.parallelSort, StampedLock和CompletableFuture等等。


抽象工厂模式（Abstract Factory Pattern）是围绕一个超级工厂创建其他工厂。该超级工厂又称为其他工厂的工厂。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。



在抽象工厂模式中，接口是负责创建一个相关对象的工厂，不需要显式指定它们的类。每个生成的工厂都能按照工厂模式提供对象。






意图：提供一个创建一系列相关或相互依赖对象的接口，而无需指定它们具体的类。

主要解决：主要解决接口选择的问题。

何时使用：系统的产品有多于一个的产品族，而系统只消费其中某一族的产品。

如何解决：在一个产品族里面，定义多个产品。

关键代码：在一个工厂里聚合多个同类产品。

应用实例：工作了，为了参加一些聚会，肯定有两套或多套衣服吧，比如说有商务装（成套，一系列具体产品）、时尚装（成套，一系列具体产品），甚至对于一个家庭来说，可能有商务女装、商务男装、时尚女装、时尚男装，这些也都是成套的，即一系列具体产品。假设一种情况（现实中是不存在的，要不然，没法进入共产主义了，但有利于说明抽象工厂模式），在您的家中，某一个衣柜（具体工厂）只能存放某一种这样的衣服（成套，一系列具体产品），每次拿这种成套的衣服时也自然要从这个衣柜中取出了。用 OO 的思想去理解，所有的衣柜（具体工厂）都是衣柜类的（抽象工厂）某一个，而每一件成套的衣服又包括具体的上衣（某一具体产品），裤子（某一具体产品），这些具体的上衣其实也都是上衣（抽象产品），具体的裤子也都是裤子（另一个抽象产品）。

优点：当一个产品族中的多个对象被设计成一起工作时，它能保证客户端始终只使用同一个产品族中的对象。

缺点：产品族扩展非常困难，要增加一个系列的某一产品，既要在抽象的 Creator 里加代码，又要在具体的里面加代码。

使用场景： 1、QQ 换皮肤，一整套一起换。 2、生成不同操作系统的程序。

注意事项：产品族难扩展，产品等级易扩展。



实现


我们将创建 Shape 和 Color 接口和实现这些接口的实体类。下一步是创建抽象工厂类 AbstractFactory。接着定义工厂类 ShapeFactory和 ColorFactory，这两个工厂类都是扩展了 AbstractFactory。然后创建一个工厂创造器/生成器类 FactoryProducer。

AbstractFactoryPatternDemo，我们的演示类使用 FactoryProducer 来获取 AbstractFactory 对象。它将向 AbstractFactory 传递形状信息 Shape（CIRCLE / RECTANGLE / SQUARE），以便获取它所需对象的类型。同时它还向 AbstractFactory 传递颜色信息Color（RED
 / GREEN / BLUE），以便获取它所需对象的类型。




步骤 1


为形状创建一个接口。

Shape.java
public interface Shape {
	public void draw();
}



步骤 2


创建实现接口的实体类。

Rectangle.java

public class Rectangle implements Shape {
	@Override
	public void draw() {
		System.out.println("invoker Rectangle's draw() method.");
	}
}


Square.java

public class Square implements Shape {
	@Override
	public void draw() {
		System.out.println("invoker Square's draw() method.");
	}
}




Circle.java


public class Circle implements Shape {
	@Override
	public void draw() {
		System.out.println("invoker Circle's draw() method.");
	}
}ShapeType.java


public enum ShapeType {

	RECTANGLE, SQUARE, CIRCLE;
}




步骤 3


为颜色创建一个接口。

Color.java
public interface Color {
	public void fill();
}






步骤4


创建实现接口的实体类。

Red.java

public class Red implements Color {
	@Override
	public void fill() {
		System.out.println("invoker Red's fill() method.");
	}
}

Green.java

public class Green implements Color {
	@Override
	public void fill() {
		System.out.println("invoker Green's fill() method.");
	}
}


Blue.java


public class Blue implements Color {
	@Override
	public void fill() {
		System.out.println("invoker Blue's fill() method.");
	}
}



ColorType.java

public enum ColorType {

	RED, GREEN, BLUE;
}




步骤 5


为 Color 和 Shape 对象创建抽象类来获取工厂。

AbstractFactory.java
public abstract class AbstractFactory {
	public abstract Shape getShape(ShapeType shapeType);

	public abstract Color getColor(ColorType colorType);
}



步骤 6


创建扩展了 AbstractFactory 的工厂类，基于给定的信息生成实体类的对象。

ShapeFactory.java

public class ShapeFactory extends AbstractFactory {

	@Override
	public Shape getShape(ShapeType shapeType) {
		if (shapeType == null) {
			return null;
		}

		if (ShapeType.RECTANGLE.equals(shapeType)) {
			return new Rectangle();
		} else if (ShapeType.SQUARE.equals(shapeType)) {
			return new Square();
		} else if (ShapeType.CIRCLE.equals(shapeType)) {
			return new Circle();
		}

		return null;
	}

	@Override
	public Color getColor(ColorType colorType) {
		return null;
	}

}

ColorFactory.java

public class ColorFactory extends AbstractFactory {

	@Override
	public Shape getShape(ShapeType shapeType) {
		return null;
	}

	@Override
	public Color getColor(ColorType colorType) {
		if (colorType == null) {
			return null;
		}

		if (ColorType.RED.equals(colorType)) {
			return new Red();
		} else if (ColorType.GREEN.equals(colorType)) {
			return new Green();
		} else if (ColorType.BLUE.equals(colorType)) {
			return new Blue();
		}

		return null;
	}

}




步骤 7


创建一个工厂创造器/生成器类，通过传递形状或颜色信息来获取工厂。

FactoryProducer.java
public class FactoryProducer {
	public static AbstractFactory getFactory(ProducerType producerType) {
		if (producerType == null) {
			return null;
		}

		if (ProducerType.SHAPE.equals(producerType)) {
			return new ShapeFactory();
		} else if (ProducerType.COLOR.equals(producerType)) {
			return new ColorFactory();
		}
		return null;
	}
}




步骤 8


使用 FactoryProducer 来获取 AbstractFactory，通过传递类型信息来获取实体类的对象。

AbstractFactoryPatternDemo.java
public class AbstractFactoryPatterDemo {
	public static void main(String[] args) {
		AbstractFactory shapeFactory = FactoryProducer.getFactory(ProducerType.SHAPE);

		Shape rectangleShape = shapeFactory.getShape(ShapeType.RECTANGLE);
		rectangleShape.draw();

		Shape squareShape = shapeFactory.getShape(ShapeType.SQUARE);
		squareShape.draw();

		Shape circleShape = shapeFactory.getShape(ShapeType.CIRCLE);
		circleShape.draw();

		AbstractFactory colorFactory = FactoryProducer.getFactory(ProducerType.COLOR);

		Color redColor = colorFactory.getColor(ColorType.RED);
		redColor.fill();

		Color greenColor = colorFactory.getColor(ColorType.GREEN);
		greenColor.fill();

		Color blueColor = colorFactory.getColor(ColorType.BLUE);
		blueColor.fill();
	}
}



步骤 9


验证输出。
invoker Rectangle's draw() method.
invoker Square's draw() method.
invoker Circle's draw() method.
invoker Red's fill() method.
invoker Green's fill() method.
invoker Blue's fill() method.


工厂模式（Factory Pattern）是 Java 中最常用的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。

在工厂模式中，我们在创建对象时不会对客户端暴露创建逻辑，并且是通过使用一个共同的接口来指向新创建的对象。






意图：定义一个创建对象的接口，让其子类自己决定实例化哪一个工厂类，工厂模式使其创建过程延迟到子类进行。

主要解决：主要解决接口选择的问题。

何时使用：我们明确地计划不同条件下创建不同实例时。

如何解决：让其子类实现工厂接口，返回的也是一个抽象的产品。

关键代码：创建过程在其子类执行。

应用实例： 1、您需要一辆汽车，可以直接从工厂里面提货，而不用去管这辆汽车是怎么做出来的，以及这个汽车里面的具体实现。 2、Hibernate 换数据库只需换方言和驱动就可以。

优点： 1、一个调用者想创建一个对象，只要知道其名称就可以了。 2、扩展性高，如果想增加一个产品，只要扩展一个工厂类就可以。 3、屏蔽产品的具体实现，调用者只关心产品的接口。

缺点：每次增加一个产品时，都需要增加一个具体类和对象实现工厂，使得系统中类的个数成倍增加，在一定程度上增加了系统的复杂度，同时也增加了系统具体类的依赖。这并不是什么好事。

使用场景： 1、日志记录器：记录可能记录到本地硬盘、系统事件、远程服务器等，用户可以选择记录日志到什么地方。 2、数据库访问，当用户不知道最后系统采用哪一类数据库，以及数据库可能有变化时。 3、设计一个连接服务器的框架，需要三个协议，"POP3"、"IMAP"、"HTTP"，可以把这三个作为产品类，共同实现一个接口。

注意事项：作为一种创建类模式，在任何需要生成复杂对象的地方，都可以使用工厂方法模式。有一点需要注意的地方就是复杂对象适合使用工厂模式，而简单对象，特别是只需要通过 new 就可以完成创建的对象，无需使用工厂模式。如果使用工厂模式，就需要引入一个工厂类，会增加系统的复杂度。

实现

我们将创建一个 Shape 接口和实现 Shape 接口的实体类。下一步是定义工厂类 ShapeFactory。

FactoryPatternDemo，我们的演示类使用 ShapeFactory 来获取 Shape 对象。它将向 ShapeFactory 传递信息（CIRCLE / RECTANGLE / SQUARE），以便获取它所需对象的类型。




步骤 1


创建一个接口。

Shape.java
public interface Shape {
	public void draw();
}

步骤 2

创建实现接口的实体类。

Rectangle.java
public class Rectangle implements Shape {

	@Override
	public void draw() {
		System.out.println("invoke rectangle's draw() method.");
	}

}
Square.java

public class Square implements Shape {
	@Override
	public void draw() {
		System.out.println("invoke square's draw() method.");
	}
}

Circle.java
public class Circle implements Shape {
	@Override
	public void draw() {
		System.out.println("invoke circle's draw() method.");
	}
}
ShapeType.java


public enum ShapeType {
	RECTANGLE, SQUARE, CIRCLE;

	private String value;

	private ShapeType() {
		this.value = name();
	}

	public String getValue() {
		return value;
	}
}


步骤 3


创建一个工厂，生成基于给定信息的实体类的对象。

ShapeFactory.java
public class ShapeFactory {
	public Shape getShape(ShapeType shapeType) {
		if (shapeType == null) {
			return null;
		}

		if (ShapeType.RECTANGLE.equals(shapeType)) {
			return new Rectangle();
		} else if (ShapeType.SQUARE.equals(shapeType)) {
			return new Square();
		} else if (ShapeType.CIRCLE.equals(shapeType)) {
			return new Circle();
		}

		return null;
	}
}

步骤 4

使用该工厂，通过传递类型信息来获取实体类的对象。

FactoryPatternDemo.java
public class FactoryPatternDemo {
	public static void main(String[] args) {
		ShapeFactory factory = new ShapeFactory();

		Shape rectangleShape = factory.getShape(ShapeType.RECTANGLE);
		rectangleShape.draw();

		Shape squareShape = factory.getShape(ShapeType.SQUARE);
		squareShape.draw();

		Shape cicleShape = factory.getShape(ShapeType.CIRCLE);
		cicleShape.draw();
	}
}

步骤 5

验证输出。
invoke rectangle's draw() method.
invoke square's draw() method.
invoke circle's draw() method.







创建maven工程时遇到一个错误如下：



web.xml
 is missing and &lt;failOnMissingWebXml&gt; is set to true
具体过程如下：


通过Eclipse的Maven创建一个war项目，如下图所示：



习惯性的勾中跳过archetype选择，然后下一步：



 选择了war形式，保存后，编译不过提示错误信息：



 通过各种百度后，有提供一个变相规避错误的方法，添加配置，该错误提示不再报出。


&lt;build&gt;
	&lt;plugins&gt;
		&lt;plugin&gt;
			&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
			&lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt;
			&lt;version&gt;2.3&lt;/version&gt;
			&lt;configuration&gt;
				&lt;failOnMissingWebXml&gt;false&lt;/failOnMissingWebXml&gt;
			&lt;/configuration&gt;
		&lt;/plugin&gt;
	&lt;/plugins&gt;
&lt;/build&gt;


spring boot quick start

在spring boot里，很吸引人的一个特性是可以直接把应用打包成为一个jar/war，然后这个jar/war是可以直接启动的，不需要另外配置一个Web
 Server。

如果之前没有使用过spring boot可以通过下面的demo来感受下。 
下面以这个工程为例，演示如何启动Spring boot项目：
&lt;code class="language-bash hljs  has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;git clone git@github.com:hengyunabc/spring-boot-demo.git
mvn spring-boot-demo
java -jar target/demo-&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;0.0&lt;/span&gt;.&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;1&lt;/span&gt;-SNAPSHOT.jar&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;/ul&gt;

如果使用的IDE是spring sts或者idea，可以通过向导来创建spring boot项目。

也可以参考官方教程： 
http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#getting-started-first-application

对spring boot的两个疑问

刚开始接触spring boot时，通常会有这些疑问

spring boot如何启动的？spring boot embed tomcat是如何工作的？ 静态文件，jsp，网页模板这些是如何加载到的？

下面来分析spring boot是如何做到的。

打包为单个jar时，spring boot的启动方式

maven打包之后，会生成两个jar文件：
&lt;code class="hljs avrasm has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;demo-&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;0.0&lt;/span&gt;&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;.1&lt;/span&gt;-SNAPSHOT&lt;span class="hljs-preprocessor" style="color: rgb(68, 68, 68); box-sizing: border-box;"&gt;.jar&lt;/span&gt;
demo-&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;0.0&lt;/span&gt;&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;.1&lt;/span&gt;-SNAPSHOT&lt;span class="hljs-preprocessor" style="color: rgb(68, 68, 68); box-sizing: border-box;"&gt;.jar&lt;/span&gt;&lt;span class="hljs-preprocessor" style="color: rgb(68, 68, 68); box-sizing: border-box;"&gt;.original&lt;/span&gt;&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;/ul&gt;

其中demo-0.0.1-SNAPSHOT.jar.original是默认的maven-jar-plugin生成的包。

demo-0.0.1-SNAPSHOT.jar是spring boot maven插件生成的jar包，里面包含了应用的依赖，以及spring boot相关的类。下面称之为fat jar。

先来查看spring boot打好的包的目录结构（不重要的省略掉）：
&lt;code class="hljs r has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;├── META-INF
│   ├── MANIFEST.MF
├── application.properties
├── com
│   └── example
│       └── SpringBootDemoApplication.class
├── lib
│   ├── aopalliance-&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;1.0&lt;/span&gt;.jar
│   ├── spring-beans-&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;4.2&lt;/span&gt;&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;.3&lt;/span&gt;.RELEASE.jar
│   ├── &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;...&lt;/span&gt;
└── org
    └── springframework
        └── boot
            └── loader
                ├── ExecutableArchiveLauncher.class
                ├── JarLauncher.class
                ├── JavaAgentDetector.class
                ├── LaunchedURLClassLoader.class
                ├── Launcher.class
                ├── MainMethodRunner.class
                ├── &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;...&lt;/span&gt;                &lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;10&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;11&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;12&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;13&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;14&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;15&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;16&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;17&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;18&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;19&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;20&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;21&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;10&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;11&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;12&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;13&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;14&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;15&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;16&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;17&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;18&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;19&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;20&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;21&lt;/li&gt;&lt;/ul&gt;

依次来看下这些内容。

MANIFEST.MF
&lt;code class="hljs http has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;&lt;span class="hljs-attribute" style="box-sizing: border-box;"&gt;Manifest-Version&lt;/span&gt;: &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;1.0&lt;/span&gt;
&lt;span class="hljs-attribute" style="box-sizing: border-box;"&gt;Start-Class&lt;/span&gt;: &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;com.example.SpringBootDemoApplication&lt;/span&gt;
&lt;span class="hljs-attribute" style="box-sizing: border-box;"&gt;Implementation-Vendor-Id&lt;/span&gt;: &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;com.example&lt;/span&gt;
&lt;span class="hljs-attribute" style="box-sizing: border-box;"&gt;Spring-Boot-Version&lt;/span&gt;: &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;1.3.0.RELEASE&lt;/span&gt;
&lt;span class="hljs-attribute" style="box-sizing: border-box;"&gt;Created-By&lt;/span&gt;: &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;Apache Maven 3.3.3&lt;/span&gt;
&lt;span class="hljs-attribute" style="box-sizing: border-box;"&gt;Build-Jdk&lt;/span&gt;: &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;1.8.0_60&lt;/span&gt;
&lt;span class="hljs-attribute" style="box-sizing: border-box;"&gt;Implementation-Vendor&lt;/span&gt;: &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;Pivotal Software, Inc.&lt;/span&gt;
&lt;span class="hljs-attribute" style="box-sizing: border-box;"&gt;Main-Class&lt;/span&gt;: &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;org.springframework.boot.loader.JarLauncher&lt;/span&gt;&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;/ul&gt;

可以看到有Main-Class是org.springframework.boot.loader.JarLauncher ，这个是jar启动的Main函数。

还有一个Start-Class是com.example.SpringBootDemoApplication，这个是我们应用自己的Main函数。
&lt;code class="language-java hljs  has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;&lt;span class="hljs-annotation" style="color: rgb(155, 133, 157); box-sizing: border-box;"&gt;@SpringBootApplication&lt;/span&gt;
&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;public&lt;/span&gt; &lt;span class="hljs-class" style="box-sizing: border-box;"&gt;&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;class&lt;/span&gt; &lt;span class="hljs-title" style="box-sizing: border-box; color: rgb(102, 0, 102);"&gt;SpringBootDemoApplication&lt;/span&gt; {&lt;/span&gt;

    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;public&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;static&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;void&lt;/span&gt; &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;main&lt;/span&gt;(String[] args) {
        SpringApplication.run(SpringBootDemoApplication.class, args);
    }
}&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;/ul&gt;

com/example 目录

这下面放的是应用的.class文件。

lib目录

这里存放的是应用的Maven依赖的jar包文件。 
比如spring-beans，spring-mvc等jar。

org/springframework/boot/loader 目录

这下面存放的是Spring boot loader的.class文件。

Archive的概念

archive即归档文件，这个概念在linux下比较常见通常就是一个tar/zip格式的压缩包jar是zip格式

在spring boot里，抽象出了Archive的概念。

一个archive可以是一个jar（JarFileArchive），也可以是一个文件目录（ExplodedArchive）。可以理解为Spring boot抽象出来的统一访问资源的层。

上面的demo-0.0.1-SNAPSHOT.jar 是一个Archive，然后demo-0.0.1-SNAPSHOT.jar里的/lib目录下面的每一个Jar包，也是一个Archive。
&lt;code class="language-java hljs  has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;public&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;abstract&lt;/span&gt; &lt;span class="hljs-class" style="box-sizing: border-box;"&gt;&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;class&lt;/span&gt; &lt;span class="hljs-title" style="box-sizing: border-box; color: rgb(102, 0, 102);"&gt;Archive&lt;/span&gt; {&lt;/span&gt;
    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;public&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;abstract&lt;/span&gt; URL &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;getUrl&lt;/span&gt;();
    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;public&lt;/span&gt; String &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;getMainClass&lt;/span&gt;();
    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;public&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;abstract&lt;/span&gt; Collection&lt;Entry&gt; &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;getEntries&lt;/span&gt;();
    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;public&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;abstract&lt;/span&gt; List&lt;Archive&gt; &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;getNestedArchives&lt;/span&gt;(EntryFilter filter);&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;/ul&gt;

可以看到Archive有一个自己的URL，比如：
&lt;code class="hljs avrasm has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;&lt;span class="hljs-label" style="box-sizing: border-box;"&gt;jar:&lt;/span&gt;file:/tmp/target/demo-&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;0.0&lt;/span&gt;&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;.1&lt;/span&gt;-SNAPSHOT&lt;span class="hljs-preprocessor" style="color: rgb(68, 68, 68); box-sizing: border-box;"&gt;.jar&lt;/span&gt;!/&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;/ul&gt;

还有一个getNestedArchives函数，这个实际返回的是demo-0.0.1-SNAPSHOT.jar/lib下面的jar的Archive列表。它们的URL是：
&lt;code class="hljs avrasm has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;&lt;span class="hljs-label" style="box-sizing: border-box;"&gt;jar:&lt;/span&gt;file:/tmp/target/demo-&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;0.0&lt;/span&gt;&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;.1&lt;/span&gt;-SNAPSHOT&lt;span class="hljs-preprocessor" style="color: rgb(68, 68, 68); box-sizing: border-box;"&gt;.jar&lt;/span&gt;!/lib/aopalliance-&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;1.0&lt;/span&gt;&lt;span class="hljs-preprocessor" style="color: rgb(68, 68, 68); box-sizing: border-box;"&gt;.jar&lt;/span&gt;
&lt;span class="hljs-label" style="box-sizing: border-box;"&gt;jar:&lt;/span&gt;file:/tmp/target/demo-&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;0.0&lt;/span&gt;&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;.1&lt;/span&gt;-SNAPSHOT&lt;span class="hljs-preprocessor" style="color: rgb(68, 68, 68); box-sizing: border-box;"&gt;.jar&lt;/span&gt;!/lib/spring-beans-&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;4.2&lt;/span&gt;&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;.3&lt;/span&gt;&lt;span class="hljs-preprocessor" style="color: rgb(68, 68, 68); box-sizing: border-box;"&gt;.RELEASE&lt;/span&gt;&lt;span class="hljs-preprocessor" style="color: rgb(68, 68, 68); box-sizing: border-box;"&gt;.jar&lt;/span&gt;&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;/ul&gt;

JarLauncher

从MANIFEST.MF可以看到Main函数是JarLauncher，下面来分析它的工作流程。

JarLauncher类的继承结构是：
&lt;code class="language-java hljs  has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;class JarLauncher extends ExecutableArchiveLauncher
class ExecutableArchiveLauncher extends Launcher&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;/ul&gt;

以demo-0.0.1-SNAPSHOT.jar创建一个Archive：

JarLauncher先找到自己所在的jar，即demo-0.0.1-SNAPSHOT.jar的路径，然后创建了一个Archive。

下面的代码展示了如何从一个类找到它的加载的位置的技巧：
&lt;code class="language-java hljs  has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;protected&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;final&lt;/span&gt; Archive &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;createArchive&lt;/span&gt;() &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;throws&lt;/span&gt; Exception {
        ProtectionDomain protectionDomain = getClass().getProtectionDomain();
        CodeSource codeSource = protectionDomain.getCodeSource();
        URI location = (codeSource == &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;null&lt;/span&gt; ? &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;null&lt;/span&gt; : codeSource.getLocation().toURI());
        String path = (location == &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;null&lt;/span&gt; ? &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;null&lt;/span&gt; : location.getSchemeSpecificPart());
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;if&lt;/span&gt; (path == &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;null&lt;/span&gt;) {
            &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;throw&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;new&lt;/span&gt; IllegalStateException(&lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"Unable to determine code source archive"&lt;/span&gt;);
        }
        File root = &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;new&lt;/span&gt; File(path);
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;if&lt;/span&gt; (!root.exists()) {
            &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;throw&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;new&lt;/span&gt; IllegalStateException(
                    &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"Unable to determine code source archive from "&lt;/span&gt; + root);
        }
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;return&lt;/span&gt; (root.isDirectory() ? &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;new&lt;/span&gt; ExplodedArchive(root)
                : &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;new&lt;/span&gt; JarFileArchive(root));
    }&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;10&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;11&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;12&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;13&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;14&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;15&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;16&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;10&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;11&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;12&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;13&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;14&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;15&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;16&lt;/li&gt;&lt;/ul&gt;

获取lib/下面的jar，并创建一个LaunchedURLClassLoader

JarLauncher创建好Archive之后，通过getNestedArchives函数来获取到demo-0.0.1-SNAPSHOT.jar/lib下面的所有jar文件，并创建为List。

注意上面提到，Archive都是有自己的URL的。

获取到这些Archive的URL之后，也就获得了一个URL[]数组，用这个来构造一个自定义的ClassLoader：LaunchedURLClassLoader。

创建好ClassLoader之后，再从MANIFEST.MF里读取到Start-Class，即com.example.SpringBootDemoApplication，然后创建一个新的线程来启动应用的Main函数。
&lt;code class="language-java hljs  has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;    &lt;span class="hljs-javadoc" style="color: rgb(136, 0, 0); box-sizing: border-box;"&gt;/**
     * Launch the application given the archive file and a fully configured classloader.
     */&lt;/span&gt;
    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;protected&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;void&lt;/span&gt; &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;launch&lt;/span&gt;(String[] args, String mainClass, ClassLoader classLoader)
            &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;throws&lt;/span&gt; Exception {
        Runnable runner = createMainMethodRunner(mainClass, args, classLoader);
        Thread runnerThread = &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;new&lt;/span&gt; Thread(runner);
        runnerThread.setContextClassLoader(classLoader);
        runnerThread.setName(Thread.currentThread().getName());
        runnerThread.start();
    }

    &lt;span class="hljs-javadoc" style="color: rgb(136, 0, 0); box-sizing: border-box;"&gt;/**
     * Create the {@code MainMethodRunner} used to launch the application.
     */&lt;/span&gt;
    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;protected&lt;/span&gt; Runnable &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;createMainMethodRunner&lt;/span&gt;(String mainClass, String[] args,
            ClassLoader classLoader) &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;throws&lt;/span&gt; Exception {
        Class&lt;?&gt; runnerClass = classLoader.loadClass(RUNNER_CLASS);
        Constructor&lt;?&gt; constructor = runnerClass.getConstructor(String.class,
                String[].class);
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;return&lt;/span&gt; (Runnable) constructor.newInstance(mainClass, args);
    }&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;10&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;11&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;12&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;13&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;14&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;15&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;16&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;17&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;18&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;19&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;20&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;21&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;22&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;10&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;11&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;12&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;13&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;14&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;15&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;16&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;17&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;18&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;19&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;20&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;21&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;22&lt;/li&gt;&lt;/ul&gt;

LaunchedURLClassLoader

LaunchedURLClassLoader和普通的URLClassLoader的不同之处是，它提供了从Archive里加载.class的能力。

结合Archive提供的getEntries函数，就可以获取到Archive里的Resource。当然里面的细节还是很多的，下面再描述。

spring boot应用启动流程总结

看到这里，可以总结下Spring Boot应用的启动流程：

spring boot应用打包之后，生成一个fat jar，里面包含了应用依赖的jar包，还有Spring boot loader相关的类Fat jar的启动Main函数是JarLauncher，它负责创建一个LaunchedURLClassLoader来加载/lib下面的jar，并以一个新线程启动应用的Main函数。

spring boot loader里的细节

代码地址：https://github.com/spring-projects/spring-boot/tree/master/spring-boot-tools/spring-boot-loader

JarFile URL的扩展

Spring boot能做到以一个fat jar来启动，最重要的一点是它实现了jar in jar的加载方式。

JDK原始的JarFile URL的定义可以参考这里：

http://docs.oracle.com/javase/7/docs/api/java/net/JarURLConnection.html

原始的JarFile URL是这样子的：
&lt;code class="hljs avrasm has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;&lt;span class="hljs-label" style="box-sizing: border-box;"&gt;jar:&lt;/span&gt;file:/tmp/target/demo-&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;0.0&lt;/span&gt;&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;.1&lt;/span&gt;-SNAPSHOT&lt;span class="hljs-preprocessor" style="color: rgb(68, 68, 68); box-sizing: border-box;"&gt;.jar&lt;/span&gt;!/&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;/ul&gt;

jar包里的资源的URL：
&lt;code class="hljs avrasm has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;&lt;span class="hljs-label" style="box-sizing: border-box;"&gt;jar:&lt;/span&gt;file:/tmp/target/demo-&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;0.0&lt;/span&gt;&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;.1&lt;/span&gt;-SNAPSHOT&lt;span class="hljs-preprocessor" style="color: rgb(68, 68, 68); box-sizing: border-box;"&gt;.jar&lt;/span&gt;!/&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;com&lt;/span&gt;/example/SpringBootDemoApplication&lt;span class="hljs-preprocessor" style="color: rgb(68, 68, 68); box-sizing: border-box;"&gt;.class&lt;/span&gt;&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;/ul&gt;

可以看到对于Jar里的资源，定义以’!/’来分隔。原始的JarFile URL只支持一个’!/’。

Spring boot扩展了这个协议，让它支持多个’!/’，就可以表示jar in jar，jar in directory的资源了。

比如下面的URL表示demo-0.0.1-SNAPSHOT.jar这个jar里lib目录下面的spring-beans-4.2.3.RELEASE.jar里面的MANIFEST.MF：
&lt;code class="hljs avrasm has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;&lt;span class="hljs-label" style="box-sizing: border-box;"&gt;jar:&lt;/span&gt;file:/tmp/target/demo-&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;0.0&lt;/span&gt;&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;.1&lt;/span&gt;-SNAPSHOT&lt;span class="hljs-preprocessor" style="color: rgb(68, 68, 68); box-sizing: border-box;"&gt;.jar&lt;/span&gt;!/lib/spring-beans-&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;4.2&lt;/span&gt;&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;.3&lt;/span&gt;&lt;span class="hljs-preprocessor" style="color: rgb(68, 68, 68); box-sizing: border-box;"&gt;.RELEASE&lt;/span&gt;&lt;span class="hljs-preprocessor" style="color: rgb(68, 68, 68); box-sizing: border-box;"&gt;.jar&lt;/span&gt;!/META-INF/MANIFEST&lt;span class="hljs-preprocessor" style="color: rgb(68, 68, 68); box-sizing: border-box;"&gt;.MF&lt;/span&gt;&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;/ul&gt;

自定义URLStreamHandler，扩展JarFile和JarURLConnection

在构造一个URL时，可以传递一个Handler，而JDK自带有默认的Handler类，应用可以自己注册Handler来处理自定义的URL。
&lt;code class="language-java hljs  has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;public&lt;/span&gt; &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;URL&lt;/span&gt;(String protocol,
           String host,
           &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;int&lt;/span&gt; port,
           String file,
           URLStreamHandler handler)
    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;throws&lt;/span&gt; MalformedURLException&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;/ul&gt;

参考： 
https://docs.oracle.com/javase/8/docs/api/java/net/URL.html#URL-java.lang.String-java.lang.String-int-java.lang.String-

Spring boot通过注册了一个自定义的Handler类来处理多重jar in jar的逻辑。

这个Handler内部会用SoftReference来缓存所有打开过的JarFile。

在处理像下面这样的URL时，会循环处理’!/’分隔符，从最上层出发，先构造出demo-0.0.1-SNAPSHOT.jar这个JarFile，再构造出spring-beans-4.2.3.RELEASE.jar这个JarFile，然后再构造出指向MANIFEST.MF的JarURLConnection。
&lt;code class="hljs avrasm has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;&lt;span class="hljs-label" style="box-sizing: border-box;"&gt;jar:&lt;/span&gt;file:/tmp/target/demo-&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;0.0&lt;/span&gt;&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;.1&lt;/span&gt;-SNAPSHOT&lt;span class="hljs-preprocessor" style="color: rgb(68, 68, 68); box-sizing: border-box;"&gt;.jar&lt;/span&gt;!/lib/spring-beans-&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;4.2&lt;/span&gt;&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;.3&lt;/span&gt;&lt;span class="hljs-preprocessor" style="color: rgb(68, 68, 68); box-sizing: border-box;"&gt;.RELEASE&lt;/span&gt;&lt;span class="hljs-preprocessor" style="color: rgb(68, 68, 68); box-sizing: border-box;"&gt;.jar&lt;/span&gt;!/META-INF/MANIFEST&lt;span class="hljs-preprocessor" style="color: rgb(68, 68, 68); box-sizing: border-box;"&gt;.MF&lt;/span&gt;&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;/ul&gt;&lt;code class="language-java hljs  has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;&lt;span class="hljs-comment" style="color: rgb(136, 0, 0); box-sizing: border-box;"&gt;//org.springframework.boot.loader.jar.Handler&lt;/span&gt;
&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;public&lt;/span&gt; &lt;span class="hljs-class" style="box-sizing: border-box;"&gt;&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;class&lt;/span&gt; &lt;span class="hljs-title" style="box-sizing: border-box; color: rgb(102, 0, 102);"&gt;Handler&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;extends&lt;/span&gt; &lt;span class="hljs-title" style="box-sizing: border-box; color: rgb(102, 0, 102);"&gt;URLStreamHandler&lt;/span&gt; {&lt;/span&gt;
    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;private&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;static&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;final&lt;/span&gt; String SEPARATOR = &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"!/"&lt;/span&gt;;
    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;private&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;static&lt;/span&gt; SoftReference&lt;Map&lt;File, JarFile&gt;&gt; rootFileCache;
    &lt;span class="hljs-annotation" style="color: rgb(155, 133, 157); box-sizing: border-box;"&gt;@Override&lt;/span&gt;
    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;protected&lt;/span&gt; URLConnection &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;openConnection&lt;/span&gt;(URL url) &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;throws&lt;/span&gt; IOException {
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;if&lt;/span&gt; (&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;this&lt;/span&gt;.jarFile != &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;null&lt;/span&gt;) {
            &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;return&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;new&lt;/span&gt; JarURLConnection(url, &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;this&lt;/span&gt;.jarFile);
        }
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;try&lt;/span&gt; {
            &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;return&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;new&lt;/span&gt; JarURLConnection(url, getRootJarFileFromUrl(url));
        }
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;catch&lt;/span&gt; (Exception ex) {
            &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;return&lt;/span&gt; openFallbackConnection(url, ex);
        }
    }
    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;public&lt;/span&gt; JarFile &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;getRootJarFileFromUrl&lt;/span&gt;(URL url) &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;throws&lt;/span&gt; IOException {
        String spec = url.getFile();
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;int&lt;/span&gt; separatorIndex = spec.indexOf(SEPARATOR);
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;if&lt;/span&gt; (separatorIndex == -&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;1&lt;/span&gt;) {
            &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;throw&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;new&lt;/span&gt; MalformedURLException(&lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"Jar URL does not contain !/ separator"&lt;/span&gt;);
        }
        String name = spec.substring(&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;0&lt;/span&gt;, separatorIndex);
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;return&lt;/span&gt; getRootJarFile(name);
    }&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;10&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;11&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;12&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;13&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;14&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;15&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;16&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;17&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;18&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;19&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;20&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;21&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;22&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;23&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;24&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;25&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;10&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;11&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;12&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;13&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;14&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;15&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;16&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;17&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;18&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;19&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;20&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;21&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;22&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;23&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;24&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;25&lt;/li&gt;&lt;/ul&gt;

ClassLoader如何读取到Resource

对于一个ClassLoader，它需要哪些能力？

查找资源读取资源

对应的API是：
&lt;code class="language-java hljs  has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;public&lt;/span&gt; URL &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;findResource&lt;/span&gt;(String name)
&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;public&lt;/span&gt; InputStream &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;getResourceAsStream&lt;/span&gt;(String name)&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;/ul&gt;

上面提到，Spring boot构造LaunchedURLClassLoader时，传递了一个URL[]数组。数组里是lib目录下面的jar的URL。

对于一个URL，JDK或者ClassLoader如何知道怎么读取到里面的内容的？

实际上流程是这样子的：

LaunchedURLClassLoader.loadClassURL.getContent()URL.openConnection()Handler.openConnection(URL)

最终调用的是JarURLConnection的getInputStream()函数。
&lt;code class="language-java hljs  has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;&lt;span class="hljs-comment" style="color: rgb(136, 0, 0); box-sizing: border-box;"&gt;//org.springframework.boot.loader.jar.JarURLConnection&lt;/span&gt;
    &lt;span class="hljs-annotation" style="color: rgb(155, 133, 157); box-sizing: border-box;"&gt;@Override&lt;/span&gt;
    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;public&lt;/span&gt; InputStream &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;getInputStream&lt;/span&gt;() &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;throws&lt;/span&gt; IOException {
        connect();
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;if&lt;/span&gt; (&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;this&lt;/span&gt;.jarEntryName.isEmpty()) {
            &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;throw&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;new&lt;/span&gt; IOException(&lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"no entry name specified"&lt;/span&gt;);
        }
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;return&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;this&lt;/span&gt;.jarEntryData.getInputStream();
    }&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;/ul&gt;

从一个URL，到最终读取到URL里的内容，整个过程是比较复杂的，总结下：

spring boot注册了一个Handler来处理”jar:”这种协议的URLspring boot扩展了JarFile和JarURLConnection，内部处理jar in jar的情况在处理多重jar in jar的URL时，spring boot会循环处理，并缓存已经加载到的JarFile对于多重jar in jar，实际上是解压到了临时目录来处理，可以参考JarFileArchive里的代码在获取URL的InputStream时，最终获取到的是JarFile里的JarEntryData

这里面的细节很多，只列出比较重要的一些点。

然后，URLClassLoader是如何getResource的呢？

URLClassLoader在构造时，有URL[]数组参数，它内部会用这个数组来构造一个URLClassPath:
&lt;code class="language-java hljs  has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;URLClassPath ucp = &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;new&lt;/span&gt; URLClassPath(urls);&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;/ul&gt;

在 URLClassPath 内部会为这些URLS 都构造一个Loader，然后在getResource时，会从这些Loader里一个个去尝试获取。 
如果获取成功的话，就像下面那样包装为一个Resource。
&lt;code class="language-java hljs  has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;Resource getResource(&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;final&lt;/span&gt; String name, &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;boolean&lt;/span&gt; check) {
    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;final&lt;/span&gt; URL url;
    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;try&lt;/span&gt; {
        url = &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;new&lt;/span&gt; URL(base, ParseUtil.encodePath(name, &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;false&lt;/span&gt;));
    } &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;catch&lt;/span&gt; (MalformedURLException e) {
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;throw&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;new&lt;/span&gt; IllegalArgumentException(&lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"name"&lt;/span&gt;);
    }
    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;final&lt;/span&gt; URLConnection uc;
    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;try&lt;/span&gt; {
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;if&lt;/span&gt; (check) {
            URLClassPath.check(url);
        }
        uc = url.openConnection();
        InputStream in = uc.getInputStream();
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;if&lt;/span&gt; (uc &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;instanceof&lt;/span&gt; JarURLConnection) {
            &lt;span class="hljs-comment" style="color: rgb(136, 0, 0); box-sizing: border-box;"&gt;/* Need to remember the jar file so it can be closed
             * in a hurry.
             */&lt;/span&gt;
            JarURLConnection juc = (JarURLConnection)uc;
            jarfile = JarLoader.checkJar(juc.getJarFile());
        }
    } &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;catch&lt;/span&gt; (Exception e) {
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;return&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;null&lt;/span&gt;;
    }
    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;return&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;new&lt;/span&gt; Resource() {
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;public&lt;/span&gt; String &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;getName&lt;/span&gt;() { &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;return&lt;/span&gt; name; }
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;public&lt;/span&gt; URL &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;getURL&lt;/span&gt;() { &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;return&lt;/span&gt; url; }
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;public&lt;/span&gt; URL &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;getCodeSourceURL&lt;/span&gt;() { &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;return&lt;/span&gt; base; }
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;public&lt;/span&gt; InputStream &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;getInputStream&lt;/span&gt;() &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;throws&lt;/span&gt; IOException {
            &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;return&lt;/span&gt; uc.getInputStream();
        }
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;public&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;int&lt;/span&gt; &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;getContentLength&lt;/span&gt;() &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;throws&lt;/span&gt; IOException {
            &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;return&lt;/span&gt; uc.getContentLength();
        }
    };
}&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;10&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;11&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;12&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;13&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;14&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;15&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;16&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;17&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;18&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;19&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;20&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;21&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;22&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;23&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;24&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;25&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;26&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;27&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;28&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;29&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;30&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;31&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;32&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;33&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;34&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;35&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;36&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;10&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;11&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;12&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;13&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;14&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;15&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;16&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;17&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;18&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;19&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;20&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;21&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;22&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;23&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;24&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;25&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;26&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;27&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;28&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;29&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;30&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;31&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;32&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;33&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;34&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;35&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;36&lt;/li&gt;&lt;/ul&gt;

从代码里可以看到，实际上是调用了url.openConnection()。这样完整的链条就可以连接起来了。

注意，URLClassPath这个类的代码在JDK里没有自带，在这里看到http://grepcode.com/file/repository.grepcode.com/java/root/jdk/openjdk/7u40-b43/sun/misc/URLClassPath.java#506

在IDE/开放目录启动Spring boot应用

在上面只提到在一个fat jar里启动Spring boot应用的过程，下面分析IDE里Spring boot是如何启动的。

在IDE里，直接运行的Main函数是应用自己的Main函数：
&lt;code class="language-java hljs  has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;&lt;span class="hljs-annotation" style="color: rgb(155, 133, 157); box-sizing: border-box;"&gt;@SpringBootApplication&lt;/span&gt;
&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;public&lt;/span&gt; &lt;span class="hljs-class" style="box-sizing: border-box;"&gt;&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;class&lt;/span&gt; &lt;span class="hljs-title" style="box-sizing: border-box; color: rgb(102, 0, 102);"&gt;SpringBootDemoApplication&lt;/span&gt; {&lt;/span&gt;

    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;public&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;static&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;void&lt;/span&gt; &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;main&lt;/span&gt;(String[] args) {
        SpringApplication.run(SpringBootDemoApplication.class, args);
    }
}&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;/ul&gt;

其实在IDE里启动Spring boot应用是最简单的一种情况，因为依赖的Jar都让IDE放到classpath里了，所以Spring boot直接启动就完事了。

还有一种情况是在一个开放目录下启动Spring boot启动。所谓的开放目录就是把fat jar解压，然后直接启动应用。
&lt;code class="hljs avrasm has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;java org&lt;span class="hljs-preprocessor" style="color: rgb(68, 68, 68); box-sizing: border-box;"&gt;.springframework&lt;/span&gt;&lt;span class="hljs-preprocessor" style="color: rgb(68, 68, 68); box-sizing: border-box;"&gt;.boot&lt;/span&gt;&lt;span class="hljs-preprocessor" style="color: rgb(68, 68, 68); box-sizing: border-box;"&gt;.loader&lt;/span&gt;&lt;span class="hljs-preprocessor" style="color: rgb(68, 68, 68); box-sizing: border-box;"&gt;.JarLauncher&lt;/span&gt;&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;/ul&gt;

这时，Spring boot会判断当前是否在一个目录里，如果是的，则构造一个ExplodedArchive（前面在jar里时是JarFileArchive），后面的启动流程类似fat jar的。

Embead Tomcat的启动流程

判断是否在web环境

spring boot在启动时，先通过一个简单的查找Servlet类的方式来判断是不是在web环境：
&lt;code class="language-java hljs  has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;private&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;static&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;final&lt;/span&gt; String[] WEB_ENVIRONMENT_CLASSES = { &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"javax.servlet.Servlet"&lt;/span&gt;,
    &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"org.springframework.web.context.ConfigurableWebApplicationContext"&lt;/span&gt; };

&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;private&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;boolean&lt;/span&gt; &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;deduceWebEnvironment&lt;/span&gt;() {
    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;for&lt;/span&gt; (String className : WEB_ENVIRONMENT_CLASSES) {
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;if&lt;/span&gt; (!ClassUtils.isPresent(className, &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;null&lt;/span&gt;)) {
            &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;return&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;false&lt;/span&gt;;
        }
    }
    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;return&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;true&lt;/span&gt;;
}&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;10&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;11&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;10&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;11&lt;/li&gt;&lt;/ul&gt;

如果是的话，则会创建AnnotationConfigEmbeddedWebApplicationContext，否则Spring context就是AnnotationConfigApplicationContext：
&lt;code class="language-java hljs  has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;&lt;span class="hljs-comment" style="color: rgb(136, 0, 0); box-sizing: border-box;"&gt;//org.springframework.boot.SpringApplication&lt;/span&gt;
    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;protected&lt;/span&gt; ConfigurableApplicationContext &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;createApplicationContext&lt;/span&gt;() {
        Class&lt;?&gt; contextClass = &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;this&lt;/span&gt;.applicationContextClass;
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;if&lt;/span&gt; (contextClass == &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;null&lt;/span&gt;) {
            &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;try&lt;/span&gt; {
                contextClass = Class.forName(&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;this&lt;/span&gt;.webEnvironment
                        ? DEFAULT_WEB_CONTEXT_CLASS : DEFAULT_CONTEXT_CLASS);
            }
            &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;catch&lt;/span&gt; (ClassNotFoundException ex) {
                &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;throw&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;new&lt;/span&gt; IllegalStateException(
                        &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"Unable create a default ApplicationContext, "&lt;/span&gt;
                                + &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"please specify an ApplicationContextClass"&lt;/span&gt;,
                        ex);
            }
        }
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;return&lt;/span&gt; (ConfigurableApplicationContext) BeanUtils.instantiate(contextClass);
    }&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;10&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;11&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;12&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;13&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;14&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;15&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;16&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;17&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;10&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;11&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;12&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;13&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;14&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;15&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;16&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;17&lt;/li&gt;&lt;/ul&gt;

获取EmbeddedServletContainerFactory的实现类

spring boot通过获取EmbeddedServletContainerFactory来启动对应的web服务器。

常用的两个实现类是TomcatEmbeddedServletContainerFactory和JettyEmbeddedServletContainerFactory。

启动Tomcat的代码：
&lt;code class="language-java hljs  has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;&lt;span class="hljs-comment" style="color: rgb(136, 0, 0); box-sizing: border-box;"&gt;//TomcatEmbeddedServletContainerFactory&lt;/span&gt;
&lt;span class="hljs-annotation" style="color: rgb(155, 133, 157); box-sizing: border-box;"&gt;@Override&lt;/span&gt;
&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;public&lt;/span&gt; EmbeddedServletContainer &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;getEmbeddedServletContainer&lt;/span&gt;(
        ServletContextInitializer... initializers) {
    Tomcat tomcat = &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;new&lt;/span&gt; Tomcat();
    File baseDir = (&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;this&lt;/span&gt;.baseDirectory != &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;null&lt;/span&gt; ? &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;this&lt;/span&gt;.baseDirectory
            : createTempDir(&lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"tomcat"&lt;/span&gt;));
    tomcat.setBaseDir(baseDir.getAbsolutePath());
    Connector connector = &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;new&lt;/span&gt; Connector(&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;this&lt;/span&gt;.protocol);
    tomcat.getService().addConnector(connector);
    customizeConnector(connector);
    tomcat.setConnector(connector);
    tomcat.getHost().setAutoDeploy(&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;false&lt;/span&gt;);
    tomcat.getEngine().setBackgroundProcessorDelay(-&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;1&lt;/span&gt;);
    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;for&lt;/span&gt; (Connector additionalConnector : &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;this&lt;/span&gt;.additionalTomcatConnectors) {
        tomcat.getService().addConnector(additionalConnector);
    }
    prepareContext(tomcat.getHost(), initializers);
    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;return&lt;/span&gt; getTomcatEmbeddedServletContainer(tomcat);
}&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;10&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;11&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;12&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;13&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;14&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;15&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;16&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;17&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;18&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;19&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;20&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;10&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;11&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;12&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;13&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;14&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;15&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;16&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;17&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;18&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;19&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;20&lt;/li&gt;&lt;/ul&gt;

会为tomcat创建一个临时文件目录，如： 
/tmp/tomcat.2233614112516545210.8080，做为tomcat的basedir。里面会放tomcat的临时文件，比如work目录。

还会初始化Tomcat的一些Servlet，比如比较重要的default/jsp servlet：
&lt;code class="language-java hljs  has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;private&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;void&lt;/span&gt; &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;addDefaultServlet&lt;/span&gt;(Context context) {
    Wrapper defaultServlet = context.createWrapper();
    defaultServlet.setName(&lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"default"&lt;/span&gt;);
    defaultServlet.setServletClass(&lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"org.apache.catalina.servlets.DefaultServlet"&lt;/span&gt;);
    defaultServlet.addInitParameter(&lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"debug"&lt;/span&gt;, &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"0"&lt;/span&gt;);
    defaultServlet.addInitParameter(&lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"listings"&lt;/span&gt;, &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"false"&lt;/span&gt;);
    defaultServlet.setLoadOnStartup(&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;1&lt;/span&gt;);
    &lt;span class="hljs-comment" style="color: rgb(136, 0, 0); box-sizing: border-box;"&gt;// Otherwise the default location of a Spring DispatcherServlet cannot be set&lt;/span&gt;
    defaultServlet.setOverridable(&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;true&lt;/span&gt;);
    context.addChild(defaultServlet);
    context.addServletMapping(&lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"/"&lt;/span&gt;, &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"default"&lt;/span&gt;);
}

&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;private&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;void&lt;/span&gt; &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;addJspServlet&lt;/span&gt;(Context context) {
    Wrapper jspServlet = context.createWrapper();
    jspServlet.setName(&lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"jsp"&lt;/span&gt;);
    jspServlet.setServletClass(getJspServletClassName());
    jspServlet.addInitParameter(&lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"fork"&lt;/span&gt;, &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"false"&lt;/span&gt;);
    jspServlet.setLoadOnStartup(&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;3&lt;/span&gt;);
    context.addChild(jspServlet);
    context.addServletMapping(&lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"*.jsp"&lt;/span&gt;, &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"jsp"&lt;/span&gt;);
    context.addServletMapping(&lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"*.jspx"&lt;/span&gt;, &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"jsp"&lt;/span&gt;);
}&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;10&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;11&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;12&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;13&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;14&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;15&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;16&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;17&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;18&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;19&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;20&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;21&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;22&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;23&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;10&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;11&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;12&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;13&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;14&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;15&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;16&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;17&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;18&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;19&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;20&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;21&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;22&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;23&lt;/li&gt;&lt;/ul&gt;

spring boot的web应用如何访问Resource

当spring boot应用被打包为一个fat jar时，是如何访问到web resource的？

实际上是通过Archive提供的URL，然后通过Classloader提供的访问classpath resource的能力来实现的。

index.html

比如需要配置一个index.html，这个可以直接放在代码里的src/main/resources/static目录下。

对于index.html欢迎页，spring boot在初始化时，就会创建一个ViewController来处理：
&lt;code class="language-java hljs  has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;&lt;span class="hljs-comment" style="color: rgb(136, 0, 0); box-sizing: border-box;"&gt;//ResourceProperties&lt;/span&gt;
&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;public&lt;/span&gt; &lt;span class="hljs-class" style="box-sizing: border-box;"&gt;&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;class&lt;/span&gt; &lt;span class="hljs-title" style="box-sizing: border-box; color: rgb(102, 0, 102);"&gt;ResourceProperties&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;implements&lt;/span&gt; &lt;span class="hljs-title" style="box-sizing: border-box; color: rgb(102, 0, 102);"&gt;ResourceLoaderAware&lt;/span&gt; {&lt;/span&gt;

    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;private&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;static&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;final&lt;/span&gt; String[] SERVLET_RESOURCE_LOCATIONS = { &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"/"&lt;/span&gt; };

    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;private&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;static&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;final&lt;/span&gt; String[] CLASSPATH_RESOURCE_LOCATIONS = {
            &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"classpath:/META-INF/resources/"&lt;/span&gt;, &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"classpath:/resources/"&lt;/span&gt;,
            &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"classpath:/static/"&lt;/span&gt;, &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"classpath:/public/"&lt;/span&gt; };
&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;/ul&gt;&lt;code class="language-java hljs  has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;&lt;span class="hljs-comment" style="color: rgb(136, 0, 0); box-sizing: border-box;"&gt;//WebMvcAutoConfigurationAdapter&lt;/span&gt;
        &lt;span class="hljs-annotation" style="color: rgb(155, 133, 157); box-sizing: border-box;"&gt;@Override&lt;/span&gt;
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;public&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;void&lt;/span&gt; &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;addViewControllers&lt;/span&gt;(ViewControllerRegistry registry) {
            Resource page = &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;this&lt;/span&gt;.resourceProperties.getWelcomePage();
            &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;if&lt;/span&gt; (page != &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;null&lt;/span&gt;) {
                logger.info(&lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"Adding welcome page: "&lt;/span&gt; + page);
                registry.addViewController(&lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"/"&lt;/span&gt;).setViewName(&lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"forward:index.html"&lt;/span&gt;);
            }
        }&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;/ul&gt;

template

像页面模板文件可以放在src/main/resources/template目录下。但这个实际上是模板的实现类自己处理的。比如ThymeleafProperties类里的：
&lt;code class="language-java hljs  has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;public&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;static&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;final&lt;/span&gt; String DEFAULT_PREFIX = &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"classpath:/templates/"&lt;/span&gt;;&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;/ul&gt;

jsp

jsp页面和template类似。实际上是通过spring mvc内置的JstlView来处理的。

可以通过配置spring.view.prefix来设定jsp页面的目录：
&lt;code class="hljs http has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;&lt;span class="hljs-attribute" style="box-sizing: border-box;"&gt;spring.view.prefix&lt;/span&gt;: &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;/WEB-INF/jsp/&lt;/span&gt;&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;/ul&gt;

spring boot里统一的错误页面的处理

对于错误页面，Spring boot也是通过创建一个BasicErrorController来统一处理的。
&lt;code class="language-java hljs  has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;&lt;span class="hljs-annotation" style="color: rgb(155, 133, 157); box-sizing: border-box;"&gt;@Controller&lt;/span&gt;
&lt;span class="hljs-annotation" style="color: rgb(155, 133, 157); box-sizing: border-box;"&gt;@RequestMapping&lt;/span&gt;(&lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"${server.error.path:${error.path:/error}}"&lt;/span&gt;)
&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;public&lt;/span&gt; &lt;span class="hljs-class" style="box-sizing: border-box;"&gt;&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;class&lt;/span&gt; &lt;span class="hljs-title" style="box-sizing: border-box; color: rgb(102, 0, 102);"&gt;BasicErrorController&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;extends&lt;/span&gt; &lt;span class="hljs-title" style="box-sizing: border-box; color: rgb(102, 0, 102);"&gt;AbstractErrorController&lt;/span&gt; 
&lt;/span&gt;&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;/ul&gt;

对应的View是一个简单的HTML提醒：
&lt;code class="language-java hljs  has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;    &lt;span class="hljs-annotation" style="color: rgb(155, 133, 157); box-sizing: border-box;"&gt;@Configuration&lt;/span&gt;
    &lt;span class="hljs-annotation" style="color: rgb(155, 133, 157); box-sizing: border-box;"&gt;@ConditionalOnProperty&lt;/span&gt;(prefix = &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"server.error.whitelabel"&lt;/span&gt;, name = &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"enabled"&lt;/span&gt;, matchIfMissing = &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;true&lt;/span&gt;)
    &lt;span class="hljs-annotation" style="color: rgb(155, 133, 157); box-sizing: border-box;"&gt;@Conditional&lt;/span&gt;(ErrorTemplateMissingCondition.class)
    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;protected&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;static&lt;/span&gt; &lt;span class="hljs-class" style="box-sizing: border-box;"&gt;&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;class&lt;/span&gt; &lt;span class="hljs-title" style="box-sizing: border-box; color: rgb(102, 0, 102);"&gt;WhitelabelErrorViewConfiguration&lt;/span&gt; {&lt;/span&gt;

        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;private&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;final&lt;/span&gt; SpelView defaultErrorView = &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;new&lt;/span&gt; SpelView(
                &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"&lt;html&gt;&lt;body&gt;&lt;h1&gt;Whitelabel Error Page&lt;/h1&gt;"&lt;/span&gt;
                        + &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"&lt;p&gt;This application has no explicit mapping for /error, so you are seeing this as a fallback.&lt;/p&gt;"&lt;/span&gt;
                        + &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"&lt;div id='created'&gt;${timestamp}&lt;/div&gt;"&lt;/span&gt;
                        + &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"&lt;div&gt;There was an unexpected error (type=${error}, status=${status}).&lt;/div&gt;"&lt;/span&gt;
                        + &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"&lt;div&gt;${message}&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;"&lt;/span&gt;);

        &lt;span class="hljs-annotation" style="color: rgb(155, 133, 157); box-sizing: border-box;"&gt;@Bean&lt;/span&gt;(name = &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"error"&lt;/span&gt;)
        &lt;span class="hljs-annotation" style="color: rgb(155, 133, 157); box-sizing: border-box;"&gt;@ConditionalOnMissingBean&lt;/span&gt;(name = &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"error"&lt;/span&gt;)
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;public&lt;/span&gt; View &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;defaultErrorView&lt;/span&gt;() {
            &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;return&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;this&lt;/span&gt;.defaultErrorView;
        }&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;10&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;11&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;12&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;13&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;14&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;15&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;16&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;17&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;10&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;11&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;12&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;13&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;14&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;15&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;16&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;17&lt;/li&gt;&lt;/ul&gt;

spring boot的这个做法很好，避免了传统的web应用来出错时，默认抛出异常，容易泄密。

spring boot应用的maven打包过程

先通过maven-shade-plugin生成一个包含依赖的jar，再通过spring-boot-maven-plugin插件把spring boot loader相关的类，还有MANIFEST.MF打包到jar里。

spring boot里有颜色日志的实现

当在shell里启动spring boot应用时，会发现它的logger输出是有颜色的，这个特性很有意思。

可以通过这个设置来关闭：
&lt;code class="hljs avrasm has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;spring&lt;span class="hljs-preprocessor" style="color: rgb(68, 68, 68); box-sizing: border-box;"&gt;.output&lt;/span&gt;&lt;span class="hljs-preprocessor" style="color: rgb(68, 68, 68); box-sizing: border-box;"&gt;.ansi&lt;/span&gt;&lt;span class="hljs-preprocessor" style="color: rgb(68, 68, 68); box-sizing: border-box;"&gt;.enabled&lt;/span&gt;=false&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;/ul&gt;

原理是通过AnsiOutputApplicationListener ，这个来获取这个配置，然后设置logback在输出时，加了一个 ColorConverter，通过org.springframework.boot.ansi.AnsiOutput ，对一些字段进行了渲染。

一些代码小技巧

实现ClassLoader时，支持JDK7并行加载

可以参考LaunchedURLClassLoader里的LockProvider
&lt;code class="language-java hljs  has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;public&lt;/span&gt; &lt;span class="hljs-class" style="box-sizing: border-box;"&gt;&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;class&lt;/span&gt; &lt;span class="hljs-title" style="box-sizing: border-box; color: rgb(102, 0, 102);"&gt;LaunchedURLClassLoader&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;extends&lt;/span&gt; &lt;span class="hljs-title" style="box-sizing: border-box; color: rgb(102, 0, 102);"&gt;URLClassLoader&lt;/span&gt; {&lt;/span&gt;

    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;private&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;static&lt;/span&gt; LockProvider LOCK_PROVIDER = setupLockProvider();
    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;private&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;static&lt;/span&gt; LockProvider &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;setupLockProvider&lt;/span&gt;() {
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;try&lt;/span&gt; {
            ClassLoader.registerAsParallelCapable();
            &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;return&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;new&lt;/span&gt; Java7LockProvider();
        }
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;catch&lt;/span&gt; (NoSuchMethodError ex) {
            &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;return&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;new&lt;/span&gt; LockProvider();
        }
    }

    &lt;span class="hljs-annotation" style="color: rgb(155, 133, 157); box-sizing: border-box;"&gt;@Override&lt;/span&gt;
    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;protected&lt;/span&gt; Class&lt;?&gt; &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;loadClass&lt;/span&gt;(String name, &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;boolean&lt;/span&gt; resolve)
            &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;throws&lt;/span&gt; ClassNotFoundException {
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;synchronized&lt;/span&gt; (LaunchedURLClassLoader.LOCK_PROVIDER.getLock(&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;this&lt;/span&gt;, name)) {
            Class&lt;?&gt; loadedClass = findLoadedClass(name);
            &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;if&lt;/span&gt; (loadedClass == &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;null&lt;/span&gt;) {
                Handler.setUseFastConnectionExceptions(&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;true&lt;/span&gt;);
                &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;try&lt;/span&gt; {
                    loadedClass = doLoadClass(name);
                }
                &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;finally&lt;/span&gt; {
                    Handler.setUseFastConnectionExceptions(&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;false&lt;/span&gt;);
                }
            }
            &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;if&lt;/span&gt; (resolve) {
                resolveClass(loadedClass);
            }
            &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;return&lt;/span&gt; loadedClass;
        }
    }&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;10&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;11&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;12&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;13&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;14&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;15&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;16&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;17&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;18&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;19&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;20&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;21&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;22&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;23&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;24&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;25&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;26&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;27&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;28&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;29&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;30&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;31&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;32&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;33&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;10&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;11&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;12&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;13&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;14&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;15&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;16&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;17&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;18&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;19&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;20&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;21&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;22&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;23&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;24&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;25&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;26&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;27&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;28&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;29&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;30&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;31&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;32&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;33&lt;/li&gt;&lt;/ul&gt;

检测jar包是否通过agent加载的

InputArgumentsJavaAgentDetector，原理是检测jar的URL是否有”-javaagent:”的前缀。
&lt;code class="language-java hljs  has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;private&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;static&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;final&lt;/span&gt; String JAVA_AGENT_PREFIX = &lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"-javaagent:"&lt;/span&gt;;&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;/ul&gt;

获取进程的PID

ApplicationPid，可以获取PID。
&lt;code class="language-java hljs  has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;private&lt;/span&gt; String &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;getPid&lt;/span&gt;() {
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;try&lt;/span&gt; {
            String jvmName = ManagementFactory.getRuntimeMXBean().getName();
            &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;return&lt;/span&gt; jvmName.split(&lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"@"&lt;/span&gt;)[&lt;span class="hljs-number" style="color: rgb(0, 102, 102); box-sizing: border-box;"&gt;0&lt;/span&gt;];
        }
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;catch&lt;/span&gt; (Throwable ex) {
            &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;return&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;null&lt;/span&gt;;
        }
    }&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;/ul&gt;

包装Logger类

spring boot里自己包装了一套logger，支持Java, log4j, log4j2, logback，以后有需要自己包装logger时，可以参考这个。

在org.springframework.boot.logging包下面。

获取原始启动的main函数

通过堆栈里获取的方式，判断main函数，找到原始启动的main函数。
&lt;code class="language-java hljs  has-numbering" style="display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: 'Source Code Pro', monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;"&gt;&lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;private&lt;/span&gt; Class&lt;?&gt; &lt;span class="hljs-title" style="box-sizing: border-box;"&gt;deduceMainApplicationClass&lt;/span&gt;() {
    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;try&lt;/span&gt; {
        StackTraceElement[] stackTrace = &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;new&lt;/span&gt; RuntimeException().getStackTrace();
        &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;for&lt;/span&gt; (StackTraceElement stackTraceElement : stackTrace) {
            &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;if&lt;/span&gt; (&lt;span class="hljs-string" style="color: rgb(0, 136, 0); box-sizing: border-box;"&gt;"main"&lt;/span&gt;.equals(stackTraceElement.getMethodName())) {
                &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;return&lt;/span&gt; Class.forName(stackTraceElement.getClassName());
            }
        }
    }
    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;catch&lt;/span&gt; (ClassNotFoundException ex) {
        &lt;span class="hljs-comment" style="color: rgb(136, 0, 0); box-sizing: border-box;"&gt;// Swallow and continue&lt;/span&gt;
    }
    &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;return&lt;/span&gt; &lt;span class="hljs-keyword" style="color: rgb(0, 0, 136); box-sizing: border-box;"&gt;null&lt;/span&gt;;
}&lt;/code&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;10&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;11&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;12&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;13&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;14&lt;/li&gt;&lt;/ul&gt;&lt;ul class="pre-numbering" style="box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);"&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;1&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;2&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;3&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;4&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;5&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;6&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;7&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;8&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;9&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;10&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;11&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;12&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;13&lt;/li&gt;&lt;li style="box-sizing: border-box; padding: 0px 5px;"&gt;14&lt;/li&gt;&lt;/ul&gt;

spirng boot的一些缺点：

当spring boot应用以一个fat jar方式运行时，会遇到一些问题。以下是个人看法：

日志不知道放哪，默认是输出到stdout的数据目录不知道放哪, jenkinns的做法是放到 ${user.home}/.jenkins 下面相对目录API不能使用，servletContext.getRealPath(“/”) 返回的是NULLspring boot应用喜欢把配置都写到代码里，有时会带来混乱。一些简单可以用xml来表达的配置可能会变得难读，而且凌乱。

总结

spring boot通过扩展了jar协议，抽象出Archive概念，和配套的JarFile，JarUrlConnection，LaunchedURLClassLoader，从而实现了上层应用无感知的all in one的开发体验。尽管Executable war并不是spring提出的概念，但spring boot让它发扬光大。

spring boot是一个惊人的项目，可以说是spring的第二春，spring-cloud-config, spring-session, metrics, remote shell等都是深爱开发者喜爱的项目、特性。几乎可以肯定设计者是有丰富的一线开发经验，深知开发人员的痛点。

适逢今日高考，加上自己有一些感慨，便记下此文，应该可以供同行一同参阅与思考。
人生起起伏伏，以软件为谋生的IT人员更是看惯各类风云跌宕。
当前时下，软件的更新是如此迅速，以至于这个还没有热手，那个又来了，信息更新如此之快，以至于我们根本没有时间来掌握更多的更新的知识，这是我们的一个很大的困惑，当然也容易让我们很多的人不知所措，新的东西肯定是市场比较急需的，而老的东西，步入者比较多，竞争也就多了。想要更具竞争性的，就只有新东西了。要能让自己与时俱进，自认为最好的方式就是呆在饥饿的边缘。
何为呆在饥饿的边缘？
何为呆在饥饿的边缘，就是让自己时刻保持饥渴的状态，处于饥渴的人，更能专于自己想要的东西，处于饥渴的人，更清楚自己要什么，更能将自己的潜能发挥到极致。
或许大家都有一个这样的经历，就是刚跳槽到一个公司时，前几个月的干劲肯定特别的足，为什么，因为这个时候的你是出于饥饿边缘的，你清楚的知道，要么努力工作，要么就可能要继续下一份工作的寻找，当然，这个状态下的你换来的可能不仅仅是其他人对你工作的肯定，收获最大的肯定是你自己，因为经过这段饥饿时间的考验，你的技能肯定有了很大的提高。不过对于我们大多数人而言，这种状态并不能持续很久，能持续很久的肯定都是大牛级别的人物了。
要能呆在饥饿的边缘，仅仅靠自己的一份热情，是极少有人能做到的，为什么呢，因为对于大部分人，在一段时间的饥饿锻炼后，就感觉不到饥饿了，就如很多人的事业发展一样，已经到了一个瓶颈了或是已经到了他能力所及的最大范围了，到了他的这个饥饿层次的顶点，再往后就不知道怎么去给自己制造饥饿感了。
如何持续呆在饥饿的边缘？
如何让自己持续的呆在饥饿的边缘，这并不是一件轻松的事情，这需要自己不断的去折腾。如何折腾，自认为是最好能断骨重造。
断骨重造，这是自己想出来的一个让自己持续呆在饥饿边缘的点子。思路来源于老鹰的生存法则。故事是这样的：当一只老鹰生存了大概30年左右，就会遇到老化的问题，就是自己的羽毛老了，不能支持自己翱翔天空；爪子老了，抓不到老鼠了；啄也老了，啄不了硬物了。此时它有两个选择，一个选择为等待死亡，另一个选择为重塑自己。如何重塑：首先，趁还有一丝生气，飞到一个高而隐蔽的地方，先用啄把自己身上的羽毛全部拔光，再慢慢等待新羽毛长齐；接着，用啄把自己的爪子全部拔掉，等待长出新爪；最后利用坚石把啄磨掉，等待长出新啄。经过这么一个重塑的过程，它就可以再活20年。这就是老鹰的断骨重造，多活20年的代价是经历一番生死的考验。当然，我所指的断骨重造没有这么的恐怖。但我们也会有遇到类似老化的时期，经历了一定时间的技术积累后，可能会变得慢慢的依赖于自己的经验积累，也会慢慢的变得更多的使用之前积累的素材，导致不再对新知识那么感兴趣，那么敏感，已经习惯了呆在自己所已知的区域（舒适区）。对于我们做技术的人的断骨重造就是：否定自己所知道的一切，抛弃之前所有的东西，以初学者的心态再去看待所有的一切，丢弃内心的浮躁，用另一种眼光去看待所遇到的一切，如此定能让自己在各方面有一个质的飞跃，或许还会有一种重见光明的感觉。
软件世界总是风云迭起，并且从不会停息，对于我们更多的从业者，就是要能在这个领域中形成一个自己的风格，才能在这个不断变化的领域拥有自己的一片天地，否则只能随波逐流，终究很快就被这股强流卷的不见踪影。时刻让自己处于饥饿的边缘，就可以让自己逐步形成自己的风格。不拘一格，不随大流，方能自成一方。


Linux系统中的wget是一个下载文件的工具，它用在命令行下。对于Linux用户是必不可少的工具，我们经常要下载一些软件或从远程服务器恢复备份到本地服务器。wget支持HTTP，HTTPS和FTP协议，可以使用HTTP代理。所谓的自动下载是指，wget可以在用户退出系统的之后在后台执行。这意味这你可以登录系统，启动一个wget下载任务，然后退出系统，wget将在后台执行直到任务完成，相对于其它大部分浏览器在下载大量数据时需要用户一直的参与，这省去了极大的麻烦。

wget 可以跟踪HTML页面上的链接依次下载来创建远程服务器的本地版本，完全重建原始站点的目录结构。这又常被称作”递归下载”。在递归下载的时候，wget 遵循Robot Exclusion标准(/robots.txt).wget可以在下载的同时，将链接转换成指向本地文件，以方便离线浏览。

wget 非常稳定，它在带宽很窄的情况下和不稳定网络中有很强的适应性.如果是由于网络的原因下载失败，wget会不断的尝试，直到整个文件下载完毕。如果是服务器打断下载过程，它会再次联到服务器上从停止的地方继续下载。这对从那些限定了链接时间的服务器上下载大文件非常有用。

1．命令格式：

wget [参数] [URL地址]

2．命令功能：

用于从网络上下载资源，没有指定目录，下载资源回默认为当前目录。wget虽然功能强大，但是使用起来还是比较简单：

1）支持断点下传功能；这一点，也是网络蚂蚁和FlashGet当年最大的卖点，现在，Wget也可以使用此功能，那些网络不是太好的用户可以放心了；

2）同时支持FTP和HTTP下载方式；尽管现在大部分软件可以使用HTTP方式下载，但是，有些时候，仍然需要使用FTP方式下载软件；

3）支持代理服务器；对安全强度很高的系统而言，一般不会将自己的系统直接暴露在互联网上，所以，支持代理是下载软件必须有的功能；

4）设置方便简单；可能，习惯图形界面的用户已经不是太习惯命令行了，但是，命令行在设置上其实有更多的优点，最少，鼠标可以少点很多次，也不要担心是否错点鼠标；

5）程序小，完全免费；程序小可以考虑不计，因为现在的硬盘实在太大了；完全免费就不得不考虑了，即使网络上有很多所谓的免费软件，但是，这些软件的广告却不是我们喜欢的。

3．命令参数：

启动参数：

-V, –version 显示wget的版本后退出

-h, –help 打印语法帮助

-b, –background 启动后转入后台执行

-e, –execute=COMMAND 执行`.wgetrc’格式的命令，wgetrc格式参见/etc/wgetrc或~/.wgetrc

记录和输入文件参数：

-o, –output-file=FILE 把记录写到FILE文件中

-a, –append-output=FILE 把记录追加到FILE文件中

-d, –debug 打印调试输出

-q, –quiet 安静模式(没有输出)

-v, –verbose 冗长模式(这是缺省设置)

-nv, –non-verbose 关掉冗长模式，但不是安静模式

-i, –input-file=FILE 下载在FILE文件中出现的URLs

-F, –force-html 把输入文件当作HTML格式文件对待

-B, –base=URL 将URL作为在-F -i参数指定的文件中出现的相对链接的前缀

–sslcertfile=FILE 可选客户端证书

–sslcertkey=KEYFILE 可选客户端证书的KEYFILE

–egd-file=FILE 指定EGD socket的文件名

下载参数：

–bind-address=ADDRESS 指定本地使用地址(主机名或IP，当本地有多个IP或名字时使用)

-t, –tries=NUMBER 设定最大尝试链接次数(0 表示无限制).

-O –output-document=FILE 把文档写到FILE文件中

-nc, –no-clobber 不要覆盖存在的文件或使用.#前缀

-c, –continue 接着下载没下载完的文件

–progress=TYPE 设定进程条标记

-N, –timestamping 不要重新下载文件除非比本地文件新

-S, –server-response 打印服务器的回应

–spider 不下载任何东西

-T, –timeout=SECONDS 设定响应超时的秒数

-w, –wait=SECONDS 两次尝试之间间隔SECONDS秒

–waitretry=SECONDS 在重新链接之间等待1…SECONDS秒

–random-wait 在下载之间等待0…2*WAIT秒

-Y, –proxy=on/off 打开或关闭代理

-Q, –quota=NUMBER 设置下载的容量限制

–limit-rate=RATE 限定下载输率

目录参数：

-nd –no-directories 不创建目录

-x, –force-directories 强制创建目录

-nH, –no-host-directories 不创建主机目录

-P, –directory-prefix=PREFIX 将文件保存到目录 PREFIX/…

–cut-dirs=NUMBER 忽略 NUMBER层远程目录

HTTP 选项参数：

–http-user=USER 设定HTTP用户名为 USER.

–http-passwd=PASS 设定http密码为 PASS

-C, –cache=on/off 允许/不允许服务器端的数据缓存 (一般情况下允许)

-E, –html-extension 将所有text/html文档以.html扩展名保存

–ignore-length 忽略 `Content-Length’头域

–header=STRING 在headers中插入字符串 STRING

–proxy-user=USER 设定代理的用户名为 USER

–proxy-passwd=PASS 设定代理的密码为 PASS

–referer=URL 在HTTP请求中包含 `Referer: URL’头

-s, –save-headers 保存HTTP头到文件

-U, –user-agent=AGENT 设定代理的名称为 AGENT而不是 Wget/VERSION

–no-http-keep-alive 关闭 HTTP活动链接 (永远链接)

–cookies=off 不使用 cookies

–load-cookies=FILE 在开始会话前从文件 FILE中加载cookie

–save-cookies=FILE 在会话结束后将 cookies保存到 FILE文件中

FTP 选项参数：

-nr, –dont-remove-listing 不移走 `.listing’文件

-g, –glob=on/off 打开或关闭文件名的 globbing机制

–passive-ftp 使用被动传输模式 (缺省值).

–active-ftp 使用主动传输模式

–retr-symlinks 在递归的时候，将链接指向文件(而不是目录)

递归下载参数：

-r, –recursive 递归下载－－慎用!

-l, –level=NUMBER 最大递归深度 (inf 或 0 代表无穷)

–delete-after 在现在完毕后局部删除文件

-k, –convert-links 转换非相对链接为相对链接

-K, –backup-converted 在转换文件X之前，将之备份为 X.orig

-m, –mirror 等价于 -r -N -l inf -nr

-p, –page-requisites 下载显示HTML文件的所有图片

递归下载中的包含和不包含(accept/reject)：

-A, –accept=LIST 分号分隔的被接受扩展名的列表

-R, –reject=LIST 分号分隔的不被接受的扩展名的列表

-D, –domains=LIST 分号分隔的被接受域的列表

–exclude-domains=LIST 分号分隔的不被接受的域的列表

–follow-ftp 跟踪HTML文档中的FTP链接

–follow-tags=LIST 分号分隔的被跟踪的HTML标签的列表

-G, –ignore-tags=LIST 分号分隔的被忽略的HTML标签的列表

-H, –span-hosts 当递归时转到外部主机

-L, –relative 仅仅跟踪相对链接

-I, –include-directories=LIST 允许目录的列表

-X, –exclude-directories=LIST 不被包含目录的列表

-np, –no-parent 不要追溯到父目录

wget -S –spider url 不下载只显示过程

4．使用实例：

实例1：使用wget下载单个文件

命令：wget http://www.minjieren.com/wordpress-3.1-zh_CN.zip

说明：

以下的例子是从网络下载一个文件并保存在当前目录，在下载的过程中会显示进度条，包含（下载完成百分比，已经下载的字节，当前下载速度，剩余下载时间）。






实例2：使用wget -O下载并以不同的文件名保存

命令：wget -O wordpress.zip http://www.minjieren.com/download.aspx?id=1080

说明：

wget默认会以最后一个符合”/”的后面的字符来命令，对于动态链接的下载通常文件名会不正确。

错误：下面的例子会下载一个文件并以名称download.aspx?id=1080保存

wget http://www.minjieren.com/download?id=1

即使下载的文件是zip格式，它仍然以download.php?id=1080命令。

正确：为了解决这个问题，我们可以使用参数-O来指定一个文件名：

wget -O wordpress.zip http://www.minjieren.com/download.aspx?id=1080




实例3：使用wget –limit -rate限速下载

命令：wget --limit-rate=300k http://www.minjieren.com/wordpress-3.1-zh_CN.zip

说明：

当你执行wget的时候，它默认会占用全部可能的宽带下载。但是当你准备下载一个大文件，而你还需要下载其它文件时就有必要限速了。




实例4：使用wget -c断点续传

命令：wget -c http://www.minjieren.com/wordpress-3.1-zh_CN.zip

说明：

使用wget -c重新启动下载中断的文件，对于我们下载大文件时突然由于网络等原因中断非常有帮助，我们可以继续接着下载而不是重新下载一个文件。需要继续中断的下载时可以使用-c参数。




实例5：使用wget -b后台下载

命令：wget -b http://www.minjieren.com/wordpress-3.1-zh_CN.zip

说明：

对于下载非常大的文件的时候，我们可以使用参数-b进行后台下载。

wget -b http://www.minjieren.com/wordpress-3.1-zh_CN.zip

Continuing in background, pid 1840.

Output will be written to `wget-log'.

你可以使用以下命令来察看下载进度：

tail -f wget-log




实例6：伪装代理名称下载

命令：

wget --user-agent="Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.16 (KHTML, like Gecko) Chrome/10.0.648.204 Safari/534.16" http://www.minjieren.com/wordpress-3.1-zh_CN.zip





说明：

有些网站能通过根据判断代理名称不是浏览器而拒绝你的下载请求。不过你可以通过–user-agent参数伪装。




实例7：使用wget –spider测试下载链接

命令：wget --spider URL

说明：

当你打算进行定时下载，你应该在预定时间测试下载链接是否有效。我们可以增加–spider参数进行检查。

wget --spider URL

如果下载链接正确，将会显示

wget --spider URL

Spider mode enabled. Check if remote file exists.

HTTP request sent, awaiting response... 200 OK

Length: unspecified [text/html]

Remote file exists and could contain further links,

but recursion is disabled -- not retrieving.

这保证了下载能在预定的时间进行，但当你给错了一个链接，将会显示如下错误

wget --spider url

Spider mode enabled. Check if remote file exists.

HTTP request sent, awaiting response... 404 Not Found

Remote file does not exist -- broken link!!!

你可以在以下几种情况下使用spider参数：

定时下载之前进行检查

间隔检测网站是否可用

检查网站页面的死链接




实例8：使用wget –tries增加重试次数

命令：wget --tries=40 URL

说明：

如果网络有问题或下载一个大文件也有可能失败。wget默认重试20次连接下载文件。如果需要，你可以使用–tries增加重试次数。




实例9：使用wget -i下载多个文件

命令：wget -i filelist.txt

说明：

首先，保存一份下载链接文件

cat &gt; filelist.txt

url1

url2

url3

url4

接着使用这个文件和参数-i下载






实例10：使用wget –mirror镜像网站

命令：wget --mirror -p --convert-links -P ./LOCAL URL

说明：

下载整个网站到本地。

–miror:开户镜像下载

-p:下载所有为了html页面显示正常的文件

–convert-links:下载后，转换成本地的链接

-P ./LOCAL：保存所有文件和目录到本地指定目录




实例11：使用wget –reject过滤指定格式下载

命令：wget --reject=gif ur

说明：

下载一个网站，但你不希望下载图片，可以使用以下命令。




实例12：使用wget -o把下载信息存入日志文件

命令：wget -o download.log URL

说明：

不希望下载信息直接显示在终端而是在一个日志文件，可以使用




实例13：使用wget -Q限制总下载文件大小

命令：wget -Q5m -i filelist.txt

说明：

当你想要下载的文件超过5M而退出下载，你可以使用。注意：这个参数对单个文件下载不起作用，只能递归下载时才有效。




实例14：使用wget -r -A下载指定格式文件

命令：wget -r -A.pdf url

说明：

可以在以下情况使用该功能：

下载一个网站的所有图片

下载一个网站的所有视频

下载一个网站的所有PDF文件




实例15：使用wget FTP下载

命令：

wget ftp-url

wget --ftp-user=USERNAME --ftp-password=PASSWORD url

说明：

可以使用wget来完成ftp链接的下载。

使用wget匿名ftp下载：

wget ftp-url

使用wget用户名和密码认证的ftp下载

wget --ftp-user=USERNAME --ftp-password=PASSWORD url



备注：编译安装

使用如下命令编译安装： 

# tar zxvf wget-1.9.1.tar.gz 

# cd wget-1.9.1 

# ./configure 

# make 

# make install


scp是secure copy的简写，用于在Linux下进行远程拷贝文件的命令，和它类似的命令有cp，不过cp只是在本机进行拷贝不能跨服务器，而且scp传输是加密的。可能会稍微影响一下速度。当你服务器硬盘变为只读 read only system时，用scp可以帮你把文件移出来。另外，scp还非常不占资源，不会提高多少系统负荷，在这一点上，rsync就远远不及它了。虽然 rsync比scp会快一点，但当小文件众多的情况下，rsync会导致硬盘I/O非常高，而scp基本不影响系统正常使用。

1．命令格式：

scp [参数] [原路径] [目标路径]

2．命令功能：

scp是 secure copy的缩写, scp是linux系统下基于ssh登陆进行安全的远程文件拷贝命令。linux的scp命令可以在linux服务器之间复制文件和目录。

3．命令参数：

-1  强制scp命令使用协议ssh1  

-2  强制scp命令使用协议ssh2  

-4  强制scp命令只使用IPv4寻址  

-6  强制scp命令只使用IPv6寻址  

-B  使用批处理模式（传输过程中不询问传输口令或短语）  

-C  允许压缩。（将-C标志传递给ssh，从而打开压缩功能）  

-p 保留原文件的修改时间，访问时间和访问权限。  

-q  不显示传输进度条。  

-r  递归复制整个目录。  

-v 详细方式显示输出。scp和ssh(1)会显示出整个过程的调试信息。这些信息用于调试连接，验证和配置问题。   

-c cipher  以cipher将数据传输进行加密，这个选项将直接传递给ssh。   

-F ssh_config  指定一个替代的ssh配置文件，此参数直接传递给ssh。  

-i identity_file  从指定文件中读取传输时使用的密钥文件，此参数直接传递给ssh。    

-l limit  限定用户所能使用的带宽，以Kbit/s为单位。     

-o ssh_option  如果习惯于使用ssh_config(5)中的参数传递方式，   

-P port  注意是大写的P, port是指定数据传输用到的端口号   

-S program  指定加密传输时所使用的程序。此程序必须能够理解ssh(1)的选项。

4．使用实例：

scp命令的实际应用概述：  

从本地服务器复制到远程服务器： 

(1) 复制文件：  

命令格式：  

scp local_file remote_username@remote_ip:remote_folder  

或者  

scp local_file remote_username@remote_ip:remote_file  

或者  

scp local_file remote_ip:remote_folder  

或者  

scp local_file remote_ip:remote_file  

第1,2个指定了用户名，命令执行后需要输入用户密码，第1个仅指定了远程的目录，文件名字不变，第2个指定了文件名  

第3,4个没有指定用户名，命令执行后需要输入用户名和密码，第3个仅指定了远程的目录，文件名字不变，第4个指定了文件名   

(2) 复制目录：  

命令格式：  

scp -r local_folder remote_username@remote_ip:remote_folder  

或者  

scp -r local_folder remote_ip:remote_folder  

第1个指定了用户名，命令执行后需要输入用户密码；  

第2个没有指定用户名，命令执行后需要输入用户名和密码；

  

从远程服务器复制到本地服务器： 

从远程复制到本地的scp命令与上面的命令雷同，只要将从本地复制到远程的命令后面2个参数互换顺序就行了。



实例1：从远处复制文件到本地目录

命令：scp root@192.168.120.204:/opt/soft/nginx-0.5.38.tar.gz /opt/soft/

说明：从192.168.120.204机器上的/opt/soft/的目录中下载nginx-0.5.38.tar.gz 文件到本地/opt/soft/目录中






实例2：从远处复制到本地

命令：scp -r root@192.168.120.204:/opt/soft/mongodb /opt/soft/

说明：从192.168.120.204机器上的/opt/soft/中下载mongodb 目录到本地的/opt/soft/目录来。






实例3：上传本地文件到远程机器指定目录

命令：scp /opt/soft/nginx-0.5.38.tar.gz root@192.168.120.204:/opt/soft/scptest

说明：复制本地opt/soft/目录下的文件nginx-0.5.38.tar.gz 到远程机器192.168.120.204的opt/soft/scptest目录






实例4：上传本地目录到远程机器指定目录

命令：scp -r /opt/soft/mongodb root@192.168.120.204:/opt/soft/scptest

说明：上传本地目录 /opt/soft/mongodb到远程机器192.168.120.204上/opt/soft/scptest的目录中去


转载于：http://www.infoq.com/cn/articles/spring-4-Java-8?utm_source=infoq&amp;utm_medium=related_content_link&amp;utm_campaign=relatedContent_articles_clk






有众多新特性和函数库的Java 8发布之后，Spring 4.x已经支持其中的大部分。有些Java 8的新特性对Spring无影响，可以直接使用，但另有些新特性需要Spring的支持。本文将带您浏览Spring 4.0和4.1已经支持的Java 8新特性。

Spring 4支持Java 6、7和8

Java 8编译器编译过的代码生成的.class文件需要在Java 8或以上的Java虚拟机上运行。由于Spring对反射机制和ASM、CGLIB等字节码操作函数库的重度使用，必须确保这些函数库能理解Java 8生成的新class文件。因此Spring将ASM、CGLIB等函数库通过jar jar(https://code.google.com/p/jarjar/)嵌入Spring框架中，这样Spring就可以同时支持Java6、7和8的字节码代码而不会触发运行时错误。

Spring框架本身是由Java 8编译器编译的，编译时使用的是生成Java 6字节码的编译命令选项。因此你可以Java6、7或者8来编译运行Spring 4.x的应用。



Java 8的设计者想保证它是向下兼容的，以使其lambda表达式能在旧版本的代码编译器中使用。向下兼容通过定义函数式接口概念实现。Spring和Java 8的Lambda表达式

基本上，Java 8的设计者分析了现有的Java代码体系，注意到很多Java程序员用只有一个方法的接口来表示方法的思想。以下就是JDK和Spring中只有一个方法的接口的例子，也就是所谓的“函数式接口”。

JDK里的函数式接口：


public interface Runnable {
    public abstract void run();}

public interface Comparable&lt;T&gt; {
    public int compareTo(T o);}

Spring框架里的函数式接口：
public interface ConnectionCallback&lt;T&gt; {
  T doInConnection(Connection con) throws SQLException, DataAccessException;}

public interface RowMapper&lt;T&gt;{
  T mapRow(ResultSet rs, int rowNum) throws SQLException;}

在Java 8里，任何函数式接口作为方法的参数传入或者作为方法返回值的场合，都可以用lambda表达式代替。例如，Spring的JdbcTemplate类里有一个方法定义如下：
public &lt;T&gt; List&lt;T&gt; query(String sql, RowMapper&lt;T&gt; rowMapper)
  throws DataAccessException

这个查询方法的第二个参数需要RowMapper接口的一个实例。在Java 8中我们可以写一个lambda表达式作为第二个参数的值传进去。

别把代码写成这样：
jdbcTemplate.query("SELECT * from products", new RowMapper&lt;Product&gt;(){
  @Override
  public Product mapRow(ResultSet rs, int rowNum) throws SQLException {
    Integer id = rs.getInt("id");
    String description = rs.getString("description");
    Integer quantity = rs.getInt("quantity");
    BigDecimal price = rs.getBigDecimal("price");
    Date availability = rs.getDate("available_date");

    Product product = new Product();
    product.setId(id);
    product.setDescription(description);
    product.setQuantity(quantity);
    product.setPrice(price);
    product.setAvailability(availability);

    return product;
  }});

我们这么写：
jdbcTemplate.query("SELECT * from queries.products", (rs, rowNum) -&gt; {
    Integer id = rs.getInt("id");
    String description = rs.getString("description");
    Integer quantity = rs.getInt("quantity");
    BigDecimal price = rs.getBigDecimal("price");
    Date availability = rs.getDate("available_date");

    Product product = new Product();
    product.setId(id);
    product.setDescription(description);
    product.setQuantity(quantity);
    product.setPrice(price);
    product.setAvailability(availability);

    return product;});

我们注意到Java 8中这段代码使用了lambda表达式，这比之前的版本中使用匿名内部类的方式紧凑、简洁得多。

涵盖Java 8中函数式接口的所有细节超出了本文的范畴，我们强烈建议您从别处详细学习函数式接口。本文想要传达的关键点在于Java
 8的lambda表达式能传到那些用Java 7或更早的JDK编译的、接受函数式接口作为参数的方法中。

Spring的代码里有很多函数式接口，因此lambda表达式很容易与Spring结合使用。即便Spring框架本身被编译成Java 6的.class文件格式，你仍然可以用Java 8的lambda表达式编写应用代码、用Java 8编译器编译、并且在Java 8虚拟机上运行，你的应用可以正常工作。

总之，因为Spring框架早在Java 8正式给函数式接口下定义之前就已经实际使用了函数式接口，因此在Spring里使用lambda表达式非常容易。

Spring 4和Java 8的时间与日期API

Java开发者们一直痛恨java.util.Date类的设计缺陷，终于，Java 8带来了全新的日期与时间API，解决了那些久被诟病的问题。这个新的日期与时间API值得用一整篇文章的篇幅来讲述，因此我们在本文不会详述其细节，而是重点关注新的java.time包中引入的众多新类，如LocalDate、LocalTime和
 LocalDateTime。

Spring有一个数据转换框架，它可以使字符串和Java数据类型相互转换。Spring 4升级了这个转换框架以支持Java 8日期与时间API里的那些类。因此你的代码可以这样写：
@RestController
public class ExampleController {

  @RequestMapping("/date/{localDate}")
  public String get(@DateTimeFormat(iso = ISO.DATE) LocalDate localDate)
  {
    return localDate.toString();
  }}

上面的例子中，get方法的参数是Java 8的LocalDate类型，Spring 4能接受一个字符串参数例如2014-02-01并将它转换成Java 8 LocalDate的实例。

要注意的是Spring通常会与其它一些库一起使用实现特定功能，比如与hibernate一起实现数据持久化，与Jackson一起实现Java对象和JSON的互相转换。

虽然Spring 4支持Java 8的日期与时间库，这并不表示第三方框架如Hibernate和Jackson等也能支持它。到本文发表时，Hibernate JIRA里仍有一个开放状态的请求HHH-8844要求在Hibernate里支持Java
 8日期与时间API。

Spring 4与重复注解

Java 8增加了对重复注解的支持，Spring 4也同样支持。特殊的是，Spring 4支持对注解@Scheduled和@PropertySource的重复。例如，请注意如下代码片段中对@PropertySource注解的重复使用：
@Configuration
@ComponentScan
@EnableAutoConfiguration
@PropertySource("classpath:/example1.properties")
@PropertySource("classpath:/example2.properties")public class Application {

        @Autowired
        private Environment env;

        @Bean
        public JdbcTemplate template(DataSource datasource) {
                System.out.println(env.getProperty("test.prop1"));
                System.out.println(env.getProperty("test.prop2"));
                return new JdbcTemplate(datasource);
        }

        public static void main(String[] args) {
                SpringApplication.run(Application.class, args);
        }}

Java 8的Optional&lt;&gt;与Spring 4.1

忘记检查空值引用是应用代码中一类常见的bug来源。消除NullPointerExceptions的方式之一是确保方法总是返回一个非空值。例如如下方法：
public interface CustomerRepository extends CrudRepository&lt;Customer, Long&gt; {
   /**
    * returns the customer for the specified id or
    * null if the value is not found
   */
   public Customer findCustomerById(String id);}

用如下有缺陷的代码来调用CustomerRepository ：
Customer customer = customerRepository.findCustomerById(“123”);
customer.getName(); // 得到空指针错误

这段代码的正确写法应该是：
Customer customer = customerRepository.findCustomerById(“123”);if(customer != null) {
  customer.getName(); // 避免空指针错误

}

理想状态下，如果我们没有检查某个值能否为空，我们希望编译器及时发现。java.util.Optional类让我们可以像这样写接口：
public interface CustomerRepository extends CrudRepository&lt;Customer, Long&gt; {
  public Optional&lt;Customer&gt; findCustomerById(String id);}

这样一来，这段代码的有缺陷版本不会被编译，开发者必须显式地检查这个Optional类型对象是否有值，代码如下：
Optional&lt;Customer&gt; optional = 
customerRepository.findCustomerById(“123”);if(optional.isPresent()) {
   Customer customer = optional.get();
   customer.getName();}

所以Optional的关键点在于确保开发者不用查阅Javadoc就能知道某个方法可以返回null，或者可以把一个null值传给某方法。编译器和方法签名有助于开发者明确知道某个值是Optional类型。关于Optional类思想的详细描述请参考这里。

Spring 4.1有两种方式支持Java Optional。Spring的@Autowired注解有一个属性"required"，使用之后我们可以把如下代码：
@Service
public class MyService {

    @Autowired(required=false)
    OtherService otherService;

    public doSomething() {
      if(otherService != null) {
        // use other service
      }
   }}

替换成：
public class MyService {

    @Autowired
    Optional&lt;OtherService&gt; otherService;

    public doSomething() {
      otherService.ifPresent( s -&gt;  {
        // use s to do something
      });
    }}


另一个能用Optional的地方是Spring MVC框架，可以用于表示某个处理方法的参数是可选的。例如：
@RequestMapping(“/accounts/{accountId}”,requestMethod=RequestMethod.POST)
void update(Optional&lt;String&gt; accountId, @RequestBody Account account)


这段代码会告诉Spring其accountId是可选参数。

总之，Java 8的Optional类通过减少空指针错误相关的缺陷简化了代码编写，同时Spring能很好地支持Java 8的Optional类。

参数名发现机制

Java 8支持在编译后的代码中保留方法的参数名。这意味着Spring 4可以从方法中提取参数名，从而使SpringMVC代码更为简洁。例如：
@RequestMapping("/accounts/{id}")public Account getAccount(@PathVariable("id") String id)

可以改写为：
@RequestMapping("/accounts/{id}")public Account getAccount(@PathVariable String id)

可以看到我们把@PathVariable(“id”) 替换成@PathVariable，因为Spring 4能从编译后的Java 8代码中获取参数名——id。只要在编译时指定了–parameters标记，Java 8编译器就会把参数名写入.class文件中。在Java 8发布之前，Spring也可以从使用-debug选项编译之后的代码中提取出参数名。

在Java 7及之前的版本中，-debug选项不会保留抽象方法的参数名。这会导致Spring Data这类基于Java接口自动生成其资源库实现的工程就会出现问题。比如接口如下：
interface CustomerRepository extends CrudRepository&lt;Customer, Long&gt; {
  @Query("select c from Customer c where c.lastname = :lastname")
  List&lt;Customer&gt; findByLastname(@Param("lastname") String lastname);}

我们能看到findByLastname仍然需要@Param(“lastname”)，这是因为findByLastname是个抽象方法，而在Java 7及之前的版本里就算用了-debug选项也不会保留其参数名。而在Java 8中，使用–parameters选项后，Spring Data就能自动找到抽象方法的参数名，我们可以把上例中的接口改写成：
interface CustomerRepository extends CrudRepository&lt;Customer, Long&gt; {
  @Query("select c from Customer c where c.lastname = :lastname")
  List&lt;Customer&gt; findByLastname(String lastname);}

这里我们已经不再需要@Param(“lastname”)，让代码更简洁且易于阅读。所以使用Java 8编译代码时加上–parameters标记是个好方法。

总结

Spring 4支持Java 6、7和8，开发者可以随意使用Java 6、7或8来编写自己的应用代码。如果使用的是Java 8，那么只要有函数式接口的地方就可以使用lambda表达式，使代码更为简洁易读。

Java 8对某些库做了改进，比如新的java.time包和Optional类，Optional类使得用Spring编写的代码更加简单明了。

最后，用–parameters选项编译Java 8代码会在编译时保留方法的参数名，使得开发者得以编写更为紧凑的Spring MVC方法和Spring Data查询方法。

如果你已经准备在项目中使用Java 8，你会发现Spring 4是个很好地利用了Java 8新特性的出色框架。


rcp代表“remote file copy”（远程文件拷贝）。该命令用于在计算机之间拷贝文件。rcp命令有两种格式。第一种格式用于文件到文件的拷贝；第二种格式用于把文件或目录拷贝到另一个目录中。

1．命令格式：

rcp [参数] [源文件] [目标文件]

2．命令功能：

rcp命令用在远端复制文件或目录，如同时指定两个以上的文件或目录，且最后的目的地是一个已经存在的目录，则它会把前面指定的所有文件或目录复制到该目录中。

3．命令参数：

各选项含义：

-r 递归地把源目录中的所有内容拷贝到目的目录中。要使用这个选项，目的必须是一个目录。

-p 试图保留源文件的修改时间和模式，忽略umask。

-k 请求rcp获得在指定区域内的远程主机的Kerberos 许可，而不是获得由krb_relmofhost⑶确定的远程主机区域内的远程主机的Kerberos许可。

-x 为传送的所有数据打开DES加密。这会影响响应时间和CPU利用率，但是可以提高安全性。如果在文件名中指定的路径不是完整的路径名，那么这个路径被解释为相对远程机上同名用户的主目录。如果没有给出远程用户名，就使用当前用户名。如果远程机上的路径包含特殊shell字符，需要用反斜线（\\）、双引号（”）或单引号（’）括起来，使所有的shell元字符都能被远程地解释。需要说明的是，rcp不提示输入口令，它通过rsh命令来执行拷贝。

directory 每个文件或目录参数既可以是远程文件名也可以是本地文件名。远程文件名具有如下形式：rname@rhost：path，其中rname是远程用户名，rhost是远程计算机名，path是这个文件的路径。

4．使用实例：

要使用 rcp，需要具备以下条件：

如果系统中有 /etc/hosts 文件，系统管理员应确保该文件包含要与之进行通信的远程主机的项。

/etc/hosts 文件中有一行文字，其中包含每个远程系统的以下信息：

internet_address   official_name   alias

例如：

9.186.10.***  webserver1.com.58.webserver

.rhosts 文件

.rhosts 文件位于远程系统的主目录下，其中包含本地系统的名称和本地登录名。

例如，远程系统的 .rhosts 文件中的项可能是：

webserver1 root

其中，webserver1 是本地系统的名称，root 是本地登录名。这样，webserver1 上的 root 即可在包含 .rhosts 文件的远程系统中来回复制文件。

配置过程:

只对root用户生效

1. 在双方root用户根目录下建立.rhosts文件,并将双方的hostname加进去.在此之前应在双方的 /etc/hosts文件中加入对方的IP和hostname

2. 把rsh服务启动起来,redhat默认是不启动的。

方法：用执行ntsysv命令,在rsh选项前用空格键选中,确定退出。然后执行：

service xinetd restart即可。

3. 到/etc/pam.d/目录下,把rsh文件中的auth required /lib/security/pam_securetty.so

一行用“#”注释掉即可。（只有注释掉这一行，才能用root用户登录）

命令使用:

将文件复制到远程系统

要将本地系统中的文件复制到远程系统，请使用以下命令：

rcplocal_fileremote_hostname:remote_fileEnter

注意，如果当前目录下没有 local_file，则除本地文件名外，还需要提供相对路径（自当前目录开始）或绝对路径名（自 / 开始）。

仅当希望将 remote_hostname 上的 remote_file 放到其他目录（远程主目录除外）下时，才需要为其指定完整的（绝对）路径。

使用实例1:将当前目录下的 test1 复制到名为 webserver1的远程系统

命令：

rcp test1 webserver1:/home/root/test3

说明：

在这种情况下，test1 被复制到远程子目录 test3下，名称仍为 test1 。如果仅提供了远程主机名，rcp 将把 test1 复制到远程主目录下，名称仍为 test1 。

还可以在目的目录中包含文件名。例如，将文件复制到名为 webserver1的系统中：

rcp test1 webserver1:/home/root/test3

在这种情况下，将 test1 复制到远程目录root 下并将其命名为 test3。

使用实例2：从远程系统复制文件：要将远程系统中的文件复制到本地目录下

命令：

rcp remote_hostname:remote_file local_fileEnter

使用实例:3:将远程系统 webserver1中的 test2 复制到当前目录：

命令：

rcp webserver1:/home/root/test2 .Enter

说明：

点 (.) 是“当前目录”的简写形式。在这种情况下，远程目录中的 test2 被复制到当前目录下，名称仍为 test2 。

如果希望用新名称复制文件，请提供目标文件名。

如果希望将 test2 复制到本地系统中的其他目录下，请使用以下绝对或相对路径名：

rcp webserver1:/home/root/test2 otherdir/ Enter

或者，如果希望用其他文件名将文件复制到其他目录下：

rcp webserver1:/home/root/test2 otherdir/otherfile Enter

使用实例4：将目录复制到远程系统：要将本地目录及其文件和子目录复制到远程系统，请同时使用 rcp 和 -r（递归）选项。

命令：

rcp –r local_dir remote_hostname:remote_dir Enter

说明：

如果当前目录下没有 local_dir，则除本地目录名外，还需要提供相对路径名（自当前目录开始）或绝对路径名（自 / 顶级目录开始）。另外，如果主目录下没有 remote_dir，则 remote_dir 将需要一个相对路径（自主目录开始）或绝对路径（自 / 开始）。

使用实例5:

要将名为 work 的子目录完整地复制到 webserver1远程计算机中的主目录下名为 products 的目录，请键入以下内容：

rcp –r work webserver1:/home/root/products Enter

此命令在 webserver1:/home/root/products 下创建名为 work 的目录及其全部内容（假定 /home/root/products 已存在于 webserver1中）。

本示例假定用户处于包含 work 的本地目录下。否则，必须提供该目录的相对或绝对路径，如 /home/root/work。

使用实例6：从远程系统复制目录：

要将远程目录及其所有文件和子目录复制到本地目录，请在以下语法中使用 rcp 和 -r（递归）选项。

命令：

rcp –r remote_hostname:remote_dir local_dir Enter

要将名为 work 的远程目录复制到当前目录，请键入以下内容：

rcp –r webserver1:/home/root/work .Enter

点 (.) 表示当前目录。将在此目录下创建 work 目录。


telnet命令通常用来远程登录。telnet程序是基于TELNET协议的远程登录客户端程序。Telnet协议是TCP/IP协议族中的一员，是Internet远程登陆服务的标准协议和主要方式。它为用户提供了在本地计算机上完成远程主机工作的 能力。在终端使用者的电脑上使用telnet程序，用它连接到服务器。终端使用者可以在telnet程序中输入命令，这些命令会在服务器上运行，就像直接在服务器的控制台上输入一样。可以在本地就能控制服务器。要开始一个 telnet会话，必须输入用户名和密码来登录服务器。Telnet是常用的远程控制Web服务器的方法。

　　但是，telnet因为采用明文传送报文，安全性不好，很多Linux服务器都不开放telnet服务，而改用更安全的ssh方式了。但仍然有很多别的系统可能采用了telnet方式来提供远程登录，因此弄清楚telnet客户端的使用方式仍是很有必要的。

telnet命令还可做别的用途，比如确定远程服务的状态，比如确定远程服务器的某个端口是否能访问。

1．命令格式：

telnet[参数][主机]

2．命令功能：

执行telnet指令开启终端机阶段作业，并登入远端主机。

3．命令参数：

-8 允许使用8位字符资料，包括输入与输出。

-a 尝试自动登入远端系统。

-b&lt;主机别名&gt; 使用别名指定远端主机名称。

-c 不读取用户专属目录里的.telnetrc文件。

-d 启动排错模式。

-e&lt;脱离字符&gt; 设置脱离字符。

-E 滤除脱离字符。

-f 此参数的效果和指定"-F"参数相同。

-F 使用Kerberos V5认证时，加上此参数可把本地主机的认证数据上传到远端主机。

-k&lt;域名&gt; 使用Kerberos认证时，加上此参数让远端主机采用指定的领域名，而非该主机的域名。

-K 不自动登入远端主机。

-l&lt;用户名称&gt; 指定要登入远端主机的用户名称。

-L 允许输出8位字符资料。

-n&lt;记录文件&gt; 指定文件记录相关信息。

-r 使用类似rlogin指令的用户界面。

-S&lt;服务类型&gt; 设置telnet连线所需的IP TOS信息。

-x 假设主机有支持数据加密的功能，就使用它。

-X&lt;认证形态&gt; 关闭指定的认证形态。

4．使用实例：

实例1：远程服务器无法访问

命令：telnet 192.168.120.206

输出：



[root@localhost ~]# telnet 192.168.120.209
Trying 192.168.120.209...
telnet: connect to address 192.168.120.209: No route to host
telnet: Unable to connect to remote host: No route to host
[root@localhost ~]# 




说明：

处理这种情况方法：

（1）确认ip地址是否正确？

（2）确认ip地址对应的主机是否已经开机？

（3）如果主机已经启动，确认路由设置是否设置正确？（使用route命令查看）

（4）如果主机已经启动，确认主机上是否开启了telnet服务？（使用netstat命令查看，TCP的23端口是否有LISTEN状态的行）

（5）如果主机已经启动telnet服务，确认防火墙是否放开了23端口的访问？（使用iptables-save查看）



实例2：域名无法解析

命令：telnet www.baidu.com

输出：



[root@localhost ~]# telnet www.baidu.com
www.baidu.com/telnet: Temporary failure in name resolution
[root@localhost ~]# 




说明：

处理这种情况方法：

（1）确认域名是否正确

（2）确认本机的域名解析有关的设置是否正确（/etc/resolv.conf中nameserver的设置是否正确，如果没有，可以使用nameserver 8.8.8.8）

（3）确认防火墙是否放开了UDP53端口的访问（DNS使用UDP协议，端口53，使用iptables-save查看）



实例3：

命令：

输出：



[root@localhost ~]# telnet 192.168.120.206
Trying 192.168.120.206...
telnet: connect to address 192.168.120.206: Connection refused
telnet: Unable to connect to remote host: Connection refused
[root@localhost ~]#




说明：

处理这种情况：

（1）确认ip地址或者主机名是否正确？

（2）确认端口是否正确，是否默认的23端口



实例4：启动telnet服务

命令：

service xinetd restart

输出：




[root@localhost ~]# cd /etc/xinetd.d/
[root@localhost xinetd.d]# ll
总计 124
-rw-r--r-- 1 root root 1157 2011-05-31 chargen-dgram
-rw-r--r-- 1 root root 1159 2011-05-31 chargen-stream
-rw-r--r-- 1 root root  523 2009-09-04 cvs
-rw-r--r-- 1 root root 1157 2011-05-31 daytime-dgram
-rw-r--r-- 1 root root 1159 2011-05-31 daytime-stream
-rw-r--r-- 1 root root 1157 2011-05-31 discard-dgram
-rw-r--r-- 1 root root 1159 2011-05-31 discard-stream
-rw-r--r-- 1 root root 1148 2011-05-31 echo-dgram
-rw-r--r-- 1 root root 1150 2011-05-31 echo-stream
-rw-r--r-- 1 root root  323 2004-09-09 eklogin
-rw-r--r-- 1 root root  347 2005-09-06 ekrb5-telnet
-rw-r--r-- 1 root root  326 2004-09-09 gssftp
-rw-r--r-- 1 root root  310 2004-09-09 klogin
-rw-r--r-- 1 root root  323 2004-09-09 krb5-telnet
-rw-r--r-- 1 root root  308 2004-09-09 kshell
-rw-r--r-- 1 root root  317 2004-09-09 rsync
-rw-r--r-- 1 root root 1212 2011-05-31 tcpmux-server
-rw-r--r-- 1 root root 1149 2011-05-31 time-dgram
-rw-r--r-- 1 root root 1150 2011-05-31 time-stream
[root@localhost xinetd.d]# cat krb5-telnet 
# default: off
# description: The kerberized telnet server accepts normal telnet sessions, \
#              but can also use Kerberos 5 authentication.
service telnet
{
        flags           = REUSE
        socket_type     = stream        
        wait            = no
        user            = root
        server          = /usr/kerberos/sbin/telnetd
        log_on_failure  += USERID
        disable         = yes
}
[root@localhost xinetd.d]# 





说明：

配置参数，通常的配置如下： 

service telnet 

{ 

disable = no #启用 

flags = REUSE #socket可重用 

socket_type = stream #连接方式为TCP 

wait = no #为每个请求启动一个进程 

user = root #启动服务的用户为root 

server = /usr/sbin/in.telnetd #要激活的进程 

log_on_failure += USERID #登录失败时记录登录用户名 

} 



如果要配置允许登录的客户端列表，加入 

only_from = 192.168.0.2 #只允许192.168.0.2登录 

如果要配置禁止登录的客户端列表，加入 

no_access = 192.168.0.{2,3,4} #禁止192.168.0.2、192.168.0.3、192.168.0.4登录 

如果要设置开放时段，加入 

access_times = 9:00-12:00 13:00-17:00 # 每天只有这两个时段开放服务（我们的上班时间：P） 

如果你有两个IP地址，一个是私网的IP地址如192.168.0.2，一个是公网的IP地址如218.75.74.83，如果你希望用户只能从私网来登录telnet服务，那么加入 

bind = 192.168.0.2 

各配置项具体的含义和语法可参考xined配置文件属性说明（man xinetd.conf） 



配置端口，修改services文件：

# vi /etc/services 

找到以下两句 

telnet 23/tcp 

telnet 23/udp 

如果前面有#字符，就去掉它。telnet的默认端口是23，这个端口也是黑客端口扫描的主要对象，因此最好将这个端口修改掉，修改的方法很简单，就是将23这个数字修改掉，改成大一点的数字，比如61123。注意，1024以下的端口号是internet保留的端口号，因此最好不要用，还应该注意不要与其它服务的端口冲突。 

启动服务：

service xinetd restart 



实例5：正常telnet

命令：telnet 192.168.120.204



说明：一般情况下不允许root从远程登录，可以先用普通账号登录，然后再用su -切到root用户。


ss是Socket Statistics的缩写。顾名思义，ss命令可以用来获取socket统计信息，它可以显示和netstat类似的内容。但ss的优势在于它能够显示更多更详细的有关TCP和连接状态的信息，而且比netstat更快速更高效。

当服务器的socket连接数量变得非常大时，无论是使用netstat命令还是直接cat /proc/net/tcp，执行速度都会很慢。可能你不会有切身的感受，但请相信我，当服务器维持的连接达到上万个的时候，使用netstat等于浪费生命，而用ss才是节省时间。

天下武功唯快不破。ss快的秘诀在于，它利用到了TCP协议栈中tcp_diag。tcp_diag是一个用于分析统计的模块，可以获得Linux 内核中第一手的信息，这就确保了ss的快捷高效。当然，如果你的系统中没有tcp_diag，ss也可以正常运行，只是效率会变得稍慢。（但仍然比 netstat要快。）

1.命令格式:

ss [参数]

ss [参数] [过滤]

2.命令功能：

ss(Socket Statistics的缩写)命令可以用来获取socket统计信息，此命令输出的结果类似于netstat输出的内容，但它能显示更多更详细的 TCP连接状态的信息，且比 netstat 更快速高效。它使用了TCP协议栈中 tcp_diag（是一个用于分析统计的模块），能直接从获得第一手内核信息，这就使得 ss命令快捷高效。在没有 tcp_diag，ss也可以正常运行。

3.命令参数：

-h, --help
帮助信息

-V, --version
程序版本信息

-n, --numeric
不解析服务名称

-r, --resolve        解析主机名

-a, --all
显示所有套接字（sockets）

-l, --listening
显示监听状态的套接字（sockets）

-o, --options        显示计时器信息

-e, --extended       显示详细的套接字（sockets）信息

-m, --memory         显示套接字（socket）的内存使用情况

-p, --processes
显示使用套接字（socket）的进程

-i, --info
显示 TCP内部信息

-s, --summary
显示套接字（socket）使用概况

-4, --ipv4           仅显示IPv4的套接字（sockets）

-6, --ipv6           仅显示IPv6的套接字（sockets）

-0, --packet
        显示 PACKET 套接字（socket）

-t, --tcp
仅显示 TCP套接字（sockets）

-u, --udp
仅显示 UCP套接字（sockets）

-d, --dccp
仅显示 DCCP套接字（sockets）

-w, --raw
仅显示 RAW套接字（sockets）

-x, --unix
仅显示 Unix套接字（sockets）

-f, --family=FAMILY  显示 FAMILY类型的套接字（sockets），FAMILY可选，支持  unix, inet, inet6, link, netlink

-A, --query=QUERY, --socket=QUERY

      QUERY := {all|inet|tcp|udp|raw|unix|packet|netlink}[,QUERY]

-D, --diag=FILE     将原始TCP套接字（sockets）信息转储到文件

 -F, --filter=FILE   从文件中都去过滤器信息

       FILTER := [ state TCP-STATE ] [ EXPRESSION ]



4.使用实例：

实例1：显示TCP连接

命令：ss -t -a






实例2：显示 Sockets 摘要

命令：ss -s






实例3：列出所有打开的网络连接端口

命令：ss -l






实例4：查看进程使用的socket

命令：ss -pl






实例5：找出打开套接字/端口应用程序

命令：ss -lp|grep 3306






实例6：显示所有UDP Sockets

命令：ss -u -a






实例7：显示所有状态为established的SMTP连接

命令：ss -o state established '( dport = :smtp or sport = :smtp )' 






实例8：显示所有状态为Established的HTTP连接

命令：ss -o state established '( dport = :http or sport = :http )' 






实例9：列举出处于 FIN-WAIT-1状态的源端口为 80或者 443，目标网络为 193.233.7/24所有 tcp套接字

命令：ss -o state fin-wait-1 '( sport = :http or sport = :https )' dst 193.233.7/24






实例10：用TCP 状态过滤Sockets:

命令：

ss -4 state FILTER-NAME-HERE 

ss -6 state FILTER-NAME-HERE






说明：

FILTER-NAME-HERE 可以代表以下任何一个：

established

syn-sent

syn-recv

fin-wait-1

fin-wait-2

time-wait

closed

close-wait

last-ack

listen

closing

 

all : 所有以上状态

connected : 除了listen and closed的所有状态

synchronized :所有已连接的状态除了syn-sent

bucket : 显示状态为maintained as minisockets,如：time-wait和syn-recv.

big : 和bucket相反.






实例11：匹配远程地址和端口号

命令：

ss dst ADDRESS_PATTERN

ss dst 192.168.1.5

ss dst 192.168.119.113:http 

ss dst 192.168.119.113:smtp 

ss dst 192.168.119.113:443






实例12：匹配本地地址和端口号

命令：

ss src ADDRESS_PATTERN

ss src 192.168.119.103

ss src 192.168.119.103:http

ss src 192.168.119.103:80

ss src 192.168.119.103:smtp

ss src 192.168.119.103:25






实例13：将本地或者远程端口和一个数比较

命令：

ss dport OP PORT 

ss sport OP PORT

说明：

ss dport OP PORT 远程端口和一个数比较；ss sport OP PORT 本地端口和一个数比较。

OP 可以代表以下任意一个: 

&lt;= or le : 小于或等于端口号

&gt;= or ge : 大于或等于端口号

== or eq : 等于端口号

!= or ne : 不等于端口号

&lt; or gt : 小于端口号

&gt; or lt : 大于端口号






实例14：ss 和 netstat 效率对比

命令：

time netstat -at

time ss

说明：

用time 命令分别获取通过netstat和ss命令获取程序和概要占用资源所使用的时间。在服务器连接数比较多的时候，netstat的效率完全没法和ss比。


netstat命令用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况。netstat是在内核中访问网络及相关信息的程序，它能提供TCP连接，TCP和UDP监听，进程内存管理的相关报告。

如果你的计算机有时候接收到的数据报导致出错数据或故障，你不必感到奇怪，TCP/IP可以容许这些类型的错误，并能够自动重发数据报。但如果累计的出错情况数目占到所接收的IP数据报相当大的百分比，或者它的数目正迅速增加，那么你就应该使用netstat查一查为什么会出现这些情况了。



1．命令格式：

netstat [-acCeFghilMnNoprstuvVwx][-A&lt;网络类型&gt;][--ip]



2．命令功能：

netstat用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况。



3．命令参数：

-a或–all 显示所有连线中的Socket。

-A&lt;网络类型&gt;或–&lt;网络类型&gt; 列出该网络类型连线中的相关地址。

-c或–continuous 持续列出网络状态。

-C或–cache 显示路由器配置的快取信息。

-e或–extend 显示网络其他相关信息。

-F或–fib 显示FIB。

-g或–groups 显示多重广播功能群组组员名单。

-h或–help 在线帮助。

-i或–interfaces 显示网络界面信息表单。

-l或–listening 显示监控中的服务器的Socket。

-M或–masquerade 显示伪装的网络连线。

-n或–numeric 直接使用IP地址，而不通过域名服务器。

-N或–netlink或–symbolic 显示网络硬件外围设备的符号连接名称。

-o或–timers 显示计时器。

-p或–programs 显示正在使用Socket的程序识别码和程序名称。

-r或–route 显示Routing Table。

-s或–statistice 显示网络工作信息统计表。

-t或–tcp 显示TCP传输协议的连线状况。

-u或–udp 显示UDP传输协议的连线状况。

-v或–verbose 显示指令执行过程。

-V或–version 显示版本信息。

-w或–raw 显示RAW传输协议的连线状况。

-x或–unix 此参数的效果和指定”-A unix”参数相同。

–ip或–inet 此参数的效果和指定”-A inet”参数相同。



4．使用实例：

实例1：无参数使用

命令：netstat

输出：




[root@localhost ~]# netstat
Active Internet connections (w/o servers)
Proto Recv-Q Send-Q Local Address               Foreign Address             State      
tcp        0    268 192.168.120.204:ssh         10.2.0.68:62420             ESTABLISHED 
udp        0      0 192.168.120.204:4371        10.58.119.119:domain        ESTABLISHED 
Active UNIX domain sockets (w/o servers)
Proto RefCnt Flags       Type       State         I-Node Path
unix  2      [ ]         DGRAM                    1491   @/org/kernel/udev/udevd
unix  4      [ ]         DGRAM                    7337   /dev/log
unix  2      [ ]         DGRAM                    708823 
unix  2      [ ]         DGRAM                    7539   
unix  3      [ ]         STREAM     CONNECTED     7287   
unix  3      [ ]         STREAM     CONNECTED     7286   
[root@localhost ~]#



说明：

从整体上看，netstat的输出结果可以分为两个部分：

一个是Active Internet connections，称为有源TCP连接，其中"Recv-Q"和"Send-Q"指的是接收队列和发送队列。这些数字一般都应该是0。如果不是则表示软件包正在队列中堆积。这种情况只能在非常少的情况见到。

另一个是Active UNIX domain sockets，称为有源Unix域套接口(和网络套接字一样，但是只能用于本机通信，性能可以提高一倍)。

Proto显示连接使用的协议,RefCnt表示连接到本套接口上的进程号,Types显示套接口的类型,State显示套接口当前的状态,Path表示连接到套接口的其它进程使用的路径名。

套接口类型：

-t ：TCP

-u ：UDP

-raw ：RAW类型

--unix ：UNIX域类型

--ax25 ：AX25类型

--ipx ：ipx类型

--netrom ：netrom类型



状态说明：

LISTEN：侦听来自远方的TCP端口的连接请求

SYN-SENT：再发送连接请求后等待匹配的连接请求（如果有大量这样的状态包，检查是否中招了）

SYN-RECEIVED：再收到和发送一个连接请求后等待对方对连接请求的确认（如有大量此状态，估计被flood攻击了）

ESTABLISHED：代表一个打开的连接

FIN-WAIT-1：等待远程TCP连接中断请求，或先前的连接中断请求的确认

FIN-WAIT-2：从远程TCP等待连接中断请求

CLOSE-WAIT：等待从本地用户发来的连接中断请求

CLOSING：等待远程TCP对连接中断的确认

LAST-ACK：等待原来的发向远程TCP的连接中断请求的确认（不是什么好东西，此项出现，检查是否被攻击）

TIME-WAIT：等待足够的时间以确保远程TCP接收到连接中断请求的确认

CLOSED：没有任何连接状态



 

  实例2：列出所有端口

命令：netstat -a

说明：显示一个所有的有效连接信息列表，包括已建立的连接（ESTABLISHED），也包括监听连接请（LISTENING）的那些连接。



 

  实例3：显示当前UDP连接状况

命令：netstat -nu



 

  实例4：显示UDP端口号的使用情况

命令：netstat -apu



 

  实例5：显示网卡列表

命令：netstat -i




  实例6：显示组播组的关系

命令：netstat -g




  实例7：显示网络统计信息

命令：netstat -s



说明：

按照各个协议分别显示其统计数据。如果我们的应用程序（如Web浏览器）运行速度比较慢，或者不能显示Web页之类的数据，那么我们就可以用本选项来查看一下所显示的信息。我们需要仔细查看统计数据的各行，找到出错的关键字，进而确定问题所在。

 

   实例8：显示监听的套接口

命令：netstat -l




  实例9：显示所有已建立的有效连接

命令：netstat -n




  实例10：显示关于以太网的统计数据

命令：netstat -e

说明：

用于显示关于以太网的统计数据。它列出的项目包括传送的数据报的总字节数、错误数、删除数、数据报的数量和广播的数量。这些统计数据既有发送的数据报数量，也有接收的数据报数量。这个选项可以用来统计一些基本的网络流量）



 

  实例11：显示关于路由表的信息

命令：netstat -r




  实例12：列出所有 tcp 端口

命令：netstat -at




  实例13：统计机器中网络连接各个状态个数

命令：netstat -a | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'




  实例14：把状态全都取出来后使用uniq -c统计后再进行排序

命令：netstat -nat |awk '{print $6}'|sort|uniq -c



 

  实例15：查看连接某服务端口最多的的IP地址

命令：

netstat -nat | grep "192.168.120.20:16067" |awk '{print $5}'|awk -F: '{print $4}'|sort|uniq -c|sort -nr|head -20




  实例16：找出程序运行的端口

命令：netstat -ap | grep ssh



 

  实例17：在 netstat 输出中显示 PID 和进程名称

命令：netstat -pt

说明：

netstat -p 可以与其它开关一起使用，就可以添加 “PID/进程名称” 到 netstat 输出中，这样 debugging 的时候可以很方便的发现特定端口运行的程序。



 

  实例18：找出运行在指定端口的进程

命令：netstat -anpt | grep ':16064'

说明：运行在端口16064的进程id为24596，再通过ps命令就可以找到具体的应用程序了。


通过traceroute我们可以知道信息从你的计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地(destination)走的路径可能会不一样，但基本上来说大部分时候所走的路由是相同的。linux系统中，我们称之为traceroute,在MS Windows中为tracert。 traceroute通过发送小的数据包到目的设备直到其返回，来测量其需要多长时间。一条路径上的每个设备traceroute要测3次。输出结果中包括每次测试的时间(ms)和设备的名称（如有的话）及其IP地址。

在大多数情况下，我们会在linux主机系统下，直接执行命令行：

traceroute hostname

而在Windows系统下是执行tracert的命令：

tracert hostname



1.命令格式：

traceroute[参数][主机]



2.命令功能：

traceroute指令让你追踪网络数据包的路由途径，预设数据包大小是40Bytes，用户可另行设置。

具体参数格式：traceroute [-dFlnrvx][-f&lt;存活数值&gt;][-g&lt;网关&gt;...][-i&lt;网络界面&gt;][-m&lt;存活数值&gt;][-p&lt;通信端口&gt;][-s&lt;来源地址&gt;][-t&lt;服务类型&gt;][-w&lt;超时秒数&gt;][主机名称或IP地址][数据包大小]


3.命令参数：

-d 使用Socket层级的排错功能。

-f 设置第一个检测数据包的存活数值TTL的大小。

-F 设置勿离断位。

-g 设置来源路由网关，最多可设置8个。

-i 使用指定的网络界面送出数据包。

-I 使用ICMP回应取代UDP资料信息。

-m 设置检测数据包的最大存活数值TTL的大小。

-n 直接使用IP地址而非主机名称。

-p 设置UDP传输协议的通信端口。

-r 忽略普通的Routing Table，直接将数据包送到远端主机上。

-s 设置本地主机送出数据包的IP地址。

-t 设置检测数据包的TOS数值。

-v 详细显示指令的执行过程。

-w 设置等待远端主机回报的时间。

-x 开启或关闭数据包的正确性检验。



4.使用实例：

实例1：traceroute 用法简单、最常用的用法

命令：traceroute www.baidu.com 

输出：




[root@localhost ~]# traceroute www.baidu.com
traceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets
 1  192.168.74.2 (192.168.74.2)  2.606 ms  2.771 ms  2.950 ms
 2  211.151.56.57 (211.151.56.57)  0.596 ms  0.598 ms  0.591 ms
 3  211.151.227.206 (211.151.227.206)  0.546 ms  0.544 ms  0.538 ms
 4  210.77.139.145 (210.77.139.145)  0.710 ms  0.748 ms  0.801 ms
 5  202.106.42.101 (202.106.42.101)  6.759 ms  6.945 ms  7.107 ms
 6  61.148.154.97 (61.148.154.97)  718.908 ms * bt-228-025.bta.net.cn (202.106.228.25)  5.177 ms
 7  124.65.58.213 (124.65.58.213)  4.343 ms  4.336 ms  4.367 ms
 8  202.106.35.190 (202.106.35.190)  1.795 ms 61.148.156.138 (61.148.156.138)  1.899 ms  1.951 ms
 9  * * *
30  * * *
[root@localhost ~]# 



说明：

记录按序列号从1开始，每个纪录就是一跳 ，每跳表示一个网关，我们看到每行有三个时间，单位是 ms，其实就是-q的默认参数。探测数据包向每个网关发送三个数据包后，网关响应后返回的时间；如果您用 traceroute -q 4 www.58.com ，表示向每个网关发送4个数据包。

有时我们traceroute 一台主机时，会看到有一些行是以星号表示的。出现这样的情况，可能是防火墙封掉了ICMP的返回信息，所以我们得不到什么相关的数据包返回数据。

有时我们在某一网关处延时比较长，有可能是某台网关比较阻塞，也可能是物理设备本身的原因。当然如果某台DNS出现问题时，不能解析主机名、域名时，也会 有延时长的现象；您可以加-n 参数来避免DNS解析，以IP格式输出数据。

如果在局域网中的不同网段之间，我们可以通过traceroute 来排查问题所在，是主机的问题还是网关的问题。如果我们通过远程来访问某台服务器遇到问题时，我们用到traceroute 追踪数据包所经过的网关，提交IDC服务商，也有助于解决问题；但目前看来在国内解决这样的问题是比较困难的，就是我们发现问题所在，IDC服务商也不可能帮助我们解决。



 

实例2：跳数设置

命令：traceroute -m 10 www.baidu.com




实例3：显示IP地址，不查主机名

命令：traceroute -n www.baidu.com




实例4：探测包使用的基本UDP端口设置6888

命令：traceroute -p 6888 www.baidu.com




实例5：把探测包的个数设置为值4

命令：traceroute -q 4 www.baidu.com




实例6：绕过正常的路由表，直接发送到网络相连的主机

命令：traceroute -r www.baidu.com




实例7：把对外发探测包的等待响应时间设置为3秒

命令：traceroute -w 3 www.baidu.com






Traceroute的工作原理：

Traceroute最简单的基本用法是：traceroute hostname

Traceroute程序的设计是利用ICMP及IP header的TTL（Time To Live）栏位（field）。首先，traceroute送出一个TTL是1的IP datagram（其实，每次送出的为3个40字节的包，包括源地址，目的地址和包发出的时间标签）到目的地，当路径上的第一个路由器（router）收到这个datagram时，它将TTL减1。此时，TTL变为0了，所以该路由器会将此datagram丢掉，并送回一个「ICMP time exceeded」消息（包括发IP包的源地址，IP包的所有内容及路由器的IP地址），traceroute 收到这个消息后，便知道这个路由器存在于这个路径上，接着traceroute 再送出另一个TTL是2 的datagram，发现第2 个路由器...... traceroute 每次将送出的datagram的TTL 加1来发现另一个路由器，这个重复的动作一直持续到某个datagram 抵达目的地。当datagram到达目的地后，该主机并不会送回ICMP time exceeded消息，因为它已是目的地了，那么traceroute如何得知目的地到达了呢？

Traceroute在送出UDP datagrams到目的地时，它所选择送达的port number 是一个一般应用程序都不会用的号码（30000 以上），所以当此UDP datagram 到达目的地后该主机会送回一个「ICMP port unreachable」的消息，而当traceroute 收到这个消息时，便知道目的地已经到达了。所以traceroute 在Server端也是没有所谓的Daemon 程式。

Traceroute提取发 ICMP TTL到期消息设备的IP地址并作域名解析。每次 ，Traceroute都打印出一系列数据,包括所经过的路由设备的域名及 IP地址,三个包每次来回所花时间。

 



windows之tracert:

格式：

tracert [-d] [-h maximum_hops] [-j host-list] [-w timeout] target_name

参数说明：

tracert [-d] [-h maximum_hops] [-j computer-list] [-w timeout] target_name

该诊断实用程序通过向目的地发送具有不同生存时间 (TL) 的 Internet 控制信息协议 (CMP) 回应报文，以确定至目的地的路由。路径上的每个路由器都要在转发该 ICMP 回应报文之前将其 TTL 值至少减 1，因此 TTL 是有效的跳转计数。当报文的 TTL 值减少到 0 时，路由器向源系统发回 ICMP 超时信息。通过发送 TTL 为 1 的第一个回应报文并且在随后的发送中每次将 TTL 值加 1，直到目标响应或达到最大 TTL 值，Tracert 可以确定路由。通过检查中间路由器发发回的 ICMP 超时 (ime Exceeded) 信息，可以确定路由器。注意，有些路由器“安静”地丢弃生存时间 (TLS) 过期的报文并且对 tracert 无效。

参数：

-d 指定不对计算机名解析地址。

-h maximum_hops 指定查找目标的跳转的最大数目。

-jcomputer-list 指定在 computer-list 中松散源路由。

-w timeout 等待由 timeout 对每个应答指定的毫秒数。

target_name 目标计算机的名称。


Linux系统的ping命令是常用的网络命令，它通常用来测试与目标主机的连通性，我们经常会说“ping一下某机器，看是不是开着”、不能打开网页时会说“你先ping网关地址192.168.1.1试试”。它通过发送ICMP ECHO_REQUEST数据包到网络主机（send ICMP ECHO_REQUEST to network hosts），并显示响应情况，这样我们就可以根据它输出的信息来确定目标主机是否可访问（但这不是绝对的）。有些服务器为了防止通过ping探测到，通过防火墙设置了禁止ping或者在内核参数中禁止ping，这样就不能通过ping确定该主机是否还处于开启状态。

linux下的ping和windows下的ping稍有区别,linux下ping不会自动终止,需要按ctrl+c终止或者用参数-c指定要求完成的回应次数。

1.命令格式：

ping [参数] [主机名或IP地址]

2.命令功能：

ping命令用于：确定网络和各外部主机的状态；跟踪和隔离硬件和软件问题；测试、评估和管理网络。如果主机正在运行并连在网上，它就对回送信号进行响应。每个回送信号请求包含一个网际协议（IP）和 ICMP 头，后面紧跟一个 tim 结构，以及来填写这个信息包的足够的字节。缺省情况是连续发送回送信号请求直到接收到中断信号（Ctrl-C）。

ping 命令每秒发送一个数据报并且为每个接收到的响应打印一行输出。ping 命令计算信号往返时间和(信息)包丢失情况的统计信息，并且在完成之后显示一个简要总结。ping 命令在程序超时或当接收到 SIGINT 信号时结束。Host 参数或者是一个有效的主机名或者是因特网地址。

3.命令参数：

-d 使用Socket的SO_DEBUG功能。

-f  极限检测。大量且快速地送网络封包给一台机器，看它的回应。

-n 只输出数值。

-q 不显示任何传送封包的信息，只显示最后的结果。

-r 忽略普通的Routing Table，直接将数据包送到远端主机上。通常是查看本机的网络接口是否有问题。

-R 记录路由过程。

-v 详细显示指令的执行过程。

&lt;p&gt;-c 数目：在发送指定数目的包后停止。

-i 秒数：设定间隔几秒送一个网络封包给一台机器，预设值是一秒送一次。

-I 网络界面：使用指定的网络界面送出数据包。

-l 前置载入：设置在送出要求信息之前，先行发出的数据包。

-p 范本样式：设置填满数据包的范本样式。

-s 字节数：指定发送的数据字节数，预设值是56，加上8字节的ICMP头，一共是64ICMP数据字节。

-t 存活数值：设置存活数值TTL的大小。



4.使用实例：

实例1：ping的通的情况

命令：ping 192.168.1.156






实例2：ping不通的情况

命令：ping 192.168.1.156






实例3：ping网关

命令：ping -b 192.168.1.156






实例4：ping指定次数

命令：ping -c 10  192.168.1.156



实例5：时间间隔和次数限制的ping

命令：ping -c 10 -i 0.5 192.168.1.156






实例6：通过域名ping公网上的站点

命令：ping -c 5 www.58.com






实例7：多参数使用

命令：ping -i 3 -s 1024 -t 255 192.168.1.156


Linux系统的route命令用于显示和操作IP路由表（show/manipulate the IP routing table）。要实现两个不同的子网之间的通信，需要一台连接两个网络的路由器，或者同时位于两个网络的网关来实现。在Linux系统中，设置路由通常是为了解决以下问题：该Linux系统在一个局域网中，局域网中有一个网关，能够让机器访问Internet，那么就需要将这台机器的IP地址设置为Linux机器的默认路由。要注意的是，直接在命令行下执行route命令来添加路由，不会永久保存，当网卡重启或者机器重启之后，该路由就失效了；可以在/etc/rc.local中添加route命令来保证该路由设置永久有效。

1．命令格式：

route [-f] [-p] [Command [Destination] [mask Netmask] [Gateway] [metric Metric]] [if Interface]] 

2．命令功能：

Route命令是用于操作基于内核ip路由表，它的主要作用是创建一个静态路由让指定一个主机或者一个网络通过一个网络接口，如eth0。当使用"add"或者"del"参数时，路由表被修改，如果没有参数，则显示路由表当前的内容。

3．命令参数：

-c 显示更多信息

-n 不解析名字

-v 显示详细的处理信息

-F 显示发送信息

-C 显示路由缓存

-f 清除所有网关入口的路由表。 

-p 与 add 命令一起使用时使路由具有永久性。

 

add:添加一条新路由。

del:删除一条路由。

-net:目标地址是一个网络。

-host:目标地址是一个主机。

netmask:当添加一个网络路由时，需要使用网络掩码。

gw:路由数据包通过网关。注意，你指定的网关必须能够达到。

metric：设置路由跳数。



Command 指定您想运行的命令 (Add/Change/Delete/Print)。 

Destination 指定该路由的网络目标。 

mask Netmask 指定与网络目标相关的网络掩码（也被称作子网掩码）。 

Gateway 指定网络目标定义的地址集和子网掩码可以到达的前进或下一跃点 IP 地址。 

metric Metric 为路由指定一个整数成本值标（从 1 至 9999），当在路由表(与转发的数据包目标地址最匹配)的多个路由中进行选择时可以使用。 

if Interface 为可以访问目标的接口指定接口索引。若要获得一个接口列表和它们相应的接口索引，使用 route print 命令的显示功能。可以使用十进制或十六进制值进行接口索引。



4．使用实例：

实例1：显示当前路由

命令：

route

route -n

输出：




[root@localhost ~]# route
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
192.168.120.0   *               255.255.255.0   U     0      0        0 eth0
e192.168.0.0     192.168.120.1   255.255.0.0     UG    0      0        0 eth0
10.0.0.0        192.168.120.1   255.0.0.0       UG    0      0        0 eth0
default         192.168.120.240 0.0.0.0         UG    0      0        0 eth0
[root@localhost ~]# route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
192.168.120.0   0.0.0.0         255.255.255.0   U     0      0        0 eth0
192.168.0.0     192.168.120.1   255.255.0.0     UG    0      0        0 eth0
10.0.0.0        192.168.120.1   255.0.0.0       UG    0      0        0 eth0
0.0.0.0         192.168.120.240 0.0.0.0         UG    0      0        0 eth0



说明：

第一行表示主机所在网络的地址为192.168.120.0，若数据传送目标是在本局域网内通信，则可直接通过eth0转发数据包;

第四行表示数据传送目的是访问Internet，则由接口eth0，将数据包发送到网关192.168.120.240

其中Flags为路由标志，标记当前网络节点的状态。

Flags标志说明：

U Up表示此路由当前为启动状态

H Host，表示此网关为一主机

G Gateway，表示此网关为一路由器

R Reinstate Route，使用动态路由重新初始化的路由

D Dynamically,此路由是动态性地写入

M Modified，此路由是由路由守护程序或导向器动态修改

! 表示此路由当前为关闭状态



备注：

route -n (-n 表示不解析名字,列出速度会比route 快)






实例2：添加网关/设置网关

命令：route add -net 224.0.0.0 netmask 240.0.0.0 dev eth0

说明：增加一条 到达244.0.0.0的路由






实例3：屏蔽一条路由

命令：route add -net 224.0.0.0 netmask 240.0.0.0 reject

说明：增加一条屏蔽的路由，目的地址为 224.x.x.x 将被拒绝






实例4：删除路由记录

命令：

route del -net 224.0.0.0 netmask 240.0.0.0

route del -net 224.0.0.0 netmask 240.0.0.0 reject






实例5：删除和添加设置默认网关

命令：

route del default gw 192.168.120.240

route add default gw 192.168.120.240


许多windows非常熟悉ipconfig命令行工具，它被用来获取网络接口配置信息并对此进行修改。Linux系统拥有一个类似的工具，也就是ifconfig(interfaces config)。通常需要以root身份登录或使用sudo以便在Linux机器上使用ifconfig工具。依赖于ifconfig命令中使用一些选项属性，ifconfig工具不仅可以被用来简单地获取网络接口配置信息，还可以修改这些配置。

1．命令格式：

ifconfig [网络设备] [参数]

2．命令功能：

ifconfig 命令用来查看和配置网络设备。当网络环境发生改变时可通过此命令对网络进行相应的配置。

3．命令参数：

up 启动指定网络设备/网卡。

down 关闭指定网络设备/网卡。该参数可以有效地阻止通过指定接口的IP信息流，如果想永久地关闭一个接口，我们还需要从核心路由表中将该接口的路由信息全部删除。

arp 设置指定网卡是否支持ARP协议。

-promisc 设置是否支持网卡的promiscuous模式，如果选择此参数，网卡将接收网络中发给它所有的数据包

-allmulti 设置是否支持多播模式，如果选择此参数，网卡将接收网络中所有的多播数据包

-a 显示全部接口信息

-s 显示摘要信息（类似于 netstat -i）

add 给指定网卡配置IPv6地址

del 删除指定网卡的IPv6地址

&lt;硬件地址&gt; 配置网卡最大的传输单元

mtu&lt;字节数&gt; 设置网卡的最大传输单元 (bytes)

netmask&lt;子网掩码&gt; 设置网卡的子网掩码。掩码可以是有前缀0x的32位十六进制数，也可以是用点分开的4个十进制数。如果不打算将网络分成子网，可以不管这一选项；如果要使用子网，那么请记住，网络中每一个系统必须有相同子网掩码。

tunel 建立隧道

dstaddr 设定一个远端地址，建立点对点通信

-broadcast&lt;地址&gt; 为指定网卡设置广播协议

-pointtopoint&lt;地址&gt; 为网卡设置点对点通讯协议

multicast 为网卡设置组播标志

address 为网卡设置IPv4地址

txqueuelen&lt;长度&gt; 为网卡设置传输列队的长度

4．使用实例：

实例1：显示网络设备信息（激活状态的）

命令：ifconfig

输出：




[root@localhost ~]# ifconfig
eth0      Link encap:Ethernet  HWaddr 00:50:56:BF:26:20  
          inet addr:192.168.120.204  Bcast:192.168.120.255  Mask:255.255.255.0
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:8700857 errors:0 dropped:0 overruns:0 frame:0
          TX packets:31533 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:596390239 (568.7 MiB)  TX bytes:2886956 (2.7 MiB)

lo        Link encap:Local Loopback  
          inet addr:127.0.0.1  Mask:255.0.0.0
          UP LOOPBACK RUNNING  MTU:16436  Metric:1
          RX packets:68 errors:0 dropped:0 overruns:0 frame:0
          TX packets:68 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0 
          RX bytes:2856 (2.7 KiB)  TX bytes:2856 (2.7 KiB)



说明：

eth0 表示第一块网卡， 其中 HWaddr 表示网卡的物理地址，可以看到目前这个网卡的物理地址(MAC地址）是 00:50:56:BF:26:20

inet addr 用来表示网卡的IP地址，此网卡的 IP地址是 192.168.120.204，广播地址， Bcast:192.168.120.255，掩码地址Mask:255.255.255.0 

lo 是表示主机的回坏地址，这个一般是用来测试一个网络程序，但又不想让局域网或外网的用户能够查看，只能在此台主机上运行和查看所用的网络接口。比如把 HTTPD服务器的指定到回坏地址，在浏览器输入 127.0.0.1 就能看到你所架WEB网站了。但只是您能看得到，局域网的其它主机或用户无从知道。

第一行：连接类型：Ethernet（以太网）HWaddr（硬件mac地址）

第二行：网卡的IP地址、子网、掩码

第三行：UP（代表网卡开启状态）RUNNING（代表网卡的网线被接上）MULTICAST（支持组播）MTU:1500（最大传输单元）：1500字节

第四、五行：接收、发送数据包情况统计

第七行：接收、发送数据字节数统计信息。




实例2：启动关闭指定网卡

命令：

ifconfig eth0 up

ifconfig eth0 down

说明：

ifconfig eth0 up 为启动网卡eth0 ；ifconfig eth0 down 为关闭网卡eth0。ssh登陆linux服务器操作要小心，关闭了就不能开启了，除非你有多网卡。








实例3：为网卡配置和删除IPv6地址

命令：

ifconfig eth0 add 33ffe:3240:800:1005::2/64

ifconfig eth0 del 33ffe:3240:800:1005::2/64

说明：

ifconfig eth0 add 33ffe:3240:800:1005::2/64 为网卡eth0配置IPv6地址；

ifconfig eth0 add 33ffe:3240:800:1005::2/64 为网卡eth0删除IPv6地址；

练习的时候，ssh登陆linux服务器操作要小心，关闭了就不能开启了，除非你有多网卡。






实例4：用ifconfig修改MAC地址

命令：ifconfig eth0 hw ether 00:AA:BB:CC:DD:EE






实例5：配置IP地址



输出：



[root@localhost ~]# ifconfig eth0 192.168.120.56 
[root@localhost ~]# ifconfig eth0 192.168.120.56 netmask 255.255.255.0 
[root@localhost ~]# ifconfig eth0 192.168.120.56 netmask 255.255.255.0 broadcast 192.168.120.255


说明：

ifconfig eth0 192.168.120.56 

给eth0网卡配置IP地：192.168.120.56

 ifconfig eth0 192.168.120.56 netmask 255.255.255.0 

给eth0网卡配置IP地址：192.168.120.56 ，并加上子掩码：255.255.255.0

ifconfig eth0 192.168.120.56 netmask 255.255.255.0 broadcast 192.168.120.255

/给eth0网卡配置IP地址：192.168.120.56，加上子掩码：255.255.255.0，加上个广播地址： 192.168.120.255






实例6：启用和关闭ARP协议

命令：

ifconfig eth0 arp

ifconfig eth0 -arp

输出：



[root@localhost ~]# ifconfig eth0 arp 
[root@localhost ~]# ifconfig eth0 -arp


说明：

ifconfig eth0 arp 开启网卡eth0 的arp协议；

ifconfig eth0 -arp 关闭网卡eth0 的arp协议；

 



实例7：设置最大传输单元

命令：ifconfig eth0 mtu 1500

说明：设置能通过的最大数据包大小为 1500 bytes

 



备注：用ifconfig命令配置的网卡信息，在网卡重启后机器重启后，配置就不存在。要想将上述的配置信息永远的存的电脑里，那就要修改网卡的配置文件了。


在windows系统中，windows提供了计划任务这一功能，在控制面板 -&gt; 性能与维护 -&gt; 任务计划， 它的功能就是安排自动运行的任务。 通过'添加任务计划'的一步步引导，则可建立一个定时执行的任务。

在linux系统中你可能已经发现了为什么系统常常会自动的进行一些任务？这些任务到底是谁在支配他们工作的？在linux系统如果你想要让自己设计的备份程序可以自动在某个时间点开始在系统底下运行，而不需要手动来启动它，又该如何处置呢？ 这些例行的工作可能又分为一次性定时工作与循环定时工作，在系统内又是哪些服务在负责？ 还有，如果你想要每年在老婆的生日前一天就发出一封信件提醒自己不要忘记，linux系统下该怎么做呢？ 

今天我们主要学习一下一次性定时计划任务的at命令的用法！

1．命令格式：

at[参数][时间]

2．命令功能：

在一个指定的时间执行一个指定任务，只能执行一次，且需要开启atd进程（

ps -ef | grep atd查看， 开启用/etc/init.d/atd start or restart； 开机即启动则需要运行chkconfig --level 2345 atd on）。

3．命令参数：

-m 当指定的任务被完成之后，将给用户发送邮件，即使没有标准输出

-I atq的别名

-d atrm的别名

-v 显示任务将被执行的时间

-c 打印任务的内容到标准输出

-V 显示版本信息

-q&lt;列队&gt; 使用指定的列队

-f&lt;文件&gt; 从指定文件读入任务而不是从标准输入读入

-t&lt;时间参数&gt; 以时间参数的形式提交要运行的任务 



at允许使用一套相当复杂的指定时间的方法。他能够接受在当天的hh:mm（小时:分钟）式的时间指定。假如该时间已过去，那么就放在第二天执行。当然也能够使用midnight（深夜），noon（中午），teatime（饮茶时间，一般是下午4点）等比较模糊的 词语来指定时间。用户还能够采用12小时计时制，即在时间后面加上AM（上午）或PM（下午）来说明是上午还是下午。 也能够指定命令执行的具体日期，指定格式为month day（月 日）或mm/dd/yy（月/日/年）或dd.mm.yy（日.月.年）。指定的日期必须跟在指定时间的后面。 上面介绍的都是绝对计时法，其实还能够使用相对计时法，这对于安排不久就要执行的命令是很有好处的。指定格式为：now + count time-units ，now就是当前时间，time-units是时间单位，这里能够是minutes（分钟）、hours（小时）、days（天）、weeks（星期）。count是时间的数量，究竟是几天，还是几小时，等等。 更有一种计时方法就是直接使用today（今天）、tomorrow（明天）来指定完成命令的时间。

TIME：时间格式，这里可以定义出什么时候要进行 at 这项任务的时间，格式有：

HH:MM

ex&gt; 04:00

在今日的 HH:MM 时刻进行，若该时刻已超过，则明天的 HH:MM 进行此任务。

HH:MM YYYY-MM-DD

ex&gt; 04:00 2009-03-17

强制规定在某年某月的某一天的特殊时刻进行该项任务

HH:MM[am|pm] [Month] [Date]

ex&gt; 04pm March 17

也是一样，强制在某年某月某日的某时刻进行该项任务

HH:MM[am|pm] + number [minutes|hours|days|weeks]

ex&gt; now + 5 minutes

ex&gt; 04pm + 3 days

就是说，在某个时间点再加几个时间后才进行该项任务。



4．使用实例：

实例1：三天后的下午 5 点锺执行 /bin/ls

命令：at 5pm+3 days






实例2：明天17点钟，输出时间到指定文件内

命令：at 17:20 tomorrow






实例3：计划任务设定后，在没有执行之前我们可以用atq命令来查看系统没有执行工作任务

命令：atq






实例4：删除已经设置的任务

命令：atrm 7






实例5：显示已经设置的任务内容

命令：at -c 8




5．atd 的启动与 at 运行的方式：

5.1 atd 的启动

要使用一次性计划任务时，我们的 Linux 系统上面必须要有负责这个计划任务的服务，那就是 atd 服务。 不过并非所有的 Linux distributions 都默认会把他打开的，所以，某些时刻我们需要手动将atd 服务激活才行。 激活的方法很简单，就是这样：

命令：

/etc/init.d/atd start 

/etc/init.d/atd restart 

输出：

[root@localhost /]# /etc/init.d/atd start

[root@localhost /]# /etc/init.d/atd 

用法：/etc/init.d/atd {start|stop|restart|condrestart|status}

[root@localhost /]# /etc/init.d/atd stop

停止 atd：[确定]

[root@localhost /]# ps -ef|grep atd

root     25062 24951  0 14:53 pts/0    00:00:00 grep atd

[root@localhost /]# /etc/init.d/atd start

[确定]td：[确定]

[root@localhost /]# ps -ef|grep atd

root     25068     1  0 14:53 ?        00:00:00 /usr/sbin/atd

root     25071 24951  0 14:53 pts/0    00:00:00 grep atd

[root@localhost /]# /etc/init.d/atd restart

停止 atd：[确定]

[确定]td：[确定]

[root@localhost /]#

说明：

/etc/init.d/atd start 没有启动的时候，直接启动atd服务

/etc/init.d/atd restart 服务已经启动后，重启 atd 服务



备注：配置一下启动时就启动这个服务，免得每次重新启动都得再来一次

命令：

chkconfig atd on

输出：

[root@localhost /]# chkconfig atd on

[root@localhost /]#



5.2 at 的运行方式

既然是计划任务，那么应该会有任务执行的方式，并且将这些任务排进行程表中。那么产生计划任务的方式是怎么进行的? 事实上，我们使用 at 这个命令来产生所要运行的计划任务，并将这个计划任务以文字档的方式写入 /var/spool/at/ 目录内，该工作便能等待 atd 这个服务的取用与运行了。就这么简单。

不过，并不是所有的人都可以进行 at 计划任务。为什么? 因为系统安全的原因。很多主机被所谓的攻击破解后，最常发现的就是他们的系统当中多了很多的黑客程序， 这些程序非常可能运用一些计划任务来运行或搜集你的系统运行信息,并定时的发送给黑客。 所以，除非是你认可的帐号，否则先不要让他们使用 at 命令。那怎么达到使用 at 的可控呢?

我们可以利用 /etc/at.allow 与 /etc/at.deny 这两个文件来进行 at 的使用限制。加上这两个文件后， at 的工作情况是这样的：

先找寻 /etc/at.allow 这个文件，写在这个文件中的使用者才能使用 at ，没有在这个文件中的使用者则不能使用 at (即使没有写在 at.deny 当中);

如果 /etc/at.allow 不存在，就寻找 /etc/at.deny 这个文件，若写在这个 at.deny 的使用者则不能使用 at ，而没有在这个 at.deny 文件中的使用者，就可以使用 at 命令了。

如果两个文件都不存在，那么只有 root 可以使用 at 这个命令。

透过这个说明，我们知道 /etc/at.allow 是管理较为严格的方式，而 /etc/at.deny 则较为松散 (因为帐号没有在该文件中，就能够运行 at 了)。在一般的 distributions 当中，由于假设系统上的所有用户都是可信任的， 因此系统通常会保留一个空的 /etc/at.deny 文件，意思是允许所有人使用 at 命令的意思 (您可以自行检查一下该文件)。 不过，万一你不希望有某些使用者使用 at 的话，将那个使用者的帐号写入 /etc/at.deny 即可！ 一个帐号写一行。


lsof（list open files）是一个列出当前系统打开文件的工具。在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件。所以如传输控制协议 (TCP) 和用户数据报协议 (UDP) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，无论这个文件的本质如何，该文件描述符为应用程序与基础操作系统之间的交互提供了通用接口。因为应用程序打开文件的描述符列表提供了大量关于这个应用程序本身的信息，因此通过lsof工具能够查看这个列表对系统监测以及排错将是很有帮助的。

1．命令格式：

lsof [参数][文件]

2．命令功能：

用于查看你进程开打的文件，打开文件的进程，进程打开的端口(TCP、UDP)。找回/恢复删除的文件。是十分方便的系统监视工具，因为 lsof 需要访问核心内存和各种文件，所以需要root用户执行。

lsof打开的文件可以是：

1.普通文件

2.目录

3.网络文件系统的文件

4.字符或设备文件

5.(函数)共享库

6.管道，命名管道

7.符号链接

8.网络文件（例如：NFS file、网络socket，unix域名socket）

9.还有其它类型的文件，等等

3．命令参数：

-a 列出打开文件存在的进程

-c&lt;进程名&gt; 列出指定进程所打开的文件

-g  列出GID号进程详情

-d&lt;文件号&gt; 列出占用该文件号的进程

+d&lt;目录&gt;  列出目录下被打开的文件

+D&lt;目录&gt;  递归列出目录下被打开的文件

-n&lt;目录&gt;  列出使用NFS的文件

-i&lt;条件&gt;  列出符合条件的进程。（4、6、协议、:端口、 @ip ）

-p&lt;进程号&gt; 列出指定进程号所打开的文件

-u  列出UID号进程详情

-h 显示帮助信息

-v 显示版本信息

4．使用实例：

实例1：无任何参数

命令：

lsof

输出：

[root@localhost ~]# lsof


COMMAND     PID USER   FD      TYPE             DEVICE     SIZE       NODE NAME
init          1 root  cwd       DIR                8,2     4096          2 /
init          1 root  rtd       DIR                8,2     4096          2 /
init          1 root  txt       REG                8,2    43496    6121706 /sbin/init
init          1 root  mem       REG                8,2   143600    7823908 /lib64/ld-2.5.so
init          1 root  mem       REG                8,2  1722304    7823915 /lib64/libc-2.5.so
init          1 root  mem       REG                8,2    23360    7823919 /lib64/libdl-2.5.so
init          1 root  mem       REG                8,2    95464    7824116 /lib64/libselinux.so.1
init          1 root  mem       REG                8,2   247496    7823947 /lib64/libsepol.so.1
init          1 root   10u     FIFO               0,17                1233 /dev/initctl
migration     2 root  cwd       DIR                8,2     4096          2 /
migration     2 root  rtd       DIR                8,2     4096          2 /
migration     2 root  txt   unknown                                        /proc/2/exe
ksoftirqd     3 root  cwd       DIR                8,2     4096          2 /
ksoftirqd     3 root  rtd       DIR                8,2     4096          2 /
ksoftirqd     3 root  txt   unknown                                        /proc/3/exe
migration     4 root  cwd       DIR                8,2     4096          2 /
migration     4 root  rtd       DIR                8,2     4096          2 /
migration     4 root  txt   unknown                                        /proc/4/exe
ksoftirqd     5 root  cwd       DIR                8,2     4096          2 /
ksoftirqd     5 root  rtd       DIR                8,2     4096          2 /
ksoftirqd     5 root  txt   unknown                                        /proc/5/exe
events/0      6 root  cwd       DIR                8,2     4096          2 /
events/0      6 root  rtd       DIR                8,2     4096          2 /
events/0      6 root  txt   unknown                                        /proc/6/exe
events/1      7 root  cwd       DIR                8,2     4096          2 /



说明：

lsof输出各列信息的意义如下：

COMMAND：进程的名称

PID：进程标识符

PPID：父进程标识符（需要指定-R参数）

USER：进程所有者

PGID：进程所属组

FD：文件描述符，应用程序通过文件描述符识别该文件。如cwd、txt等

（1）cwd：表示current work dirctory，即：应用程序的当前工作目录，这是该应用程序启动的目录，除非它本身对这个目录进行更改

（2）txt ：该类型的文件是程序代码，如应用程序二进制文件本身或共享库，如上列表中显示的 /sbin/init 程序

（3）lnn：library references (AIX);

（4）er：FD information error (see NAME column);

（5）jld：jail directory (FreeBSD);

（6）ltx：shared library text (code and data);

（7）mxx ：hex memory-mapped type number xx.

（8）m86：DOS Merge mapped file;

（9）mem：memory-mapped file;

（10）mmap：memory-mapped device;

（11）pd：parent directory;

（12）rtd：root directory;

（13）tr：kernel trace file (OpenBSD);

（14）v86  VP/ix mapped file;

（15）0：表示标准输出

（16）1：表示标准输入

（17）2：表示标准错误

一般在标准输出、标准错误、标准输入后还跟着文件状态模式：r、w、u等

（1）u：表示该文件被打开并处于读取/写入模式

（2）r：表示该文件被打开并处于只读模式

（3）w：表示该文件被打开并处于

（4）空格：表示该文件的状态模式为unknow，且没有锁定

（5）-：表示该文件的状态模式为unknow，且被锁定

同时在文件状态模式后面，还跟着相关的锁

（1）N：for a Solaris NFS lock of unknown type;

（2）r：for read lock on part of the file;

（3）R：for a read lock on the entire file;

（4）w：for a write lock on part of the file;（文件的部分写锁）

（5）W：for a write lock on the entire file;（整个文件的写锁）

（6）u：for a read and write lock of any length;

（7）U：for a lock of unknown type;

（8）x：for an SCO OpenServer Xenix lock on part      of the file;

（9）X：for an SCO OpenServer Xenix lock on the      entire file;

（10）space：if there is no lock.

TYPE：文件类型，如DIR、REG等，常见的文件类型

（1）DIR：表示目录

（2）CHR：表示字符类型

（3）BLK：块设备类型

（4）UNIX： UNIX 域套接字

（5）FIFO：先进先出 (FIFO) 队列

（6）IPv4：网际协议 (IP) 套接字

DEVICE：指定磁盘的名称

SIZE：文件的大小

NODE：索引节点（文件在磁盘上的标识）

NAME：打开文件的确切名称



实例2：查看谁正在使用某个文件，也就是说查找某个文件相关的进程

命令：lsof /bin/bash






实例3：递归查看某个目录的文件信息

命令：lsof test/test3






实例4：不使用+D选项，遍历查看某个目录的所有文件信息的方法

命令：lsof |grep 'test/test3'






实例5：列出某个用户打开的文件信息

命令：lsof -u username

说明: -u 选项，u其实是user的缩写






实例6：列出某个程序进程所打开的文件信息

命令：lsof -c mysql

说明:

 -c 选项将会列出所有以mysql这个进程开头的程序的文件，其实你也可以写成 lsof | grep mysql, 但是第一种方法明显比第二种方法要少打几个字符了






实例7：列出多个进程多个打开的文件信息

命令：lsof -c mysql -c apache






实例8：列出某个用户以及某个进程所打开的文件信息

命令：lsof  -u test -c mysql 

说明：用户与进程可相关，也可以不相关






实例9：列出除了某个用户外的被打开的文件信息

命令：lsof -u ^root

说明：这个符号在用户名之前，将会把是root用户打开的进程不让显示






实例10：通过某个进程号显示该进行打开的文件

命令：lsof -p 1






实例11：列出多个进程号对应的文件信息

命令：lsof -p 1,2,3






实例12：列出除了某个进程号，其他进程号所打开的文件信息

命令：lsof -p ^1






实例13：列出所有的网络连接

命令：lsof -i






实例14：列出所有tcp 网络连接信息

命令：lsof -i tcp






实例15：列出所有udp网络连接信息

命令：lsof -i udp






实例16：列出谁在使用某个端口

命令：lsof -i :3306






实例17：列出谁在使用某个特定的udp端口

命令：lsof -i udp:55






或者：特定的tcp端口

命令：lsof -i tcp:80






实例18：列出某个用户的所有活跃的网络端口

命令：lsof -a -u test -i






实例19：列出所有网络文件系统

命令：lsof -N






实例20：域名socket文件

命令：lsof -u






实例21：某个用户组所打开的文件信息

命令：lsof -g 5555






实例22：根据文件描述列出对应的文件信息

命令：

lsof -d description(like 2)

例如：lsof  -d  txt

例如：lsof  -d  1

例如：lsof  -d  2

说明：

0表示标准输入，1表示标准输出，2表示标准错误，从而可知：所以大多数应用程序所打开的文件的 FD 都是从 3 开始






实例23：根据文件描述范围列出文件信息

命令：lsof -d 2-3






实例24：列出COMMAND列中包含字符串" sshd"，且文件描符的类型为txt的文件信息

命令：lsof -c sshd -a -d txt




实例25：列出被进程号为1234的进程所打开的所有IPV4 network files 

命令：lsof -i 4 -a -p 1234






实例26：列出目前连接主机peida.linux上端口为：20，21，22，25，53，80相关的所有文件信息，且每隔3秒不断的执行lsof指令

命令：lsof -i @peida.linux:20,21,22,25,53,80  -r  3


前一天学习了 at 命令是针对仅运行一次的任务，循环运行的例行性计划任务，linux系统则是由 cron (crond) 这个系统服务来控制的。Linux 系统上面原本就有非常多的计划性工作，因此这个系统服务是默认启动的。另外, 由于使用者自己也可以设置计划任务，所以， Linux 系统也提供了使用者控制计划任务的命令 :crontab 命令。

一、crond简介

crond是linux下用来周期性的执行某种任务或等待处理某些事件的一个守护进程，与windows下的计划任务类似，当安装完成操作系统后，默认会安装此服务工具，并且会自动启动crond进程，crond进程每分钟会定期检查是否有要执行的任务，如果有要执行的任务，则自动执行该任务。

Linux下的任务调度分为两类，系统任务调度和用户任务调度。

系统任务调度：系统周期性所要执行的工作，比如写缓存数据到硬盘、日志清理等。在/etc目录下有一个crontab文件，这个就是系统任务调度的配置文件。

/etc/crontab文件包括下面几行：

[root@localhost ~]# cat /etc/crontab 

SHELL=/bin/bash

PATH=/sbin:/bin:/usr/sbin:/usr/bin

MAILTO=""HOME=/



# run-parts

51 * * * * root run-parts /etc/cron.hourly

24 7 * * * root run-parts /etc/cron.daily

22 4 * * 0 root run-parts /etc/cron.weekly

42 4 1 * * root run-parts /etc/cron.monthly

[root@localhost ~]#



前四行是用来配置crond任务运行的环境变量，第一行SHELL变量指定了系统要使用哪个shell，这里是bash，第二行PATH变量指定了系统执行命令的路径，第三行MAILTO变量指定了crond的任务执行信息将通过电子邮件发送给root用户，如果MAILTO变量的值为空，则表示不发送任务执行信息给用户，第四行的HOME变量指定了在执行命令或者脚本时使用的主目录。第六至九行表示的含义将在下个小节详细讲述。这里不在多说。

用户任务调度：用户定期要执行的工作，比如用户数据备份、定时邮件提醒等。用户可以使用 crontab 工具来定制自己的计划任务。所有用户定义的crontab 文件都被保存在 /var/spool/cron目录中。其文件名与用户名一致。



使用者权限文件：

文件：

/etc/cron.deny

说明：

该文件中所列用户不允许使用crontab命令

文件：

/etc/cron.allow

说明：

该文件中所列用户允许使用crontab命令

文件：

/var/spool/cron/

说明：

所有用户crontab文件存放的目录,以用户名命名



crontab文件的含义：

用户所建立的crontab文件中，每一行都代表一项任务，每行的每个字段代表一项设置，它的格式共分为六个字段，前五段是时间设定段，第六段是要执行的命令段，格式如下：

minute   hour   day   month   week   command

其中：

minute： 表示分钟，可以是从0到59之间的任何整数。

hour：表示小时，可以是从0到23之间的任何整数。

day：表示日期，可以是从1到31之间的任何整数。

month：表示月份，可以是从1到12之间的任何整数。

week：表示星期几，可以是从0到7之间的任何整数，这里的0或7代表星期日。

command：要执行的命令，可以是系统命令，也可以是自己编写的脚本文件。

 

在以上各个字段中，还可以使用以下特殊字符：

星号（*）：代表所有可能的值，例如month字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作。

逗号（,）：可以用逗号隔开的值指定一个列表范围，例如，“1,2,5,7,8,9”

中杠（-）：可以用整数之间的中杠表示一个整数范围，例如“2-6”表示“2,3,4,5,6”

正斜线（/）：可以用正斜线指定时间的间隔频率，例如“0-23/2”表示每两小时执行一次。同时正斜线可以和星号一起使用，例如*/10，如果用在minute字段，表示每十分钟执行一次。



二、crond服务

安装crontab：

yum install crontabs

服务操作说明：

/sbin/service crond start //启动服务

/sbin/service crond stop //关闭服务

/sbin/service crond restart //重启服务

/sbin/service crond reload //重新载入配置

查看crontab服务状态：

service crond status

手动启动crontab服务：

service crond start

查看crontab服务是否已设置为开机启动，执行命令：

ntsysv

加入开机自动启动：

chkconfig –level 35 crond on



三、crontab命令详解

1．命令格式：

crontab [-u user] file

crontab [-u user] [ -e | -l | -r ]

2．命令功能：

通过crontab 命令，我们可以在固定的间隔时间执行指定的系统指令或 shell script脚本。时间间隔的单位可以是分钟、小时、日、月、周及以上的任意组合。这个命令非常设合周期性的日志分析或数据备份等工作。

3．命令参数：

-u user：用来设定某个用户的crontab服务，例如，“-u ixdba”表示设定ixdba用户的crontab服务，此参数一般有root用户来运行。

file：file是命令文件的名字,表示将file做为crontab的任务列表文件并载入crontab。如果在命令行中没有指定这个文件，crontab命令将接受标准输入（键盘）上键入的命令，并将它们载入crontab。

-e：编辑某个用户的crontab文件内容。如果不指定用户，则表示编辑当前用户的crontab文件。

-l：显示某个用户的crontab文件内容，如果不指定用户，则表示显示当前用户的crontab文件内容。

-r：从/var/spool/cron目录中删除某个用户的crontab文件，如果不指定用户，则默认删除当前用户的crontab文件。

-i：在删除用户的crontab文件时给确认提示。

4．常用方法：

1). 创建一个新的crontab文件



在考虑向cron进程提交一个crontab文件之前，首先要做的一件事情就是设置环境变量EDITOR。cron进程根据它来确定使用哪个编辑器编辑crontab文件。9 9 %的UNIX和LINUX用户都使用vi，如果你也是这样，那么你就编辑$ HOME目录下的. profile文件，在其中加入这样一行：

EDITOR=vi; export EDITOR

然后保存并退出。不妨创建一个名为&lt;user&gt; cron的文件，其中&lt;user&gt;是用户名，例如， davecron。在该文件中加入如下的内容。

     # (put your own initials here)echo the date to the console every

     # 15minutes between 6pm and 6am

     0,15,30,45 18-06 * * * /bin/echo 'date' &gt; /dev/console

    保存并退出。确信前面5个域用空格分隔。

在上面的例子中，系统将每隔1 5分钟向控制台输出一次当前时间。如果系统崩溃或挂起，从最后所显示的时间就可以一眼看出系统是什么时间停止工作的。在有些系统中，用tty1来表示控制台，可以根据实际情况对上面的例子进行相应的修改。为了提交你刚刚创建的crontab文件，可以把这个新创建的文件作为cron命令的参数：

    $ crontab davecron

现在该文件已经提交给cron进程，它将每隔1 5分钟运行一次。

同时，新创建文件的一个副本已经被放在/var/spool/cron目录中，文件名就是用户名(即dave)。

2). 列出crontab文件

   为了列出crontab文件，可以用：

    $ crontab -l

    0,15,30,45,18-06 * * * /bin/echo `date` &gt; dev/tty1

你将会看到和上面类似的内容。可以使用这种方法在$ H O M E目录中对crontab文件做一备份：

    $ crontab -l &gt; $HOME/mycron

    这样，一旦不小心误删了crontab文件，可以用上一节所讲述的方法迅速恢复。

3). 编辑crontab文件

   如果希望添加、删除或编辑crontab文件中的条目，而E D I TO R环境变量又设置为v i，那么就可以用v i来编辑crontab文件，相应的命令为：

    $ crontab -e

可以像使用v i编辑其他任何文件那样修改crontab文件并退出。如果修改了某些条目或添加了新的条目，那么在保存该文件时， c r o n会对其进行必要的完整性检查。如果其中的某个域出现了超出允许范围的值，它会提示你。

我们在编辑crontab文件时，没准会加入新的条目。例如，加入下面的一条：

   # DT:delete core files,at 3.30am on 1,7,14,21,26,26 days of each month

    30 3 1,7,14,21,26 * * /bin/find -name "core' -exec rm {} \;

现在保存并退出。最好在crontab文件的每一个条目之上加入一条注释，这样就可以知道它的功能、运行时间，更为重要的是，知道这是哪位用户的作业。

现在让我们使用前面讲过的crontab -l命令列出它的全部信息：

   $ crontab -l 

   # (crondave installed on Tue May 4 13:07:43 1999)

   # DT:ech the date to the console every 30 minites

  0,15,30,45 18-06 * * * /bin/echo `date` &gt; /dev/tty1

   # DT:delete core files,at 3.30am on 1,7,14,21,26,26 days of each month

   30 3 1,7,14,21,26 * * /bin/find -name "core' -exec rm {} \;

4). 删除crontab文件

要删除crontab文件，可以用：

   $ crontab -r

5). 恢复丢失的crontab文件

如果不小心误删了crontab文件，假设你在自己的$ H O M E目录下还有一个备份，那么可以将其拷贝到/var/spool/cron/&lt;username&gt;，其中&lt;username&gt;是用户名。如果由于权限问题无法完成拷贝，可以用：

    $ crontab &lt;filename&gt;

    其中，&lt;filename&gt;是你在$ H O M E目录中副本的文件名。

我建议你在自己的$ H O M E目录中保存一个该文件的副本。我就有过类似的经历，有数次误删了crontab文件（因为r键紧挨在e键的右边）。这就是为什么有些系统文档建议不要直接编辑crontab文件，而是编辑该文件的一个副本，然后重新提交新的文件。

有些crontab的变体有些怪异，所以在使用crontab命令时要格外小心。如果遗漏了任何选项，crontab可能会打开一个空文件，或者看起来像是个空文件。这时敲delete键退出，不要按&lt;Ctrl-D&gt;，否则你将丢失crontab文件。

5．使用实例

实例1：每1分钟执行一次command

命令：

* * * * * command

 

实例2：每小时的第3和第15分钟执行

命令：

3,15 * * * * command

 

实例3：在上午8点到11点的第3和第15分钟执行

命令：

3,15 8-11 * * * command

 

实例4：每隔两天的上午8点到11点的第3和第15分钟执行

命令：

3,15 8-11 */2 * * command

 

实例5：每个星期一的上午8点到11点的第3和第15分钟执行

命令：

3,15 8-11 * * 1 command

 

实例6：每晚的21:30重启smb 

命令：

30 21 * * * /etc/init.d/smb restart

 

实例7：每月1、10、22日的4 : 45重启smb 

命令：

45 4 1,10,22 * * /etc/init.d/smb restart

 

实例8：每周六、周日的1 : 10重启smb

命令：

10 1 * * 6,0 /etc/init.d/smb restart

 

实例9：每天18 : 00至23 : 00之间每隔30分钟重启smb 

命令：

0,30 18-23 * * * /etc/init.d/smb restart

 

实例10：每星期六的晚上11 : 00 pm重启smb 

命令：

0 23 * * 6 /etc/init.d/smb restart

 

实例11：每一小时重启smb 

命令：

* */1 * * * /etc/init.d/smb restart

 

实例12：晚上11点到早上7点之间，每隔一小时重启smb 

命令：

* 23-7/1 * * * /etc/init.d/smb restart

 

实例13：每月的4号与每周一到周三的11点重启smb 

命令：

0 11 4 * mon-wed /etc/init.d/smb restart

 

实例14：一月一号的4点重启smb 

命令：

0 4 1 jan * /etc/init.d/smb restart



实例15：每小时执行/etc/cron.hourly目录内的脚本

命令：

01   *   *   *   *     root run-parts /etc/cron.hourly

说明：

run-parts这个参数了，如果去掉这个参数的话，后面就可以写要运行的某个脚本名，而不是目录名了



四、使用注意事项

1. 注意环境变量问题

有时我们创建了一个crontab，但是这个任务却无法自动执行，而手动执行这个任务却没有问题，这种情况一般是由于在crontab文件中没有配置环境变量引起的。

在crontab文件中定义多个调度任务时，需要特别注意的一个问题就是环境变量的设置，因为我们手动执行某个任务时，是在当前shell环境下进行的，程序当然能找到环境变量，而系统自动执行任务调度时，是不会加载任何环境变量的，因此，就需要在crontab文件中指定任务运行所需的所有环境变量，这样，系统执行任务调度时就没有问题了。

不要假定cron知道所需要的特殊环境，它其实并不知道。所以你要保证在shelll脚本中提供所有必要的路径和环境变量，除了一些自动设置的全局变量。所以注意如下3点：

1）脚本中涉及文件路径时写全局路径；

2）脚本执行要用到java或其他环境变量时，通过source命令引入环境变量，如：

cat start_cbp.sh

#!/bin/sh

source /etc/profile

export RUN_CONF=/home/d139/conf/platform/cbp/cbp_jboss.conf

/usr/local/jboss-4.0.5/bin/run.sh -c mev &amp;

3）当手动执行脚本OK，但是crontab死活不执行时。这时必须大胆怀疑是环境变量惹的祸，并可以尝试在crontab中直接引入环境变量解决问题。如：

0 * * * * . /etc/profile;/bin/sh /var/www/java/audit_no_count/bin/restart_audit.sh



2. 注意清理系统用户的邮件日志

每条任务调度执行完毕，系统都会将任务输出信息通过电子邮件的形式发送给当前系统用户，这样日积月累，日志信息会非常大，可能会影响系统的正常运行，因此，将每条任务进行重定向处理非常重要。

例如，可以在crontab文件中设置如下形式，忽略日志输出：

0 */3 * * * /usr/local/apache2/apachectl restart &gt;/dev/null 2&gt;&amp;1

“/dev/null 2&gt;&amp;1”表示先将标准输出重定向到/dev/null，然后将标准错误重定向到标准输出，由于标准输出已经重定向到了/dev/null，因此标准错误也会重定向到/dev/null，这样日志输出问题就解决了。



3. 系统级任务调度与用户级任务调度

系统级任务调度主要完成系统的一些维护操作，用户级任务调度主要完成用户自定义的一些任务，可以将用户级任务调度放到系统级任务调度来完成（不建议这么做），但是反过来却不行，root用户的任务调度操作可以通过“crontab –uroot –e”来设置，也可以将调度任务直接写入/etc/crontab文件，需要注意的是，如果要定义一个定时重启系统的任务，就必须将任务放到/etc/crontab文件，即使在root用户下创建一个定时重启系统的任务也是无效的。

4. 其他注意事项

新创建的cron job，不会马上执行，至少要过2分钟才执行。如果重启cron则马上执行。

当crontab突然失效时，可以尝试/etc/init.d/crond restart解决问题。或者查看日志看某个job有没有执行/报错tail -f /var/log/cron。

千万别乱运行crontab -r。它从Crontab目录（/var/spool/cron）中删除用户的Crontab文件。删除了该用户的所有crontab都没了。

在crontab中%是有特殊含义的，表示换行的意思。如果要用的话必须进行转义\%，如经常用的date ‘+%Y%m%d’在crontab里是不会执行的，应该换成date ‘+\%Y\%m\%d’。


watch是一个非常实用的命令，基本所有的Linux发行版都带有这个小工具，如同名字一样，watch可以帮你监测一个命令的运行结果，省得你一遍遍的手动运行。在Linux下，watch是周期性的执行下个程序，并全屏显示执行结果。你可以拿他来监测你想要的一切命令的结果变化，比如 tail 一个 log 文件，ls 监测某个文件的大小变化，看你的想象力了！

1．命令格式：

watch[参数][命令]

2．命令功能：

可以将命令的输出结果输出到标准输出设备，多用于周期性执行命令/定时执行命令

3．命令参数：

-n或--interval  watch缺省每2秒运行一下程序，可以用-n或-interval来指定间隔的时间。

-d或--differences  用-d或--differences 选项watch 会高亮显示变化的区域。 而-d=cumulative选项会把变动过的地方(不管最近的那次有没有变动)都高亮显示出来。

-t 或-no-title  会关闭watch命令在顶部的时间间隔,命令，当前时间的输出。

     -h, --help 查看帮助文档

4．使用实例：

实例1：

命令：每隔一秒高亮显示网络链接数的变化情况

watch -n 1 -d netstat -ant




实例2：每隔一秒高亮显示http链接数的变化情况

命令：watch -n 1 -d 'pstree|grep http'

说明：每隔一秒高亮显示http链接数的变化情况。 后面接的命令若带有管道符，需要加''将命令区域归整。




实例3：实时查看模拟攻击客户机建立起来的连接数

命令：watch 'netstat -an | grep:21 | \ grep&lt;模拟攻击客户机的IP&gt;| wc -l' 




实例4：监测当前目录中 scf' 的文件的变化

命令：watch -d 'ls -l|grep scf' 






实例5：10秒一次输出系统的平均负载

命令：watch -n 10 'cat /proc/loadavg'


Linux系统中的 iostat是I/O statistics（输入/输出统计）的缩写，iostat工具将对系统的磁盘操作活动进行监视。它的特点是汇报磁盘活动统计情况，同时也会汇报出CPU使用情况。同vmstat一样，iostat也有一个弱点，就是它不能对某个进程进行深入分析，仅对系统的整体情况进行分析。iostat属于sysstat软件包。可以用yum install sysstat 直接安装。

1．命令格式：

iostat[参数][时间][次数]

2．命令功能：

  
通过iostat方便查看CPU、网卡、tty设备、磁盘、CD-ROM 等等设备的活动情况,
负载信息。

3．命令参数：

-C 显示CPU使用情况

-d 显示磁盘使用情况

-k 以 KB 为单位显示

-m 以 M 为单位显示

-N 显示磁盘阵列(LVM) 信息

-n 显示NFS 使用情况

-p[磁盘] 显示磁盘和分区的情况

-t 显示终端和CPU的信息

-x 显示详细信息

-V 显示版本信息

4．使用实例：

实例1：显示所有设备负载情况

命令：iostat

输出：


[root@CT1186 ~]# iostat
Linux 2.6.18-128.el5 (CT1186)   2012年12月28日

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           8.30    0.02    5.07    0.17    0.00   86.44

Device:            tps   Blk_read/s   Blk_wrtn/s   Blk_read   Blk_wrtn
sda              22.73        43.70       487.42  674035705 7517941952
sda1              0.00         0.00         0.00       2658        536
sda2              0.11         3.74         3.51   57721595   54202216
sda3              0.98         0.61        17.51    9454172  270023368
sda4              0.00         0.00         0.00          6          0
sda5              6.95         0.12       108.73    1924834 1677123536
sda6              2.20         0.18        31.22    2837260  481488056
sda7             12.48        39.04       326.45  602094508 5035104240





说明：

cpu属性值说明：

%user：CPU处在用户模式下的时间百分比。

%nice：CPU处在带NICE值的用户模式下的时间百分比。

%system：CPU处在系统模式下的时间百分比。

%iowait：CPU等待输入输出完成时间的百分比。

%steal：管理程序维护另一个虚拟处理器时，虚拟CPU的无意识等待时间百分比。

%idle：CPU空闲时间百分比。



备注：如果%iowait的值过高，表示硬盘存在I/O瓶颈，%idle值高，表示CPU较空闲，如果%idle值高但系统响应慢时，有可能是CPU等待分配内存，此时应加大内存容量。%idle值如果持续低于10，那么系统的CPU处理能力相对较低，表明系统中最需要解决的资源是CPU。



disk属性值说明：

rrqm/s:  每秒进行 merge 的读操作数目。即 rmerge/s

wrqm/s:  每秒进行 merge 的写操作数目。即 wmerge/s

r/s:  每秒完成的读 I/O 设备次数。即 rio/s

w/s:  每秒完成的写 I/O 设备次数。即 wio/s

rsec/s:  每秒读扇区数。即 rsect/s

wsec/s:  每秒写扇区数。即 wsect/s

rkB/s:  每秒读K字节数。是 rsect/s 的一半，因为每扇区大小为512字节。

wkB/s:  每秒写K字节数。是 wsect/s 的一半。

avgrq-sz:  平均每次设备I/O操作的数据大小 (扇区)。

avgqu-sz:  平均I/O队列长度。

await:  平均每次设备I/O操作的等待时间 (毫秒)。

svctm: 平均每次设备I/O操作的服务时间 (毫秒)。

%util:  一秒中有百分之多少的时间用于 I/O 操作，即被io消耗的cpu百分比



备注：如果 %util 接近 100%，说明产生的I/O请求太多，I/O系统已经满负荷，该磁盘可能存在瓶颈。如果 svctm 比较接近 await，说明 I/O 几乎没有等待时间；如果 await 远大于 svctm，说明I/O 队列太长，io响应太慢，则需要进行必要优化。如果avgqu-sz比较大，也表示有当量io在等待。



实例2：定时显示所有信息

命令：iostat 2 3



说明：每隔 2秒刷新显示，且显示3次






实例3：显示指定磁盘信息

命令：iostat -d sda1






实例4：显示tty和Cpu信息

命令：iostat -t






实例5：以M为单位显示所有信息

命令：iostat -m






实例6：查看TPS和吞吐量信息

命令：iostat -d -k 1 1

输出：


[root@CT1186 ~]# iostat -d -k 1 1
Linux 2.6.18-128.el5 (CT1186)   2012年12月28日

Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn
sda              22.72        21.85       243.71  337017916 3758984340
sda1              0.00         0.00         0.00       1329        268
sda2              0.11         1.87         1.76   28860797   27101108
sda3              0.98         0.31         8.75    4727086  135012508
sda4              0.00         0.00         0.00          3          0
sda5              6.95         0.06        54.37     962481  838566148
sda6              2.20         0.09        15.61    1418630  240744712
sda7             12.48        19.52       163.22  301047254 2517559596 





说明：

tps：该设备每秒的传输次数（Indicate the number of transfers per second that were issued to the device.）。“一次传输”意思是“一次I/O请求”。多个逻辑请求可能会被合并为“一次I/O请求”。“一次传输”请求的大小是未知的。

kB_read/s：每秒从设备（drive expressed）读取的数据量；

kB_wrtn/s：每秒向设备（drive expressed）写入的数据量；

kB_read：读取的总数据量；kB_wrtn：写入的总数量数据量；

这些单位都为Kilobytes。

上面的例子中，我们可以看到磁盘sda以及它的各个分区的统计数据，当时统计的磁盘总TPS是22.73，下面是各个分区的TPS。（因为是瞬间值，所以总TPS并不严格等于各个分区TPS的总和）






实例7：查看设备使用率（%util）、响应时间（await）

命令：iostat -d -x -k 1 1

输出：


[root@CT1186 ~]# iostat -d -x -k 1 1
Linux 2.6.18-128.el5 (CT1186)   2012年12月28日

Device:         rrqm/s   wrqm/s   r/s   w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await  svctm  %util
sda               0.44    38.59  0.40 22.32    21.85   243.71    23.37     0.04    1.78   4.20   9.54
sda1              0.00     0.00  0.00  0.00     0.00     0.00    18.90     0.00    8.26   6.46   0.00
sda2              0.36     0.43  0.11  0.01     1.87     1.76    63.57     0.01   63.75   1.94   0.02
sda3              0.00     1.24  0.04  0.95     0.31     8.75    18.42     0.04   39.77   8.73   0.86
sda4              0.00     0.00  0.00  0.00     0.00     0.00     2.00     0.00   19.67  19.67   0.00
sda5              0.00     6.65  0.00  6.94     0.06    54.37    15.67     0.26   36.81   4.48   3.11
sda6              0.00     1.71  0.01  2.19     0.09    15.61    14.29     0.03   12.40   5.84   1.28
sda7              0.08    28.56  0.25 12.24    19.52   163.22    29.28     0.27   21.46   5.00   6.25 





说明：

rrqm/s：  每秒进行 merge 的读操作数目.即 delta(rmerge)/s

wrqm/s： 每秒进行 merge 的写操作数目.即 delta(wmerge)/s

r/s：  每秒完成的读 I/O 设备次数.即 delta(rio)/s

w/s：  每秒完成的写 I/O 设备次数.即 delta(wio)/s

rsec/s：  每秒读扇区数.即 delta(rsect)/s

wsec/s： 每秒写扇区数.即 delta(wsect)/s

rkB/s：  每秒读K字节数.是 rsect/s 的一半,因为每扇区大小为512字节.(需要计算)

wkB/s：  每秒写K字节数.是 wsect/s 的一半.(需要计算)

avgrq-sz：平均每次设备I/O操作的数据大小 (扇区).delta(rsect+wsect)/delta(rio+wio)

avgqu-sz：平均I/O队列长度.即 delta(aveq)/s/1000 (因为aveq的单位为毫秒).

await：  平均每次设备I/O操作的等待时间 (毫秒).即 delta(ruse+wuse)/delta(rio+wio)

svctm： 平均每次设备I/O操作的服务时间 (毫秒).即 delta(use)/delta(rio+wio)

%util： 一秒中有百分之多少的时间用于 I/O 操作,或者说一秒中有多少时间 I/O 队列是非空的，即 delta(use)/s/1000 (因为use的单位为毫秒)



如果 %util 接近 100%，说明产生的I/O请求太多，I/O系统已经满负荷，该磁盘可能存在瓶颈。

idle小于70% IO压力就较大了，一般读取速度有较多的wait。

同时可以结合vmstat 查看查看b参数(等待资源的进程数)和wa参数(IO等待所占用的CPU时间的百分比，高过30%时IO压力高)。

另外 await 的参数也要多和 svctm 来参考。差的过高就一定有 IO 的问题。

avgqu-sz 也是个做 IO 调优时需要注意的地方，这个就是直接每次操作的数据的大小，如果次数多，但数据拿的小的话，其实 IO 也会很小。如果数据拿的大，才IO 的数据会高。也可以通过 avgqu-sz × ( r/s or w/s ) = rsec/s or wsec/s。也就是讲，读定速度是这个来决定的。

svctm 一般要小于 await (因为同时等待的请求的等待时间被重复计算了)，svctm 的大小一般和磁盘性能有关，CPU/内存的负荷也会对其有影响，请求过多也会间接导致 svctm 的增加。await 的大小一般取决于服务时间(svctm) 以及 I/O 队列的长度和 I/O 请求的发出模式。如果 svctm 比较接近 await，说明 I/O 几乎没有等待时间；如果 await 远大于 svctm，说明 I/O 队列太长，应用得到的响应时间变慢，如果响应时间超过了用户可以容许的范围，这时可以考虑更换更快的磁盘，调整内核 elevator 算法，优化应用，或者升级 CPU。

队列长度(avgqu-sz)也可作为衡量系统 I/O 负荷的指标，但由于 avgqu-sz 是按照单位时间的平均值，所以不能反映瞬间的 I/O 洪水。



       形象的比喻：
       r/s+w/s 类似于交款人的总数
      平均队列长度(avgqu-sz)类似于单位时间里平均排队人的个数
      平均服务时间(svctm)类似于收银员的收款速度
      平均等待时间(await)类似于平均每人的等待时间
      平均I/O数据(avgrq-sz)类似于平均每人所买的东西多少
       I/O 操作率 (%util)类似于收款台前有人排队的时间比例

       设备IO操作:总IO(io)/s = r/s(读) +w/s(写) =1.46 + 25.28=26.74
      平均每次设备I/O操作只需要0.36毫秒完成,现在却需要10.57毫秒完成，因为发出的
请求太多(每秒26.74个)，假如请求时同时发出的，可以这样计算平均等待时间:
      平均等待时间=单个I/O服务器时间*(1+2+...+请求总数-1)/请求总数 
       每秒发出的I/0请求很多,但是平均队列就4,表示这些请求比较均匀,大部分处理还是比较及时。






   实例8：查看cpu状态

   命令：iostat -c 1 3

经过前面两次的翻译，虽然对量子计算机有进一步的了解，但是对于涉及更深一层次的量子计算的知识时，还是束手无策，暂时对该文先做草率翻译，望知识高深者多多指点。
原文链接地址：https://quantumexperience.ng.bluemix.net/qstage/#/tutorial?sectionId=75a85f7e14ae3fd4329ad5c3e59466ea&amp;pageIndex=2


量子定律是,据我们所知,最基本的物理定律,他们是不可亵渎的。这是我们对量子物理衍化出的五个关键定律。


量子是一个系统
每个物理系统对应希尔伯特空间（1）的维数等于系统的最大数量的可靠的可识别的状态（2）。


量子态是一个系统的配置
希尔伯特空间中的每个方向(射线)对应于一个可能的系统状态（3）,两种状态是可靠的区分当且仅当它们的方向正交(内积为零)。


量子态的变化,自然想要发展,但它总是可以撤销
进化的一个封闭的系统是一个幺正（4）变换希尔伯特空间。


扩展——部分如何做出一个整体
复合系统的希尔伯特空间是希尔伯特空间部分（5）的张量积。


量子计量的概率性的
每个可能的测量系统上对应于一个分辨它的希尔伯特空间正交的子空间其中，在状态|ψ&gt;结果发生的概率和测量后的状态 。


这五个原则是整个量子世界的基础。
说明
（1）希尔伯特空间是一个复系数和内积的线性向量空间   。
（2）对于单个量子位,有两个标准正交状态(基于计算的状态)依据惯例的表示  和
  。
（3）其它量子位包括   。
（4）齐一表示线性的和内积相互防护。
（5）一个two-qubit系统可以存在于一个生产的状态如|00&gt;或|0+&gt;，但是还在纠缠态  ，量子位都没有一个明确的状态,虽然两个量子位在一起。 
（6）测量导致系统行为的概率和忽略每个测试的状态,除非该状态碰巧完全的依赖一个子空间  。
   


vmstat是Virtual Meomory Statistics（虚拟内存统计）的缩写，可对操作系统的虚拟内存、进程、CPU活动进行监控。他是对系统的整体情况进行统计，不足之处是无法对某个进程进行深入分析。vmstat 工具提供了一种低开销的系统性能观察方式。因为vmstat本身就是低开销工具，在非常高负荷的服务器上，你需要查看并监控系统的健康情况,在控制窗口还是能够使用vmstat输出结果。在学习vmstat命令前，我们先了解一下Linux系统中关于物理内存和虚拟内存相关信息。

物理内存和虚拟内存区别：

我们知道，直接从物理内存读写数据要比从硬盘读写数据要快的多，因此，我们希望所有数据的读取和写入都在内存完成，而内存是有限的，这样就引出了物理内存与虚拟内存的概念。

物理内存就是系统硬件提供的内存大小，是真正的内存，相对于物理内存，在linux下还有一个虚拟内存的概念，虚拟内存就是为了满足物理内存的不足而提出的策略，它是利用磁盘空间虚拟出的一块逻辑内存，用作虚拟内存的磁盘空间被称为交换空间（Swap Space）。

作为物理内存的扩展，linux会在物理内存不足时，使用交换分区的虚拟内存，更详细的说，就是内核会将暂时不用的内存块信息写到交换空间，这样以来，物理内存得到了释放，这块内存就可以用于其它目的，当需要用到原始的内容时，这些信息会被重新从交换空间读入物理内存。

linux的内存管理采取的是分页存取机制，为了保证物理内存能得到充分的利用，内核会在适当的时候将物理内存中不经常使用的数据块自动交换到虚拟内存中，而将经常使用的信息保留到物理内存。

要深入了解linux内存运行机制，需要知道下面提到的几个方面：

首先，Linux系统会不时的进行页面交换操作，以保持尽可能多的空闲物理内存，即使并没有什么事情需要内存，Linux也会交换出暂时不用的内存页面。这可以避免等待交换所需的时间。

其次，linux进行页面交换是有条件的，不是所有页面在不用时都交换到虚拟内存，linux内核根据”最近最经常使用“算法，仅仅将一些不经常使用的页面文件交换到虚拟内存，有时我们会看到这么一个现象：linux物理内存还有很多，但是交换空间也使用了很多。其实，这并不奇怪，例如，一个占用很大内存的进程运行时，需要耗费很多内存资源，此时就会有一些不常用页面文件被交换到虚拟内存中，但后来这个占用很多内存资源的进程结束并释放了很多内存时，刚才被交换出去的页面文件并不会自动的交换进物理内存，除非有这个必要，那么此刻系统物理内存就会空闲很多，同时交换空间也在被使用，就出现了刚才所说的现象了。关于这点，不用担心什么，只要知道是怎么一回事就可以了。

最后，交换空间的页面在使用时会首先被交换到物理内存，如果此时没有足够的物理内存来容纳这些页面，它们又会被马上交换出去，如此以来，虚拟内存中可能没有足够空间来存储这些交换页面，最终会导致linux出现假死机、服务异常等问题，linux虽然可以在一段时间内自行恢复，但是恢复后的系统已经基本不可用了。

因此，合理规划和设计linux内存的使用，是非常重要的。

虚拟内存原理：

在系统中运行的每个进程都需要使用到内存，但不是每个进程都需要每时每刻使用系统分配的内存空间。当系统运行所需内存超过实际的物理内存，内核会释放某些进程所占用但未使用的部分或所有物理内存，将这部分资料存储在磁盘上直到进程下一次调用，并将释放出的内存提供给有需要的进程使用。

在Linux内存管理中，主要是通过“调页Paging”和“交换Swapping”来完成上述的内存调度。调页算法是将内存中最近不常使用的页面换到磁盘上，把活动页面保留在内存中供进程使用。交换技术是将整个进程，而不是部分页面，全部交换到磁盘上。

分页(Page)写入磁盘的过程被称作Page-Out，分页(Page)从磁盘重新回到内存的过程被称作Page-In。当内核需要一个分页时，但发现此分页不在物理内存中(因为已经被Page-Out了)，此时就发生了分页错误（Page Fault）。

当系统内核发现可运行内存变少时，就会通过Page-Out来释放一部分物理内存。尽管Page-Out不是经常发生，但是如果Page-out频繁不断的发生，直到当内核管理分页的时间超过运行程式的时间时，系统效能会急剧下降。这时的系统已经运行非常慢或进入暂停状态，这种状态亦被称作thrashing(颠簸)。

 

1．命令格式：

vmstat [-a] [-n] [-S unit] [delay [ count]]

vmstat [-s] [-n] [-S unit]

vmstat [-m] [-n] [delay [ count]]

vmstat [-d] [-n] [delay [ count]]

vmstat [-p disk partition] [-n] [delay [ count]]

vmstat [-f]

vmstat [-V]

2．命令功能：

用来显示虚拟内存的信息

3．命令参数：

-a：显示活跃和非活跃内存

-f：显示从系统启动至今的fork数量 。

-m：显示slabinfo

-n：只在开始时显示一次各字段名称。

-s：显示内存相关统计信息及多种系统活动数量。

delay：刷新时间间隔。如果不指定，只显示一条结果。

count：刷新次数。如果不指定刷新次数，但指定了刷新时间间隔，这时刷新次数为无穷。

-d：显示磁盘相关统计信息。

-p：显示指定磁盘分区统计信息

-S：使用指定单位显示。参数有 k 、K 、m 、M ，分别代表1000、1024、1000000、1048576字节（byte）。默认单位为K（1024 bytes）

-V：显示vmstat版本信息。

4．使用实例：

实例1：显示虚拟内存使用情况

命令：vmstat

输出：


[root@localhost ~]# vmstat 5 6
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0      0 3029876 199616 690980    0    0     0     2    3    2  0  0 100  0  0
 0  0      0 3029752 199616 690980    0    0     0    41 1009   39  0  0 100  0  0
 0  0      0 3029752 199616 690980    0    0     0     3 1004   36  0  0 100  0  0
 0  0      0 3029752 199616 690980    0    0     0     4 1004   36  0  0 100  0  0
 0  0      0 3029752 199616 690980    0    0     0     6 1003   33  0  0 100  0  0



 0  0      0 3029752 199616 690980    0    0     0     5 1003   33  0  0 100  0  0 





说明：

字段说明：

Procs（进程）：

r: 运行队列中进程数量

b: 等待IO的进程数量

Memory（内存）：

swpd: 使用虚拟内存大小

free: 可用内存大小

buff: 用作缓冲的内存大小

cache: 用作缓存的内存大小

Swap：

si: 每秒从交换区写到内存的大小

so: 每秒写入交换区的内存大小

IO：（现在的Linux版本块的大小为1024bytes）

bi: 每秒读取的块数

bo: 每秒写入的块数

系统：

in: 每秒中断数，包括时钟中断。

cs: 每秒上下文切换数。

CPU（以百分比表示）：

us: 用户进程执行时间(user time)

sy: 系统进程执行时间(system time)

id: 空闲时间(包括IO等待时间),中央处理器的空闲时间 。以百分比表示。

wa: 等待IO时间

备注： 如果 r经常大于 4 ，且id经常少于40，表示cpu的负荷很重。如果pi，po 长期不等于0，表示内存不足。如果disk 经常不等于0， 且在 b中的队列 大于3， 表示 io性能不好。Linux在具有高稳定性、可靠性的同时，具有很好的可伸缩性和扩展性，能够针对不同的应用和硬件环境调整，优化出满足当前应用需要的最佳性能。因此企业在维护Linux系统、进行系统调优时，了解系统性能分析工具是至关重要的。



命令：

vmstat 5 5

表示在5秒时间内进行5次采样。将得到一个数据汇总他能够反映真正的系统情况。



实例2：显示活跃和非活跃内存

命令：vmstat -a 2 5

输出：


[root@localhost ~]# vmstat -a 2 5
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------
 r  b   swpd   free  inact active   si   so    bi    bo   in   cs us sy id wa st
 0  0      0 3029752 387728 513008    0    0     0     2    3    2  0  0 100  0  0
 0  0      0 3029752 387728 513076    0    0     0     0 1005   34  0  0 100  0  0
 0  0      0 3029752 387728 513076    0    0     0    22 1004   36  0  0 100  0  0
 0  0      0 3029752 387728 513076    0    0     0     0 1004   33  0  0 100  0  0
 0  0      0 3029752 387728 513076    0    0     0     0 1003   32  0  0 100  0  0



[root@localhost ~]#  



说明：

使用-a选项显示活跃和非活跃内存时，所显示的内容除增加inact和active外，其他显示内容与例子1相同。

字段说明：

Memory（内存）：

inact: 非活跃内存大小（当使用-a选项时显示）

active: 活跃的内存大小（当使用-a选项时显示）



实例3：查看系统已经fork了多少次

命令：vmstat -f






实例4：查看内存使用的详细信息

命令：vmstat -s






实例5：查看磁盘的读/写

命令：vmstat -d






实例6：查看系统的slab信息

命令：vmstat -m


free命令可以显示Linux系统中空闲的、已用的物理内存及swap内存,及被内核使用的buffer。在Linux系统监控的工具中，free命令是最经常使用的命令之一。

1．命令格式：

free [参数]

2．命令功能：

free 命令显示系统使用和空闲的内存情况，包括物理内存、交互区内存(swap)和内核缓冲区内存。共享内存将被忽略。

3．命令参数：

-b 　以Byte为单位显示内存使用情况。 

-k 　以KB为单位显示内存使用情况。 

-m 　以MB为单位显示内存使用情况。

-g   以GB为单位显示内存使用情况。 

-o 　不显示缓冲区调节列。 

-s&lt;间隔秒数&gt; 　持续观察内存使用状况。 

-t 　显示内存总和列。 

-V 　显示版本信息。 

4．使用实例：

实例1：显示内存使用情况

命令：

free

free -g

free -m

输出：

[root@SF1150 service]# free

             total       used       free     shared    buffers     cached

Mem:      32940112   30841684    2098428          0    4545340   11363424

-/+ buffers/cache:   14932920   18007192

Swap:     32764556    1944984   30819572

[root@SF1150 service]# free -g

             total       used       free     shared    buffers     cached

Mem:            31         29          2          0          4         10

-/+ buffers/cache:         14         17

Swap:           31          1         29

[root@SF1150 service]# free -m

             total       used       free     shared    buffers     cached

Mem:         32168      30119       2048          0       4438      11097

-/+ buffers/cache:      14583      17584

Swap:        31996       1899      30097

说明：

下面是对这些数值的解释：

total:总计物理内存的大小。

used:已使用多大。

free:可用有多少。

Shared:多个进程共享的内存总额。

Buffers/cached:磁盘缓存的大小。

第三行(-/+ buffers/cached):

used:已使用多大。

free:可用有多少。

第四行是交换分区SWAP的，也就是我们通常所说的虚拟内存。

区别：第二行(mem)的used/free与第三行(-/+ buffers/cache) used/free的区别。 这两个的区别在于使用的角度来看，第一行是从OS的角度来看，因为对于OS，buffers/cached 都是属于被使用，所以他的可用内存是2098428KB,已用内存是30841684KB,其中包括，内核（OS）使用+Application(X, oracle,etc)使用的+buffers+cached.

第三行所指的是从应用程序角度来看，对于应用程序来说，buffers/cached 是等于可用的，因为buffer/cached是为了提高文件读取的性能，当应用程序需在用到内存的时候，buffer/cached会很快地被回收。

所以从应用程序的角度来说，可用内存=系统free memory+buffers+cached。

如本机情况的可用内存为：

18007156=2098428KB+4545340KB+11363424KB



接下来解释什么时候内存会被交换，以及按什么方交换。 

当可用内存少于额定值的时候，就会开会进行交换.如何看额定值： 

命令：cat /proc/meminfo 

输出：

[root@SF1150 service]# cat /proc/meminfo

MemTotal:     32940112 kB

MemFree:       2096700 kB

Buffers:       4545340 kB

Cached:       11364056 kB

SwapCached:    1896080 kB

Active:       22739776 kB

Inactive:      7427836 kB

HighTotal:           0 kB

HighFree:            0 kB

LowTotal:     32940112 kB

LowFree:       2096700 kB

SwapTotal:    32764556 kB

SwapFree:     30819572 kB

Dirty:             164 kB

Writeback:           0 kB

AnonPages:    14153592 kB

Mapped:          20748 kB

Slab:           590232 kB

PageTables:      34200 kB

NFS_Unstable:        0 kB

Bounce:              0 kB

CommitLimit:  49234612 kB

Committed_AS: 23247544 kB

VmallocTotal: 34359738367 kB

VmallocUsed:    278840 kB

VmallocChunk: 34359459371 kB

HugePages_Total:     0HugePages_Free:      0HugePages_Rsvd:      0Hugepagesize:     2048 kB



交换将通过三个途径来减少系统中使用的物理页面的个数：　 

1.减少缓冲与页面cache的大小， 

2.将系统V类型的内存页面交换出去，　 

3.换出或者丢弃页面。(Application 占用的内存页，也就是物理内存不足）。 

事实上，少量地使用swap是不是影响到系统性能的。



那buffers和cached都是缓存，两者有什么区别呢？

为了提高磁盘存取效率, Linux做了一些精心的设计, 除了对dentry进行缓存(用于VFS,加速文件路径名到inode的转换), 还采取了两种主要Cache方式：Buffer Cache和Page Cache。前者针对磁盘块的读写，后者针对文件inode的读写。这些Cache有效缩短了 I/O系统调用(比如read,write,getdents)的时间。

磁盘的操作有逻辑级（文件系统）和物理级（磁盘块），这两种Cache就是分别缓存逻辑和物理级数据的。

Page cache实际上是针对文件系统的，是文件的缓存，在文件层面上的数据会缓存到page cache。文件的逻辑层需要映射到实际的物理磁盘，这种映射关系由文件系统来完成。当page cache的数据需要刷新时，page cache中的数据交给buffer cache，因为Buffer Cache就是缓存磁盘块的。但是这种处理在2.6版本的内核之后就变的很简单了，没有真正意义上的cache操作。

Buffer cache是针对磁盘块的缓存，也就是在没有文件系统的情况下，直接对磁盘进行操作的数据会缓存到buffer cache中，例如，文件系统的元数据都会缓存到buffer cache中。

简单说来，page cache用来缓存文件数据，buffer cache用来缓存磁盘数据。在有文件系统的情况下，对文件操作，那么数据会缓存到page cache，如果直接采用dd等工具对磁盘进行读写，那么数据会缓存到buffer cache。

所以我们看linux,只要不用swap的交换空间,就不用担心自己的内存太少.如果常常swap用很多,可能你就要考虑加物理内存了.这也是linux看内存是否够用的标准.

如果是应用服务器的话，一般只看第二行，+buffers/cache,即对应用程序来说free的内存太少了，也是该考虑优化程序或加内存了。



实例2：以总和的形式显示内存的使用信息

命令：free -t 






实例3：周期性的查询内存使用信息

命令：free -s 10



说明：每10s 执行一次命令

       最近看了一些量子计算机的相关信息，尝试翻译一些外文。在翻译过程中，发现自己一方面对量子计算机的一些专业术语了解还是比较少，另一方面发现对于翻译这个工作，不是想象中的那么简单，很多词句感觉理解，但是一旦翻译成中文，就是感觉丢失了一些原文的本意。因此在翻译过程中也颇为苦恼，也希望有相关爱好的多多指正，指出不足或提出改进，不胜感激。
下文原文地址：https://quantumexperience.ng.bluemix.net/qstage/#/tutorial?sectionId=75a85f7e14ae3fd4329ad5c3e59466ea&amp;pageIndex=1        


       当今的计算机进行计算和处理信息使用的标准(或物理学家会说,“古典”)的计算模型,可以追溯到图灵和冯·诺依曼。在这个模型中，所有的信息都简化为二进制，取0或1的值——所有的处理都可以通过简单的逻辑门路（AND，OR，NOT，NAND）一次作用于一个或两个二进制。在任意节点的估算，一个传统的计算机的状态完全取决于它所有二进制的状态，所以一个n位计算机可能存在2^NOT，NAND）一次作用于一个或两个二进制。在任意节点的估算，一个传统的计算机的状态完全取决于它所有二进制的状态，所以一个n位计算机可能存在2^n种可能的状态，从00...0到11...1。

        与此同时，量子计算机的力量在于它有非常丰富的计算机指令状态。像任何普通的计算机，量子计算机也有二进制。但是不是0和1，它是量子二进制，或是量子比特，可以代表一个0,1，或者两者兼而有之，该属性称为叠加。这本身并没有太大的帮助，因为电脑的比特在0和1之间的媒介可以只是一个模拟计算机,几乎比一个普通的数字计算机更强大。量子计算机利用一种特殊的叠加,使得出现许多逻辑状态指数，所有状态从|00...0&gt;到|11...1&gt;。这是一个壮举，传统计算机无法实现它。绝大多数的量子叠加,最有用的量子计算,是混乱的——整个电脑的状态不符合任何作业于个别量子比特的数字或模拟状态。虽然不是许多传统计算机指数级别那么强大，一个量子计算机意味着比任何传统计算机都强大——无论是确定性的、概率性的或模拟的。几个著名的问题(如大数据因式分解),量子计算机明显胜过传统计算机。一个量子计算机工作一天所做的因式分解的量，一台传统计算机可能需要花费数百万年才能完成。

        有人可能会认为理解量子计算和量子物理学的难点在于“数学之难”...但事实上,数学上地、量子概念只比高中代数稍微复杂一点。量子物理是很难的,因为,就像爱因斯坦的相对论,它内在的想法很简单但非常违反直觉。对于相对论,奇怪的想法是,时间和空间是相互联系的,当常识告诉我们他们应该各行其是。如果你试图向某人从时间和空间开始解释相对论,你可能遭到白眼。一个更好的方式就像爱因斯坦做的一样,解释相对论遵循一个简单的物理原理:对所有的观察者光速都是一样的。这一个谦虚的想法就变成了极其深刻,必然逻辑的爱因斯坦的时空。

        对于量子物理,必须接受一个违反直觉的想法：（1）一个物理系统在完美的状态仍然可能出现异常；（2）两个系统,相距太远相互影响可以不过的行为方式,尽管单独随机,但强烈相关。不幸的是,不像相对论,这些结论没有单一的简单的物理原理。我们能做的是将量子力学抽象为数学法则,从所有观察到的量子粒子的行为(在量子计算机和量子比特)可以推断和预测的数学规则。就如相对论,我们必须警惕试图用传统术语描述量子概念。


top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。下面详细介绍它的使用方法。top是一个动态显示过程,即可以通过用户按键来不断刷新当前状态.如果在前台执行该命令,它将独占前台,直到用户终止该程序为止.比较准确的说,top命令提供了实时的对系统处理器的状态监视.它将显示系统中CPU最“敏感”的任务列表.该命令可以按CPU使用.内存使用和执行时间对任务进行排序；而且该命令的很多特性都可以通过交互式命令或者在个人定制文件中进行设定.

1．命令格式：

top [参数]

2．命令功能：

显示当前系统正在执行的进程的相关信息，包括进程ID、内存占用率、CPU占用率等

3．命令参数：

-b 批处理

-c 显示完整的治命令

-I 忽略失效过程

-s 保密模式

-S 累积模式

-i&lt;时间&gt; 设置间隔时间

-u&lt;用户名&gt; 指定用户名

-p&lt;进程号&gt; 指定进程

-n&lt;次数&gt; 循环显示的次数



4．使用实例：

实例1：显示进程信息

命令：top



输出：

[root@TG1704 log]# top

top - 14:06:23 up 70 days, 16:44,  2 users,  load average: 1.25, 1.32, 1.35

Tasks: 206 total,   1 running, 205 sleeping,   0 stopped,   0 zombie

Cpu(s):  5.9%us,  3.4%sy,  0.0%ni, 90.4%id,  0.0%wa,  0.0%hi,  0.2%si,  0.0%st

Mem:  32949016k total, 14411180k used, 18537836k free,   169884k buffers

Swap: 32764556k total,        0k used, 32764556k free,  3612636k cached



  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                                                                

28894 root      22   0 1501m 405m  10m S 52.2  1.3   2534:16 java                                                                   

18249 root      18   0 3201m 1.9g  11m S 35.9  6.0 569:39.41 java                                                                   

 2808 root      25   0 3333m 1.0g  11m S 24.3  3.1 526:51.85 java                                                                   

25668 root      23   0 3180m 704m  11m S 14.0  2.2 360:44.53 java                                                                   

  574 root      25   0 3168m 611m  10m S 12.6  1.9 556:59.63 java                                                                   

 1599 root      20   0 3237m 1.9g  11m S 12.3  6.2 262:01.14 java                                                                   

 1008 root      21   0 3147m 842m  10m S  0.3  2.6   4:31.08 java                                                                   

13823 root      23   0 3031m 2.1g  10m S  0.3  6.8 176:57.34 java                                                                   

28218 root      15   0 12760 1168  808 R  0.3  0.0   0:01.43 top                                                                    

29062 root      20   0 1241m 227m  10m S  0.3  0.7   2:07.32 java                                                                   

    1 root      15   0 10368  684  572 S  0.0  0.0   1:30.85 init                                                                   

    2 root      RT  -5     0    0    0 S  0.0  0.0   0:01.01 migration/0                                                            

    3 root      34  19     0    0    0 S  0.0  0.0   0:00.00 ksoftirqd/0                                                            

    4 root      RT  -5     0    0    0 S  0.0  0.0   0:00.00 watchdog/0                                                             

    5 root      RT  -5     0    0    0 S  0.0  0.0   0:00.80 migration/1                                                            

    6 root      34  19     0    0    0 S  0.0  0.0   0:00.00 ksoftirqd/1                                                            

    7 root      RT  -5     0    0    0 S  0.0  0.0   0:00.00 watchdog/1                                                             

    8 root      RT  -5     0    0    0 S  0.0  0.0   0:20.59 migration/2                                                            

    9 root      34  19     0    0    0 S  0.0  0.0   0:00.09 ksoftirqd/2                                                            

   10 root      RT  -5     0    0    0 S  0.0  0.0   0:00.00 watchdog/2                                                             

   11 root      RT  -5     0    0    0 S  0.0  0.0   0:23.66 migration/3                                                            

   12 root      34  19     0    0    0 S  0.0  0.0   0:00.03 ksoftirqd/3                                                            

   13 root      RT  -5     0    0    0 S  0.0  0.0   0:00.00 watchdog/3                                                             

   14 root      RT  -5     0    0    0 S  0.0  0.0   0:20.29 migration/4                                                            

   15 root      34  19     0    0    0 S  0.0  0.0   0:00.07 ksoftirqd/4                                                            

   16 root      RT  -5     0    0    0 S  0.0  0.0   0:00.00 watchdog/4                                                             

   17 root      RT  -5     0    0    0 S  0.0  0.0   0:23.07 migration/5                                                            

   18 root      34  19     0    0    0 S  0.0  0.0   0:00.07 ksoftirqd/5                                                            

   19 root      RT  -5     0    0    0 S  0.0  0.0   0:00.00 watchdog/5                                                             

   20 root      RT  -5     0    0    0 S  0.0  0.0   0:17.16 migration/6                                                            

   21 root      34  19     0    0    0 S  0.0  0.0   0:00.05 ksoftirqd/6                                                            

   22 root      RT  -5     0    0    0 S  0.0  0.0   0:00.00 watchdog/6                                                             

   23 root      RT  -5     0    0    0 S  0.0  0.0   0:58.28 migration/7





说明：

统计信息区：

前五行是当前系统情况整体的统计信息区。下面我们看每一行信息的具体意义。

第一行，任务队列信息，同 uptime 命令的执行结果，具体参数说明情况如下：

14:06:23 — 当前系统时间

up 70 days, 16:44 — 系统已经运行了70天16小时44分钟（在这期间系统没有重启过的吆！）

2 users — 当前有2个用户登录系统

load average: 1.15, 1.42, 1.44 — load average后面的三个数分别是1分钟、5分钟、15分钟的负载情况。

load average数据是每隔5秒钟检查一次活跃的进程数，然后按特定算法计算出的数值。如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了。

第二行，Tasks — 任务（进程），具体信息说明如下：

系统现在共有206个进程，其中处于运行中的有1个，205个在休眠（sleep），stoped状态的有0个，zombie状态（僵尸）的有0个。

第三行，cpu状态信息，具体属性说明如下：

5.9%us — 用户空间占用CPU的百分比。

3.4% sy — 内核空间占用CPU的百分比。

0.0% ni — 改变过优先级的进程占用CPU的百分比

90.4% id — 空闲CPU百分比

0.0% wa — IO等待占用CPU的百分比

0.0% hi — 硬中断（Hardware IRQ）占用CPU的百分比

0.2% si — 软中断（Software Interrupts）占用CPU的百分比

备注：在这里CPU的使用比率和windows概念不同，需要理解linux系统用户空间和内核空间的相关知识！

第四行,内存状态，具体信息如下：

32949016k total — 物理内存总量（32GB）

14411180k used — 使用中的内存总量（14GB）

18537836k free — 空闲内存总量（18GB）

169884k buffers — 缓存的内存量 （169M）

第五行，swap交换分区信息，具体信息说明如下：

32764556k total — 交换区总量（32GB）

0k used — 使用的交换区总量（0K）

32764556k free — 空闲交换区总量（32GB）

3612636k cached — 缓冲的交换区总量（3.6GB）



备注：

第四行中使用中的内存总量（used）指的是现在系统内核控制的内存数，空闲内存总量（free）是内核还未纳入其管控范围的数量。纳入内核管理的内存不见得都在使用中，还包括过去使用过的现在可以被重复利用的内存，内核并不把这些可被重新使用的内存交还到free中去，因此在linux上free内存会越来越少，但不用为此担心。

如果出于习惯去计算可用内存数，这里有个近似的计算公式：第四行的free + 第四行的buffers + 第五行的cached，按这个公式此台服务器的可用内存：18537836k +169884k +3612636k = 22GB左右。

对于内存监控，在top里我们要时刻监控第五行swap交换分区的used，如果这个数值在不断的变化，说明内核在不断进行内存和swap的数据交换，这是真正的内存不够用了。

第六行，空行。

第七行以下：各进程（任务）的状态监控，项目列信息说明如下：

PID — 进程id

USER — 进程所有者

PR — 进程优先级

NI — nice值。负值表示高优先级，正值表示低优先级

VIRT — 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES

RES — 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA

SHR — 共享内存大小，单位kb

S — 进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程

%CPU — 上次更新到现在的CPU时间占用百分比

%MEM — 进程使用的物理内存百分比

TIME+ — 进程使用的CPU时间总计，单位1/100秒

COMMAND — 进程名称（命令名/命令行）



其他使用技巧：

1.多U多核CPU监控

在top基本视图中，按键盘数字“1”，可监控每个逻辑CPU的状况：

 

观察上图，服务器有16个逻辑CPU，实际上是4个物理CPU。再按数字键1，就会返回到top基本视图界面。

2.高亮显示当前运行进程

敲击键盘“b”（打开/关闭加亮效果），top的视图变化如下：

     

我们发现进程id为2570的“top”进程被加亮了，top进程就是视图第二行显示的唯一的运行态（runing）的那个进程，可以通过敲击“y”键关闭或打开运行态进程的加亮效果。

3.进程字段排序

默认进入top时，各进程是按照CPU的占用量来排序的，在下图中进程ID为28894的java进程排在第一（cpu占用142%），进程ID为574的java进程排在第二（cpu占用16%）。

      

    敲击键盘“x”（打开/关闭排序列的加亮效果），top的视图变化如下：

       


可以看到，top默认的排序列是“%CPU”。



4. 通过”shift + &gt;”或”shift + &lt;”可以向右或左改变排序列

下图是按一次”shift + &gt;”的效果图,视图现在已经按照%MEM来排序。

       
 



实例2：显示 完整命令

命令：top -c






实例3：以批处理模式显示程序信息

命令：top -b






实例4：以累积模式显示程序信息

命令：top -S






实例5：设置信息更新次数

命令：top -n 2

说明：表示更新两次后终止更新显示






实例6：设置信息更新时间

命令：top -d 3

说明：表示更新周期为3秒






实例7：显示指定的进程信息

命令：top -p 574




     5.top交互命令



在top 命令执行过程中可以使用的一些交互命令。这些命令都是单字母的，如果在命令行中使用了s 选项， 其中一些命令可能会被屏蔽。

h 显示帮助画面，给出一些简短的命令总结说明

k 终止一个进程。

i 忽略闲置和僵死进程。这是一个开关式命令。

q 退出程序

r 重新安排一个进程的优先级别

S 切换到累计模式

s 改变两次刷新之间的延迟时间（单位为s），如果有小数，就换算成m s。输入0值则系统将不断刷新，默认值是5 s

f或者F 从当前显示中添加或者删除项目

o或者O 改变显示项目的顺序

l 切换显示平均负载和启动时间信息

m 切换显示内存信息

t 切换显示进程和CPU状态信息

c 切换显示命令名称和完整命令行

M 根据驻留内存大小进行排序

P 根据CPU使用百分比大小进行排序

T 根据时间/累计时间进行排序
W 将当前设置写入~/.toprc文件中


Linux系统中的killall命令用于杀死指定名字的进程（kill processes by name）。我们可以使用kill命令杀死指定进程PID的进程，如果要找到我们需要杀死的进程，我们还需要在之前使用ps等命令再配合grep来查找进程，而killall把这两个过程合二为一，是一个很好用的命令。

1．命令格式：

killall[参数][进程名]

2．命令功能：

用来结束同名的的所有进程

3．命令参数：

-Z 只杀死拥有scontext 的进程

-e 要求匹配进程名称

-I 忽略小写

-g 杀死进程组而不是进程

-i 交互模式，杀死进程前先询问用户

-l 列出所有的已知信号名称

-q 不输出警告信息

-s 发送指定的信号

-v 报告信号是否成功发送

-w 等待进程死亡

--help 显示帮助信息

--version 显示版本显示



4．使用实例：

实例1：杀死所有同名进程

命令：killall vi






实例2：向进程发送指定信号

命令：

后台运行程序：vi &amp;

杀死 vi进程：killall -TERM vi  或者  killall -KILL vi






实例3：把所有的登录后的shell给杀掉

命令：killall -9 bash

输出：

[root@localhost ~]# w

 18:01:03 up 41 days, 18:53,  3 users,  load average: 0.00, 0.00, 0.00USER     TTY      FROM              LOGIN@   IDLE   JCPU   PCPU WHAT

root     pts/0    10.2.0.68        14:58    9:52   0.10s  0.10s -bash

root     pts/1    10.2.0.68        17:51    0.00s  0.02s  0.00s w

root     pts/2    10.2.0.68        17:51    9:24   0.01s  0.01s -bash

[root@localhost ~]# killall -9 bash

[root@localhost ~]# w

 18:01:48 up 41 days, 18:54,  1 user,  load average: 0.07, 0.02, 0.00USER     TTY      FROM              LOGIN@   IDLE   JCPU   PCPU WHAT

root     pts/0    10.2.0.68        18:01    0.00s  0.01s  0.00s w

[root@localhost ~]#



说明：

运行命令：killall -9 bash 后，所有bash都会被卡掉了，所以当前所有连接丢失了。需要重新连接并登录。


Linux中的kill命令用来终止指定的进程（terminate a process）的运行，是Linux下进程管理的常用命令。通常，终止一个前台进程可以使用Ctrl+C键，但是，对于一个后台进程就须用kill命令来终止，我们就需要先使用ps/pidof/pstree/top等工具获取进程PID，然后使用kill命令来杀掉该进程。kill命令是通过向进程发送指定的信号来结束相应进程的。在默认情况下，采用编号为15的TERM信号。TERM信号将终止所有不能捕获该信号的进程。对于那些可以捕获该信号的进程就要用编号为9的kill信号，强行“杀掉”该进程。 

1．命令格式：

kill[参数][进程号]

2．命令功能：

发送指定的信号到相应进程。不指定型号将发送SIGTERM（15）终止指定进程。如果无法终止该程序可用“-KILL”参数，其发送的信号为SIGKILL(9)，将强制结束进程，使用ps命令或者jobs命令可以查看进程号。root用户将影响用户的进程，非root用户只能影响自己的进程。



3．命令参数：

-l  信号，若果不加信号的编号参数，则使用“-l”参数会列出全部的信号名称

-a  当处理当前进程时，不限制命令名和进程号的对应关系

-p  指定kill 命令只打印相关进程的进程号，而不发送任何信号

-s  指定发送信号

-u  指定用户 



注意：

1、kill命令可以带信号号码选项，也可以不带。如果没有信号号码，kill命令就会发出终止信号(15)，这个信号可以被进程捕获，使得进程在退出之前可以清理并释放资源。也可以用kill向进程发送特定的信号。例如：

kill -2 123

它的效果等同于在前台运行PID为123的进程时按下Ctrl+C键。但是，普通用户只能使用不带signal参数的kill命令或最多使用-9信号。

2、kill可以带有进程ID号作为参数。当用kill向这些进程发送信号时，必须是这些进程的主人。如果试图撤销一个没有权限撤销的进程或撤销一个不存在的进程，就会得到一个错误信息。

3、可以向多个进程发信号或终止它们。

4、当kill成功地发送了信号后，shell会在屏幕上显示出进程的终止信息。有时这个信息不会马上显示，只有当按下Enter键使shell的命令提示符再次出现时，才会显示出来。

5、应注意，信号使进程强行终止，这常会带来一些副作用，如数据丢失或者终端无法恢复到正常状态。发送信号时必须小心，只有在万不得已时，才用kill信号(9)，因为进程不能首先捕获它。要撤销所有的后台作业，可以输入kill 0。因为有些在后台运行的命令会启动多个进程，跟踪并找到所有要杀掉的进程的PID是件很麻烦的事。这时，使用kill 0来终止所有由当前shell启动的进程，是个有效的方法。

4．使用实例：

实例1：列出所有信号名称

命令：kill -l






实例2：得到指定信号的数值

命令：kill -l KILL

     kill -l SIGKILL

 
     kill -l TERM

 
     kill -l SIGTERM






实例3：先用ps查找进程，然后用kill杀掉

命令：kill 3268






实例4：彻底杀死进程

命令：kill –9 3268 






实例5：杀死指定用户所有进程

命令：kill -9 $(ps -ef | grep peidalinux)

    kill -u peidalinux






实例6：init进程是不可杀的

命令：kill -9 1



说明：

init是Linux系统操作中不可缺少的程序之一。所谓的init进程，它是一个由内核启动的用户级进程。内核自行启动（已经被载入内存，开始运行，并已初始化所有的设备驱动程序和数据结构等）之后，就通过启动一个用户级程序init的方式，完成引导进程。所以,init始终是第一个进程（其进程编号始终为1）。其它所有进程都是init进程的子孙。init进程是不可杀的！


Linux中的ps命令是Process Status的缩写。ps命令用来列出系统中当前运行的那些进程。ps命令列出的是当前那些进程的快照，就是执行ps命令的那个时刻的那些进程，如果想要动态的显示进程信息，就可以使用top命令。

要对进程进行监测和控制，首先必须要了解当前进程的情况，也就是需要查看当前进程，而 ps 命令就是最基本同时也是非常强大的进程查看命令。使用该命令可以确定有哪些进程正在运行和运行的状态、进程是否结束、进程有没有僵死、哪些进程占用了过多的资源等等。总之大部分信息都是可以通过执行该命令得到的。

ps 为我们提供了进程的一次性的查看，它所提供的查看结果并不动态连续的；如果想对进程时间监控，应该用 top 工具。

kill 命令用于杀死进程。



linux上进程有5种状态: 

1. 运行(正在运行或在运行队列中等待) 

2. 中断(休眠中,受阻,在等待某个条件的形成或接受到信号) 

3. 不可中断(收到信号不唤醒和不可运行,进程必须等待直到有中断发生) 

4. 僵死(进程已终止,但进程描述符存在,直到父进程调用wait4()系统调用后释放) 

5. 停止(进程收到SIGSTOP, SIGSTP, SIGTIN, SIGTOU信号后停止运行运行) 



ps工具标识进程的5种状态码: 

D 不可中断 uninterruptible sleep (usually IO) 

R 运行 runnable (on run queue) 

S 中断 sleeping 

T 停止 traced or stopped 

Z 僵死 a defunct (”zombie”) process 



1．命令格式：

ps[参数]

2．命令功能：

用来显示当前进程的状态

3．命令参数：

a  显示所有进程

-a 显示同一终端下的所有程序

-A 显示所有进程

c  显示进程的真实名称

-N 反向选择

-e 等于“-A”

e  显示环境变量

f  显示程序间的关系

-H 显示树状结构

r  显示当前终端的进程

T  显示当前终端的所有程序

u  指定用户的所有进程

-au 显示较详细的资讯

-aux 显示所有包含其他使用者的行程 

-C&lt;命令&gt; 列出指定命令的状况

--lines&lt;行数&gt; 每页显示的行数

--width&lt;字符数&gt; 每页显示的字符数

--help 显示帮助信息

--version 显示版本显示

4．使用实例：

实例1：显示所有进程信息

命令：ps -A






实例2：显示指定用户信息

命令：ps -u root






实例3：显示所有进程信息，连同命令行

命令：ps -ef






实例4： ps 与grep 常用组合用法，查找特定进程

命令：ps -ef|grep ssh






实例5：将目前属于您自己这次登入的 PID 与相关信息列示出来

命令：ps -l

输出：

[root@localhost test6]# ps -l

F S   UID   PID  PPID  C PRI  NI ADDR SZ WCHAN  TTY          TIME CMD

4 S     0 17398 17394  0  75   0 - 16543 wait   pts/0    00:00:00 bash

4 R     0 17469 17398  0  77   0 - 15877 -      pts/0    00:00:00 ps



说明：

各相关信息的意义：

F 代表这个程序的旗标 (flag)， 4 代表使用者为 super user

S 代表这个程序的状态 (STAT)，关于各 STAT 的意义将在内文介绍

UID 程序被该 UID 所拥有

PID 就是这个程序的 ID ！

PPID 则是其上级父程序的ID

C CPU 使用的资源百分比

PRI 这个是 Priority (优先执行序) 的缩写，详细后面介绍

NI 这个是 Nice 值，在下一小节我们会持续介绍

ADDR 这个是 kernel function，指出该程序在内存的那个部分。如果是个 running的程序，一般就是 "-"

SZ 使用掉的内存大小

WCHAN 目前这个程序是否正在运作当中，若为 - 表示正在运作

TTY 登入者的终端机位置

TIME 使用掉的 CPU 时间。

CMD 所下达的指令为何



在预设的情况下， ps 仅会列出与目前所在的 bash shell 有关的 PID 而已，所以， 当我使用 ps -l 的时候，只有三个 PID。



实例6：列出目前所有的正在内存当中的程序

命令：ps aux

输出：

[root@localhost test6]# ps aux

USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND

root         1  0.0  0.0  10368   676 ?        Ss   Nov02   0:00 init [3]                  

root         2  0.0  0.0      0     0 ?        S&lt;   Nov02   0:01 [migration/0]

root         3  0.0  0.0      0     0 ?        SN   Nov02   0:00 [ksoftirqd/0]

root         4  0.0  0.0      0     0 ?        S&lt;   Nov02   0:01 [migration/1]

root         5  0.0  0.0      0     0 ?        SN   Nov02   0:00 [ksoftirqd/1]

root         6  0.0  0.0      0     0 ?        S&lt;   Nov02  29:57 [events/0]

root         7  0.0  0.0      0     0 ?        S&lt;   Nov02   0:00 [events/1]

root         8  0.0  0.0      0     0 ?        S&lt;   Nov02   0:00 [khelper]

root        49  0.0  0.0      0     0 ?        S&lt;   Nov02   0:00 [kthread]

root        54  0.0  0.0      0     0 ?        S&lt;   Nov02   0:00 [kblockd/0]

root        55  0.0  0.0      0     0 ?        S&lt;   Nov02   0:00 [kblockd/1]

root        56  0.0  0.0      0     0 ?        S&lt;   Nov02   0:00 [kacpid]

……省略部分结果



说明：

USER：该 process 属于那个使用者账号的

PID ：该 process 的号码

%CPU：该 process 使用掉的 CPU 资源百分比

%MEM：该 process 所占用的物理内存百分比

VSZ ：该 process 使用掉的虚拟内存量 (Kbytes)

RSS ：该 process 占用的固定的内存量 (Kbytes)

TTY ：该 process 是在那个终端机上面运作，若与终端机无关，则显示 ?，另外， tty1-tty6 是本机上面的登入者程序，若为 pts/0 等等的，则表示为由网络连接进主机的程序。

STAT：该程序目前的状态，主要的状态有

R ：该程序目前正在运作，或者是可被运作

S ：该程序目前正在睡眠当中 (可说是 idle 状态)，但可被某些讯号 (signal) 唤醒。

T ：该程序目前正在侦测或者是停止了

Z ：该程序应该已经终止，但是其父程序却无法正常的终止他，造成 zombie (疆尸) 程序的状态

START：该 process 被触发启动的时间

TIME ：该 process 实际使用 CPU 运作的时间

COMMAND：该程序的实际指令



实例7：列出类似程序树的程序显示

命令：ps -axjf






实例8：找出与 cron 与 syslog 这两个服务有关的 PID 号码

命令：ps aux | egrep '(cron|syslog)'






其他实例：

1. 可以用 | 管道和 more 连接起来分页查看

命令：ps -aux |more



2. 把所有进程显示出来，并输出到ps001.txt文件

命令：ps -aux &gt; ps001.txt



3. 输出指定的字段

命令：ps -o pid,ppid,pgrp,session,tpgid,comm


Linux系统中的wc(Word Count)命令的功能为统计指定文件中的字节数、字数、行数，并将统计结果显示输出。

1．命令格式：

wc [选项]文件...

2．命令功能：

统计指定文件中的字节数、字数、行数，并将统计结果显示输出。该命令统计指定文件中的字节数、字数、行数。如果没有给出文件名，则从标准输入读取。wc同时也给出所指定文件的总统计数。

3．命令参数：

-c 统计字节数。

-l 统计行数。

-m 统计字符数。这个标志不能与 -c 标志一起使用。

-w 统计字数。一个字被定义为由空白、跳格或换行字符分隔的字符串。

-L 打印最长行的长度。

-help 显示帮助信息

--version 显示版本信息

4．使用实例：

实例1：查看文件的字节数、字数、行数

命令：wc test.txt








实例2：用wc命令怎么做到只打印统计数字不打印文件名

命令：wc -l test.txt

说明：使用管道线，这在编写shell脚本时特别有用。






实例3：用来统计当前目录下的文件数

命令：ls -l | wc -l

说明：数量中包含当前目录


Linux系统中grep命令是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。grep全称是Global Regular Expression Print，表示全局正则表达式版本，它的使用权限是所有用户。

grep的工作方式是这样的，它在一个或多个文件中搜索字符串模板。如果模板包括空格，则必须被引用，模板后的所有字符串被看作文件名。搜索的结果被送到标准输出，不影响原文件内容。

grep可用于shell脚本，因为grep通过返回一个状态值来说明搜索的状态，如果模板搜索成功，则返回0，如果搜索不成功，则返回1，如果搜索的文件不存在，则返回2。我们利用这些返回值就可进行一些自动化的文本处理工作。



1．命令格式：

grep [option] pattern file

2．命令功能：

用于过滤/搜索的特定字符。可使用正则表达式和多种命令配合使用，使用上十分灵活。

3．命令参数：

-a   --text   #不要忽略二进制的数据。   

-A&lt;显示行数&gt;   --after-context=&lt;显示行数&gt;   #除了显示符合范本样式的那一列之外，并显示该行之后的内容。   

-b   --byte-offset   #在显示符合样式的那一行之前，标示出该行第一个字符的编号。   

-B&lt;显示行数&gt;   --before-context=&lt;显示行数&gt;   #除了显示符合样式的那一行之外，并显示该行之前的内容。   

-c    --count   #计算符合样式的列数。   

-C&lt;显示行数&gt;    --context=&lt;显示行数&gt;或-&lt;显示行数&gt;   #除了显示符合样式的那一行之外，并显示该行之前后的内容。   

-d &lt;动作&gt;      --directories=&lt;动作&gt;   #当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作。   

-e&lt;范本样式&gt;  --regexp=&lt;范本样式&gt;   #指定字符串做为查找文件内容的样式。   

-E      --extended-regexp   #将样式为延伸的普通表示法来使用。   

-f&lt;规则文件&gt;  --file=&lt;规则文件&gt;   #指定规则文件，其内容含有一个或多个规则样式，让grep查找符合规则条件的文件内容，格式为每行一个规则样式。   

-F   --fixed-regexp   #将样式视为固定字符串的列表。   

-G   --basic-regexp   #将样式视为普通的表示法来使用。   

-h   --no-filename   #在显示符合样式的那一行之前，不标示该行所属的文件名称。   

-H   --with-filename   #在显示符合样式的那一行之前，表示该行所属的文件名称。   

-i    --ignore-case   #忽略字符大小写的差别。   

-l    --file-with-matches   #列出文件内容符合指定的样式的文件名称。   

-L   --files-without-match   #列出文件内容不符合指定的样式的文件名称。   

-n   --line-number   #在显示符合样式的那一行之前，标示出该行的列数编号。   

-q   --quiet或--silent   #不显示任何信息。   

-r   --recursive   #此参数的效果和指定“-d recurse”参数相同。   

-s   --no-messages   #不显示错误信息。   

-v   --revert-match   #显示不包含匹配文本的所有行。   

-V   --version   #显示版本信息。   

-w   --word-regexp   #只显示全字符合的列。   

-x    --line-regexp   #只显示全列符合的列。   

-y   #此参数的效果和指定“-i”参数相同。

  

4．规则表达式：

grep的规则表达式:

^  #锚定行的开始 如：'^grep'匹配所有以grep开头的行。    

$  #锚定行的结束 如：'grep$'匹配所有以grep结尾的行。    

.  #匹配一个非换行符的字符 如：'gr.p'匹配gr后接一个任意字符，然后是p。    

*  #匹配零个或多个先前字符 如：'*grep'匹配所有一个或多个空格后紧跟grep的行。    

.*   #一起用代表任意字符。   

[]   #匹配一个指定范围内的字符，如'[Gg]rep'匹配Grep和grep。    

[^]  #匹配一个不在指定范围内的字符，如：'[^A-FH-Z]rep'匹配不包含A-R和T-Z的一个字母开头，紧跟rep的行。    

\(..\)  #标记匹配字符，如'\(love\)'，love被标记为1。    

\&lt;      #锚定单词的开始，如:'\&lt;grep'匹配包含以grep开头的单词的行。    

\&gt;      #锚定单词的结束，如'grep\&gt;'匹配包含以grep结尾的单词的行。    

x\{m\}  #重复字符x，m次，如：'0\{5\}'匹配包含5个o的行。    

x\{m,\}  #重复字符x,至少m次，如：'o\{5,\}'匹配至少有5个o的行。    

x\{m,n\}  #重复字符x，至少m次，不多于n次，如：'o\{5,10\}'匹配5--10个o的行。   

\w    #匹配文字和数字字符，也就是[A-Za-z0-9]，如：'G\w*p'匹配以G后跟零个或多个文字或数字字符，然后是p。   

\W    #\w的反置形式，匹配一个或多个非单词字符，如点号句号等。   

\b    #单词锁定符，如: '\bgrep\b'只匹配grep。  



POSIX字符:

为了在不同国家的字符编码中保持一至，POSIX(The Portable Operating System Interface)增加了特殊的字符类，如[:alnum:]是[A-Za-z0-9]的另一个写法。要把它们放到[]号内才能成为正则表达式，如[A- Za-z0-9]或[[:alnum:]]。在linux下的grep除fgrep外，都支持POSIX的字符类。



[:alnum:]    #文字数字字符   

[:alpha:]    #文字字符   

[:digit:]    #数字字符   

[:graph:]    #非空字符（非空格、控制字符）   

[:lower:]    #小写字符   

[:cntrl:]    #控制字符   

[:print:]    #非空字符（包括空格）   

[:punct:]    #标点符号   

[:space:]    #所有空白字符（新行，空格，制表符）   

[:upper:]    #大写字符   

[:xdigit:]   #十六进制数字（0-9，a-f，A-F）  

5．使用实例：

实例1：查找指定进程

命令：ps -ef|grep svn

说明：

第一条记录是查找出的进程；第二条结果是grep进程本身，并非真正要找的进程。






实例2：查找指定进程个数

命令：

ps -ef|grep svn -c

ps -ef|grep -c svn






实例3：从文件中读取关键词进行搜索

命令：cat test.txt | grep -f test2.txt

说明：

输出test.txt文件中含有从test2.txt文件中读取出的关键词的内容行






   实例3：从文件中读取关键词进行搜索 且显示行号

   命令：cat test.txt | grep -nf test2.txt



   说明：输出test.txt文件中含有从test2.txt文件中读取出的关键词的内容行，并显示每一行的行号






   实例5：从文件中查找关键词

   命令：grep 'linux' test.txt






   实例6：从多个文件中查找关键词

   命令：grep 'linux' test.txt test2.txt



   说明：多文件时，输出查询到的信息内容行时，会把文件的命名在行最前面输出并且加上":"作为标示符






   实例7：grep不显示本身进程

   命令：

      ps aux|grep \[s]sh

      ps aux | grep ssh | grep -v "grep"






   实例8：找出已u开头的行内容

   命令：cat test.txt |grep ^u






   实例9：输出非u开头的行内容

   命令：cat test.txt |grep ^[^u]






   实例10：输出以hat结尾的行内容

   命令：cat test.txt |grep hat$






   实例11：显示包含ed或者at字符的内容行

   命令：cat test.txt |grep -E "ed|at"






   实例13：显示当前目录下面以.txt 结尾的文件中的所有包含每个字符串至少有7个连续小写字符的字符串的行

   命令：grep '[a-z]\{7\}' *.txt


cal命令可以用来显示公历（阳历）日历。公历是现在国际通用的历法，又称格列历，通称阳历。“阳历”又名“太阳历”，系以地球绕行太阳一周为一年，为西方各国所通用，故又名“西历”。

1．命令格式：

cal [参数][月份][年份]

2．命令功能：

用于查看日历等时间信息，如只有一个参数，则表示年份(1-9999)，如有两个参数，则表示月份和年份

3．命令参数：

-1 显示一个月的月历

-3 显示系统前一个月，当前月，下一个月的月历

-s  显示星期天为一个星期的第一天，默认的格式

-m 显示星期一为一个星期的第一天
       -j  显示在当年中的第几天（一年日期按天算，从1月1号算起，默认显示当前月在一年中的天数）
       -y  显示当前年份的日历



4．使用实例：

实例1：显示当前月份日历

命令：cal






实例2：显示指定月份的日历

命令：cal 9 2012




实例3：显示2013年日历

命令：cal -y 2013 






  实例4：显示自1月1日的天数

  命令：cal -j






实例5：星期一显示在第一列

  命令：cal -m


在linux环境中，不管是编程还是其他维护，时间是必不可少的，也经常会用到时间的运算，熟练运用date命令来表示自己想要表示的时间，肯定可以给自己的工作带来诸多方便。

1．命令格式：

  
date [参数]... [+格式]

2．命令功能：

date 可以用来显示或设定系统的日期与时间。

3．命令参数：

必要参数:

%H 小时(以00-23来表示)。 

%I 小时(以01-12来表示)。 

%K 小时(以0-23来表示)。 

%l 小时(以0-12来表示)。 

%M 分钟(以00-59来表示)。 

%P AM或PM。 

%r 时间(含时分秒，小时以12小时AM/PM来表示)。 

%s 总秒数。起算时间为1970-01-01 00:00:00 UTC。 

%S 秒(以本地的惯用法来表示)。 

%T 时间(含时分秒，小时以24小时制来表示)。 

%X 时间(以本地的惯用法来表示)。 

%Z 市区。 

%a 星期的缩写。 

%A 星期的完整名称。 

%b 月份英文名的缩写。 

%B 月份的完整英文名称。 

%c 日期与时间。只输入date指令也会显示同样的结果。 

%d 日期(以01-31来表示)。 

%D 日期(含年月日)。 

%j 该年中的第几天。 

%m 月份(以01-12来表示)。 

%U 该年中的周数。 

%w 该周的天数，0代表周日，1代表周一，异词类推。 

%x 日期(以本地的惯用法来表示)。 

%y 年份(以00-99来表示)。 

%Y 年份(以四位数来表示)。 

%n 在显示时，插入新的一行。 

%t 在显示时，插入tab。 

MM 月份(必要) 

DD 日期(必要) 

hh 小时(必要) 

mm 分钟(必要)

ss 秒(选择性) 



选择参数:

-d&lt;字符串&gt; 　显示字符串所指的日期与时间。字符串前后必须加上双引号。 

-s&lt;字符串&gt; 　根据字符串来设置日期与时间。字符串前后必须加上双引号。 

-u 　显示GMT。 

--help 　在线帮助。 

--version 　显示版本信息 



4．使用说明：

1.在显示方面，使用者可以设定欲显示的格式，格式设定为一个加号后接数个标记，其中可用的标记列表如下: % :  打印出 %：

%n : 下一行

%t : 跳格

%H : 小时(00..23)

%I : 小时(01..12)

%k : 小时(0..23)

%l : 小时(1..12)

%M : 分钟(00..59)

%p : 显示本地 AM 或 PM

%r : 直接显示时间 (12 小时制，格式为 hh:mm:ss [AP]M)

%s : 从 1970 年 1 月 1 日 00:00:00 UTC 到目前为止的秒数

%S : 秒(00..61)

%T : 直接显示时间 (24 小时制)

%X : 相当于 %H:%M:%S

%Z : 显示时区 %a : 星期几 (Sun..Sat)

%A : 星期几 (Sunday..Saturday)

%b : 月份 (Jan..Dec)

%B : 月份 (January..December)

%c : 直接显示日期与时间

%d : 日 (01..31)

%D : 直接显示日期 (mm/dd/yy)

%h : 同 %b

%j : 一年中的第几天 (001..366)

%m : 月份 (01..12)

%U : 一年中的第几周 (00..53) (以 Sunday 为一周的第一天的情形)

%w : 一周中的第几天 (0..6)

%W : 一年中的第几周 (00..53) (以 Monday 为一周的第一天的情形)

%x : 直接显示日期 (mm/dd/yy)

%y : 年份的最后两位数字 (00.99)

%Y : 完整年份 (0000..9999)



2.在设定时间方面：

date -s //设置当前时间，只有root权限才能设置，其他只能查看。

date -s 20080523 //设置成20080523，这样会把具体时间设置成空00:00:00

date -s 01:01:01 //设置具体时间，不会对日期做更改

date -s “01:01:01 2008-05-23″ //这样可以设置全部时间

date -s “01:01:01 20080523″ //这样可以设置全部时间

date -s “2008-05-23 01:01:01″ //这样可以设置全部时间

date -s “20080523 01:01:01″ //这样可以设置全部时间

3.加减：

date +%Y%m%d         //显示前天年月日

date +%Y%m%d --date="+1 day"  //显示前一天的日期

date +%Y%m%d --date="-1 day"  //显示后一天的日期

date +%Y%m%d --date="-1 month"  //显示上一月的日期

date +%Y%m%d --date="+1 month"  //显示下一月的日期

date +%Y%m%d --date="-1 year"  //显示前一年的日期

date +%Y%m%d --date="+1 year"  //显示下一年的日期



5．使用实例：

实例1：显示当前时间

命令：

date

date '+%c'

date '+%D'

date '+%x'

date '+%T'

date '+%X'

输出：

[root@localhost ~]# date

2016年 5月 26日 星期四 08:31:35 CST

[root@localhost ~]# date '+%c'

2016年 5月 26日 星期四 08时34分44秒

[root@localhost ~]# date '+%x'

2016年5月26日

[root@localhost ~]# date '+%T'

08:35:36

[root@localhost ~]# date '+%X'

08时35分54秒






实例2：显示日期和设定时间

命令：date --date 08:42:00

输出：

[root@localhost ~]# date '+%c'

2016年5月26日 星期四 08时41分37秒

[root@localhost ~]# date --date 08:42:00

2016年5月26日 星期四 08:42:00 CST

[root@localhost ~]# date '+%c' --date 08:45:00

2016年5月26日 星期四 08时45分00秒








实例3：date -d参数使用

命令：

输出：

[root@localhost ~]# date -d "nov 22"

2016年5月26日 星期四 00:00:00 CST

[root@localhost ~]# date -d '2 weeks'

2016年5月26日 星期四08:50:21 CST

说明：

date 命令的另一个扩展是 -d 选项，该选项非常有用。使用这个功能强大的选项，通过将日期作为引号括起来的参数提供，您可以快速地查明一个特定的日期。-d 选项还可以告诉您，相对于当前日期若干天的究竟是哪一天，从现在开始的若干天或若干星期以后，或者以前（过去）。通过将这个相对偏移使用引号括起来，作为 -d 选项的参数，就可以完成这项任务。

具体说明如下：

date -d "nov 22"  今年的 11 月 22 日是星期三

date -d '2 weeks' 2周后的日期

date -d 'next monday' (下周一的日期)

date -d next-day +%Y%m%d（明天的日期）或者：date -d tomorrow +%Y%m%d

date -d last-day +%Y%m%d(昨天的日期) 或者：date -d yesterday +%Y%m%d

date -d last-month +%Y%m(上个月是几月)

date -d next-month +%Y%m(下个月是几月)

使用 ago 指令，您可以得到过去的日期：

date -d '30 days ago' （30天前的日期）

使用负数以得到相反的日期：

date -d 'dec 14 -2 weeks' （相对:dec 14这个日期的两周前的日期）

date -d '-100 days' (100天以前的日期)

date -d '50 days'(50天后的日期)






实例4：显示月份和日数

命令：date  '+%B %d'






实例5：显示时间后跳行，再显示目前日期 

命令：date '+%T%n%D'


diff命令是linux上非常重要的命令，用于比较文件的内容，特别是比较两个版本不同的文件以找到改动的地方。diff在命令行中打印每一个行的改动。最新版本的diff还支持二进制文件。diff程序的输出被称为补丁(patch)，因为Linux系统中还有一个patch程序，可以根据diff的输出将a.c的文件内容更新为b.c。diff是svn、cvs、git等版本控制工具不可或缺的一部分。

1．命令格式：

diff[参数][文件1或目录1][文件2或目录2]

2．命令功能：

diff命令能比较单个文件或者目录内容。如果指定比较的是文件，则只有当输入为文本文件时才有效。以逐行的方式，比较文本文件的异同处。如果指定比较的是目录的的时候，diff命令会比较两个目录下名字相同的文本文件。列出不同的二进制文件、公共子目录和只在一个目录出现的文件。



3．命令参数：

- 指定要显示多少行的文本。此参数必须与-c或-u参数一并使用。

-a或--text 　diff预设只会逐行比较文本文件。

-b或--ignore-space-change 　不检查空格字符的不同。

-B或--ignore-blank-lines 　不检查空白行。

-c 　显示全部内文，并标出不同之处。

-C或--context 　与执行"-c-"指令相同。

-d或--minimal 　使用不同的演算法，以较小的单位来做比较。

-D或ifdef 　此参数的输出格式可用于前置处理器巨集。

-e或--ed 　此参数的输出格式可用于ed的script文件。

-f或-forward-ed 　输出的格式类似ed的script文件，但按照原来文件的顺序来显示不同处。

-H或--speed-large-files 　比较大文件时，可加快速度。

-l或--ignore-matching-lines 　若两个文件在某几行有所不同，而这几行同时都包含了选项中指定的字符或字符串，则不显示这两个文件的差异。

-i或--ignore-case 　不检查大小写的不同。

-l或--paginate 　将结果交由pr程序来分页。

-n或--rcs 　将比较结果以RCS的格式来显示。

-N或--new-file 　在比较目录时，若文件A仅出现在某个目录中，预设会显示：Only in目录：文件A若使用-N参数，则diff会将文件A与一个空白的文件比较。

-p 　若比较的文件为C语言的程序码文件时，显示差异所在的函数名称。

-P或--unidirectional-new-file 　与-N类似，但只有当第二个目录包含了一个第一个目录所没有的文件时，才会将这个文件与空白的文件做比较。

-q或--brief 　仅显示有无差异，不显示详细的信息。

-r或--recursive 　比较子目录中的文件。

-s或--report-identical-files 　若没有发现任何差异，仍然显示信息。

-S或--starting-file 　在比较目录时，从指定的文件开始比较。

-t或--expand-tabs 　在输出时，将tab字符展开。

-T或--initial-tab 　在每行前面加上tab字符以便对齐。

-u,-U或--unified= 　以合并的方式来显示文件内容的不同。

-v或--version 　显示版本信息。

-w或--ignore-all-space 　忽略全部的空格字符。

-W或--width 　在使用-y参数时，指定栏宽。

-x或--exclude 　不比较选项中所指定的文件或目录。

-X或--exclude-from 　您可以将文件或目录类型存成文本文件，然后在=中指定此文本文件。

-y或--side-by-side 　以并列的方式显示文件的异同之处。

--help 　显示帮助。

--left-column 　在使用-y参数时，若两个文件某一行内容相同，则仅在左侧的栏位显示该行内容。

--suppress-common-lines 　在使用-y参数时，仅显示不同之处。



4．使用实例：



实例1：比较两个文件

命令：diff log2014.log log2013.log 

输出：

[root@localhost test3]# diff log2014.log log2013.log 

3c3

&lt; 2014-03

---

&gt; 2013-03

8c8

&lt; 2013-07

---

&gt; 2013-08

11,12d10

&lt; 2013-11

&lt; 2013-12



说明：

上面的“3c3”和“8c8”表示log2014.log和log20143log文件在3行和第8行内容有所不同；"11,12d10"表示第一个文件比第二个文件多了第11和12行。

diff 的normal 显示格式有三种提示:

a - add

c - change

d - delete 






实例2：并排格式输出

命令：diff log2013.log log2014.log  -y -W 50

输出：

[root@localhost test3]# diff log2014.log log2013.log  -y -W 50

2013-01                 2013-01

2013-02                 2013-02

2014-03               | 2013-03

2013-04                 2013-04

2013-05                 2013-05

2013-06                 2013-06

2013-07                 2013-07

2013-07               | 2013-08

2013-09                 2013-09

2013-10                 2013-10

2013-11               &lt;

2013-12               &lt;

[root@localhost test3]# diff log2013.log log2014.log  -y -W 50

2013-01                 2013-01

2013-02                 2013-02

2013-03               | 2014-03

2013-04                 2013-04

2013-05                 2013-05

2013-06                 2013-06

2013-07                 2013-07

2013-08               | 2013-07

2013-09                 2013-09

2013-10                 2013-10

                      &gt; 2013-11

                      &gt; 2013-12



说明：

“|”表示前后2个文件内容有不同

“&lt;”表示后面文件比前面文件少了1行内容

“&gt;”表示后面文件比前面文件多了1行内容






实例3：上下文输出格式

命令：diff log2013.log log2014.log  -c

输出：

[root@localhost test3]# diff log2013.log log2014.log  -c

*** log2013.log 2012-12-07 16:36:26.000000000 +0800

--- log2014.log 2012-12-07 18:01:54.000000000 +0800

***************

*** 1,10 ****

  2013-01

  2013-02

! 2013-03

  2013-04

  2013-05

  2013-06

  2013-07

! 2013-08

  2013-09

  2013-10

--- 1,12 ----

  2013-01

  2013-02

! 2014-03

  2013-04

  2013-05

  2013-06

  2013-07

! 2013-07

  2013-09

  2013-10

+ 2013-11

+ 2013-12[root@localhost test3]# diff log2014.log log2013.log  -c

*** log2014.log 2012-12-07 18:01:54.000000000 +0800

--- log2013.log 2012-12-07 16:36:26.000000000 +0800

***************

*** 1,12 ****

  2013-01

  2013-02

! 2014-03

  2013-04

  2013-05

  2013-06

  2013-07

! 2013-07

  2013-09

  2013-10

- 2013-11

- 2013-12

--- 1,10 ----

  2013-01

  2013-02

! 2013-03

  2013-04

  2013-05

  2013-06

  2013-07

! 2013-08

  2013-09

  2013-10[root@localhost test3]#



说明：

这种方式在开头两行作了比较文件的说明，这里有三种特殊字符：

“＋” 比较的文件的后者比前者多一行

“－” 比较的文件的后者比前者少一行

“！” 比较的文件两者有差别的行






实例4：统一格式输出

命令：diff log2014.log log2013.log  -u

输出：

[root@localhost test3]# diff log2014.log log2013.log  -u

--- log2014.log 2012-12-07 18:01:54.000000000 +0800

+++ log2013.log 2012-12-07 16:36:26.000000000 +0800

@@ -1,12 +1,10 @@

 2013-01

 2013-02

-2014-03

+2013-03

 2013-04

 2013-05

 2013-06

 2013-07

-2013-07

+2013-08

 2013-09

 2013-10

-2013-11

-2013-12



说明：

它的第一部分，也是文件的基本信息：

--- log2014.log 2012-12-07 18:01:54.000000000 +0800

+++ log2013.log 2012-12-07 16:36:26.000000000 +0800

"---"表示变动前的文件，"+++"表示变动后的文件。

第二部分，变动的位置用两个@作为起首和结束。

　　@@ -1,12 +1,10 @@

前面的"-1,12"分成三个部分：减号表示第一个文件（即log2014.log），"1"表示第1行，"12"表示连续12行。合在一起，就表示下面是第一个文件从第1行开始的连续12行。同样的，"+1,10"表示变动后，成为第二个文件从第1行开始的连续10行。






实例5：比较文件夹不同

命令：diff  test3 test6






实例6：比较两个文件不同，并生产补丁

命令：diff -ruN log2013.log log2014.log &gt;patch.log






实例7：打补丁

命令：cat log2013.log


ln是linux中又一个非常重要命令，它的功能是为某一个文件在另外一个位置建立一个同步的链接。当我们需要在不同的目录，用到相同的文件时，我们不需要在每一个需要的目录下都放一个必须相同的文件，我们只要在某个固定的目录，放上该文件，然后在 其它的目录下用ln命令链接（link）它就可以，不必重复的占用磁盘空间。

1．命令格式：

 ln [参数][源文件或目录][目标文件或目录]

2．命令功能：

Linux文件系统中，有所谓的链接(link)，我们可以将其视为档案的别名，而链接又可分为两种 : 硬链接(hard link)与软链接(symbolic link)，硬链接的意思是一个档案可以有多个名称，而软链接的方式则是产生一个特殊的档案，该档案的内容是指向另一个档案的位置。硬链接是存在同一个文件系统中，而软链接却可以跨越不同的文件系统。

软链接：

1.软链接，以路径的形式存在。类似于Windows操作系统中的快捷方式

2.软链接可以 跨文件系统 ，硬链接不可以

3.软链接可以对一个不存在的文件名进行链接

4.软链接可以对目录进行链接

硬链接:

1.硬链接，以文件副本的形式存在。但不占用实际空间。

2.不允许给目录创建硬链接

3.硬链接只有在同一个文件系统中才能创建



 
这里有两点要注意：

第一，ln命令会保持每一处链接文件的同步性，也就是说，不论你改动了哪一处，其它的文件都会发生相同的变化。

第二，ln的链接又分软链接和硬链接两种，软链接就是ln –s 源文件目标文件，它只会在你选定的位置上生成一个文件的镜像，不会占用磁盘空间，硬链接 ln 源文件目标文件，没有参数-s， 它会在你选定的位置上生成一个和源文件大小相同的文件，无论是软链接还是硬链接，文件都保持同步变化。

ln指令用在链接文件或目录，如同时指定两个以上的文件或目录，且最后的目的地是一个已经存在的目录，则会把前面指定的所有文件或目录复制到该目录中。若同时指定多个文件或目录，且最后的目的地并非是一个已存在的目录，则会出现错误信息。



3．命令参数：

必要参数:

-b 删除，覆盖以前建立的链接

-d 允许超级用户制作目录的硬链接

-f 强制执行

-i 交互模式，文件存在则提示用户是否覆盖

-n 把符号链接视为一般目录

-s 软链接(符号链接)

-v 显示详细的处理过程



选择参数:

-S “-S&lt;字尾备份字符串&gt; ”或 “--suffix=&lt;字尾备份字符串&gt;”

-V “-V&lt;备份方式&gt;”或“--version-control=&lt;备份方式&gt;”

--help 显示帮助信息

--version 显示版本信息



4．使用实例：

实例1：给文件创建软链接

命令：ln -s log2013.log link2013



说明：为log2013.log文件创建软链接link2013，如果log2013.log丢失，link2013将失效






实例2：给文件创建硬链接

命令：ln log2013.log ln2013



说明：为log2013.log创建硬链接ln2013，log2013.log与ln2013的各项属性相同






实例3：接上面两实例，链接完毕后，删除和重建链接原文件

命令：ll

说明：

1.源文件被删除后，并没有影响硬链接文件；软链接文件在centos系统下不断的闪烁，提示源文件已经不存在

2.重建源文件后，软链接不在闪烁提示，说明已经链接成功，找到了链接文件系统；重建后，硬链接文件并没有受到源文件影响，硬链接文件的内容还是保留了删除前源文件的内容，说明硬链接已经失效






实例4：将文件链接为另一个目录中的相同名字

命令：ln log2013.log test3

说明：在test3目录中创建了log2013.log的硬链接，修改test3目录中的log2013.log文件，同时也会同步到源文件






实例5：给目录创建软链接

命令：ln -sv /opt/soft/test/test3 /opt/soft/test/test5



说明：

1.目录只能创建软链接

2.目录创建链接必须用绝对路径，相对路径创建会不成功，会提示：符号连接的层数过多 这样的错误

3.在链接目标目录中修改文件都会在源文件目录中同步变化


Linux du命令也是查看使用空间的，但是与df命令不同的是Linux du命令是对文件和目录磁盘使用的空间的查看，还是和df命令有一些区别的。

1．命令格式：

du [选项][文件]

2．命令功能：

显示每个文件和目录的磁盘使用空间。

3．命令参数：

-a或-all  显示目录中个别文件的大小。   

-b或-bytes  显示目录或文件大小时，以byte为单位。   

-c或--total  除了显示个别目录或文件的大小外，同时也显示所有目录或文件的总和。 

-k或--kilobytes  以KB(1024bytes)为单位输出。

-m或--megabytes  以MB为单位输出。   

-s或--summarize  仅显示总计，只列出最后加总的值。

-h或--human-readable  以K，M，G为单位，提高信息的可读性。

-x或--one-file-xystem  以一开始处理时的文件系统为准，若遇上其它不同的文件系统目录则略过。 

-L&lt;符号链接&gt;或--dereference&lt;符号链接&gt; 显示选项中所指定符号链接的源文件大小。   

-S或--separate-dirs   显示个别目录的大小时，并不含其子目录的大小。 

-X&lt;文件&gt;或--exclude-from=&lt;文件&gt;  在&lt;文件&gt;指定目录或文件。   

--exclude=&lt;目录或文件&gt;         略过指定的目录或文件。    

-D或--dereference-args   显示指定符号链接的源文件大小。   

-H或--si  与-h参数相同，但是K，M，G是以1000为换算单位。   

-l或--count-links   重复计算硬件链接的文件。  



4．使用实例：

实例1：显示目录或者文件所占空间 

命令：du



说明：只显示当前目录下面的子目录的目录大小和当前目录的总的大小，最下面的1288为当前目录的总大小






实例2：显示指定文件所占空间

命令：du log2012.log






实例3：查看指定目录的所占空间

命令：du scf






实例4：显示多个文件所占空间

命令：du log30.tar.gz log31.tar.gz






实例5：只显示总和的大小

命令：du -s






实例6：方便阅读的格式显示

命令：du -h test






实例7：文件和目录都显示

命令：du -ah test






实例8：显示几个文件或目录各自占用磁盘空间的大小，还统计它们的总和

命令：du -c log30.tar.gz log31.tar.gz



说明：加上-c选项后，du不仅显示两个目录各自占用磁盘空间的大小，还在最后一行统计它们的总和。






实例9：按照空间大小排序

命令：du|sort -nr|more






实例10：输出当前目录下各个子目录所使用的空间

命令：du -h  --max-depth=1

 在这里你将了解一些关于量子计算的信息。虽然今天量子处理器规模适中，但他的复杂性在持续的增长中。建立一个新量子学习者社区和改变我们对计算的认识的时机已经成熟。IBM量子团队已经完成了用户指南,以帮助您理解量子世界。我们对IBM量子体验的目标是让你了解量子计算，构造你自己的认识，在仿真环境中运行它们，甚至通过IBM云在世界上第一个完全可控制的量子处理器上运行它们。
  
IBM量子体验有如下几部分组成：
1、通过一组教程，会使你从理解基本简单的单量子位（single-qubit）（第二部分）实验到复杂的多量子位实验（第三部分），然后转向更高级的量子算法领域（第四部分）和量子纠错领域（第五部分）。


2、量子设计，就是一个图形用户界面,你可以写你自己的量子得分,就像一个作曲家组成乐谱。
3、量子模拟器可以用来测试你的量子分数。
4、进入一个真实的量子处理器运行在IBM量子计算实验室之一,在那里你的分数量子可以被演示。
5、在不久的将来:量子社区是你的量子分数,想法,经验可以被讨论和共享地方。


我们需要注意到IBM量子体验目前在“预览”阶段，我们期望通过社区力量帮助完善其功能，改善整个界面。我们有一个bug追踪器与错误图标，您可以访问每个页面的底部。请让我们知道你的想法和意见，以便我们可以收集反馈不断提升开发经验，或请与我们分享任何你可能观察到的很酷的分数和结果!



为确保每个人都有机会使用真正的设备，我们建立了一个货币体系。如果你加入了IBM量子体验并成为一个标准用户，你可以自由访问我们的模拟功能以及先前从设备缓存的结果。通过并完成教程，您将获得单位运行实时实验量子处理器的硬件。这个系统允许我们管理正在排队的实验的运行，目前我们只有一个量子处理器连接到云，以及我们要妥善的安排时间处理发送给它的指令集。此外，你会发现当真正的处理器在维护和校准时那会是一个间歇性的时期。当你的单元在使用时，你可以将要求补充在“帐户”信息页面。在那里，你也会注意到你有机会请求升级你的用户状态。与我们分享你的故事，告诉我们为什么你想成为一个量子专家的用户体验。


对于那些希望跳到IBM量子体验是如何工作的,跳到量子设计。如果你想首先提高你对量子世界的理解,请继续阅读下面几节，我们将开始一个野生和迷人的以量子位开始的旅程。


我们想确认下基于IARPA Multi-Qubit连贯操作程序以及有限合伙人量子特性确认和验证程序已经完成。研究中执行这些程序让这量子体验成为可能。




Jay Gambetta, Jerry Chow, and the IBM Quantum team




原文链接地址：
https://quantumexperience.ng.bluemix.net/qstage/#/tutorial?sectionId=75a85f7e14ae3fd4329ad5c3e59466ea







linux中df命令的功能是用来检查linux服务器的文件系统的磁盘空间占用情况。可以利用该命令来获取硬盘被占用了多少空间，目前还剩下多少空间等信息。

1．命令格式：

df [选项] [文件]

2．命令功能：

显示指定磁盘文件的可用空间。如果没有文件名被指定，则所有当前被挂载的文件系统的可用空间将被显示。默认情况下，磁盘空间将以 1KB 为单位进行显示，除非环境变量 POSIXLY_CORRECT 被指定，那样将以512字节为单位进行显示

3．命令参数：

必要参数：

-a 全部文件系统列表

-h 方便阅读方式显示

-H 等于“-h”，但是计算式，1K=1000，而不是1K=1024

-i 显示inode信息

-k 区块为1024字节

-l 只显示本地文件系统

-m 区块为1048576字节

--no-sync 忽略 sync 命令

-P 输出格式为POSIX

--sync 在取得磁盘信息前，先执行sync命令

-T 文件系统类型



选择参数：

--block-size=&lt;区块大小&gt; 指定区块大小

-t&lt;文件系统类型&gt; 只显示选定文件系统的磁盘信息

-x&lt;文件系统类型&gt; 不显示选定文件系统的磁盘信息

--help 显示帮助信息

--version 显示版本信息



4．使用实例：

实例1：显示磁盘使用情况

命令：df

输出：

[root@CT1190 log]# df

文件系统               1K-块        已用     可用 已用% 挂载点

/dev/sda7             19840892    890896  17925856   5% /

/dev/sda9            203727156 112797500  80413912  59% /opt

/dev/sda8              4956284    570080   4130372  13% /var

/dev/sda6             19840892   1977568  16839184  11% /usr

/dev/sda3               988116     23880    913232   3% /boot

tmpfs                 16473212         0  16473212   0% /dev/shm

说明：

linux中df命令的输出清单的第1列是代表文件系统对应的设备文件的路径名（一般是硬盘上的分区）；第2列给出分区包含的数据块（1024字节）的数目；第3，4列分别表示已用的和可用的数据块数目。用户也许会感到奇怪的是，第3，4列块数之和不等于第2列中的块数。这是因为缺省的每个分区都留了少量空间供系统管理员使用。即使遇到普通用户空间已满的情况，管理员仍能登录和留有解决问题所需的工作空间。清单中Use% 列表示普通用户空间使用的百分比，即使这一数字达到100％，分区仍然留有系统管理员使用的空间。最后，Mounted on列表示文件系统的挂载点。



实例2：以inode模式来显示磁盘使用情况

命令：df -i

输出：

[root@CT1190 log]# df -i

文件系统               Inode (I)已用 (I)可用 (I)已用% 挂载点

/dev/sda7            5124480    5560 5118920    1% /

/dev/sda9            52592640   50519 52542121    1% /opt

/dev/sda8            1280000    8799 1271201    1% /var

/dev/sda6            5124480   80163 5044317    2% /usr

/dev/sda3             255232      34  255198    1% /boot

tmpfs                4118303       1 4118302    1% /dev/shm

说明：



实例3：显示指定类型磁盘

命令：df -t ext3

输出：

[root@CT1190 log]# df -t ext3

文件系统               1K-块        已用     可用 已用% 挂载点

/dev/sda7             19840892    890896  17925856   5% /

/dev/sda9            203727156  93089700 100121712  49% /opt

/dev/sda8              4956284    570104   4130348  13% /var

/dev/sda6             19840892   1977568  16839184  11% /usr

/dev/sda3               988116     23880    913232   3% /boot

说明：



实例4：列出各文件系统的i节点使用情况

命令：df -ia

输出：

[root@CT1190 log]# df -ia

文件系统               Inode (I)已用 (I)可用 (I)已用% 挂载点

/dev/sda7            5124480    5560 5118920    1% 

/proc                       0       0       0    -  /proc

sysfs                      0       0       0    -  /sys

devpts                     0       0       0    -  /dev/pts

/dev/sda9            52592640   50519 52542121    1% /opt

/dev/sda8            1280000    8799 1271201    1% /var

/dev/sda6            5124480   80163 5044317    2% /usr

/dev/sda3             255232      34  255198    1% /boot

tmpfs                4118303       1 4118302    1% /dev/shm

none                       0       0       0    -  /proc/sys/fs/binfmt_misc



说明：



实例5：列出文件系统的类型

命令：df -T

输出：

root@CT1190 log]# df -T

文件系统      类型     1K-块        已用     可用 已用% 挂载点

/dev/sda7     ext3    19840892    890896  17925856   5% /

/dev/sda9     ext3   203727156  93175692 100035720  49% /opt

/dev/sda8     ext3     4956284    570104   4130348  13% /var

/dev/sda6     ext3    19840892   1977568  16839184  11% /usr

/dev/sda3     ext3      988116     23880    913232   3% /boot

tmpfs        tmpfs    16473212         0  16473212   0% /dev/shm

说明：



实例6：以更易读的方式显示目前磁盘空间和使用情况 

命令：df -h

输出：

[root@CT1190 log]# df -h

文件系统              容量  已用 可用 已用% 挂载点

/dev/sda7              19G  871M   18G   5% /

/dev/sda9             195G   89G   96G  49% /opt

/dev/sda8             4.8G  557M  4.0G  13% /var

/dev/sda6              19G  1.9G   17G  11% /usr

/dev/sda3             965M   24M  892M   3% /boot

tmpfs                  16G     0   16G   0% /dev/shm

[root@CT1190 log]# df -H

文件系统               容量   已用  可用 已用% 挂载点

/dev/sda7               21G   913M    19G   5% /

/dev/sda9              209G    96G   103G  49% /opt

/dev/sda8              5.1G   584M   4.3G  13% /var

/dev/sda6               21G   2.1G    18G  11% /usr

/dev/sda3              1.1G    25M   936M   3% /boot

tmpfs                   17G      0    17G   0% /dev/shm

[root@CT1190 log]# df -lh

文件系统              容量  已用 可用 已用% 挂载点

/dev/sda7              19G  871M   18G   5% /

/dev/sda9             195G   89G   96G  49% /opt

/dev/sda8             4.8G  557M  4.0G  13% /var

/dev/sda6              19G  1.9G   17G  11% /usr

/dev/sda3             965M   24M  892M   3% /boot

tmpfs                  16G     0   16G   0% /dev/shm

[root@CT1190 log]# df -k

文件系统               1K-块        已用     可用 已用% 挂载点

/dev/sda7             19840892    890896  17925856   5% /

/dev/sda9            203727156  93292572  99918840  49% /opt

/dev/sda8              4956284    570188   4130264  13% /var

/dev/sda6             19840892   1977568  16839184  11% /usr

/dev/sda3               988116     23880    913232   3% /boot

tmpfs                 16473212         0  16473212   0% /dev/shm



说明：

-h更具目前磁盘空间和使用情况 以更易读的方式显示

-H根上面的-h参数相同,不过在根式化的时候,采用1000而不是1024进行容量转换

-k以单位显示磁盘的使用情况

-l显示本地的分区的磁盘空间使用率,如果服务器nfs了远程服务器的磁盘,那么在df上加上-l后系统显示的是过滤nsf驱动器后的结果

-i显示inode的使用情况。linux采用了类似指针的方式管理磁盘空间影射.这也是一个比较关键应用


减少文件大小有两个明显的好处，一是可以减少存储空间，二是通过网络传输文件时，可以减少传输的时间。gzip是在Linux系统中经常使用的一个对文件进行压缩和解压缩的命令，既方便又好用。gzip不仅可以用来压缩大的、较少使用的文件以节省磁盘空间，还可以和tar命令一起构成Linux操作系统中比较流行的压缩文件格式。据统计，gzip命令对文本文件有60%～70%的压缩率。

1．命令格式：

gzip[参数][文件或者目录]

2．命令功能：

gzip是个使用广泛的压缩程序，文件经它压缩过后，其名称后面会多出".gz"的扩展名。

3．命令参数：

-a或--ascii 　使用ASCII文字模式。 

-c或--stdout或--to-stdout 　把压缩后的文件输出到标准输出设备，不去更动原始文件。 

-d或--decompress或----uncompress 　解开压缩文件。 

-f或--force 　强行压缩文件。不理会文件名称或硬连接是否存在以及该文件是否为符号连接。 

-h或--help 　在线帮助。 

-l或--list 　列出压缩文件的相关信息。 

-L或--license 　显示版本与版权信息。 

-n或--no-name 　压缩文件时，不保存原来的文件名称及时间戳记。 

-N或--name 　压缩文件时，保存原来的文件名称及时间戳记。 

-q或--quiet 　不显示警告信息。 

-r或--recursive 　递归处理，将指定目录下的所有文件及子目录一并处理。 

-S&lt;压缩字尾字符串&gt;或----suffix&lt;压缩字尾字符串&gt; 　更改压缩字尾字符串。 

-t或--test 　测试压缩文件是否正确无误。 

-v或--verbose 　显示指令执行过程。 

-V或--version 　显示版本信息。 

-num 用指定的数字num调整压缩的速度，-1或--fast表示最快压缩方法（低压缩比），-9或--best表示最慢压缩方法（高压缩比）。系统缺省值为6。 



4．使用实例：

实例1：把test6目录下的每个文件压缩成.gz文件

命令：gzip *






实例2：把例1中每个压缩的文件解压，并列出详细的信息

命令：gzip -dv *






实例3：详细显示例1中每个压缩的文件的信息，并不解压

命令：gzip -l *






实例4：压缩一个tar备份文件，此时压缩文件的扩展名为.tar.gz

命令：gzip -r log.tar






实例5：递归的压缩目录

命令：gzip -rv test6



说明：这样，所有test下面的文件都变成了*.gz，目录依然存在只是目录里面的文件相应变成了*.gz.这就是压缩，和打包不同。因为是对目录操作，所以需要加上-r选项，这样也可以对子目录进行递归了。 






实例6：递归地解压目录

命令：gzip -dr test6

         最近在跟人聊java的容器，在聊到WeakHashMap时，被问Weak是什么意思，当时没能回答出来，后面同事继续问java有哪几种引用，当时便有一种智商严重不足的感觉。于是便整理出这篇文章，希望各位多提意见。
         java中提供了4个级别的引用：强引用、软引用、弱引用和虚引用。这4个引用在java.lang.ref包下：


一、强引用（FinalReference）
         强引用在程序代码这是普遍存在的，类似Object o = new Object()这类的引用，只要强引用还存在，垃圾回收集器永远不会回收被引用的对象。
         强引用具备以下三个特点：
1、强引用可以直接访问目标对象。
2、强引用锁指向的对象任何时候都不会被系统回收。JVM宁愿抛出OOM（OutOfMemory）异常也不回收强引用所指向的对象。
3、强引用可能导致内存泄漏。


强引用的源码如下：

package java.lang.ref;

/**
 * Final references, used to implement finalization
 */
class FinalReference&lt;T&gt; extends Reference&lt;T&gt; {

    public FinalReference(T referent, ReferenceQueue&lt;? super T&gt; q) {
        super(referent, q);
    }
} 只有一个构造函数，根据所给的对象的引用和引用队列构造一个强引用。


二、软引用（SoftReference）
用来描述一类还有用但并非必须的对象。对于软引用关联着的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收。如果这次回收还没有足够的内存，才会抛出内存溢出异常。
 
对于软引用关联着的对象，如果内存充足，则垃圾回收器不会回收这些对象的内存，如果内存不足，则这些对象的内存被回收。在JDK1.2之后，提供了SoftReference类来实现软引用。软引用可以用来实现内存敏感的高速缓存。软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收器回收，java虚拟机就会把这个软引用加入到与之关联的引用队列中。
package collections.ref;

import java.lang.ref.Reference;
import java.lang.ref.ReferenceQueue;
import java.lang.ref.SoftReference;

public class SoftRefTest
{
    private static ReferenceQueue&lt;MyObject&gt; softQueue = new ReferenceQueue&lt;&gt;();

    public static class MyObject{

        @Override
        protected void finalize() throws Throwable
        {
            super.finalize();
            System.out.println("MyObject's finalize called");
        }

        @Override
        public String toString()
        {
            return "I am MyObject";
        }
    }

    public static class CheckRefQueue implements Runnable
    {
        Reference&lt;MyObject&gt; obj = null;
        @Override
        public void run()
        {
            try
            {
                obj = (Reference&lt;MyObject&gt;)softQueue.remove();
            }
            catch (InterruptedException e)
            {
                e.printStackTrace();
            }
            if(obj != null)
            {
                System.out.println("Object for SoftReference is "+obj.get());
            }
        }
    }

    public static void main(String[] args)
    {
        MyObject object = new MyObject();
        SoftReference&lt;MyObject&gt; softRef = new SoftReference&lt;&gt;(object,softQueue);
        new Thread(new CheckRefQueue()).start();

        object = null;    //删除强引用
        System.gc();
        System.out.println("After GC: Soft Get= "+softRef.get());
        System.out.println("分配大块内存");
        byte[] b = new byte[5*1024*928];
        System.out.println("After new byte[]:Soft Get= "+softRef.get());
        System.gc();
    }
}
运行参数1：
-Xmx5M 运行结果：
After GC: Soft Get= I am MyObject
分配大块内存
MyObject's finalize called
Object for SoftReference is null
After new byte[]:Soft Get= null 运行参数2：
-Xmx5M -XX:PrintGCDetails 运行结果2：
[GC [PSYoungGen: 680K-&gt;504K(2560K)] 680K-&gt;512K(6144K), 0.0040658 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
[Full GC [PSYoungGen: 504K-&gt;0K(2560K)] [ParOldGen: 8K-&gt;482K(3584K)] 512K-&gt;482K(6144K) [PSPermGen: 2491K-&gt;2490K(21504K)], 0.0188479 secs] [Times: user=0.01 sys=0.00, real=0.02 secs] 
After GC: Soft Get= I am MyObject
分配大块内存
[GC [PSYoungGen: 123K-&gt;64K(2560K)] 605K-&gt;546K(7680K), 0.0004285 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
[GC [PSYoungGen: 64K-&gt;64K(2560K)] 546K-&gt;546K(7680K), 0.0003019 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
[Full GC [PSYoungGen: 64K-&gt;0K(2560K)] [ParOldGen: 482K-&gt;482K(4608K)] 546K-&gt;482K(7168K) [PSPermGen: 2493K-&gt;2493K(21504K)], 0.0094748 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] 
[GC [PSYoungGen: 0K-&gt;0K(2560K)] 482K-&gt;482K(7680K), 0.0003759 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
[Full GC [PSYoungGen: 0K-&gt;0K(2560K)] [ParOldGen: 482K-&gt;472K(5120K)] 482K-&gt;472K(7680K) [PSPermGen: 2493K-&gt;2493K(21504K)], 0.0101017 secs] [Times: user=0.06 sys=0.00, real=0.01 secs] 
MyObject's finalize called
Object for SoftReference is null
After new byte[]:Soft Get= null
[GC [PSYoungGen: 122K-&gt;32K(2560K)] 5235K-&gt;5144K(7680K), 0.0004806 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
[Full GC [PSYoungGen: 32K-&gt;0K(2560K)] [ParOldGen: 5112K-&gt;5112K(5120K)] 5144K-&gt;5112K(7680K) [PSPermGen: 2493K-&gt;2493K(21504K)], 0.0136270 secs] [Times: user=0.06 sys=0.00, real=0.01 secs] 
Heap
 PSYoungGen      total 2560K, used 20K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000)
  eden space 2048K, 1% used [0x00000000ffd00000,0x00000000ffd05250,0x00000000fff00000)
  from space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000)
  to   space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000)
 ParOldGen       total 5120K, used 5112K [0x00000000ff800000, 0x00000000ffd00000, 0x00000000ffd00000)
  object space 5120K, 99% used [0x00000000ff800000,0x00000000ffcfe188,0x00000000ffd00000)
 PSPermGen       total 21504K, used 2500K [0x00000000fa600000, 0x00000000fbb00000, 0x00000000ff800000)
  object space 21504K, 11% used [0x00000000fa600000,0x00000000fa871190,0x00000000fbb00000)
       加入 -XX:PrintGCDetails参数运行可以更形象的看到GC回收的细节。 
??这个案例1中，首先构造MyObject对象，并将其赋值给object变量，构成强引用。然后使用SoftReference构造这个MyObject对象的软引用softRef，并注册到softQueue引用队列。当softRef被回收时，会被加入softQueue队列。设置obj=null，删除这个强引用，因此，系统内对MyObject对象的引用只剩下软引用。此时，显示调用GC，通过软引用的get()方法，取得MyObject对象的引用，发现对象并未被回收，这说明GC在内存充足的情况下，不会回收软引用对象。 
??接着，请求一块大的堆空间5*1024*928，这个操作会使系统堆内存使用紧张，从而产生新一轮的GC。在这次GC后，softRef.get()不再返回MyObject对象，而是返回null，说明在系统内存紧张的情况下，软引用被回收。软引用被回收时，会被加入注册的引用队列。 
??如果将上面案例中的数组再改大点，比如5*1024*1024，就会抛出OOM异常：

After GC: Soft Get= I am MyObject
分配大块内存
MyObject's finalize called
Object for SoftReference is null
Exception in thread "main" java.lang.OutOfMemoryError: Java heap space
    at collections.ref.SoftRefTest.main(SoftRefTest.java:58)
软引用主要应用于内存敏感的高速缓存，在Android系统中经常使用到。一般情况下，Android应用会用到大量的默认图片，这些图片很多地方会用到。如果每次都去读取图片，由于读取文件需要硬件操作，速度较慢，会导致性能较低。所以我们考虑将图片缓存起来，需要的时候直接从内存中读取。但是，由于图片占用内存空间比较大，缓存很多图片需要很多的内存，就可能比较容易发生OutOfMemory异常。这时，我们可以考虑使用软引用技术来避免这个问题发生。SoftReference可以解决oom的问题，每一个对象通过软引用进行实例化，这个对象就以cache的形式保存起来，当再次调用这个对象时，那么直接通过软引用中的get（）方法，就可以得到对象中中的资源数据，这样就没必要再次进行读取了，直接从cache中就可以读取得到，当内存将要发生OOM的时候，GC会迅速把所有的软引用清除，防止oom发生。

 案例2：
public class BitMapManager {
    private Map&lt;String, SoftReference&lt;Bitmap&gt;&gt; imageCache = new HashMap&lt;String, SoftReference&lt;Bitmap&gt;&gt;();

    //保存Bitmap的软引用到HashMap
    public void saveBitmapToCache(String path) {
        // 强引用的Bitmap对象
        Bitmap bitmap = BitmapFactory.decodeFile(path);
        // 软引用的Bitmap对象
        SoftReference&lt;Bitmap&gt; softBitmap = new SoftReference&lt;Bitmap&gt;(bitmap);
        // 添加该对象到Map中使其缓存
        imageCache.put(path, softBitmap);
        // 使用完后手动将位图对象置null
        bitmap = null;
    }

    public Bitmap getBitmapByPath(String path) {

        // 从缓存中取软引用的Bitmap对象
        SoftReference&lt;Bitmap&gt; softBitmap = imageCache.get(path);
        // 判断是否存在软引用
        if (softBitmap == null) {
            return null;
        }
        // 取出Bitmap对象，如果由于内存不足Bitmap被回收，将取得空
        Bitmap bitmap = softBitmap.get();
        return bitmap;
    }
}

三、弱引用（WeakReference）
用来描述非必须的对象，但是它的强度比软引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发送之前。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。一旦一个弱引用对象被垃圾回收器回收，便会加入到一个注册引用队列中。 
??我们略微修改一下案例1的代码，如下：

package collections.ref;

import java.lang.ref.Reference;
import java.lang.ref.ReferenceQueue;
import java.lang.ref.WeakReference;

public class WeakRefTest
{
    private static ReferenceQueue&lt;MyObject&gt; weakQueue = new ReferenceQueue&lt;&gt;();

    public static class MyObject{

        @Override
        protected void finalize() throws Throwable
        {
            super.finalize();
            System.out.println("MyObject's finalize called");
        }

        @Override
        public String toString()
        {
            return "I am MyObject";
        }
    }

    public static class CheckRefQueue implements Runnable
    {
        Reference&lt;MyObject&gt; obj = null;
        @Override
        public void run()
        {
            try
            {
                obj = (Reference&lt;MyObject&gt;)weakQueue.remove();
            }
            catch (InterruptedException e)
            {
                e.printStackTrace();
            }
            if(obj != null)
            {
                System.out.println("删除的弱引用为："+obj+"  but获取弱引用的对象obj.get()="+obj.get());
            }
        }
    }

    public static void main(String[] args)
    {
        MyObject object = new MyObject();
        Reference&lt;MyObject&gt; weakRef = new WeakReference&lt;&gt;(object,weakQueue);
        System.out.println("创建的弱引用为："+weakRef);
        new Thread(new CheckRefQueue()).start();

        object = null;
        System.out.println("Before GC: Weak Get= "+weakRef.get());
        System.gc();
        System.out.println("After GC: Weak Get= "+weakRef.get());
    }
}
不加参数运行结果：

创建的弱引用为：java.lang.ref.WeakReference@29e07d3e
Before GC: Weak Get= I am MyObject
After GC: Weak Get= null
MyObject's finalize called
删除的弱引用为：java.lang.ref.WeakReference@29e07d3e  but获取弱引用的对象obj.get()=null
可以看到，在GC之前，弱引用对象并未被垃圾回收器发现，因此通过 weakRef.get()可以获取对应的对象引用。但是只要进行垃圾回收，弱引用一旦被发现，便会立即被回收，并加入注册引用队列中。此时再试图通过weakRef.get()获取对象的引用就会失败。 
??弱引用的相关实际案例可以参考WeakHashMap。

软引用、弱引用都非常适合来保存那些可有可无的缓存数据。如果这么做，当系统内存不足时，这些缓存数据会被回收，不会导致内存溢出。而当内存资源充足时，这些缓存数据又可以存在相当长的时间，从而起来加速系统的作用。



四、虚引用（PhantomReference）
虚引用也称为幽灵引用或者幻影引用，它是最弱的一种引用关系。一个持有虚引用的对象，和没有引用几乎是一样的，随时都有可能被垃圾回收器回收。当试图通过虚引用的get()方法取得强引用时，总是会失败。并且，虚引用必须和引用队列一起使用，它的作用在于跟踪垃圾回收过程。 
??虚引用中get方法的实现如下：

public T get() {
        return null;
    }
可以看到永远返回null. 
??我们再来修改一下案例1的代码：
package collections.ref;

import java.lang.ref.PhantomReference;
import java.lang.ref.Reference;
import java.lang.ref.ReferenceQueue;
import java.util.concurrent.TimeUnit;

public class PhantomRefTest
{
    private static ReferenceQueue&lt;MyObject&gt; phanQueue = new ReferenceQueue&lt;&gt;();

    public static class MyObject{

        @Override
        protected void finalize() throws Throwable
        {
            super.finalize();
            System.out.println("MyObject's finalize called");
        }

        @Override
        public String toString()
        {
            return "I am MyObject";
        }
    }

    public static class CheckRefQueue implements Runnable
    {
        Reference&lt;MyObject&gt; obj = null;
        @Override
        public void run()
        {
            try
            {
                obj = (Reference&lt;MyObject&gt;)phanQueue.remove();
                System.out.println("删除的虚引用为："+obj+"  but获取虚引用的对象obj.get()="+obj.get());
                System.exit(0);
            }
            catch (InterruptedException e)
            {
                e.printStackTrace();
            }
        }
    }

    public static void main(String[] args) throws InterruptedException
    {
        MyObject object = new MyObject();
        Reference&lt;MyObject&gt; phanRef = new PhantomReference&lt;&gt;(object,phanQueue);
        System.out.println("创建的虚引用为："+phanRef);
        new Thread(new CheckRefQueue()).start();

        object = null;
        TimeUnit.SECONDS.sleep(1);
        int i =1;
        while(true)
        {
            System.out.println("第"+i+++"次gc");
            System.gc();
            TimeUnit.SECONDS.sleep(1);
        }
    }
}
运行结果：

创建的虚引用为：java.lang.ref.PhantomReference@3a6646fc
第1次gc
MyObject's finalize called
第2次gc
删除的虚引用为：java.lang.ref.PhantomReference@3a6646fc  but获取虚引用的对象obj.get()=null
可以看到，再经过一次GC之后，系统找到了垃圾对象，并调用finalize()方法回收内存，但没有立即加入回收队列。第二次GC时，该对象真正被GC清楚，此时，加入虚引用队列。 
?? 虚引用的最大作用在于跟踪对象回收，清理被销毁对象的相关资源。 
?? 通常当对象不被使用时，重载该对象的类的finalize方法可以回收对象的资源。但是如果使用不慎，会使得对象复活，譬如这么编写finalize方法：

public class Test{
    public static Test obj;

    @Override protected void finalize() throws Throwable{
        super.finalize();
        obj = this;
    }
}
对上面这个类Test中obj = new Test();然后obj=null；之后调用System.gc()企图销毁对象，但是很抱歉，不管你调用多少次System.gc()都没有什么用，除非你在下面的代码中再就obj=null;这样才能回收对象，这是因为JVM对某一个对象至多只执行一次被重写的finalize方法。 
??上面的小片段说明重写finalize的方法并不是很靠谱，可以使用虚引用来清理对象所占用的资源。 
??如下代码所示：
public class PhantomRefTest2
{
    private static ReferenceQueue&lt;MyObject&gt; phanQueue = new ReferenceQueue&lt;&gt;();
    private static Map&lt;Reference&lt;MyObject&gt;,String&gt; map = new HashMap&lt;&gt;();

    public static class MyObject{

        @Override
        protected void finalize() throws Throwable
        {
            super.finalize();
            System.out.println("MyObject's finalize called");
        }

        @Override
        public String toString()
        {
            return "I am MyObject";
        }
    }

    public static class CheckRefQueue implements Runnable
    {
        Reference&lt;MyObject&gt; obj = null;
        @Override
        public void run()
        {
            try
            {
                obj = (Reference&lt;MyObject&gt;)phanQueue.remove();
                Object value = map.get(obj);
                System.out.println("clean resource:"+value);
                map.remove(obj);

                System.out.println("删除的虚引用为："+obj+"  but获取虚引用的对象obj.get()="+obj.get());
                System.exit(0);
            }
            catch (InterruptedException e)
            {
                e.printStackTrace();
            }
        }
    }

    public static void main(String[] args) throws InterruptedException
    {
        MyObject object = new MyObject();
        Reference&lt;MyObject&gt; phanRef = new PhantomReference&lt;&gt;(object,phanQueue);
        System.out.println("创建的虚引用为："+phanRef);
        new Thread(new CheckRefQueue()).start();
        map.put(phanRef, "Some Resources");

        object = null;
        TimeUnit.SECONDS.sleep(1);
        int i =1;
        while(true)
        {
            System.out.println("第"+i+++"次gc");
            System.gc();
            TimeUnit.SECONDS.sleep(1);
        }
    }
}
运行结果：
创建的虚引用为：java.lang.ref.PhantomReference@6a07348e
第1次gc
MyObject's finalize called
第2次gc
clean resource:Some Resources
删除的虚引用为：java.lang.ref.PhantomReference@6a07348e  but获取虚引用的对象obj.get()=null

1、什么是引用类型
 
    引用类型（reference type）指向一个对象，不是原始值，指向对象的变量是引用变量。
 
    在java里面除去基本数据类型，其它类型都是引用数据类型，自己定义的class类都是引用类型，可以像基本类型一样使用。

    示例如下：

    public
 class MyDate {
        private
 int day = 8;
        private
 int month = 8;
        private
 int year = 2008;
        private
 MyDate(int day, int month, int year){...}
        public
 void print(){...}
    }
    public
 class TestMyDate {
        public
 static void main(String args[]) {
            //这个today变量就是一个引用类型的变量
            MyDate
 today = new MyDate(23, 7, 2008);
        }
    }

2、引用类型的赋值

    在java编程语言中，用类的一个类型声明的变量被指定为引用类型，这是因为它正在引用一个非原始类型，这对赋值具有重要的意义。如下代码：

    int
 x = 7;
    int
 y = x;
    String
 s = "Hello";
    String
 t = s;

    四个变量被创建：两个原始类型
 int 和两个引用类型String。x的值是7，这个值被复制到y；x和y是两个独立的变量且其中任何一个的进一步的变化都不对另外一个构成影响。至于变量s和t，只有一个String对象存在，它包含了文本"Hello"，s和t均引用这个单一个对象。

    

    如果将变量t重新定义为t="World"；则新的对象World被创建，而t引用这个对象。
      
      
     

3、按值传递和按引用传递的区别

    1）按值传递
   
    指的是在方法调用时，传递的参数是按值的拷贝传递。示例如下：

1.    public
 class TempTest {
2.        private
 void test1(int a) {
3.            //
 做点事情
4.            a++;
5.        }
6.       
7.        public
 static void main(String args[]) {
8.            TempTest
 t = new TempTest();
9.            int
 a = 3;
10.            t.test1(a);//这里传递的参数a就是按值传递。
11.            System.out.printIn("main方法中的a==="
 + a);
12.         }
13.     }
   
    按值传递的重要特点：传递的是值的拷贝，也就是说传递后就互不相关了。第9行的a和第2行的a是两个变量，当改变第2行的a的值，第9行a的值是不变的，所以打印结果是3。

    main  方法中的a
 为 3
    test1
 方法中的a 为 4
   
    我们把第9行的a称之为实参，第2行的a称之为形参；对于基本数据类型，形参数据的改变，不影响实参的数据。

    2）按引用传递

    指的是在方法调用时，传递的参数是按引用进行传递，其实传递的是引用的地址，也就是变量所对应的内存空间的地址。

    示例如下：

1.    public
 class TempTest {
2.        private
 void test1(A a) {
3.            a.age
 = 20;
4.            System.out.printIn("test1方法中的age="+a.age);
5.        }
6.        public
 static void main(String args[]) {
7.            TempTest
 t = new TempTest();
8.            A
 a = new A();
9.            a.age
 = 10;
10.           t.test1(a);//
 这里传递的参数a就是按引用传递
11.              System.out.printIn("main方法中的age="+a.age);
12.         }
13.     }
14.     classA
 {
15.         public
 int age = 0;
16.     }
  

    运行结果如下：test1方法中的age
 = 20  main方法中的age
 = 20

    按引用传递的重要特点：

    传递的是值的引用，也就是说传递前和传递后都指向同一个引用（也就是同一个内存空间）。

    要想正确理解按引用传递的过程，就必须学会理解内存分配的过程，内存分配示意图可以辅助我们去理解这个过程。

    用上面的例子来进行分析：
  
    （1）、运行开始，运行第8行，创建了一个A的实例，内存分配示意图如下：

      main方法中的a 
   
      

    （2）、运行第9行，修改了A实例里面的age的值，内存分配示意图如下：   
   
      main方法中的a  
     
       
 
    （3）、运行第10行，是把main方法中的变量a所引用的内存空间地址，按引用传递给test1方法中的a变量。请注意：这两个a变量是完全不同的，不要被名称相同所蒙蔽，但它们指向了同一个A实例。内存分配示意图如下：

    

    （4）、运行第3行，为test1方法中的变量a指向A实例的age进行赋值，完成后形成新的内存示意图如下：

     
     此时A实例的age值的变化是由test1方法引起的。
   
    （5）、运行第4行，根据此时的内存示意图，输出test1方法中的age=20
    
    （6）、运行第11行，根据此时的内存示意图，输出main方法中的age=20

    3）对上述例子的改变

    理解了上面的例子，可能有人会问，那么能不能让按照引用传递的值，相互不影响呢？就是test1方法里面的修改不影响到main方法里面的呢？

    方法是在test1方法里面新new一个实例就可以了。改变成下面的例子，其中第3行为新加的：

1.    public
 class TempTest {
2.        private
 void test1(A a) {
3.            a
 = new A();// 新加的一行
4.            a.age
 = 20;
5.            System.out.printIn("test1方法中的age="+a.age);
6.        }
7.        public
 static void main(String args[]) {
8.            TempTest
 t = new TempTest();
9.            A
 a = new A();
10.            a.age
 = 10;
11.           t.test1(a);//
 这里传递的参数a就是按引用传递
12.              System.out.printIn("main方法中的age="+a.age);
13.         }
14.     }
15.     classA
 {
16.         public
 int age = 0;
17.     }
  

    运行结果为：test1方法中的age=20  main方法中的age=10

    实现了按引用传递的值传递前与传递后互不影响，还是使用内存示意图来理解一下：

    （1）、运行开始，运行第9行，创建了一个A实例，内存分配示意图如下：

    
   
    （2）、运行第10行，是修改A实例里面的age的值，运行后内存分配示意图如下：

    
   
    （3）、运行第11行，是把mian方法中的变量a所引用的内存地址，按引用传递给test1方法中的a变量。请注意：这两个a变量是完全不同的，不要被名称相同所蒙蔽。

    

     （4）、运行第3行，为test1方法中的变量a重新生成了新的A实例，完成后形成的新的内存示意图如下：

    

     （5）、运行第4行，为test1方法中的变量a指向的新的A实例的age进行赋值，完成后形成新的内存示意图如下：

    

    注意：这个时候test1方法中的变量a的age被改变，而main方法中的a变量是没有改变的。

     （6）、运行第5行，根据此时的内存示意图，输出test1方法中的age=20

     （7）、运行第12行，根据此时的内存示意图，输出main方法中的age=10

    说明：

    （1）、“在Java里面参数传递都是按值传递”这句话的意思是：按值传递是传递的值的拷贝，按引用传递其实传递的是引用的地址值，所以统称按值传递。

    （2）、在Java里面只有基本类型和按照下面这种定义方式的String是按值传递，其它的都是按引用传递。就是直接使用双引号定义的字符串方式：String
 str = "Java快车";


      Linux /etc/group文件与/etc/passwd和/etc/shadow文件都是有关于系统管理员对用户和用户组管理时相关的文件。linux /etc/group文件是有关于系统管理员对用户和用户组管理的文件,linux用户组的所有信息都存放在/etc/group文件中。具有某种共同特征的用户集合起来就是用户组（Group）。用户组（Group）配置文件主要有 /etc/group和/etc/gshadow，其中/etc/gshadow是/etc/group的加密信息文件。

      将用户分组是Linux系统中对用户进行管理及控制访问权限的一种手段。每个用户都属于某个用户组；一个组中可以有多个用户，一个用户也可以属于不同的组。当一个用户同时是多个组中的成员时，在/etc/passwd文件中记录的是用户所属的主组，也就是登录时所属的默认组，而其他组称为附加组。

     用户组的所有信息都存放在/etc/group文件中。此文件的格式是由冒号(:)隔开若干个字段，这些字段具体如下：

     组名:口令:组标识号:组内用户列表

     具体解释：

     组名：

     组名是用户组的名称，由字母或数字构成。与/etc/passwd中的登录名一样，组名不应重复。

     口令：

     口令字段存放的是用户组加密后的口令字。一般Linux系统的用户组都没有口令，即这个字段一般为空，或者是*。

     组标识号：

     组标识号与用户标识号类似，也是一个整数，被系统内部用来标识组。别称GID。

     组内用户列表：

     是属于这个组的所有用户的列表，不同用户之间用逗号(,)分隔。这个用户组可能是用户的主组，也可能是附加组。

     说明：

     我们以root:x:0:root,linuxsir 为例： 用户组root，x是密码段，表示没有设置密码，GID是0,root用户组下包括root、linuxsir以及GID为0的其它用户。


      chown将指定文件的拥有者改为指定的用户或组，用户可以是用户名或者用户ID；组可以是组名或者组ID；文件是以空格分开的要改变权限的文件列表，支持通配符。系统管理员经常使用chown命令，在将文件拷贝到另一个用户的名录下之后，让用户拥有使用该文件的权限。 

　　1．命令格式：

　　　　chown [选项]... [所有者][:[组]] 文件...

　　2．命令功能：

　　　　通过chown改变文件的拥有者和群组。在更改文件的所有者或所属群组时，可以使用用户名称和用户识别码设置。普通用户不能将自己的文件改变成其他的拥有者。其操作权限一般为管理员。

　　3．命令参数：

　　必要参数:

　　　　-c 显示更改的部分的信息

　　　　-f 忽略错误信息

　　　　-h 修复符号链接

　　　　-R 处理指定目录以及其子目录下的所有文件

　　　　-v 显示详细的处理信息

　　　　-deference 作用于符号链接的指向，而不是链接文件本身

　　选择参数:

　　　　--reference=&lt;目录或文件&gt; 把指定的目录/文件作为参考，把操作的文件/目录设置成参考文件/目录相同拥有者和群组

　　　　--from=&lt;当前用户：当前群组&gt; 只有当前用户和群组跟指定的用户和群组相同时才进行改变

　　　　--help 显示帮助信息

　　　　--version 显示版本信息

　　4．使用实例：

　　实例1：改变拥有者和群组

　　命令：

　　　　chown mail:mail log2012.log

　　说明：

　　实例2：改变文件拥有者和群组

　　命令：

　　　　chown root: log2012.log

　　说明：

　　实例3：改变文件群组

　　命令：

　　　　chown :mail log2012.log

　　实例4：改变指定目录以及其子目录下的所有文件的拥有者和群组 

　　命令：

　　　　chown -R -v root:mail test6


在lunix系统里，文件或目录的权限的掌控以拥有者及所诉群组来管理。可以使用chgrp指令取变更文件与目录所属群组，这种方式采用群组名称或群组识别码都可以。Chgrp命令就是change group的缩写！要被改变的组名必须要在/etc/group文件内存在才行。

1．命令格式：

chgrp [选项] [组] [文件]

2．命令功能：

chgrp命令可采用群组名称或群组识别码的方式改变文件或目录的所属群组。使用权限是超级用户。 

3．命令参数：

必要参数:

-c 当发生改变时输出调试信息

-f 不显示错误信息

-R 处理指定目录以及其子目录下的所有文件

-v 运行时显示详细的处理信息

--dereference 作用于符号链接的指向，而不是符号链接本身

--no-dereference 作用于符号链接本身



选择参数:

--reference=&lt;文件或者目录&gt;

--help 显示帮助信息

--version 显示版本信息



4．使用实例：

实例1：改变文件的群组属性 

命令：

chgrp -v bin log2012.log

输出：

[root@localhost test]# ll

---xrw-r-- 1 root root 302108 11-13 06:03 log2012.log

[root@localhost test]# chgrp -v bin log2012.log

“log2012.log” 的所属组已更改为 bin

[root@localhost test]# ll

---xrw-r-- 1 root bin  302108 11-13 06:03 log2012.log

说明：

将log2012.log文件由root群组改为bin群组



实例2：根据指定文件改变文件的群组属性 

命令：

chgrp --reference=log2012.log log2013.log

输出：

[root@localhost test]# ll

---xrw-r-- 1 root bin  302108 11-13 06:03 log2012.log

-rw-r--r-- 1 root root     61 11-13 06:03 log2013.log

[root@localhost test]#  chgrp --reference=log2012.log log2013.log 

[root@localhost test]# ll

---xrw-r-- 1 root bin  302108 11-13 06:03 log2012.log

-rw-r--r-- 1 root bin      61 11-13 06:03 log2013.log

说明：

改变文件log2013.log 的群组属性，使得文件log2013.log的群组属性和参考文件log2012.log的群组属性相同



实例3：改变指定目录以及其子目录下的所有文件的群组属性 

命令：

输出：

[root@localhost test]# ll

drwxr-xr-x 2 root root   4096 11-30 08:39 test6

[root@localhost test]# cd test6

[root@localhost test6]# ll

---xr--r-- 1 root root 302108 11-30 08:39 linklog.log

---xr--r-- 1 root root 302108 11-30 08:39 log2012.log

-rw-r--r-- 1 root root     61 11-30 08:39 log2013.log

-rw-r--r-- 1 root root      0 11-30 08:39 log2014.log

-rw-r--r-- 1 root root      0 11-30 08:39 log2015.log

-rw-r--r-- 1 root root      0 11-30 08:39 log2016.log

-rw-r--r-- 1 root root      0 11-30 08:39 log2017.log

[root@localhost test6]# cd ..

[root@localhost test]# chgrp -R bin test6

[root@localhost test]# cd test6

[root@localhost test6]# ll

---xr--r-- 1 root bin 302108 11-30 08:39 linklog.log

---xr--r-- 1 root bin 302108 11-30 08:39 log2012.log

-rw-r--r-- 1 root bin     61 11-30 08:39 log2013.log

-rw-r--r-- 1 root bin      0 11-30 08:39 log2014.log

-rw-r--r-- 1 root bin      0 11-30 08:39 log2015.log

-rw-r--r-- 1 root bin      0 11-30 08:39 log2016.log

-rw-r--r-- 1 root bin      0 11-30 08:39 log2017.log

[root@localhost test6]# cd ..

[root@localhost test]# ll

drwxr-xr-x 2 root bin    4096 11-30 08:39 test6

[root@localhost test]#

说明：

改变指定目录以及其子目录下的所有文件的群组属性



实例4：通过群组识别码改变文件群组属性

命令：

chgrp -R 100 test6

输出：

[root@localhost test]# chgrp -R 100 test6

[root@localhost test]# ll

drwxr-xr-x 2 root users   4096 11-30 08:39 test6

[root@localhost test]# cd test6

[root@localhost test6]# ll

---xr--r-- 1 root users 302108 11-30 08:39 linklog.log

---xr--r-- 1 root users 302108 11-30 08:39 log2012.log

-rw-r--r-- 1 root users     61 11-30 08:39 log2013.log

-rw-r--r-- 1 root users      0 11-30 08:39 log2014.log

-rw-r--r-- 1 root users      0 11-30 08:39 log2015.log

-rw-r--r-- 1 root users      0 11-30 08:39 log2016.log

-rw-r--r-- 1 root users      0 11-30 08:39 log2017.log

[root@localhost test6]#

说明：

通过群组识别码改变文件群组属性，100为users群组的识别码，具体群组和群组识别码可以去/etc/group文件中查看


通过SSH访问服务器，难免会要用到压缩，解压缩，打包，解包等，这时候tar命令就是是必不可少的一个功能强大的工具。linux中最流行的tar是麻雀虽小，五脏俱全，功能强大。

tar命令可以为linux的文件和目录创建档案。利用tar，可以为某一特定文件创建档案（备份文件），也可以在档案中改变文件，或者向档案中加入新的文件。tar最初被用来在磁带上创建档案，现在，用户可以在任何设备上创建档案。利用tar命令，可以把一大堆的文件和目录全部打包成一个文件，这对于备份文件或将几个文件组合成为一个文件以便于网络传输是非常有用的。

首先要弄清两个概念：打包和压缩。打包是指将一大堆文件或目录变成一个总的文件；压缩则是将一个大的文件通过一些压缩算法变成一个小文件。

为什么要区分这两个概念呢？这源于Linux中很多压缩程序只能针对一个文件进行压缩，这样当你想要压缩一大堆文件时，你得先将这一大堆文件先打成一个包（tar命令），然后再用压缩程序进行压缩（gzip bzip2命令）。

linux下最常用的打包程序就是tar了，使用tar程序打出来的包我们常称为tar包，tar包文件的命令通常都是以.tar结尾的。生成tar包后，就可以用其它的程序来进行压缩。

1．命令格式：

tar[必要参数][选择参数][文件] 

2．命令功能：

用来压缩和解压文件。tar本身不具有压缩功能。他是调用压缩功能实现的 

3．命令参数：

必要参数有如下：

-A 新增压缩文件到已存在的压缩

-B 设置区块大小

-c 建立新的压缩文件

-d 记录文件的差别

-r 添加文件到已经压缩的文件

-u 添加改变了和现有的文件到已经存在的压缩文件

-x 从压缩的文件中提取文件

-t 显示压缩文件的内容

-z 支持gzip解压文件

-j 支持bzip2解压文件

-Z 支持compress解压文件

-v 显示操作过程

-l 文件系统边界设置

-k 保留原有文件不覆盖

-m 保留文件不被覆盖

-W 确认压缩文件的正确性



可选参数如下：

-b 设置区块数目

-C 切换到指定目录

-f 指定压缩文件

--help 显示帮助信息

--version 显示版本信息



4．常见解压/压缩命令



tar 
解包：tar xvf FileName.tar
打包：tar cvf FileName.tar DirName
（注：tar是打包，不是压缩！）


.gz
解压1：gunzip FileName.gz
解压2：gzip -d FileName.gz
压缩：gzip FileName


.tar.gz 和 .tgz
解压：tar zxvf FileName.tar.gz
压缩：tar zcvf FileName.tar.gz DirName

.bz2
解压1：bzip2 -d FileName.bz2
解压2：bunzip2 FileName.bz2
压缩： bzip2 -z FileName


.tar.bz2
解压：tar jxvf FileName.tar.bz2
压缩：tar jcvf FileName.tar.bz2 DirName

.bz
解压1：bzip2 -d FileName.bz
解压2：bunzip2 FileName.bz
压缩：未知


.tar.bz
解压：tar jxvf FileName.tar.bz
压缩：未知

.Z
解压：uncompress FileName.Z
压缩：compress FileName


.tar.Z
解压：tar Zxvf FileName.tar.Z
压缩：tar Zcvf FileName.tar.Z DirName


.zip
解压：unzip FileName.zip
压缩：zip FileName.zip DirName

.rar
解压：rar x FileName.rar
压缩：rar a FileName.rar DirName 

 

5．使用实例

实例1：将文件全部打包成tar包

命令：

tar -cvf log.tar log2012.log

tar -zcvf log.tar.gz log2012.log

tar -jcvf log.tar.bz2 log2012.log

输出：

[root@localhost test]# ls -al log2012.log

---xrw-r-- 1 root root 302108 11-13 06:03 log2012.log

[root@localhost test]# tar -cvf log.tar log2012.log 

log2012.log

[root@localhost test]# tar -zcvf log.tar.gz log2012.log

log2012.log

[root@localhost test]# tar -jcvf log.tar.bz2 log2012.log 

log2012.log

[root@localhost test]# ls -al *.tar*

-rw-r--r-- 1 root root 307200 11-29 17:54 log.tar

-rw-r--r-- 1 root root   1413 11-29 17:55 log.tar.bz2

-rw-r--r-- 1 root root   1413 11-29 17:54 log.tar.gz

说明：

tar -cvf log.tar log2012.log    仅打包，不压缩！ 

tar -zcvf log.tar.gz log2012.log   打包后，以 gzip 压缩 

tar -zcvf log.tar.bz2 log2012.log  打包后，以 bzip2 压缩 

在参数 f 之后的文件档名是自己取的，我们习惯上都用 .tar 来作为辨识。 如果加 z 参数，则以 .tar.gz 或 .tgz 来代表 gzip 压缩过的 tar包； 如果加 j 参数，则以 .tar.bz2 来作为tar包名。



实例2：查阅上述 tar包内有哪些文件

命令：

tar -ztvf log.tar.gz

输出：

[root@localhost test]# tar -ztvf log.tar.gz

---xrw-r-- root/root    302108 2012-11-13 06:03:25 log2012.log

说明：

由于我们使用 gzip 压缩的log.tar.gz，所以要查阅log.tar.gz包内的文件时，就得要加上 z 这个参数了。



实例3：将tar 包解压缩

命令：

tar -zxvf /opt/soft/test/log.tar.gz

输出：

[root@localhost test3]# ll

总计 0[root@localhost test3]# tar -zxvf /opt/soft/test/log.tar.gz

log2012.log

[root@localhost test3]# ls

log2012.log

[root@localhost test3]#



说明：

在预设的情况下，我们可以将压缩档在任何地方解开的



实例4：只将 /tar 内的 部分文件解压出来

命令：

tar -zxvf /opt/soft/test/log30.tar.gz log2013.log

输出：

[root@localhost test]# tar -zcvf log30.tar.gz log2012.log log2013.log 

log2012.log

log2013.log

[root@localhost test]# ls -al log30.tar.gz 

-rw-r--r-- 1 root root 1512 11-30 08:19 log30.tar.gz

[root@localhost test]# tar -zxvf log30.tar.gz log2013.log

log2013.log

[root@localhost test]# ll

-rw-r--r-- 1 root root   1512 11-30 08:19 log30.tar.gz

[root@localhost test]# cd test3

[root@localhost test3]# tar -zxvf /opt/soft/test/log30.tar.gz log2013.log

log2013.log

[root@localhost test3]# ll

总计 4

-rw-r--r-- 1 root root 61 11-13 06:03 log2013.log

[root@localhost test3]#

说明：

我可以透过 tar -ztvf 来查阅 tar 包内的文件名称，如果单只要一个文件，就可以透过这个方式来解压部分文件！



实例5：文件备份下来，并且保存其权限

命令：

tar -zcvpf log31.tar.gz log2014.log log2015.log log2016.log 

输出：

[root@localhost test]# ll

总计 0

-rw-r--r-- 1 root root      0 11-13 06:03 log2014.log

-rw-r--r-- 1 root root      0 11-13 06:06 log2015.log

-rw-r--r-- 1 root root      0 11-16 14:41 log2016.log

[root@localhost test]# tar -zcvpf log31.tar.gz log2014.log log2015.log log2016.log 

log2014.log

log2015.log

log2016.log

[root@localhost test]# cd test6

[root@localhost test6]# ll

[root@localhost test6]# tar -zxvpf /opt/soft/test/log31.tar.gz 

log2014.log

log2015.log

log2016.log

[root@localhost test6]# ll

总计 0

-rw-r--r-- 1 root root 0 11-13 06:03 log2014.log

-rw-r--r-- 1 root root 0 11-13 06:06 log2015.log

-rw-r--r-- 1 root root 0 11-16 14:41 log2016.log

[root@localhost test6]#

说明：

这个 -p 的属性是很重要的，尤其是当您要保留原本文件的属性时

实例6：在 文件夹当中，比某个日期新的文件才备份

命令：

tar -N "2012/11/13" -zcvf log17.tar.gz test

输出：

[root@localhost soft]# tar -N "2012/11/13" -zcvf log17.tar.gz test

tar: Treating date `2012/11/13' as 2012-11-13 00:00:00 + 0 nanoseconds

test/test/log31.tar.gz

test/log2014.log

test/linklog.log

test/log2015.log

test/log2013.log

test/log2012.log

test/log2017.log

test/log2016.log

test/log30.tar.gz

test/log.tar

test/log.tar.bz2

test/log.tar.gz

说明：



实例7：备份文件夹内容是排除部分文件

命令：

tar --exclude scf/service -zcvf scf.tar.gz scf/*

输出：

[root@localhost test]# tree scf

scf

|-- bin

|-- doc

|-- lib

`-- service

   
 `-- deploy

       
  
|-- info

       
  
`-- product



7 directories, 0 files

[root@localhost test]# tar --exclude scf/service -zcvf scf.tar.gz scf/* 

scf/bin/

scf/doc/

scf/lib/

[root@localhost test]#


chmod命令用于改变linux系统文件或目录的访问权限。用它控制文件或目录的访问权限。该命令有两种用法。一种是包含字母和操作符表达式的文字设定法；另一种是包含数字的数字设定法。

Linux系统中的每个文件和目录都有访问许可权限，用它来确定谁可以通过何种方式对文件和目录进行访问和操作。
　　文件或目录的访问权限分为只读，只写和可执行三种。以文件为例，只读权限表示只允许读其内容，而禁止对其做任何的更改操作。可执行权限表示允许将该文件作为一个程序执行。文件被创建时，文件所有者自动拥有对该文件的读、写和可执行权限，以便于对文件的阅读和修改。用户也可根据需要把访问权限设置为需要的任何组合。
　　有三种不同类型的用户可对文件或目录进行访问：文件所有者，同组用户、其他用户。所有者一般是文件的创建者。所有者可以允许同组用户有权访问文件，还可以将文件的访问权限赋予系统中的其他用户。在这种情况下，系统中每一位用户都能访问该用户拥有的文件或目录。
　　每一文件或目录的访问权限都有三组，每组用三位表示，分别为文件属主的读、写和执行权限；与属主同组的用户的读、写和执行权限；系统中其他用户的读、写和执行权限。当用ls -l命令显示文件或目录的详细信息时，最左边的一列为文件的访问权限。 例如：

命令： 

ls -al

输出：

[root@localhost test]# ll -al

总计 316lrwxrwxrwx 1 root root     11 11-22 06:58 linklog.log -&gt; log2012.log

-rw-r--r-- 1 root root 302108 11-13 06:03 log2012.log

-rw-r--r-- 1 root root     61 11-13 06:03 log2013.log

-rw-r--r-- 1 root root      0 11-13 06:03 log2014.log

-rw-r--r-- 1 root root      0 11-13 06:06 log2015.log

-rw-r--r-- 1 root root      0 11-16 14:41 log2016.log

-rw-r--r-- 1 root root      0 11-16 14:43 log2017.log

我们以log2012.log为例：

-rw-r--r-- 1 root root 296K 11-13 06:03 log2012.log

第一列共有10个位置，第一个字符指定了文件类型。在通常意义上，一个目录也是一个文件。如果第一个字符是横线，表示是一个非目录的文件。如果是d，表示是一个目录。从第二个字符开始到第十个共9个字符，3个字符一组，分别表示了3组用户对文件或者目录的权限。权限字符用横线代表空许可，r代表只读，w代表写，x代表可执行。

例如：
　　- rw- r-- r--
　　表示log2012.log是一个普通文件；log2012.log的属主有读写权限；与log2012.log属主同组的用户只有读权限；其他用户也只有读权限。

　　确定了一个文件的访问权限后，用户可以利用Linux系统提供的chmod命令来重新设定不同的访问权限。也可以利用chown命令来更改某个文件或目录的所有者。利用chgrp命令来更改某个文件或目录的用户组。 

chmod命令是非常重要的，用于改变文件或目录的访问权限。用户用它控制文件或目录的访问权限。chmod命令详细情况如下。

1. 命令格式:

chmod [-cfvR] [--help] [--version] mode file   

2. 命令功能：

用于改变文件或目录的访问权限，用它控制文件或目录的访问权限。

3. 命令参数：

必要参数：
-c 当发生改变时，报告处理信息
-f 错误信息不输出
-R 处理指定目录以及其子目录下的所有文件
-v 运行时显示详细处理信息

选择参数：
--reference=&lt;目录或者文件&gt; 设置成具有指定目录或者文件具有相同的权限
--version 显示版本信息
&lt;权限范围&gt;+&lt;权限设置&gt; 使权限范围内的目录或者文件具有指定的权限
&lt;权限范围&gt;-&lt;权限设置&gt; 删除权限范围的目录或者文件的指定权限
&lt;权限范围&gt;=&lt;权限设置&gt; 设置权限范围内的目录或者文件的权限为指定的值


权限范围：
u ：目录或者文件的当前的用户
g ：目录或者文件的当前的群组
o ：除了目录或者文件的当前用户或群组之外的用户或者群组
a ：所有的用户及群组

权限代号：
r ：读权限，用数字4表示
w ：写权限，用数字2表示
x ：执行权限，用数字1表示
- ：删除权限，用数字0表示
s ：特殊权限 



该命令有两种用法。一种是包含字母和操作符表达式的文字设定法；另一种是包含数字的数字设定法。
　　1）. 文字设定法:
　　
chmod ［who］ ［+ | - | =］ ［mode］ 文件名
　　2）. 数字设定法
　　我们必须首先了解用数字表示的属性的含义：0表示没有权限，1表示可执行权限，2表示可写权限，4表示可读权限，然后将其相加。所以数字属性的格式应为3个从0到7的八进制数，其顺序是（u）（g）（o）。
　　例如，如果想让某个文件的属主有“读/写”二种权限，需要把4（可读）+2（可写）＝6（读/写）。
　　数字设定法的一般形式为：
　　
chmod ［mode］ 文件名



数字与字符对应关系如下：

r=4，w=2，x=1
若要rwx属性则4+2+1=7
若要rw-属性则4+2=6；
若要r-x属性则4+1=7。 


4. 使用实例：
实例1：增加文件所有用户组可执行权限

命令：

chmod a+x log2012.log

输出：

[root@localhost test]# ls -al log2012.log 

-rw-r--r-- 1 root root 302108 11-13 06:03 log2012.log

[root@localhost test]# chmod a+x log2012.log 

[root@localhost test]# ls -al log2012.log 

-rwxr-xr-x 1 root root 302108 11-13 06:03 log2012.log

[root@localhost test]#

说明：
　　即设定文件log2012.log的属性为：文件属主（u） 增加执行权限；与文件属主同组用户（g） 增加执行权限；其他用户（o） 增加执行权限。
　

实例2：同时修改不同用户权限

命令：

chmod ug+w,o-x log2012.log

输出：

[root@localhost test]# ls -al log2012.log 

-rwxr-xr-x 1 root root 302108 11-13 06:03 log2012.log

[root@localhost test]# chmod ug+w,o-x log2012.log 

[root@localhost test]# ls -al log2012.log 

-rwxrwxr-- 1 root root 302108 11-13 06:03 log2012.log


说明：
　　即设定文件text的属性为：文件属主（u） 增加写权限;与文件属主同组用户（g） 增加写权限;其他用户（o） 删除执行权限



实例3：删除文件权限

命令：

chmod a-x log2012.log

输出：

[root@localhost test]# ls -al log2012.log 

-rwxrwxr-- 1 root root 302108 11-13 06:03 log2012.log

[root@localhost test]# chmod a-x log2012.log 

[root@localhost test]# ls -al log2012.log 

-rw-rw-r-- 1 root root 302108 11-13 06:03 log2012.log

说明：
　
删除所有用户的可执行权限 
　

实例4：使用“=”设置权限 

命令：

chmod u=x log2012.log

输出：

[root@localhost test]# ls -al log2012.log 

-rw-rw-r-- 1 root root 302108 11-13 06:03 log2012.log

[root@localhost test]# chmod u=x log2012.log 

[root@localhost test]# ls -al log2012.log 

---xrw-r-- 1 root root 302108 11-13 06:03 log2012.log

说明：

撤销原来所有的权限，然后使拥有者具有可读权限 



实例5：对一个目录及其子目录所有文件添加权限 

命令：

chmod -R u+x test4

输出：

[root@localhost test]# cd test4

[root@localhost test4]# ls -al

总计 312drwxrwxr-x 2 root root   4096 11-13 05:50 .

drwxr-xr-x 5 root root   4096 11-22 06:58 ..

-rw-r--r-- 1 root root 302108 11-12 22:54 log2012.log

-rw-r--r-- 1 root root     61 11-12 22:54 log2013.log

-rw-r--r-- 1 root root      0 11-12 22:54 log2014.log

[root@localhost test4]# cd ..

[root@localhost test]# chmod -R u+x test4

[root@localhost test]# cd test4

[root@localhost test4]# ls -al

总计 312drwxrwxr-x 2 root root   4096 11-13 05:50 .

drwxr-xr-x 5 root root   4096 11-22 06:58 ..

-rwxr--r-- 1 root root 302108 11-12 22:54 log2012.log

-rwxr--r-- 1 root root     61 11-12 22:54 log2013.log

-rwxr--r-- 1 root root      0 11-12 22:54 log2014.log

说明：

递归地给test4目录下所有文件和子目录的属主分配权限 



其他一些实例：

1）. 

命令：

chmod 751 file   

说明：

给file的属主分配读、写、执行(7)的权限，给file的所在组分配读、执行(5)的权限，给其他用户分配执行(1)的权限

2）. 

命令：

chmod u=rwx,g=rx,o=x file 

说明：

上例的另一种形式

3）. 

命令

chmod =r file 

说明：                　　　　

为所有用户分配读权限

3）. 

命令：

chmod 444 file 

说明： 

   
同上例

4）. 

命令：

chmod a-wx,a+r   file

说明：

同上例


用SSH管理linux服务器时经常需要远程与本地之间交互文件.而直接用SecureCRT自带的上传下载功能无疑是最方便的，SecureCRT下的文件传输协议有ASCII、Xmodem、Zmodem。
文件传输协议：
 
      文件传输是数据交换的主要形式。在进行文件传输时，为使文件能被正确识别和传送，我们需要在两台计算机之间建立统一的传输协议。这个协议包括了文件的识别、传送的起止时间、错误的判断与纠正等内容。常见的传输协议有以下几种： 
ASCII：这是最快的传输协议，但只能传送文本文件。 
        Xmodem：这种古老的传输协议速度较慢，但由于使用了CRC错误侦测方法，传输的准确率可高达99.6%。 
        Ymodem：这是Xmodem的改良版，使用了1024位区段传送，速度比Xmodem要快
Zmodem：Zmodem采用了串流式（streaming）传输方式，传输速度较快，而且还具有自动改变区段大小和断点续传、快速错误侦测等功能。这是目前最流行的文件传输协议。 
除以上几种外，还有Imodem、Jmodem、Bimodem、Kermit、Lynx等协议，由于没有多数厂商支持，这里就略去不讲。


SecureCRT可以使用linux下的zmodem协议来快速的传送文件,使用非常方便.具体步骤：

一．在使用SecureCRT上传下载之前需要给服务器安装lrzsz：

1、从下面的地址下载 lrzsz-0.12.20.tar.gz

http://down1.chinaunix.net/distfiles/lrzsz-0.12.20.tar.gz

2、查看里面的INSTALL文档了解安装参数说明和细节

3、解压文件

tar zxvf lrzsz-0.12.20.tar.gz

4、进入目录

cd lrzsz-0.12.20

5、./configure --prefix=/usr/local/lrzsz

6、make

7、make install

8、建立软链接

#cd /usr/bin

#ln -s /usr/local/lrzsz/bin/lrz rz

#ln -s /usr/local/lrzsz/bin/lsz sz

9、测试

运行 rz 弹出SecureCRT上传窗口,用SecureCRT来上传和下载文件。



二．设置SecureCRT上传和下载的默认目录就行

options-&gt;session options -&gt;Terminal-&gt;Xmodem/Zmodem 下
在右栏directory设置上传和下载的目录


三．使用Zmodem从客户端上传文件到linux服务器

1.在用SecureCRT登陆linux终端.
       2.选中你要放置上传文件的路径，在目录下然后输入rz命令,SecureCRT会弹出文件选择对话框，在查找范围中找到你要上传的文件，按Add按钮。然后OK就可以把文件上传到linux上了。
或者在Transfer-&gt;Zmodem Upoad list弹出文件选择对话框，选好文件后按Add按钮。然后OK窗口自动关闭。然后在linux下选中存放文件的目录，输入rz命令。liunx就把那个文件上传到这个目录下了。



四．使用Zmodem下载文件到客户端：
sz filename
zmodem接收可以自行启动.下载的文件存放在你设定的默认下载目录下.



rz，sz是Linux/Unix同Windows进行ZModem文件传输的命令行工具windows端需要支持ZModem的telnet/ssh客户端，SecureCRT就可以用SecureCRT登陆到Unix/Linux主机（telnet或ssh均可）O 运行命令rz，即是接收文件，SecureCRT就会弹出文件选择对话框，选好文件之后关闭对话框，文件就会上传到当前目录 O 运行命令sz file1 file2就是发文件到windows上（保存的目录是可以配置） 比ftp命令方便多了，而且服务器不用再开FTP服务了


Linux 文件或目录的属性主要包括：文件或目录的节点、种类、权限模式、链接数量、所归属的用户和用户组、最近访问或修改的时间等内容。具体情况如下：

命令： 

ls -lih

输出：

[root@localhost test]# ls -lih

总计 316K

2095120 lrwxrwxrwx 1 root root   11 11-22 06:58 linklog.log -&gt; log2012.log

2095112 -rw-r--r-- 1 root root 296K 11-13 06:03 log2012.log

2095110 -rw-r--r-- 1 root root   61 11-13 06:03 log2013.log

2095107 -rw-r--r-- 1 root root    0 11-13 06:03 log2014.log

2095117 -rw-r--r-- 1 root root    0 11-13 06:06 log2015.log

2095118 -rw-r--r-- 1 root root    0 11-16 14:41 log2016.log

2095119 -rw-r--r-- 1 root root    0 11-16 14:43 log2017.log

2095113 drwxr-xr-x 6 root root 4.0K 10-27 01:58 scf

2095109 drwxrwxr-x 2 root root 4.0K 11-13 06:08 test3

2095131 drwxrwxr-x 2 root root 4.0K 11-13 05:50 test4

说明：

第一列：inode

第二列：文件种类和权限；

第三列： 硬链接个数；

第四列： 属主；

第五列：所归属的组；

第六列：文件或目录的大小；

第七列和第八列：最后访问或修改时间；

第九列：文件名或目录名



我们以log2012.log为例：

2095112 -rw-r--r-- 1 root root 296K 11-13 06:03 log2012.log

inode 的值是：2095112 

文件类型：文件类型是-，表示这是一个普通文件。

文件权限：文件权限是rw-r--r-- ，表示文件属主可读、可写、不可执行，文件所归属的用户组不可写，可读，不可执行，其它用户不可写，可读，不可执行；



硬链接个数： log2012.log这个文件没有硬链接；因为数值是1，就是他本身；

文件属主：也就是这个文件归哪于哪个用户 ，它归于root，也就是第一个root；

文件属组：也就是说，对于这个文件，它归属于哪个用户组，在这里是root用户组；

文件大小：文件大小是296k个字节；

访问可修改时间 ：这里的时间是最后访问的时间，最后访问和文件被修改或创建的时间，有时并不是一致的；

当然文档的属性不仅仅包括这些，这些是我们最常用的一些属性。



关于inode：

inode 译成中文就是索引节点。每个存储设备或存储设备的分区（存储设备是硬盘、软盘、U盘等等）被格式化为文件系统后，应该有两部份，一部份是inode，另一部份是Block，Block是用来存储数据用的。而inode呢，就是用来存储这些数 据的信息，这些信息包括文件大小、属主、归属的用户组、读写权限等。inode为每个文件进行信息索引，所以就有了inode的数值。操作系统根据指令， 能通过inode值最快的找到相对应的文件。

做个比喻，比如一本书，存储设备或分区就相当于这本书，Block相当于书中的每一页，inode 就相当于这本书前面的目录，一本书有很多的内容，如果想查找某部份的内容，我们可以先查目录，通过目录能最快的找到我们想要看的内容。虽然不太恰当，但还是比较形象。

当我们用ls 查看某个目录或文件时，如果加上-i 参数，就可以看到inode节点了；比如我们前面所说的例子：

[root@localhost test]#  ls -li log2012.log 

2095112 -rw-r--r-- 1 root root 302108 11-13 06:03 log2012.log

log2012.log 的inode值是 2095112 ； 查看一个文件或目录的inode，要通过ls 命令的的 -i参数。


Linux文件类型和Linux文件的文件名所代表的意义是两个不同的概念。我们通过一般应用程序而创建的比如file.txt、file.tar.gz ，这些文件虽然要用不同的程序来打开，但放在Linux文件类型中衡量的话，大多是常规文件（也被称为普通文件）。

一. 文件类型

Linux文件类型常见的有：普通文件、目录文件、字符设备文件和块设备文件、符号链接文件等，现在我们进行一个简要的说明。

1. 普通文件 

用 ls -lh 来查看某个文件的属性，可以看到有类似-rwxrwxrwx，值得注意的是第一个符号是 - ，这样的文件在Linux中就是普通文件。这些文件一般是用一些相关的应用程序创建，比如图像工具、文档工具、归档工具... .... 或 cp工具等。这类文件的删除方式是用rm 命令。 另外，依照文件的内容，又大略可以分为：

1&gt;. 纯文本档(ASCII)：

这是Linux系统中最多的一种文件类型，称为纯文本档是因为内容为我们人类可以直接读到的数据，例如数字、字母等等。 几乎只要我们可以用来做为设定的文件都属于这一种文件类型。 举例来说，你可以用命令： cat ~/.bashrc 来看到该文件的内容。 (cat 是将一个文件内容读出来的指令).

2&gt;. 二进制文件(binary)：

Linux系统其实仅认识且可以执行二进制文件(binary file)。Linux当中的可执行文件(scripts, 文字型批处理文件不算)就是这种格式的文件。 刚刚使用的命令cat就是一个binary file。

3&gt;. 数据格式文件(data)： 

有些程序在运作的过程当中会读取某些特定格式的文件，那些特定格式的文件可以被称为数据文件 (data file)。举例来说，我们的Linux在使用者登录时，都会将登录的数据记录在 /var/log/wtmp那个文件内，该文件是一个data file，他能够透过last这个指令读出来！ 但是使用cat时，会读出乱码～因为他是属于一种特殊格式的文件？



2. 目录文件

当我们在某个目录下执行，看到有类似 drwxr-xr-x ，这样的文件就是目录，目录在Linux是一个比较特殊的文件。注意它的第一个字符是d。创建目录的命令可以用 mkdir 命令，或cp命令，cp可以把一个目录复制为另一个目录。删除用rm 或rmdir命令。 



3. 字符设备或块设备文件 

如时您进入/dev目录，列一下文件，会看到类似如下的:

[root@localhost ~]# ls -al /dev/tty

crw-rw-rw- 1 root tty 5, 0 11-03 15:11 /dev/tty

[root@localhost ~]# ls -la /dev/sda1

brw-r----- 1 root disk 8, 1 11-03 07:11 /dev/sda1

我们看到/dev/tty的属性是 crw-rw-rw- ，注意前面第一个字符是 c ，这表示字符设备文件。比如猫等串口设备。我们看到 /dev/sda1 的属性是 brw-r----- ，注意前面的第一个字符是b，这表示块设备，比如硬盘，光驱等设备。

这个种类的文件，是用mknode来创建，用rm来删除。目前在最新的Linux发行版本中，我们一般不用自己来创建设备文件。因为这些文件是和内核相关联的。

与系统周边及储存等相关的一些文件， 通常都集中在/dev这个目录之下！通常又分为两种：

区块(block)设备档 ：

就是一些储存数据， 以提供系统随机存取的接口设备，举例来说，硬盘与软盘等就是啦！ 你可以随机的在硬盘的不同区块读写，这种装置就是成组设备！你可以自行查一下/dev/sda看看， 会发现第一个属性为[ b ]！

字符(character)设备文件：

亦即是一些串行端口的接口设备， 例如键盘、鼠标等等！这些设备的特色就是一次性读取的，不能够截断输出。 举例来说，你不可能让鼠标跳到另一个画面，而是滑动到另一个地方！第一个属性为 [ c ]。



4. 数据接口文件(sockets)： 

数据接口文件（或者：套接口文件），这种类型的文件通常被用在网络上的数据承接了。我们可以启动一个程序来监听客户端的要求， 而客户端就可以透过这个socket来进行数据的沟通了。第一个属性为 [ s ]， 最常在/var/run这个目录中看到这种文件类型了。

例如：当我们启动MySQL服务器时，会产生一个mysql.sock的文件。

[root@localhost ~]# ls -lh /var/lib/mysql/mysql.sock 

srwxrwxrwx 1 mysql mysql 0 04-19 11:12 /var/lib/mysql/mysql.sock

注意这个文件的属性的第一个字符是 s。



5. 符号链接文件： 

当我们查看文件属性时，会看到有类似 lrwxrwxrwx,注意第一个字符是l，这类文件是链接文件。是通过ln -s 源文件名 新文件名 。上面是一个例子，表示setup.log是install.log的软链接文件。怎么理解呢？这和Windows操作系统中的快捷方式有点相似。

符号链接文件的创建方法举例:

[root@localhost test]# ls -lh log2012.log

-rw-r--r-- 1 root root 296K 11-13 06:03 log2012.log

[root@localhost test]# ln -s log2012.log  linklog.log

[root@localhost test]# ls -lh *.log

lrwxrwxrwx 1 root root   11 11-22 06:58 linklog.log -&gt; log2012.log

-rw-r--r-- 1 root root 296K 11-13 06:03 log2012.log



6. 数据输送文件（FIFO,pipe）:

FIFO也是一种特殊的文件类型，他主要的目的在解决多个程序同时存取一个文件所造成的错误问题。 FIFO是first-in-first-out的缩写。第一个属性为[p] 。



二. Linux文件扩展名

1. 扩展名类型

基本上，Linux的文件是没有所谓的扩展名的，一个Linux文件能不能被执行，与他的第一栏的十个属性有关， 与档名根本一点关系也没有。这个观念跟Windows的情况不相同喔！在Windows底下， 能被执行的文件扩展名通常是 .com .exe .bat等等，而在Linux底下，只要你的权限当中具有x的话，例如[ -rwx-r-xr-x ] 即代表这个文件可以被执行。



不过，可以被执行跟可以执行成功是不一样的～举例来说，在root家目录下的install.log 是一个纯文本档，如果经由修改权限成为 -rwxrwxrwx 后，这个文件能够真的执行成功吗？ 当然不行～因为他的内容根本就没有可以执行的数据。所以说，这个x代表这个文件具有可执行的能力， 但是能不能执行成功，当然就得要看该文件的内容.

虽然如此，不过我们仍然希望可以藉由扩展名来了解该文件是什么东西，所以，通常我们还是会以适当的扩展名来表示该文件是什么种类的。底下有数种常用的扩展名：

*.sh ： 脚本或批处理文件 (scripts)，因为批处理文件为使用shell写成的，所以扩展名就编成 .sh 

*Z, *.tar, *.tar.gz, *.zip, *.tgz： 经过打包的压缩文件。这是因为压缩软件分别为 gunzip, tar 等等的，由于不同的压缩软件，而取其相关的扩展名！

*.html, *.php：网页相关文件，分别代表 HTML 语法与 PHP 语法的网页文件。 .html 的文件可使用网页浏览器来直接开启，至于 .php 的文件， 则可以透过 client 端的浏览器来 server 端浏览，以得到运算后的网页结果。

基本上，Linux系统上的文件名真的只是让你了解该文件可能的用途而已，真正的执行与否仍然需要权限的规范才行。例如虽然有一个文件为可执行文件，如常见的/bin/ls这个显示文件属性的指令，不过，如果这个文件的权限被修改成无法执行时，那么ls就变成不能执行。

上述的这种问题最常发生在文件传送的过程中。例如你在网络上下载一个可执行文件，但是偏偏在你的 Linux系统中就是无法执行！呵呵！那么就是可能文件的属性被改变了。不要怀疑，从网络上传送到你的 Linux系统中，文件的属性与权限确实是会被改变的。



2. Linux文件名长度限制：

在Linux底下，使用预设的Ext2/Ext3文件系统时，针对文件名长度限制为：

单一文件或目录的最大容许文件名为 255 个字符

包含完整路径名称及目录 (/) 之完整档名为 4096 个字符

是相当长的档名！我们希望Linux的文件名可以一看就知道该文件在干嘛的， 所以档名通常是很长很长。



3. Linux文件名的字符的限制：

由于Linux在文字接口下的一些指令操作关系，一般来说，你在设定Linux底下的文件名时， 最好可以避免一些特殊字符比较好！例如底下这些：

* ? &gt; &lt; ; &amp; ! [ ] | \ ' " ` ( ) { }

因为这些符号在文字接口下，是有特殊意义的。另外，文件名的开头为小数点“.”时， 代表这个文件为隐藏文件！同时，由于指令下达当中，常常会使用到 -option 之类的选项， 所以你最好也避免将文件档名的开头以 - 或 + 来命名。


对于每一个Linux学习者来说，了解Linux文件系统的目录结构，是学好Linux的至关重要的一步.，深入了解linux文件目录结构的标准和每个目录的详细功能，对于我们用好linux系统只管重要，下面我们就开始了解一下linux目录结构的相关知识。

当在使用Linux的时候，如果您通过ls –l / 就会发现，在/下包涵很多的目录，比如etc、usr、var、bin ... ... 等目录，而在这些目录中，我们进去看看，发现也有很多的目录或文件。文件系统在Linux下看上去就象树形结构，所以我们可以把文件系统的结构形象的称为 树形结构。

文件系统的是用来组织和排列文件存取的，所以她是可见的，在Linux中，我们可以通过ls等工具来查看其结构，在Linux系统中，我们见到的都是树形结构；比如操作系统安装在一个文件系统中，他表现为由/ 起始的树形结构。linux文件系统的最顶端是/，我们称/为Linux的root，也就是 Linux操作系统的文件系统。Linux的文件系统的入口就是/，所有的目录、文件、设备都在/之下，/就是Linux文件系统的组织者，也是最上级的领导者。

由于linux是开放源代码，各大公司和团体根据linux的核心代码做各自的操作，编程。这样就造成在根下的目录的不同。这样就造成个人不能使用他人的linux系统的PC。因为你根本不知道一些基本的配置，文件在哪里。。。这就造成了混乱。这就是FHS（Filesystem Hierarchy Standard ）机构诞生的原因。该机构是linux爱好者自发的组成的一个团体，主要是是对linux做一些基本的要求，不至于是操作者换一台主机就成了linux的‘文盲’。

根据FHS(http://www.pathname.com/fhs/)的官方文件指出， 他们的主要目的是希望让使用者可以了解到已安装软件通常放置于那个目录下， 所以他们希望独立的软件开发商、操作系统制作者、以及想要维护系统的用户，都能够遵循FHS的标准。 也就是说，FHS的重点在于规范每个特定的目录下应该要放置什么样子的数据而已。 这样做好处非常多，因为Linux操作系统就能够在既有的面貌下(目录架构不变)发展出开发者想要的独特风格。

事实上，FHS是根据过去的经验一直再持续的改版的，FHS依据文件系统使用的频繁与否与是否允许使用者随意更动， 而将目录定义成为四种交互作用的形态，用表格来说有点像底下这样：








可分享的(shareable)



不可分享的(unshareable)





不变的(static)


/usr (软件放置处)


/etc (配置文件)




/opt (第三方协力软件)


/boot (开机与核心档)





可变动的(variable)


/var/mail (使用者邮件信箱)


/var/run (程序相关)




/var/spool/news (新闻组)


/var/lock (程序相关)







四中类型:

1. 可分享的：

可以分享给其他系统挂载使用的目录，所以包括执行文件与用户的邮件等数据， 是能够分享给网络上其他主机挂载用的目录；

2. 不可分享的：

自己机器上面运作的装置文件或者是与程序有关的socket文件等， 由于仅与自身机器有关，所以当然就不适合分享给其他主机了。

3. 不变的：

有些数据是不会经常变动的，跟随着distribution而不变动。 例如函式库、文件说明文件、系统管理员所管理的主机服务配置文件等等；

4. 可变动的：

经常改变的数据，例如登录文件、一般用户可自行收受的新闻组等。



事实上，FHS针对目录树架构仅定义出三层目录底下应该放置什么数据而已，分别是底下这三个目录的定义：

/ (root, 根目录)：与开机系统有关；

/usr (unix software resource)：与软件安装/执行有关；

/var (variable)：与系统运作过程有关。



一. 根目录 (/) 的意义与内容：

根目录是整个系统最重要的一个目录，因为不但所有的目录都是由根目录衍生出来的， 同时根目录也与开机/还原/系统修复等动作有关。 由于系统开机时需要特定的开机软件、核心文件、开机所需程序、 函式库等等文件数据，若系统出现错误时，根目录也必须要包含有能够修复文件系统的程序才行。 因为根目录是这么的重要，所以在FHS的要求方面，他希望根目录不要放在非常大的分区， 因为越大的分区内你会放入越多的数据，如此一来根目录所在分区就可能会有较多发生错误的机会。

因此FHS标准建议：根目录(/)所在分区应该越小越好， 且应用程序所安装的软件最好不要与根目录放在同一个分区内，保持根目录越小越好。 如此不但效能较佳，根目录所在的文件系统也较不容易发生问题。说白了，就是根目录和Windows的C盘一个样。

根据以上原因，FHS认为根目录(/)下应该包含如下子目录：





目录



应放置档案内容




/bin


系统有很多放置执行档的目录，但/bin比较特殊。因为/bin放置的是在单人维护模式下还能够被操作的指令。在/bin底下的指令可以被root与一般帐号所使用，主要有：cat,chmod(修改权限), chown, date, mv, mkdir, cp, bash等等常用的指令。




/boot


主要放置开机会使用到的档案，包括Linux核心档案以及开机选单与开机所需设定档等等。Linux kernel常用的档名为：vmlinuz ，如果使用的是grub这个开机管理程式，则还会存在/boot/grub/这个目录。




/dev


在Linux系统上，任何装置与周边设备都是以档案的型态存在于这个目录当中。 只要通过存取这个目录下的某个档案，就等于存取某个装置。比要重要的档案有/dev/null, /dev/zero, /dev/tty , /dev/lp*, / dev/hd*, /dev/sd*等等




/etc


系统主要的设定档几乎都放置在这个目录内，例如人员的帐号密码档、各种服务的启始档等等。 一般来说，这个目录下的各档案属性是可以让一般使用者查阅的，但是只有root有权力修改。 FHS建议不要放置可执行档(binary)在这个目录中。 比较重要的档案有：/etc/inittab, /etc/init.d/, /etc/modprobe.conf, /etc/X11/, /etc/fstab, /etc/sysconfig/等等。 另外，其下重要的目录有：/etc/init.d/ ：所有服务的预设启动script都是放在这里的，例如要启动或者关闭iptables的话： /etc/init.d/iptables start、/etc/init.d/ iptables stop
/etc/xinetd.d/ ：这就是所谓的super daemon管理的各项服务的设定档目录。
/etc/X11/ ：与X Window有关的各种设定档都在这里，尤其是xorg.conf或XF86Config这两个X Server的设定档。




/home


这是系统预设的使用者家目录(home directory)。 在你新增一个一般使用者帐号时，预设的使用者家目录都会规范到这里来。比较重要的是，家目录有两种代号： 
~ ：代表当前使用者的家目录，而 ~guest：则代表用户名为guest的家目录。




/lib


系统的函式库非常的多，而/lib放置的则是在开机时会用到的函式库，以及在/bin或/sbin底下的指令会呼叫的函式库而已 。 什么是函式库呢？妳可以将他想成是外挂，某些指令必须要有这些外挂才能够顺利完成程式的执行之意。 尤其重要的是/lib/modules/这个目录，因为该目录会放置核心相关的模组(驱动程式)。




/media


media是媒体的英文，顾名思义，这个/media底下放置的就是可移除的装置。 包括软碟、光碟、DVD等等装置都暂时挂载于此。 常见的档名有：/media/floppy, /media/cdrom等等。




/mnt


如果妳想要暂时挂载某些额外的装置，一般建议妳可以放置到这个目录中。在古早时候，这个目录的用途与/media相同啦。 只是有了/media之后，这个目录就用来暂时挂载用了。




/opt


这个是给第三方协力软体放置的目录 。 什么是第三方协力软体啊？举例来说，KDE这个桌面管理系统是一个独立的计画，不过他可以安装到Linux系统中，因此KDE的软体就建议放置到此目录下了。 另外，如果妳想要自行安装额外的软体(非原本的distribution提供的)，那么也能够将你的软体安装到这里来。 不过，以前的Linux系统中，我们还是习惯放置在/usr/local目录下。




/root


系统管理员(root)的家目录。 之所以放在这里，是因为如果进入单人维护模式而仅挂载根目录时，该目录就能够拥有root的家目录，所以我们会希望root的家目录与根目录放置在同一个分区中。




/sbin


Linux有非常多指令是用来设定系统环境的，这些指令只有root才能够利用来设定系统，其他使用者最多只能用来查询而已。放在/sbin底下的为开机过程中所需要的，里面包括了开机、修复、还原系统所需要的指令。至于某些伺服器软体程式，一般则放置到/usr/sbin/当中。至于本机自行安装的软体所产生的系统执行档(system binary)，则放置到/usr/local/sbin/当中了。常见的指令包括：fdisk, fsck, ifconfig, init, mkfs等等。




/srv


srv可以视为service的缩写，是一些网路服务启动之后，这些服务所需要取用的资料目录。 常见的服务例如WWW, FTP等等。 举例来说，WWW伺服器需要的网页资料就可以放置在/srv/www/里面。呵呵，看来平时我们编写的代码应该放到这里了。




/tmp


这是让一般使用者或者是正在执行的程序暂时放置档案的地方。这个目录是任何人都能够存取的，所以你需要定期的清理一下。当然，重要资料不可放置在此目录啊。 因为FHS甚至建议在开机时，应该要将/tmp下的资料都删除。






事实上FHS针对根目录所定义的标准就仅限于上表，不过仍旧有些目录也需要我们了解一下，具体如下：







目录



应放置文件内容




/lost+found


这个目录是使用标准的ext2/ext3档案系统格式才会产生的一个目录，目的在于当档案系统发生错误时，将一些遗失的片段放置到这个目录下。 这个目录通常会在分割槽的最顶层存在，例如你加装一个硬盘于/disk中，那在这个系统下就会自动产生一个这样的目录/disk/lost+found




/proc


这个目录本身是一个虚拟文件系统(virtual filesystem)喔。 他放置的资料都是在内存当中，例如系统核心、行程资讯(process)（是进程吗?）、周边装置的状态及网络状态等等。因为这个目录下的资料都是在记忆体（内存）当中，所以本身不占任何硬盘空间。比较重要的档案（目录）例如： /proc/cpuinfo, /proc/dma, /proc/interrupts, /proc/ioports, /proc/net/*等等。呵呵，是虚拟内存吗[guest]？




/sys


这个目录其实跟/proc非常类似，也是一个虚拟的档案系统，主要也是记录与核心相关的资讯。 包括目前已载入的核心模组与核心侦测到的硬体装置资讯等等。 这个目录同样不占硬盘容量。






除了这些目录的内容之外，另外要注意的是，因为根目录与开机有关，开机过程中仅有根目录会被挂载， 其他分区则是在开机完成之后才会持续的进行挂载的行为。就是因为如此，因此根目录下与开机过程有关的目录， 就不能够与根目录放到不同的分区去。那哪些目录不可与根目录分开呢？有底下这些：

/etc：配置文件

/bin：重要执行档

/dev：所需要的装置文件

/lib：执行档所需的函式库与核心所需的模块

/sbin：重要的系统执行文件

这五个目录千万不可与根目录分开在不同的分区。请背下来啊。 



二. /usr 的意义与内容：

依据FHS的基本定义，/usr里面放置的数据属于可分享的与不可变动的(shareable, static)， 如果你知道如何透过网络进行分区的挂载(例如在服务器篇会谈到的NFS服务器)，那么/usr确实可以分享给局域网络内的其他主机来使用喔。

/usr不是user的缩写，其实usr是Unix Software Resource的缩写， 也就是Unix操作系统软件资源所放置的目录，而不是用户的数据啦。这点要注意。 FHS建议所有软件开发者，应该将他们的数据合理的分别放置到这个目录下的次目录，而不要自行建立该软件自己独立的目录。



因为是所有系统默认的软件(distribution发布者提供的软件)都会放置到/usr底下，因此这个目录有点类似Windows 系统的C:\Windows\ + C:\Program files\这两个目录的综合体，系统刚安装完毕时，这个目录会占用最多的硬盘容量。 一般来说，/usr的次目录建议有底下这些：





目录



应放置文件内容




/usr/X11R6/ 


为X Window System重要数据所放置的目录，之所以取名为X11R6是因为最后的X版本为第11版，且该版的第6次释出之意。 




/usr/bin/ 


绝大部分的用户可使用指令都放在这里。请注意到他与/bin的不同之处。(是否与开机过程有关) 




/usr/include/ 


c/c++等程序语言的档头(header)与包含档(include)放置处，当我们以tarball方式 (*.tar.gz 的方式安装软件)安装某些数据时，会使用到里头的许多包含档。 




/usr/lib/ 


包含各应用软件的函式库、目标文件(object file)，以及不被一般使用者惯用的执行档或脚本(script)。 某些软件会提供一些特殊的指令来进行服务器的设定，这些指令也不会经常被系统管理员操作， 那就会被摆放到这个目录下啦。要注意的是，如果你使用的是X86_64的Linux系统， 那可能会有/usr/lib64/目录产生 




/usr/local/ 


统管理员在本机自行安装自己下载的软件(非distribution默认提供者)，建议安装到此目录， 这样会比较便于管理。举例来说，你的distribution提供的软件较旧，你想安装较新的软件但又不想移除旧版， 此时你可以将新版软件安装于/usr/local/目录下，可与原先的旧版软件有分别啦。 你可以自行到/usr/local去看看，该目录下也是具有bin, etc, include, lib...的次目录 




/usr/sbin/ 


非系统正常运作所需要的系统指令。最常见的就是某些网络服务器软件的服务指令(daemon) 




/usr/share/ 


放置共享文件的地方，在这个目录下放置的数据几乎是不分硬件架构均可读取的数据， 因为几乎都是文本文件嘛。在此目录下常见的还有这些次目录：/usr/share/man：联机帮助文件
/usr/share/doc：软件杂项的文件说明
/usr/share/zoneinfo：与时区有关的时区文件





/usr/src/ 


一般原始码建议放置到这里，src有source的意思。至于核心原始码则建议放置到/usr/src/linux/目录下。 







三.  /var 的意义与内容：

如果/usr是安装时会占用较大硬盘容量的目录，那么/var就是在系统运作后才会渐渐占用硬盘容量的目录。 因为/var目录主要针对常态性变动的文件，包括缓存(cache)、登录档(log file)以及某些软件运作所产生的文件， 包括程序文件(lock file, run file)，或者例如MySQL数据库的文件等等。常见的次目录有：





目录



应放置文件内容




/var/cache/


应用程序本身运作过程中会产生的一些暂存档




/var/lib/


程序本身执行的过程中，需要使用到的数据文件放置的目录。在此目录下各自的软件应该要有各自的目录。 举例来说，MySQL的数据库放置到/var/lib/mysql/而rpm的数据库则放到/var/lib/rpm去




/var/lock/


某些装置或者是文件资源一次只能被一个应用程序所使用，如果同时有两个程序使用该装置时， 就可能产生一些错误的状况，因此就得要将该装置上锁(lock)，以确保该装置只会给单一软件所使用。 举例来说，刻录机正在刻录一块光盘，你想一下，会不会有两个人同时在使用一个刻录机烧片？ 如果两个人同时刻录，那片子写入的是谁的数据？所以当第一个人在刻录时该刻录机就会被上锁， 第二个人就得要该装置被解除锁定(就是前一个人用完了)才能够继续使用




/var/log/


非常重要。这是登录文件放置的目录。里面比较重要的文件如/var/log/messages, /var/log/wtmp(记录登入者的信息)等。




/var/mail/


放置个人电子邮件信箱的目录，不过这个目录也被放置到/var/spool/mail/目录中，通常这两个目录是互为链接文件。




/var/run/


某些程序或者是服务启动后，会将他们的PID放置在这个目录下




/var/spool/


这个目录通常放置一些队列数据，所谓的“队列”就是排队等待其他程序使用的数据。 这些数据被使用后通常都会被删除。举例来说，系统收到新信会放置到/var/spool/mail/中， 但使用者收下该信件后该封信原则上就会被删除。信件如果暂时寄不出去会被放到/var/spool/mqueue/中， 等到被送出后就被删除。如果是工作排程数据(crontab)，就会被放置到/var/spool/cron/目录中。







由于FHS仅是定义出最上层(/)及次层(/usr, /var)的目录内容应该要放置的文件或目录数据， 因此，在其他次目录层级内，就可以随开发者自行来配置了。



四. 目录树(directory tree) :

在Linux底下，所有的文件与目录都是由根目录开始的。那是所有目录与文件的源头, 然后再一个一个的分支下来，因此，我们也称这种目录配置方式为：目录树(directory tree), 这个目录树的主要特性有：

目录树的启始点为根目录 (/, root)；

每一个目录不止能使用本地端的 partition 的文件系统，也可以使用网络上的 filesystem 。举例来说， 可以利用 Network File System (NFS) 服务器挂载某特定目录等。

每一个文件在此目录树中的文件名(包含完整路径)都是独一无二的。



如果我们将整个目录树以图的方法来显示，并且将较为重要的文件数据列出来的话，那么目录树架构就如下图所示：



五. 绝对路径与相对路径

除了需要特别注意的FHS目录配置外，在文件名部分我们也要特别注意。因为根据档名写法的不同，也可将所谓的路径(path)定义为绝对路径(absolute)与相对路径(relative)。 这两种文件名/路径的写法依据是这样的：

绝对路径：

由根目录(/)开始写起的文件名或目录名称， 例如 /home/dmtsai/.bashrc；

相对路径：

相对于目前路径的文件名写法。 例如 ./home/dmtsai 或 http://www.cnblogs.com/home/dmtsai/ 等等。反正开头不是 / 就属于相对路径的写法

而你必须要了解，相对路径是以你当前所在路径的相对位置来表示的。举例来说，你目前在 /home 这个目录下， 如果想要进入 /var/log 这个目录时，可以怎么写呢？

cd /var/log   (absolute)

cd ../var/log (relative)

因为你在 /home 底下，所以要回到上一层 (../) 之后，才能继续往 /var 来移动的，特别注意这两个特殊的目录：

.  ：代表当前的目录，也可以使用 ./ 来表示；

.. ：代表上一层目录，也可以 ../ 来代表。

这个 . 与 .. 目录概念是很重要的，你常常会看到 cd .. 或 ./command 之类的指令下达方式， 就是代表上一层与目前所在目录的工作状态。



实例1：如何先进入/var/spool/mail/目录，再进入到/var/spool/cron/目录内？

命令：

cd /var/spool/mail

cd ../cron

说明：

由于/var/spool/mail与/var/spool/cron是同样在/var/spool/目录中。如此就不需要在由根目录开始写起了。这个相对路径是非常有帮助的，尤其对于某些软件开发商来说。 一般来说，软件开发商会将数据放置到/usr/local/里面的各相对目录。 但如果用户想要安装到不同目录呢？就得要使用相对路径。



实例2：网络文件常常提到类似./run.sh之类的数据，这个指令的意义为何？

说明：

由于指令的执行需要变量的支持，若你的执行文件放置在本目录，并且本目录并非正规的执行文件目录(/bin, /usr/bin等为正规)，此时要执行指令就得要严格指定该执行档。./代表本目录的意思，所以./run.sh代表执行本目录下， 名为run.sh的文件。

此处讲解find一些常用参数的一些常用实例和一些具体用法和注意事项。


1．使用name选项：

文件名选项是find命令最常用的选项，要么单独使用该选项，要么和其他选项一起使用。可以使用某种文件名模式来匹配文件，记住要用引号将文件名模式引起来。不管当前路径是什么，如果想要在自己的根目录$HOME中查找文件名符合*.log的文件，使用~作为 'pathname'参数，波浪号~代表了你的$HOME目录。

find ~ -name "*.log" -print  

想要在当前目录及子目录中查找所有的‘ *.log‘文件，可以用： 

find . -name "*.log" -print  

想要的当前目录及子目录中查找文件名以一个大写字母开头的文件，可以用：  

find . -name "[A-Z]*" -print  

想要在/etc目录中查找文件名以host开头的文件，可以用：  

find /etc -name "host*" -print  

想要查找$HOME目录中的文件，可以用：  

find ~ -name "*" -print 或find . -print  

要想让系统高负荷运行，就从根目录开始查找所有的文件。  

find / -name "*" -print  

如果想在当前目录查找文件名以一个个小写字母开头，最后是4到9加上.log结束的文件：  

命令：find . -name "[a-z]*[4-9].log" -print



2．用perm选项：

按照文件权限模式用-perm选项,按文件权限模式来查找文件的话。最好使用八进制的权限表示法。  

如在当前目录下查找文件权限位为755的文件，即文件属主可以读、写、执行，其他用户可以读、执行的文件，可以用：  

find . -perm 755 -print

还有一种表达方法：在八进制数字前面要加一个横杠-，表示都匹配，如-007意思是权限至少是007，-005意思是权限至少005,

命令：find . -perm -005



3．忽略某个目录：

如果在查找文件时希望忽略某个目录，因为你知道那个目录中没有你所要查找的文件，那么可以使用-prune选项来指出需要忽略的目录。在使用-prune选项时要当心，因为如果你同时使用了-depth选项，那么-prune选项就会被find命令忽略。如果希望在test目录下查找文件，但不希望在test/test3目录下查找，可以用：  

命令：find test -path "test/test3" -prune -o -print



4．使用find查找文件的时候怎么避开某个文件目录： 

实例1：在test 目录下查找不在test4子目录之内的所有文件

命令：find test -path "test/test4" -prune -o -print



说明：

find [-path ..] [expression] 

在路径列表的后面的是表达式 

-path "test" -prune -o -print 是 -path "test" -a -prune -o -print 的简写表达式按顺序求值, -a 和 -o 都是短路求值，与shell的 &amp;&amp; 和 || 类似如果 

-path "test" 为真，则求值 -prune , -prune 返回真，与逻辑表达式为真；否则不求值 -prune，与逻辑表达式为假。如果 -path "test" -a -prune 为假，则求值 -print ，-print返回真，或逻辑表达式为真；否则不求值 -print，或逻辑表达式为真。 

这个表达式组合特例可以用伪码写为:

if -path "test" then  

-prune  

else  

-print  






实例2：避开多个文件夹:

命令：find test \( -path test/test4 -o -path test/test3 \) -prune -o -print 

说明：圆括号表示表达式的结合。\表示引用，即指示shell不对后面的字符作特殊解释，而留给find命令去解释其意义。 

 

实例3：查找某一确定文件，-name等选项加在-o 之后

命令：find test \(-path test/test4 -o -path test/test3 \) -prune -o -name "*.log" -print






5．使用user和nouser选项：

按文件属主查找文件：

实例1：在$HOME目录中查找文件属主为peida的文件 

命令：find ~ -user peida -print  

实例2：在/etc目录下查找文件属主为peida的文件: 

命令：find /etc -user peida -print  

实例3：为了查找属主帐户已经被删除的文件，可以使用-nouser选项。在/home目录下查找所有的这类文件

命令：find /home -nouser -print

说明：这样就能够找到那些属主在/etc/passwd文件中没有有效帐户的文件。在使用-nouser选项时，不必给出用户名； find命令能够为你完成相应的工作。






6．使用group和nogroup选项：

就像user和nouser选项一样，针对文件所属于的用户组， find命令也具有同样的选项，为了在/apps目录下查找属于gem用户组的文件，可以用：find /apps -group gem -print  

要查找没有有效所属用户组的所有文件，可以使用nogroup选项。下面的find命令从文件系统的根目录处查找这样的文件:

find / -nogroup-print






7．按照更改时间或访问时间等查找文件：

如果希望按照更改时间来查找文件，可以使用mtime,atime或ctime选项。如果系统突然没有可用空间了，很有可能某一个文件的长度在此期间增长迅速，这时就可以用mtime选项来查找这样的文件。  

用减号-来限定更改时间在距今n日以内的文件，而用加号+来限定更改时间在距今n日以前的文件。  

希望在系统根目录下查找更改时间在5日以内的文件，可以用：

find / -mtime -5 -print

为了在/var/adm目录下查找更改时间在3日以前的文件，可以用:

find /var/adm -mtime +3 -print






8．查找比某个文件新或旧的文件：

如果希望查找更改时间比某个文件新但比另一个文件旧的所有文件，可以使用-newer选项。

它的一般形式为：  

newest_file_name ! oldest_file_name  

其中，！是逻辑非符号。  

实例1：查找更改时间比文件log2012.log新但比文件log2017.log旧的文件

命令：find -newer log2012.log ! -newer log2017.log






实例2：查找更改时间在比log2012.log文件新的文件  

命令：find . -newer log2012.log -print






9．使用type选项：

实例1：在/etc目录下查找所有的目录  

命令：find /etc -type d -print  




实例2：在当前目录下查找除目录以外的所有类型的文件  

命令：find . ! -type d -print  




实例3：在/etc目录下查找所有的符号链接文件

命令：find /etc -type l -print






10．使用size选项：

   可以按照文件长度来查找文件，这里所指的文件长度既可以用块（block）来计量，也可以用字节来计量。以字节计量文件长度的表达形式为    Nc；以块计量文件长度只用数字表示即可。  

在按照文件长度查找文件时，一般使用这种以字节表示的文件长度，在查看文件系统的大小，因为这时使用块来计量更容易转换。  

实例1：在当前目录下查找文件长度大于1 M字节的文件  

命令：find . -size +1000000c -print




实例2：在/home/apache目录下查找文件长度恰好为100字节的文件:  

命令：find /home/apache -size 100c -print  




实例3：在当前目录下查找长度超过10块的文件（一块等于512字节） 

命令：find . -size +10 -print






11．使用depth选项：

  在使用find命令时，可能希望先匹配所有的文件，再在子目录中查找。使用depth选项就可以使find命令这样做。这样做的一个原因就是，当在   使用find命令向磁带上备份文件系统时，希望首先备份所有的文件，其次再备份子目录中的文件。  

 实例1：find命令从文件系统的根目录开始，查找一个名为CON.FILE的文件。   

 命令：find / -name "CON.FILE" -depth -print

 说明：它将首先匹配所有的文件然后再进入子目录中查找




12．使用mount选项： 

  在当前的文件系统中查找文件（不进入其他文件系统），可以使用find命令的mount选项。

  实例1：从当前目录开始查找位于本文件系统中文件名以XC结尾的文件  

  命令：find . -name "*.XC" -mount -print 



在使用 find命令的-exec选项处理匹配到的文件时， find命令将所有匹配到的文件一起传递给exec执行。但有些系统对能够传递给exec的命令长度有限制，这样在find命令运行几分钟之后，就会出现溢出错误。错误信息通常是“参数列太长”或“参数列溢出”。这就是xargs命令的用处所在，特别是与find命令一起使用。  

find命令把匹配到的文件传递给xargs命令，而xargs命令每次只获取一部分文件而不是全部，不像-exec选项那样。这样它可以先处理最先获取的一部分文件，然后是下一批，并如此继续下去。  

在有些系统中，使用-exec选项会为处理每一个匹配到的文件而发起一个相应的进程，并非将匹配到的文件全部作为参数一次执行；这样在有些情况下就会出现进程过多，系统性能下降的问题，因而效率不高； 而使用xargs命令则只有一个进程。另外，在使用xargs命令时，究竟是一次获取所有的参数，还是分批取得参数，以及每一次获取参数的数目都会根据该命令的选项及系统内核中相应的可调参数来确定。




使用实例：

实例1： 查找系统中的每一个普通文件，然后使用xargs命令来测试它们分别属于哪类文件 
命令：find . -type f -print | xargs file

实例2：在整个系统中查找内存信息转储文件(core dump) ，然后把结果保存到/tmp/core.log 文件中
命令：find / -name "core" -print | xargs echo "" &gt;/tmp/core.log
 
实例3:在当前目录下查找所有用户具有读、写和执行权限的文件，并收回相应的写权限
命令：find . -perm -7 -print | xargs chmod o-w

实例4：用grep命令在所有的普通文件中搜索hostname这个词
命令：find . -type f -print | xargs grep "hostname"

实例5：用grep命令在当前目录下的所有普通文件中搜索hostnames这个词
命令：find . -name \* -type f -print | xargs grep "hostnames"

实例6：使用xargs执行mv 
命令：find . -name "*.log" | xargs -i mv {} test4

实例7：find后执行xargs提示xargs: argument line too long解决方法：
命令：find . -type f -atime +0 -print0 | xargs -0 -l1 -t rm -f

实例8：使用-i参数默认的前面输出用{}代替，-I参数可以指定其他代替字符，如例子中的[] 
命令：find . -name "file" | xargs -I [] cp [] ..

实例9：xargs的-p参数的使用 
命令：find . -name "*.log" | xargs -p -i mv {} ..



find是我们很常用的一个Linux命令，但是我们一般查找出来的并不仅仅是看看而已，还会有进一步的操作，这个时候exec的作用就显现出来了。 

exec解释：

-exec  参数后面跟的是command命令，它的终止是以;为结束标志的，所以这句命令后面的分号是不可缺少的，考虑到各个系统中分号会有不同的意义，所以前面加反斜杠。

{}   花括号代表前面find查找出来的文件名。

使用find时，只要把想要的操作写在一个文件里，就可以用exec来配合find查找，很方便的。在有些操作系统中只允许-exec选项执行诸如ls或ls -l这样的命令。大多数用户使用这一选项是为了查找旧文件并删除它们。建议在真正执行rm命令删除文件之前，最好先用ls命令看一下，确认它们是所要删除的文件。 exec选项后面跟随着所要执行的命令或脚本，然后是一对儿{ }，一个空格和一个\，最后是一个分号。为了使用exec选项，必须要同时使用print选项。如果验证一下find命令，会发现该命令只输出从当前路径起的相对路径及文件名。






实例1：ls -l命令放在find命令的-exec选项中 

命令：find . -type f -exec ls -l {} \;




实例2：在目录中查找更改时间在n日以前的文件并删除它们

命令：find . -type f -mtime +14 -exec rm {} \; 




实例3：在目录中查找更改时间在n日以前的文件并删除它们，在删除之前先给出提示

命令：find . -name "*.log" -mtime +5 -ok rm {} \;




实例4：-exec中使用grep命令

命令：find /etc -name "passwd*" -exec grep "root" {} \;






实例5：查找文件移动到指定目录  

命令：find . -name "*.log" -exec mv {} .. \;




实例6：用exec选项执行cp命令 

命令：find . -name "*.log" -exec cp {} test3 \;

   Linux下find命令在目录结构中搜索文件，并执行指定的操作。find命令提供了相当多的查找条件，功能很强大。由于find具有强大的功能，所以它的选项也很多，其中大部分选项都值得我们花时间来了解一下。即使系统中含有网络文件系统(NFS)，find命令在该文件系统中同样有效，只要具有相应的权限。在运行一个非常消耗资源的find命令时，很多人都倾向于把它放在后台执行，因为遍历一个大的文件系统可能会花费很长的时间(这里是指30G字节以上的文件系统)。

1、命令格式
find pathname -options [-print -exec -ok ...]
2、命令功能
用于在文件树种查找文件，并作出相应的处理 
3、命令参数
pathname: find命令所查找的目录路径。例如用.来表示当前目录，用/来表示系统根目录。 
-print： find命令将匹配的文件输出到标准输出。 
-exec： find命令对匹配的文件执行该参数所给出的shell命令。相应命令的形式为'command' {  } \;，注意{   }和\；之间的空格。 

-ok： 和-exec的作用相同，只不过以一种更为安全的模式来执行该参数所给出的shell命令，在执行每一个命令之前，都会给出提示，让用户来确定是否执行。
4、命令选项
-name    
按照文件名查找文件。
-perm   按照文件权限来查找文件。
-prune   使用这一选项可以使find命令不在当前指定的目录中查找，如果同时使用-depth选项，那么-prune将被find命令忽略。
-user   按照文件属主来查找文件。
-group   按照文件所属的组来查找文件。
-mtime -n +n 按照文件的更改时间来查找文件， - n表示文件更改时间距现在n天以内，+ n表示文件更改时间距现在n天以前。find命令还有-atime和-ctime 选项，但它们都和-m time选项。
-nogroup   查找无有效所属组的文件，即该文件所属的组在/etc/groups中不存在。
-nouser   查找无有效属主的文件，即该文件的属主在/etc/passwd中不存在。
-newer file1 ! file2  查找更改时间比文件file1新但比文件file2旧的文件。
-type   查找某一类型的文件，诸如：
b  - 块设备文件。
d - 目录。
c - 字符设备文件。
p - 管道文件。
l - 符号链接文件。
f - 普通文件。
-size n：[c] 查找文件长度为n块的文件，带有c时表示文件长度以字节计。-depth：在查找文件时，首先查找当前目录中的文件，然后再在其子目录中查找。
-fstype： 查找位于某一类型文件系统中的文件，这些文件系统类型通常可以在配置文件/etc/fstab中找到，该配置文件中包含了本系统中有关文件系统的信息。
-mount： 在查找文件时不跨越文件系统mount点。
-follow： 如果find命令遇到符号链接文件，就跟踪至链接所指向的文件。
-cpio： 对匹配的文件使用cpio命令，将这些文件备份到磁带设备中。
另外,下面三个的区别:
-amin n   查找系统中最后N分钟访问的文件
-atime n   查找系统中最后n*24小时访问的文件
-cmin n   查找系统中最后N分钟被改变文件状态的文件
-ctime n   查找系统中最后n*24小时被改变文件状态的文件
-mmin n   查找系统中最后N分钟被改变文件数据的文件
-mtime n   查找系统中最后n*24小时被改变文件数据的文件
5、使用范例
实例1：查找指定时间内修改过的文件
命令：find -atime -2

实例2：根据关键字查找
命令：find -name "*.log"

实例3：按照目录或文件的权限来查找文件
命令：find /opt/soft/test/ -perm 777
      实例4：按类型查找
      命令：find . -type f -name "*.log"
      实例5：查找当前所有目录并排序
      命令：find . -type d | sort


     实例6：按大小查找文件
     命令：find . -size +1000c -print


locate 让使用者可以很快速的搜寻档案系统内是否有指定的档案。其方法是先建立一个包括系统内所有档案名称及路径的数据库，之后当寻找时就只需查询这个数据库，而不必实际深入档案系统之中了。

1、命令格式
locate [选择参数] [样式]
2、命令功能
locate命令可以在搜寻数据库时快速找到档案，数据库由updatedb程序更新，updatedb是由cron daemon周期性建立的，locate命令在搜寻数据库
时比由整个由硬盘资料来搜寻资料来得快，但较差劲的是locate所找到的档案若是最近才建立或刚更名的，可能会找不到，在内定值中，updatedb每天
会跑一次，可以由修改crontab来更新设定值。(etc/crontab)
locate指定用在搜寻符合条件的档案，它会去储存档案与目录名称的数据库内，寻找合乎范本样式条件的档案或目录，可以使用特殊字元（如”*”或
”?”等）来指定范本样式，如指定范本为kcpa*ner, locate会找出所有起始字串为kcpa且结尾为ner的档案或目录，如名称为kcpartner若目录录名称
为kcpa_ner则会列出该目录下包括 子目录在内的所有档案。
locate指令和find找寻档案的功能类似，但locate是透过update程序将硬盘中的所有档案和目录资料先建立一个索引数据库，执行loacte时直接找该
索引，查询速度会较快，索引数据库一般是由操作系统管理，但也可以直接下达update强迫系统立即修改索引数据库。
3、命令参数
-e   将排除在寻找的范围之外。
-1  如果 是 1．则启动安全模式。在安全模式下，使用者不会看到权限无法看到 的档案。这会始速度减慢，因为 locate 必须至实际的档案系统中取得档案的
权限资料。
-f   将特定的档案系统排除在外，例如我们没有到理要把 proc 档案系统中的档案 放在资料库中。
-q  安静模式，不会显示任何错误讯息。
-n 至多显示 n个输出。
-r 使用正规运算式 做寻找的条件。
-o 指定资料库存的名称。
-d 指定资料库的路径
-h 显示辅助讯息
-V 显示程式的版本讯息
4、使用范例
实例1：查找和pwd相关的所有文件
命令：locate pwd

实例2：搜索etc目录下所有以sh开头的文件 
命令：locate /etc/sh

实例3：搜索etc目录下，所有以m开头的文件
命令：locate /etc/m

whereis命令用于程序名的搜索，而且只搜索二进制文件（参数-b）、man说明文件（参数-m）和源代码文件（参数-s）。如果省略参数，则返回所有信息。

1、命令格式
whereis [-bmsu] [BMS 目录名 -f ] 文件名
2、命令功能
whereis命令可定位可执行文件、源代码文件、帮助文件在文件系统中的位置。这些文件的属性应属于原始代码，二进制文件，或是帮助文件。
whereis还具有搜索源代码、指定备用搜索路径和搜索不寻常项的能力。
3、命令参数
  -b         search only for binaries
  -B &lt;dirs&gt; define binaries lookup path
  -m         search only for manuals
  -M &lt;dirs&gt;   
define man lookup path
  -s         search only for sources
  -S &lt;dirs&gt;   
define sources lookup path
  -f         
terminate &lt;dirs&gt; argument list
  -u         search for unusual entries
  -l         output effective lookup paths
4、使用范例
实例1：将和**相关的文件都查找出来
命令：whereis svn


实例2：只将二进制文件查找出来
命令：whereis -b svn


which命令的作用是，在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。

1、命令格式
which 可执行文件名称 
2、命令功能
which指令会在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。
3、命令参数
-n 　指定文件名长度，指定的长度必须大于或等于所有文件中最长的文件名。
-p 　与-n参数相同，但此处的包括了文件的路径。
-w 　指定输出时栏位的宽度。
-V 　显示版本信息
4、使用范例
实例1：查找文件、显示路径
命令：which lsmod


实例2：用which找出which
命令：which which


实例3：找出cd这个命令
命令：which cd


慈母手中线，游子身上衣。
临行密密缝，意恐迟迟归。
谁言寸草心，报得三春晖。
   


十月怀胎母遭难，一声啼叫喜心头。
日夜交替精心护，岁岁年年茁壮长。
时时刻刻心操碎，行走步步用手牵。
会说会走三岁满，学人说话父母欢。
求学路途母牵盼，远走他乡母担忧。
常思常念常许愿，望孩在外多平安。
儿女回家笑常在，嘘寒问暖忙炒菜。
风吹日晒雨里走，岁月蹉跎两鬓霜。
暗中时滴思亲泪，只恐思孩泪更多。
愿天下为人父母，健康平安多春秋。
——赠与天下慈母
   

在java泛型中
？代表不确定的java类型
T代表java类型
K V 代表java键值中的key和value
E代表Element


Object跟这些字符代表的java类型有什么区别呢
Object是所有类的根类，是具体的一个类，使用的时候可能是需要类型强制转换的，？T这些类型在使用的时候就已经知道类型了，不需要类型强制转换。

tail命令从指定点开始将文件写出到标准输出。使用tail命令的-f命令可以方便的查阅正在改变的日志文件，tail -f filename会把filename里最尾部的内容显示在屏幕上，并不断刷新，使你看到最新的内容。
1、命令格式
tail[必要参数][选择参数][文件]
2、命令功能
用于显示指定文件末尾内容，不指定文件时，作为输入信息进行处理。常用查看日志文件。
3、命令参数
-f     循环读取
-q   不显示读取信息
-v    显示详细的处理信息
-c   显示的字节数
-n   显示行数
--pid 与-f合用，表示在进程id，pid死掉后结束
-q  从不输出给文件名的首部
-s  与-f合用，在每次反复的间隔休眠5s
4、使用范例
实例1：显示文件末尾内容
命令：tail -n 5 log.log


实例2：循环查看文件内容
命令：tail -f log.log


实例3：从第n行开始显示文件
命令：tail -n +n log.log

head是用来显示开头或结尾某个数量的文字区块，head用来显示档案的开头至标准输出。
1、命令格式
head [参数] [文件]
2、命令功能
head用来显示档案的开头至标准输出中，默认head命令打印其相应文件的开头10行。
3、命令参数
 -c, --bytes=[-]K         print the first K bytes of each file;
                             with the leading '-', print all but the last
                             K bytes of each file
  -n, --lines=[-]K         print the first K lines instead of the first 10;
                             with the leading '-', print all but the last
                             K lines of each file
  -q, --quiet, --silent    never print headers giving file names
  -v, --verbose            always print headers giving file names
          --help     display this help and exit
          --version  output version information and exit
4、使用范例
实例1：显示文件的前n行
命令：head -n 5 log.log


实例2：显示文件前n个字节
命令：head -c 20 log.log


实例3：文件除了最后n个字节以外的内容
命令：head -c -32 log.log


实例4：输出文件除了最后n行的全部内容
命令：head -n -6 log.log

less 工具也是对文件或其它输出进行分页显示的工具，应该说是linux正统查看文件内容的工具，功能极其强大。less 的用法比起 more 更加的有弹性。在 more 的时候，我们并没有办法向前面翻， 只能往后面看，但若使用了 less 时，就可以使用 [pageup] [pagedown] 等按键的功能来往前往后翻看文件，更容易用来查看一个文件的内容！除此之外，在 less 里头可以拥有更多的搜索功能，不止可以向下搜，也可以向上搜。

1、命令格式
less [参数]  文件
2、命令功能
less 与 more 类似，但使用 less 可以随意浏览文件，而 more 仅能向前移动，却不能向后移动，而且 less 在查看之前不会加载整个文件。
3、命令参数


-b &lt;缓冲区大小&gt; 设置缓冲区的大小

-e  当文件显示结束后，自动离开

-f  强迫打开特殊文件，例如外围设备代号、目录和二进制文件

-g  只标志最后搜索的关键词

-i  忽略搜索时的大小写

-m  显示类似more命令的百分比

-N  显示每行的行号

-o &lt;文件名&gt; 将less 输出的内容在指定文件中保存起来

-Q  不使用警告音

-s  显示连续空行为一行

-S  行过长时间将超出部分舍弃

-x &lt;数字&gt; 将“tab”键显示为规定的数字空格

/字符串：向下搜索“字符串”的功能

?字符串：向上搜索“字符串”的功能

n：重复前一个搜索（与 / 或 ? 有关）

N：反向重复前一个搜索（与 / 或 ? 有关）

b  向后翻一页

d  向后翻半页

h  显示帮助界面

Q  退出less 命令

u  向前滚动半页

y  向前滚动一行

空格键 滚动一行

回车键 滚动一页

[pagedown]： 向下翻动一页

[pageup]：   向上翻动一页
4、使用实例
实例1：查看文件
命令：less log2013.log


实例2：ps查看进程信息并通过less分页显示 
命令：ps -ef |less


实例3：查看命令历史使用记录并通过less分页显示
命令：history | less


实例4：浏览多个文件 
命令：Less log2013.log log2014.log


























石器时代已远去，青铜时代无需提。
铁器时代旧话题，四大发明提一提。
工业革命新篇章，人类智慧大扩张。
 
细看时下分水岭，互联移动是尖兵。
苹果安卓相互拼，暗度陈仓有三星。
三国鼎立未成候，各路诸侯欲插手。


纵观科技另一席
超大数据需处理，轻松搞定云处理。
海量数据难整理，可靠帮手大数据。
无人驾驶已开启，无人飞机送快递。
包裹沉重是问题，智能设备帮你提。
健康问题是否急，穿戴设备告诉你。
动态模拟现真景，立体打印出原型。
生物制药新领域，攻克难题帮续命。
 
半壁江山终谁据，三载过后再来议。
   

more命令，功能类似 cat ，cat命令是整个文件的内容从上到下显示在屏幕上。 more以一页一页的显示方便使用者逐页阅读，按空白键（space）就往下一页显示，按 b 键往回（back）一页显示，还有搜寻字串的功能 。more命令从前向后读取文件，因此在启动时就加载整个文件。
1、基本命令
more [-dlfpcsu ] [-num ] [+/ pattern] [+ linenum] [file ... ]

2、命令功能
more命令和cat的功能一样都是查看文件里的内容，但有所不同的是more可以按页来查看文件的内容，还支持直接跳转行等功能。
3、命令参数
  -d        display help instead of ring bell
  -f        count logical, rather than screen lines
  -l        suppress pause after form feed
  -p        do not scroll, clean screen and display text
  -c        do not scroll, display text and clean line ends
  -u        suppress underlining
  -s        squeeze multiple blank lines into one
  -NUM      specify the number of lines per screenful
  +NUM      display file beginning from line number NUM
  +/STRING  display file beginning from search string match
  -V        output version information and exit

4、使用范例
实例1：显示文件中从第3行起的内容
命令：more +3 log.log


实例2：从文件中查找第一个出现"day3"字符串的行，并从该处前两行开始显示输出 
命令：more +/day3 log.log


实例3：设定每屏显示行数 
命令：more -5 log.log

实例4：列一个目录下的文件，由于内容太多，我们应该学会用more来分页显示。这得和管道 | 结合起来 
命令：ls -l  | more -5

nl命令用于计算文件中行号。nl可以将输出的内容自动加上行号，其可以将行号做比较多的显示设计，包括位数和是否自动补0等等的功能。
1、命令格式
nl [选项] [文件]
2、命令参数
 -b, --body-numbering=STYLE      use STYLE for numbering body lines
  -d, --section-delimiter=CC      use CC for separating logical pages
  -f, --footer-numbering=STYLE    use STYLE for numbering footer lines
  -h, --header-numbering=STYLE    use STYLE for numbering header lines
  -i, --line-increment=NUMBER     line number increment at each line
  -l, --join-blank-lines=NUMBER   group of NUMBER empty lines counted as one
  -n, --number-format=FORMAT      insert line numbers according to FORMAT
  -p, --no-renumber               do not reset line numbers at logical pages
  -s, --number-separator=STRING   add STRING after (possible) line number
  -v, --starting-line-number=NUMBER  first line number on each logical page
  -w, --number-width=NUMBER       use NUMBER columns for line numbers
             --help     display this help and exit
             --version  output version information and exit
3、命令功能
nl 命令读取 File 参数（缺省情况下标准输入），计算输入中的行号，将计算过的行号写入标准输出。 
在输出中，nl 命令根据您在命令行中指定的标志来计算左边的行。 输入文本必须写在逻辑页中。每个逻辑页
有头、主体和页脚节（可以有空节）。 除非使用 -p 标志，nl 命令在每个逻辑页开始的地方重新设置行号。
可以单独为头、主体和页脚节设置行计算标志（例如，头和页脚行可以被计算然而文本行不能）。
4、使用范例
实例1：列出log.log的内容
命令：nl log.log


实例2：列出log.log的内容，空行也加上行号
命令：nl -b a log.log


实例3：让行号前面自动补上0，统一输出格式
命令：nl -b a -n rz log.log

cat命令用于连接文件或标准输入并打印。该命令用于显示文件内容或将几个文件连接起来显示，或从标准输入读取内容并显示，常与重定向符号配合使用。
1、命令格式
cat [选项] [文件]...
2、命令功能
a、一次显示整个文件：cat filename
b、从键盘创建一个文件：cat &gt; filename，只能创建新文件，不能编辑已有文件
c、将几个文件合并为一个文件：cat file1 file2 &gt;file
3、命令参数
-A,--show-all
equivalent to -vET
-b,--number-nonblank
number nonempty output lines,overrides -n
-e  
equivalent to -vE
-E,--show-ends 
display $ at end of each line
-n,--number
number all output lines
-s,--squeeze-blank 
suppress repeated empty output lines
-t  
equals to -vT
-T,--show -tabs
display TAB characters as ^I
-u (ignored)
-v,--show-nonprinting
use ^ and M- notation,except for LFD and TAB
    --help 
display this help and exit
   --version
output version information and exit
4、使用范例
实例1：把log1.log 的文件内容加上行号后输入log2.log文件中
命令：cat -n log1.log log2.log


实例2：把log1.log和log2.log的文件内容加上行号（空白行不加）之后将内容附加到log.log里
命令：cat -b log1.log log2.log log.log

linux的touch命令不常用，一般在使用make时会用到，用来修改时间戳，或新建一个不存在的文件。
1、命令格式
touch [选项] [文件]
2、命令参数


-a   或--time=atime或--time=access或--time=use 　只更改存取时间。

-c   或--no-create 　不建立任何文档。

-d 　使用指定的日期时间，而非现在的时间。

-f 　此参数将忽略不予处理，仅负责解决BSD版本touch指令的兼容性问题。

-m   或--time=mtime或--time=modify 　只更改变动时间。

-r 　把指定文档或目录的日期时间，统统设成和参考文档或目录的日期时间相同。

-t 　使用指定的日期时间，而非现在的时间。
3、命令功能
touch命令参数可以更改文档或目录的日期时间，包括存取和更改时间。
4、使用范例
实例1：创建不存在的文件
命令：touch log1.log  log2.log


实例2：更改多个文件的时间戳相同
命令：touch -r log1.log log2.log


实例3：设定文件的时间戳
命令：touch -t 201211142234.50 log1.log

     在初次使用java时，往往我们对最基本的java类会忽略对其内部基本的实现的了解，也往往不屑于了解其内部实现机制，以为它们本来就是这样子。而其实贯穿java的整个过程，所有上层的使用，都是源于对底层的扩展，所以要真正去了解这门语言，就必须得从其底层开始认真去了解它。而要深入了解，就需要更多去关注其内部的实现是怎样子的。
     在使用IDE的过程中，我们经常会需要能在IDE中就可以便捷的去查看java的源码，但若没有做相关设置，一般在IDE是查看不了java源码的，此次提供在eclipse中设置查看java源码的方式。
设置步骤如下:

1.点 “window”-&gt; "Preferences" -&gt; "Java" -&gt; "Installed JRES"

2.此时"Installed JRES"右边是列表窗格，列出了系统中的 JRE 环境，选择你的JRE，然后点边上的 "Edit..."， 会出现一个窗口(Edit JRE)

3.选中rt.jar文件的这一项：“c:\program files\java\jre_1.8\lib\rt.jar” 
点 左边的“+” 号展开它，

4.展开后，可以看到“Source Attachment:(none)”，点这一项，点右边的按钮“Source Attachment...”, 选择你的JDK目录下的 “src.zip”文件(该文件在JDK安装目录的根目录下)

5.一路点"ok"，设置完成

设置完成后，按住ctrl键再用鼠标单击某一个jdk方法名或类名，便能看到该方法的源代码了。此外按F3也能实现。

PS：rt.jar包含了jdk的基础类库，也就是你在java
 doc里面看到的所有的类的class文件；src.zip文件里面放着的正是基本类所对应的源文件（即*.java格式的文件）；同理，我们可以去网上下载各个JAVA开源框架所对应的源代码包，比如spring-src.zip，然后再按照上面的设置步骤设置，就可以查看到对应的JAVA框架源代码了。

cp命令用来复制文件或者目录，为linux常用命令之一。一般情况下，shell会设置一个别名，在命令行下复制文件时，如果目标文件已经存在，就会询问是否覆盖，不管是否使用-i参数。在shell脚本中执行cp时，没有-i参数不会询问是否覆盖。命令行和shell脚本的执行方式有些不同。
1、命令格式
cp [选项]..  [-T] 源  目的   或：cp [选项]..   源...  目录      或：cp [选项]..  -t   目录  源...
2、命令功能
将源文件复制至目标文件，或将多个源文件复制至目标目录。
3、命令参数


-a, --archive    等于-dR --preserve=all

    --backup[=CONTROL    为每个已存在的目标文件创建备份

-b                类似--backup 但不接受参数

   --copy-contents        在递归处理是复制特殊文件内容

-d                等于--no-dereference --preserve=links

-f, --force        如果目标文件无法打开则将其移除并重试(当 -n 选项

                    存在时则不需再选此项)

-i, --interactive        覆盖前询问(使前面的 -n 选项失效)

-H                跟随源文件中的命令行符号链接

-l, --link            链接文件而不复制

-L, --dereference   总是跟随符号链接

-n, --no-clobber   不要覆盖已存在的文件(使前面的 -i 选项失效)

-P, --no-dereference   不跟随源文件中的符号链接

-p                等于--preserve=模式,所有权,时间戳

    --preserve[=属性列表   保持指定的属性(默认：模式,所有权,时间戳)，如果

               可能保持附加属性：环境、链接、xattr 等

-R, -r, --recursive  复制目录及目录内的所有项目

4、使用范例
实例1：复制单个文件到目标目录，文件在目标文件中不存在
命令：cp log.log test5
实例2：目标文件存在时，会询问是否覆盖
命令：cp log.log test5

实例3：复制整个目录
命令：目标目录存在时：cp -a test3 test5
   目标目录不存在cp -a test3 test4


实例4：复制的 log.log 建立一个连结档 log_link.log

命令：cp -s log.log log_link.log


mv是move的缩写，可以用来移动文件或将文件改名（move（rename）files），是linux下常用命令，经常用来备份文件或者目录。
1、命令格式
mv [选项] 源文件或者目录，目标文件或者目录
2、命令功能
视mv命令中第二个参数类型的不同（是目标文件还是目标目录），mv命令将文件重命名或将其移至一个新的目录中。当第二个参数类型是文件时，mv命令完成文件重命名，此时，源文件只能有一个（也可以是源目录名），它将所给的源文件或目录重命名为给定的目标文件名。当第二个参数是已存在的目录名称时，源文件或目录参数可以有多个，mv命令将各参数指定的源文件均移至目标目录中。在跨文件系统移动文件时，mv先拷贝，再将原有文件删除，而链至该文件的链接也将丢失。
3、命令参数
   -b ：若需覆盖文件，则覆盖前先行备份。 
   -f ：force 强制的意思，如果目标文件已经存在，不会询问而直接覆盖；
   -i ：若目标文件 (destination) 已经存在时，就会询问是否覆盖！
   -u ：若目标文件已经存在，且 source 比较新，才会更新(update)


 -t  ： --target-directory=DIRECTORY move all SOURCE arguments into DIRECTORY，即指定mv的目标目录，该选项适用于移动多个源文件到一个目录的情况，此时目标目录在前，源文件在后。
4、命令实例
   实例一：文件改名


   命令：

mv test.log test1.txt

实例二：移动文件

  命令： mv test1.txt test3

  实例三：将文件log1.txt,log2.txt,log3.txt移动到目录test3中。 

  命令：

mv log1.txt log2.txt log3.txt test3

mv -t /opt/soft/test/test4/ log1.txt log2.txt 
log3.txt 

  实例四：将文件file1改名为file2，如果file2已经存在，则询问是否覆盖

  命令：mv -i log1.txt log2.txt

  实例五：将文件file1改名为file2，即使file2存在，也是直接覆盖掉。

  命令：mv -f log3.txt log2.txt

  实例六：目录的移动

  命令：mv dir1 dir2 

  实例7：移动当前文件夹下的所有文件到上一级目录

  命令：mv * ../

  实例八：把当前目录的一个子目录里的文件移动到另一个子目录里

  命令：mv test3/*.txt test5

  实例九：文件被覆盖前做简单备份，前面加参数-b

  命令：mv log1.txt -b log2.txt

  说明：

             -b 不接受参数，mv会去读取环境变量VERSION_CONTROL来作为备份策略。

--backup该选项指定如果目标文件存在时的动作，共有四种备份策略：

1.CONTROL=none或off : 不备份。

2.CONTROL=numbered或t：数字编号的备份

3.CONTROL=existing或nil：如果存在以数字编号的备份，则继续编号备份m+1...n：

执行mv操作前已存在以数字编号的文件log2.txt.~1~，那么再次执行将产生log2.txt~2~，以次类推。如果之前没有以数字编号的文件，
则使用下面讲到的简单备份。

4.CONTROL=simple或never：使用简单备份：在被覆盖前进行了简单备份，简单备份只能有一份，再次被覆盖时，简单备份也会被覆盖。


rmdir的功能是删除空目录，一个目录被删除之前必须的空的。（注意：rm -r dir命令可以代替rmdir，但危险性很大）。删除某目录时必须具有对父目录的写权限。
1、命令格式
rmdir [选项]  目录
2、命令功能
从一个目录中删除一个或多个子目录项，删除目录时需要有对父目录写的权限。
3、命令参数
-p 递归删除目录dirname，当子目录删除后其父目录为空时，也一同被删除。如果整个路径被删除或由于某种原因保留部分路径，则系统在标准输出上显示相应的信息。
-v，--verbose，显示指令执行过程。
4、命令实例
实例1：不能删除非空目录
命令：rmdir home


实例2：rmdir -p 当子目录被删除后使它也成为空目录的话，则一并删除。
命令：rmdir -p logs

rm命令为删除文件和目录的命令，其功能为删除一个目录中的一个或多个文件或目录。对于链接文件，只是删除了链接，原有文件均保持不变。rm是一个危险的命令，使用时需要特别当心。在执行rm之前最好先确认一下在哪个目录，到底要删除什么东西，操作时保持高度清醒的头脑。
1、命令格式
rm [选项]文件
2、命令功能
删除一个目录中的一个或多个文件或目录，如果没有使用-r选项，则rm不会删除目录。如果使用rm来删除文件，通常可以将该文件恢复原状。
3、命令参数
-f，--force，忽略不存在的文件，从不给出提示。
-i，--interactive，进行交互式删除。
-r，-R，-recursive，指示rm将参数中列出的全部目录和子目录均递归地删除。
-v，--verbose，详细显示进行的步骤。
--help，显示帮助信息并退出。
--version，显示版本信息并退出
4、命令实例
实例1：删除文件file，系统会先询问是否删除。
命令：rm 文件名
说明：输入命令后，系统会询问是否删除，输入y后就会删除文件，输入n则不。


实例2：强行删除file，系统不再提示。
命令：rm -f 文件


实例3：删除任何.*（某一后缀）文件，删除前逐一询问确认
命令：rm -i *.*


实例4：强test子目录及子目录中所有档案删除
命令：rm -r test


实例5：rm -rf test2命令会将test2子目录及子目录中所有档案删除并且不一一确认
命令：rm -rf test2


实例6：删除以-f开头的文件
命令：rm -- -f


实例7：自定义回收站功能
命令：myrm(){ D=/tmp/$(date +%Y%m%d%H%M%S); mkdir -p $D; mv "$@" $D &amp;&amp; echo "moved to $D ok"; }
说明：上面的操作过程模拟了回收站的效果，即删除文件的时候只是把文件放到一个临时目录中，这样在需要的时候还可以恢复过来。

mkdir命令用来创建指定的名称的目录，要求创建目录的用户在当前目录中具有写权限，并且指定的目录名不能是当前目录中已有的目录。
1、命令格式
mkdir [选项]目录
2、命令功能
通过该命令可以在指定的位置创建名称为dirName的文件夹或目录。要求创建文件夹或目录的用户必须对所创建的文件夹父文件夹具有写权限，但在同一个文件夹或目录下不能有同名（区分大小写）的文件夹或目录。
3、命令参数
-m，-mode=模式，设定权限&lt;模式&gt;（类似chmod），而不是rwxrwxrwx或umask
-p，--parents，可以是一个路径名称。若路径中的某些目录尚不存在，加上此选项后，系统将自动建立好那些尚不存在的目录，即一次可以建立多个目录。
-v，--verbose，每次创建新目录都显示信息。
--help，显示帮助信息并退出。
--version，输出版本信息并退出。
4、命令实例
实例1：创建一个空目录
命令：mkdir test1


实例2：递归创建多个目录
命令：mkdir -p test1/test11


实例3：创建权限为777的目录
命令：mkdir -m 777 test3


实例4：创建新目录都显示信息
命令：mkdir -v test4


实例5：一个命令创建项目的目录结构
命令：mkdir -vp test/test1/test2/test3


1 添加redis支持

在pom.xml中添加


Xml代码  



&lt;dependency&gt;  
   &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;  
   &lt;artifactId&gt;spring-boot-starter-redis&lt;/artifactId&gt;  
&lt;/dependency&gt;  


 

2 redis配置


Java代码  



package com.wisely.ij.config;  


import java.lang.reflect.Method;
import org.springframework.cache.CacheManager;
import org.springframework.cache.annotation.CachingConfigurerSupport;
import org.springframework.cache.annotation.EnableCaching;
import org.springframework.cache.interceptor.KeyGenerator;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.data.redis.cache.RedisCacheManager;
import org.springframework.data.redis.connection.RedisConnectionFactory;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.data.redis.core.StringRedisTemplate;
import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer；
import com.fasterxml.jackson.annotation.JsonAutoDetect.Visibility;

import com.fasterxml.jackson.annotation.PropertyAccessor;

import com.fasterxml.jackson.databind.ObjectMapper;
import com.fasterxml.jackson.databind.ObjectMapper.DefaultTyping;



@Configuration  
@EnableCaching  
public class RedisConfig extends CachingConfigurerSupport{  
  
    @Bean  
    public KeyGenerator wiselyKeyGenerator(){  
        return new KeyGenerator() {  
            @Override  
            public Object generate(Object target, Method method, Object... params) {  
                StringBuilder sb = new StringBuilder();  
                sb.append(target.getClass().getName());  
                sb.append(method.getName());  
                for (Object obj : params) {  
                    sb.append(obj.toString());  
                }  
                return sb.toString();  
            }  
        };  
  
    }  
  
    @Bean  
    public CacheManager cacheManager(RedisTemplate&lt;?, ?&gt; redisTemplate) {  
        return new RedisCacheManager(redisTemplate);  
    }  
  
    @Bean  
    public RedisTemplate&lt;String, String&gt; redisTemplate(  
            RedisConnectionFactory factory) {  
        StringRedisTemplate template = new StringRedisTemplate(factory);  
        Jackson2JsonRedisSerializer&lt;Object&gt; jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer&lt;Object&gt;(Object.class);  
        ObjectMapper om = new ObjectMapper();  
        om.setVisibility(PropertyAccessor.ALL, Visibility.ANY);  
        om.enableDefaultTyping(DefaultTyping.NON_FINAL);  
        jackson2JsonRedisSerializer.setObjectMapper(om);  
        template.setValueSerializer(jackson2JsonRedisSerializer);  
        template.afterPropertiesSet();  


        return template;  
    }  
}  


 

 

3 redis服务器配置


Properties代码  



# REDIS (RedisProperties)  
spring.redis.database=0 # database name  
spring.redis.host=localhost # server host  
spring.redis.password= # server password  
spring.redis.port=6379 # connection port  
spring.redis.pool.max-idle=10 # pool settings ...  
spring.redis.pool.min-idle=0  
spring.redis.pool.max-active=10  
spring.redis.pool.max-wait=-1 


 

4 应用

测试两个实体类


Java代码  



package com.wisely.ij.domain;  
  
public class Address {  
    private Long id;  
    private String province;  
    private String city;  
  
    public Address(Long id,String province, String city) {  
        this.id = id;  
        this.province = province;  
        this.city = city;  
    }  
  
    public Address() {  
    }  
  
    public Long getId() {  
        return id;  
    }  
  
    public void setId(Long id) {  
        this.id = id;  
    }  
  
    public String getProvince() {  
        return province;  
    }  
  
    public void setProvince(String province) {  
        this.province = province;  
    }  
  
    public String getCity() {  
        return city;  
    }  
  
    public void setCity(String city) {  
        this.city = city;  
    }  
}  


 


Java代码  



package com.wisely.ij.domain;  
  
public class User {  
    private Long id;  
    private String firstName;  
    private String lastName;  
  
    public User(Long id,String firstName, String lastName) {  
        this.id = id ;  
        this.firstName = firstName;  
        this.lastName = lastName;  
    }  
  
    public User() {  
    }  
  
    public Long getId() {  
        return id;  
    }  
  
    public void setId(Long id) {  
        this.id = id;  
    }  
  
    public String getFirstName() {  
        return firstName;  
    }  
  
    public void setFirstName(String firstName) {  
        this.firstName = firstName;  
    }  
  
    public String getLastName() {  
        return lastName;  
    }  
  
    public void setLastName(String lastName) {  
        this.lastName = lastName;  
    }  
}  


 

 使用演示


Java代码  



package com.wisely.ij.service;  
  
import com.wisely.ij.domain.Address;  
import com.wisely.ij.domain.User;  
import org.springframework.cache.annotation.Cacheable;  
import org.springframework.stereotype.Service;  
  
@Service  
public class DemoService {  
    @Cacheable(value = "usercache", key = "#id + '_' + #firstName + '_' + #lastName") 
    public User findUser(Long id,String firstName,String lastName){  
        System.out.println("无缓存的时候调用这里。");  
        return new User(id,firstName,lastName);  
    }  


    @Cacheable(value = "addresscache", key = "#id + '_' + #province + '_' + #city")
    public Address findAddress(Long id,String province,String city){  
        System.out.println("无缓存的时候调用这里。");  
        return new Address(id,province,city);  
    }  
}  


 


Java代码  



package com.wisely.ij.web;  
  
import com.wisely.ij.domain.Address;  
import com.wisely.ij.domain.User;  
import com.wisely.ij.service.DemoService;  
import org.springframework.beans.factory.annotation.Autowired;  
import org.springframework.stereotype.Controller;  
import org.springframework.web.bind.annotation.RequestMapping;  
import org.springframework.web.bind.annotation.ResponseBody;  
  
@RestController
public class DemoEndpoint{  
  
    @Autowired  
    DemoService demoService;  
  
    @RequestMapping(value = "/test", method = RequestMethod.GET, produces = MediaType.APPLICATION_JSON_UTF8_VALUE)   
    public String putCache(){  
        demoService.findUser(1L, "zhang", "san");
        demoService.findAddress(2L, "jx", "gz");
        System.out.println("if it not print '无缓存的时候调用。' ,it means the test is success.");
        return "OK";
    }  
    @RequestMapping(value = "/test2", method = RequestMethod.GET, produces = MediaType.APPLICATION_JSON_UTF8_VALUE)  
    public String testCache(){  
        User user = demoService.findUser(1L, "zhang", "san");  
        Address address =demoService.findAddress(2L, "jx", "gz");  
        System.out.println("it not excute query");  
        System.out.println("user:"+"/"+user.getFirstName()+"/"+user.getLastName());  
        System.out.println("address:"+"/"+address.getProvince()+"/"+address.getCity());  
        return "OK";  
    }  
}  


 

5 检验

 

先访问http://localhost:8080/test 保存缓存



 

再访问http://localhost:8080/test2 调用缓存里的数据

 





pwd命令用来查看当前工作目录的完整路径。当你不确定当前位置时，使用pwd命令可以很好的帮你确定位置。
1、命令格式
pwd [选项]
2、命令功能
查看当前目录的完整路径
3、常用参数
一般情况下不带任何参数
如果目录是链接时：使用pwd -p命令显示出实际路径，而非使用链接路径
4、常用实例


实例1：用 pwd 命令查看默认工作目录的完整路径

命令：

pwd 




实例2：使用 pwd 命令查看指定文件夹

命令：

pwd




实例三：目录连接链接时，pwd -P  显示出实际路径，而非使用连接（link）路径；pwd显示的是连接路径

命令：

pwd -P








实例4：/bin/pwd

命令：

/bin/pwd [选项]

选项：

-L 目录连接链接时，输出连接路径

-P 输出物理路径




实例五：当前目录被删除了，而pwd命令仍然显示那个目录

cd命令是linux的最基本命令之一，其它命令的操作都是建立在cd命令之上的。要学习linux基本命令，首先要掌握cd命令的使用方法技巧。
1、命令格式
cd [目录名]
2、命令功能
切换当前目录至dirName
3、常用范例



3.1 例一：进入系统根目录

命令：

cd / 

说明：进入系统根目录,上面命令执行完后拿ls命令看一下，当前目录已经到系统根目录了 




命令：

cd .. 或者 cd .. //

说明：

进入系统根目录可以使用“ cd .. ”一直退，就可以到达根目录 






命令：

cd ../.. //

说明：使用cd 命令实现进入当前目录的父目录的父目录。 






例2：使用 cd 命令进入当前用户主目录

“当前用户主目录”和“系统根目录”是两个不同的概念。进入当前用户主目录有两个方法。

命令1：

cd




命令2：

cd ~




例3：跳转到指定目录

命令： 

cd /opt/soft

说明：

跳转到指定目录，从根目录开始，目录名称前加 / ,当前目录内的子目录直接写名称即可




例四：返回进入此目录之前所在的目录

命令：

cd -






例五：把上个命令的参数作为cd参数使用。 

命令：

cd !$




ls命令是linux下最常用的命令。ls命令就是list的缩写，缺省下ls用来打印出当前目录的清单，如果ls指定其他目录，那么就会显示指定目录里的文件及文件夹清单。通过ls命令不仅可以查看linux文件夹包含的文件，而且可以查看文件权限(包括目录、文件夹、文件权限)查看目录信息等等。ls 命令在日常的linux操作中用的很多!



1、ls命令格式
ls [选项] [目录名]
2、ls命令功能
列出目标目录中所有的子目录和文件。
3、常用参数


-a, 列出目录下的所有文件，包括以“.”开头的隐含文件

-A 同-a，但不列出“.”(表示当前目录)和“..”(表示当前目录的父目录)。




-c  配合 -lt：根据 ctime 排序及显示 ctime (文件状态最后更改的时间)配合 -l：显示 ctime 但根据名称排序否则：根          据 ctime 排序

-C 每栏由上至下列出项目

–color[=WHEN] 控制是否使用色彩分辨文件。WHEN 可以是'never'、'always'或'auto'其中之一

-d, –directory 将目录象文件一样显示，而不是显示其下的文件。

-D, –dired 产生适合 Emacs 的 dired 模式使用的结果

-f 对输出的文件不进行排序，-aU 选项生效，-lst 选项失效

-g 类似 -l,但不列出所有者

-G, –no-group 不列出任何有关组的信息

-h, –human-readable 以容易理解的格式列出文件大小 (例如 1K 234M 2G)

–si 类似 -h,但文件大小取 1000 的次方而不是 1024

-H, –dereference-command-line 使用命令列中的符号链接指示的真正目的地

–indicator-style=方式 指定在每个项目名称后加上指示符号&lt;方式&gt;：none (默认)，classify (-F)，file-type (-p)

-i, –inode 印出每个文件的 inode 号

-I, –ignore=样式 不印出任何符合 shell 万用字符&lt;样式&gt;的项目

-k 即 –block-size=1K,以 k 字节的形式表示文件的大小。

-l 除了文件名之外，还将文件的权限、所有者、文件大小等信息详细列出来。

-L, –dereference 当显示符号链接的文件信息时，显示符号链接所指示的对象而并非符号链接本身的信息

-m 所有项目以逗号分隔，并填满整行行宽

-o 类似 -l,显示文件的除组信息外的详细信息。   

-r, –reverse 依相反次序排列

-R, –recursive 同时列出所有子目录层



-s, –size 以块大小为单位列出所有文件的大小

-S 根据文件大小排序

–sort=WORD 以下是可选用的 WORD 和它们代表的相应选项：

extension -X status -c

none -U time -t

size -S atime -u

time -t access -u

version -v use -u

-t 以文件修改时间排序

-u 配合 -lt:显示访问时间而且依访问时间排序

配合 -l:显示访问时间但根据名称排序

否则：根据访问时间排序

-U 不进行排序;依文件系统原有的次序列出项目

-v 根据版本进行排序

-w, –width=COLS 自行指定屏幕宽度而不使用目前的数值

-x 逐行列出项目而不是逐栏列出

-X 根据扩展名排序

-1 每行只列出一个文件

–help 显示此帮助信息并离开

–version 显示版本信息并离开






4、常用范例



例一：列出/home/peidachang文件夹下的所有文件和目录的详细资料

命令：ls -l -R /home/peidachang

在使用 ls 命令时要注意命令的格式：在命令提示符后，首先是命令的关键字，接下来是命令参数，在命令参数之前要有一短横线“-”，所有的命令参数都有特定的作用，自己可以根据需要选用一个或者多个参数，在命令参数的后面是命令的操作对象。在以上这条命令“ ls -l -R /home/peidachang”中，“ls” 是命令关键字，“-l -R”是参数，“ /home/peidachang”是命令的操作对象。在这条命令中，使用到了两个参数，分别为“l”和“R”，当然，你也可以把他们放在一起使用，如下所示：

命令：ls -lR /home/peidachang

这种形式和上面的命令形式执行的结果是完全一样的。另外，如果命令的操作对象位于当前目录中，可以直接对操作对象进行操作;如果不在当前目录则需要给出操作对象的完整路径，例如上面的例子中，我的当前文件夹是peidachang文件夹，我想对home文件夹下的peidachang文件进行操作，我可以直接输入 ls -lR peidachang，也可以用 ls -lR /home/peidachang。 

例二：列出当前目录中所有以“t”开头的目录的详细内容，可以使用如下命令：

命令：ls -l t*   

可以查看当前目录下文件名以“t”开头的所有文件的信息。其实，在命令格式中，方括号内的内容都是可以省略的，对于命令ls而言，如果省略命令参数和操作对象，直接输入“ ls ”，则将会列出当前工作目录的内容清单。

例三：只列出文件下的子目录

命令：ls -F /opt/soft |grep /$  

列出 /opt/soft 文件下面的子目录

输出：

[root@localhost opt]# ls -F /opt/soft |grep /$

jdk1.6.0_16/

subversion-1.6.1/

tomcat6.0.32/

命令：ls -l /opt/soft | grep "^d"

列出 /opt/soft 文件下面的子目录详细情况

输出：

[root@localhost opt]#  ls -l /opt/soft | grep "^d"

drwxr-xr-x 10 root root      4096 09-17 18:17 jdk1.6.0_16

drwxr-xr-x 16 1016 1016      4096 10-11 03:25 subversion-1.6.1

drwxr-xr-x  9 root root      4096 2011-11-01 tomcat6.0.32

例四：列出目前工作目录下所有名称是s 开头的档案，愈新的排愈后面，可以使用如下命令：

命令：ls -ltr s*

输出：

[root@localhost opt]# ls -ltr s*

src:

总计 0



script:

总计 0



soft:

总计 350644

drwxr-xr-x  9 root root      4096 2011-11-01 tomcat6.0.32

-rwxr-xr-x  1 root root  81871260 09-17 18:15 jdk-6u16-linux-x64.bin

drwxr-xr-x 10 root root      4096 09-17 18:17 jdk1.6.0_16

-rw-r--r--  1 root root 205831281 09-17 18:33 apache-tomcat-6.0.32.tar.gz

-rw-r--r--  1 root root   5457684 09-21 00:23 tomcat6.0.32.tar.gz

-rw-r--r--  1 root root   4726179 10-10 11:08 subversion-deps-1.6.1.tar.gz

-rw-r--r--  1 root root   7501026 10-10 11:08 subversion-1.6.1.tar.gz

drwxr-xr-x 16 1016 1016      4096 10-11 03:25 subversion-1.6.1

例五：列出目前工作目录下所有档案及目录;目录于名称后加"/", 可执行档于名称后加"*" 

命令：ls -AF

输出：

[root@localhost opt]# ls -AF

log/  script/  soft/  src/  svndata/  web/

例六：计算当前目录下的文件数和目录数

命令：

ls -l * |grep "^-"|wc -l ---文件个数  

ls -l * |grep "^d"|wc -l    ---目录个数

例七: 在ls中列出文件的绝对路径

命令：ls | sed "s:^:`pwd`/:"

输出：

    [root@localhost opt]# ls | sed "s:^:`pwd`/:" 

    /opt/log

    /opt/script

    /opt/soft

    /opt/src

    /opt/svndata

    /opt/web



例九：列出当前目录下的所有文件（包括隐藏文件）的绝对路径， 对目录不做递归

命令：find $PWD -maxdepth 1 | xargs ls -ld

输出：

[root@localhost opt]# find $PWD -maxdepth 1 | xargs ls -ld

drwxr-xr-x 8 root root 4096 10-11 03:43 /opt

drwxr-xr-x 2 root root 4096 2012-03-08 /opt/log

drwxr-xr-x 2 root root 4096 2012-03-08 /opt/script

drwxr-xr-x 5 root root 4096 10-11 03:21 /opt/soft

drwxr-xr-x 2 root root 4096 2012-03-08 /opt/src

drwxr-xr-x 4 root root 4096 10-11 05:22 /opt/svndata

drwxr-xr-x 4 root root 4096 10-09 00:45 /opt/web

例十：递归列出当前目录下的所有文件（包括隐藏文件）的绝对路径

命令： find $PWD | xargs ls -ld 



例十一：指定文件时间输出格式

命令：

 ls -tl --time-style=full-iso

输出：

[root@localhost soft]# ls -tl --time-style=full-iso 

总计 350644

drwxr-xr-x 16 1016 1016 4096 2012-10-11 03:25:58.000000000 +0800 subversion-1.6.1



 ls -ctl --time-style=long-iso

输出：

[root@localhost soft]# ls -ctl --time-style=long-iso

总计 350644

drwxr-xr-x 16 1016 1016      4096 2012-10-11 03:25 subversion-1.6.1
5、扩展，显示彩色目录列表



打开/etc/bashrc, 加入如下一行:

    alias ls="ls --color"

    下次启动bash时就可以像在Slackware里那样显示彩色的目录列表了, 其中颜色的含义如下:

    1. 蓝色--&gt;目录

    2. 绿色--&gt;可执行文件

    3. 红色--&gt;压缩文件

    4. 浅蓝色--&gt;链接文件

    5. 灰色--&gt;其他文件




3、




最近在思考架构方面一些最基本的问题，比如什么是架构？如何评价一个架构的好坏？是否有一些通用的基本原则指引架构设计？在面向对象设计方面，有单一职责、里氏替换、依赖倒置、接口隔离、迪米特、开闭原则等等基本原则；那么，在架构设计方面是否也有类似的基本原则呢？本文就先聊聊第一个问题。

什么是架构

关于什么是架构，业界从来没有一个统一的定义。Martin Fowler在《企业应用架构模式》中也没有对其给出定义，只是提到能够统一的内容有两点：

最高层次的系统分解；系统中不易改变的决定。

《软件架构设计》一书则将架构定义总结为组成派和决策派：

组成派：架构=组件+交互：软件系统的架构将系统描述为计算组件及组件之间的交互。决策派：架构=重要决策集：软件架构是在一些重要方面所作出的决策的集合。

而架构的概念最初来源于建筑，因此，我想从建筑的角度去思考这个问题。Wikipedia中，对架构，即Architecture的定义如下：


   Architecture is both the process and the product of planning, designing, and constructing buildings and other physical structures.


简单翻译就是：架构是规划、设计和构建建筑物或其他物理构筑物的过程和结果。

从上面的定义中可知，首先，架构的最终目标是为了产出建筑物或其他物理构筑物，构筑物可以只是一套房子，也可以是一栋楼盘，抑或是一个小区、商业区，甚至是一个城市。构筑物越大，其架构必然也越复杂。

其次，产出建筑物之前需要经过三个阶段：规划(planning)、设计(designing)和构建(constructing)。这三个阶段其实也是架构的核心了。比如，开发商要建一个住宅小区，首先肯定要对该小区有一个整体的规划吧：小区的建设选址、建设的规模、建设的内容、投资估算、建设周期等等。接着，就要对小区的各方面进行设计了，最高层次的应该是小区的总体布局设计，拆分开的话就是各楼盘的设计、绿化的设计、各种配套设施的设计等等，再细化下去就是各种户型的设计、楼盘内和小区内各种走道的设计等等。最后，构建阶段也就是施工阶段了，是将之前所有的想法转为实际的建筑物的阶段。

最后，架构包含了以上的过程和结果。也就是说，对小区总体规划的过程是架构，规划的结果方案也是架构，小区总体布局的设计、楼盘的设计、户型的设计等等的每个过程也都是架构，每个过程产出的设计方案也是架构，构建阶段的施工图也是架构，可以说，产出建筑物期间的每个过程和结果都是架构。

那么，如果将建筑物换成了软件，那就变成对软件架构的定义了：软件架构是规划、设计和构建软件的过程和结果。

相应地，软件架构的最终目标就是为了产出软件，可以是一个App，也可以是一个平台，如SaaS、PaaS、BaaS等等，甚至还可以是智慧城市这样庞大的生态系统，地球人都知道，越庞大复杂的系统，架构越难。规划阶段更多考虑的是软件的需求，包括业务上功能性需求和技术上的非功能性需求，如可靠性、可扩展性、可维护性等；此阶段的架构一般为系统架构。设计阶段的工作更多的就是拆分细化，以满足各种需求；此阶段的架构一般为逻辑架构。构建阶段主要就是对软件的实现和部署了；此阶段的架构一般为物理架构。

最后

其实，对架构的每种定义都没有错，就像《软件架构设计》一书也说过的，只是每个人所看的角度不同而已。从上面的定义中也可知，架构涵盖了软件研发的方方面面，很难有人能够全部都懂，大部分架构师懂得的只是其中的某些方面。一栋高楼大厦也不是一个人完成的。

安装说明 
安装环境：CentOS-7
安装方式：源码安装 
软件：apache-tomcat-8.0.14.tar.gz
下载地址：http://tomcat.apache.org/download-80.cgi


安装前提 
系统必须已安装配置JDK6+

1、安装tomcat 
将apache-tomcat-8.0.14.tar.gz文件上传到/home/[username](该路径可以由自己指定)中执行以下操作：




[java] view plaincopy

 




[root@localhost ~]# cd /home/[username]
[root@localhost ~]# tar -zxv -f apache-tomcat-8.0.14.tar.gz // 解压压缩包  
[root@localhost ~]# rm -rf apache-tomcat-8.0.14.tar.gz // 删除压缩包  
[root@localhost ~]# mv apache-tomcat-8.0.14.tar.gz
  






2、启动TOMCAT

执行以下操作（根据自己指定的路径找到文件启动）：



[java] view plaincopy

 




[root@localhost /]# /home/[username]/apache-tomcat-8.0.33/bin/startup.sh
  


显示如下，则代表成功
Using CATALINA_BASE:  

/home/[username]/apache-tomcat-8.0.33
Using CATALINA_HOME:  

/home/[username]/apache-tomcat-8.0.33
Using CATALINA_TMPDIR:

/home/[username]/apache-tomcat-8.0.33/temp
Using JRE_HOME:         /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.77-0.b03.el7_2.x86_64/
Using CLASSPATH:      

/home/[username]/apache-tomcat-8.0.33/bin/bootstrap.jar:/home/[username]/apache-tomcat-8.0.33/bin/tomcat-juli.jar
Tomcat started.防火墙开放8080端口增加8080端口到防火墙配置中，执行以下操作：



[java] view plaincopy

 




[root@localhost ~]# vi + /etc/sysconfig/iptables&lt;/span&gt;  

#增加以下代码
-A RH-Firewall-1-INPUT -m state --state NEW -m tcp -p tcp --dport 8080 -j ACCEPT


重启防火墙



[java] view plaincopy

 




[root@localhost ~]# service iptables restart
  

检验Tomcat安装运行


通过以下地址查看tomcat是否运行正常（如果是虚拟机操作，对应ip地址要使用虚拟机的地址）：
http://127.0.0.1:8080/
看到tomcat系统界面，说明安装成功！

停止Tomcat



[java] view plaincopy

 




[root@localhost ~]# /home/[username]/apache-tomcat-8.0.33/bin/shutdown.sh //停止tomcat&lt;/span&gt;  





具体方法如下

git pull origin 分支

//出现错误

git stash  缓存起来

git pull origin 分支

git stash pop //还原

git stash clear




参考资料：

http://www.01happy.com/git-resolve-conflicts/




开发人员常常遇到这种情况：花了几天时间一直在做一个新功能，已经改了差不多十几个文件，突然有一个bug需要紧急解决，然后给一个build测试组。在Git问世之前基本上靠手动备份，费时且容易出错。

git stash命令简而言之就是帮助开发人员暂时搁置当前已做的改动，倒退到改动前的状态，进行其他的必要操作（比如发布，或者解决一个bug，或者branch，等等），之后还可以重新载入之前搁置的改动，很cool吧？

首先，用git add把所有的改动加到staging area。

git add .


接着用git stash把这些改动搁置。

git stash

到这里，当前工作平台就回复到改动之前了。该干嘛干嘛，此处省略1万字。

需要找回之前搁置的改动继续先前的工作了？

git stash apply 即可。

也可以用 git stash list 来查看所有的搁置版本（可能搁置了很多次，最好不要这样，容易搞混）

在出现一个搁置栈的情况下，比如如果你想找回栈中的第2个，可以用 git
 stash apply stash@{1}

如果想找回第1个，可以用 git stash pop

如果想删除一个stash，git stash drop &lt;id&gt;

删除所有stash，git stash clear


     CentOS 7的yum源中没有正常安装mysql时的mysql-sever文件，需要去官网上下载，下载及安装命令如下：



 


# wget http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpm
# rpm -ivh mysql-community-release-el7-5.noarch.rpm
# yum install mysql-community-server






     成功安装之后重启mysql服务






# service mysqld restart






     初次安装mysql是root账户是没有密码的

     设置密码的方法




 


# mysql -uroot
mysql&gt; set password for ‘root’@‘localhost’ = password('mypasswd');
mysql&gt; exit





     至此mysql安装结束。

在linux操作系统中，我们会经常要用到wget下载文件。wget非常稳定，它在带宽很窄的情况下和不稳定网络中有很强的适应性。
在linux中使用wget时，若报-bash: wget: command not found，则表明没有安装wget，需要安装，安装命令如下：
yum -y install wget

安装完成即可以使用。

restful中的mapping部分method部分对应有POST、GET、PUT、PATCH、DELETE五个请求属性
在开始之前，先说说restful中的r指的是什么，r指的是resource，即资源，也即restful的终极就是对资源的操作，如资源创建、查询、更改、删除等。


对应属性都有什么样的特性呢？
先看GET，GET请求属性是一般对应的是查询类的操作，并且对应的动作是幂等的（幂等的具体意思可以自己去查找），其请求成功一般返回的是200，意为OK，一切正常，去请求的参数会在url中被体现，形式为？name=afd&amp;&amp;password=akjg等，其中name，password即为其对应的参数。


POST，一般对应的是save或update操作，多数为save，update还是用的少一些，其操作是非幂等的，请求成功一般返回201，created，资源创建成功。其对应的请求参数一般存放在body中，不放在url中，其请求参数在url中是不可见的。


PUT/PATCH，这两个请求属性一般对应的是update操作，PUT一般是对整个资源的更新，PATCH是对某个属性的更新，喻义补丁，请求成功一般返回204，no content，请求参数一般放于body中


DELETE，对应删除操作，请求成功一般返回204，no content

CentOS 6.X 和 7.X 自带有OpenJDK
 runtime environment  (openjdk)。它是一个在linux上实现开源的java 平台。
安装方式：
1、输入以下命令，以查看可用的JDK软件包列表;
yum
 search java | grep -i --color JDK

2、在CentOS linux安装 JAVA SDK
在命令行终端以root用户 输入以下命令yum安装 OpenSDK ：
yum
 install java-1.8.0-openjdk  java-1.8.0-openjdk-devel  #安装openjdk



待以上命令执行完成，则表示jdk安装成功。


3、在centos linux上设置JAVA_HOME environment variable(JAVA_HOME环境变量)
rhel 和 centos linux 使用yum命令后，将 OpenSDK 安装到/usr/lib/jvm/ 目录：

4、用cd
 命令进入到jvm下唯一的一个目录中 java-1.8.0-openjdk-1.8.0.51.x86_64
 ，而 jre-1.8.0-openjdk.x86_64
 这个链接是指向  java-1.8.0-openjdk-1.8.0.51.x86_64 这个文件夹，所以，可以直接用export命令将 JAVA_HOME 指向 jre-1.8.0-openjdk.x86_64 这个链接。
即使用export命令:
 export
 JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.51.x86_64

但是这样只能在当前会话中有效，一旦注销下线，就失效了。

5、标准方式配置环境变量
进行下面的操作：

vi 
 /etc/profile

将下面的三行粘贴到
 /etc/profile   中：
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.51.x86_64
export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
export PATH=$PATH:$JAVA_HOME/bin

保存关闭，后，执行：source 
 /etc/profile  #让设置立即生效。

在输入以下命令，来确认这三个变量是否设成了我们想要的：

[root@~]#
 echo $JAVA_HOME
[root@ ~]# echo $CLASSPATH
[root@ ~]# echo $PATH



6、测试java是否安装配置成功


查看 java 版本，输入命令：
[root@~]#  java     -version

7、创建一个java小程序测试下，名字叫 HelloWorld.java ，输入以下命令：
[root@ ~]# touch HelloWorld.java

将以下代码复制到 HelloWorld.java 中 ：
public class HelloWorld {
pu
blic static void main(String[] args) {
System.out.println("Hello, World! This is a test code by nixCraft!");
}
}

复制进去后，保存关闭文件。编译和运行这个小程序，输入以下命令:
[root@ ~]#  javac HelloWorld.java
[root@ ~]#  java HelloWorld

会得到以下显示：
Hello, World! This is a test code by nixCraft!

8、如何(怎样)运行 .jar  这类java应用？

语法如下：
[root@~]# java -jar file.jar
[root@~]# java -jar /path/to/my/java/app.jar  #/path/to/my/java/app.jar表示应用的路径
[root@ ~]# java -jar /path/to/my/java/app.jar arg1 arg2   # arg1表示参数1 ，arg2表示参数2



C


以下是关于HashCode的官方文档定义：





[plain] view
 plain copy






hashcode方法返回该对象的哈希码值。支持该方法是为哈希表提供一些优点，例如，java.util.Hashtable 提供的哈希表。   
  
hashCode 的常规协定是：   
在 Java 应用程序执行期间，在同一对象上多次调用 hashCode 方法时，必须一致地返回相同的整数，前提是对象上 equals 
比较中所用的信息没有被修改。从某一应用程序的一次执行到同一应用程序的另一次执行，该整数无需保持一致。   
如果根据 equals(Object) 方法，两个对象是相等的，那么在两个对象中的每个对象上调用 hashCode 方法都必须生成相同
的整数结果。   
以下情况不 是必需的：如果根据 equals(java.lang.Object) 方法，两个对象不相等，那么在两个对象中的任一对象上调用 
hashCode 方法必定会生成不同的整数结果。但是，程序员应该知道，为不相等的对象生成不同整数结果可以提高哈希表的性能。   
实际上，由 Object 类定义的 hashCode 方法确实会针对不同的对象返回不同的整数。（这一般是通过将该对象的内部地址转
换成一个整数来实现的，但是 JavaTM 编程语言不需要这种实现技巧。）   
  
当equals方法被重写时，通常有必要重写 hashCode 方法，以维护 hashCode 方法的常规协定，该协定声明相等对象必须具有
相等的哈希码。  


以上这段官方文档的定义，我们可以抽出成以下几个关键点：



1、hashCode的存在主要是用于查找的快捷性，如Hashtable，HashMap等，hashCode是用来在散列存储结构中确定对象的存储地址的；

2、如果两个对象相同，就是适用于equals(java.lang.Object) 方法，那么这两个对象的hashCode一定要相同；

3、如果对象的equals方法被重写，那么对象的hashCode也尽量重写，并且产生hashCode使用的对象，一定要和equals方法中使用的一致，否则就会违反上面提到的第2点；

4、两个对象的hashCode相同，并不一定表示两个对象就相同，也就是不一定适用于equals(java.lang.Object) 方法，只能够说明这两个对象在散列存储结构中，如Hashtable，他们“存放在同一个篮子里”。




再归纳一下就是hashCode是用于查找使用的，而equals是用于比较两个对象的是否相等的。以下这段话是从别人帖子回复拷贝过来的：





[plain] view
 plain copy






1.hashcode是用来查找的，如果你学过数据结构就应该知道，在查找和排序这一章有  
例如内存中有这样的位置  
0  1  2  3  4  5  6  7    
而我有个类，这个类有个字段叫ID,我要把这个类存放在以上8个位置之一，如果不用hashcode而任意存放，那么当查找时就需
要到这八个位置里挨个去找，或者用二分法一类的算法。  
但如果用hashcode那就会使效率提高很多。  
我们这个类中有个字段叫ID,那么我们就定义我们的hashcode为ID％8，然后把我们的类存放在取得得余数那个位置。比如我们
的ID为9，9除8的余数为1，那么我们就把该类存在1这个位置，如果ID是13，求得的余数是5，那么我们就把该类放在5这个位置
。这样，以后在查找该类时就可以通过ID除 8求余数直接找到存放的位置了。  
  
2.但是如果两个类有相同的hashcode怎么办那（我们假设上面的类的ID不是唯一的），例如9除以8和17除以8的余数都是1，那
么这是不是合法的，回答是：可以这样。那么如何判断呢？在这个时候就需要定义 equals了。  
也就是说，我们先通过 hashcode来判断两个类是否存放某个桶里，但这个桶里可能有很多类，那么我们就需要再通过 equals 
来在这个桶里找到我们要的类。  
那么。重写了equals()，为什么还要重写hashCode()呢？  
想想，你要在一个桶里找东西，你必须先要找到这个桶啊，你不通过重写hashcode()来找到桶，光重写equals()有什么用啊  






最后，我们来看一个具体的示例吧，





[java] view
 plain copy






public class HashTest {  
    private int i;  
  
    public int getI() {  
        return i;  
    }  
  
    public void setI(int i) {  
        this.i = i;  
    }  
  
    public int hashCode() {  
        return i % 10;  
    }  
  
    public final static void main(String[] args) {  
        HashTest a = new HashTest();  
        HashTest b = new HashTest();  
        a.setI(1);  
        b.setI(1);  
        Set&lt;HashTest&gt; set = new HashSet&lt;HashTest&gt;();  
        set.add(a);  
        set.add(b);  
        System.out.println(a.hashCode() == b.hashCode());  
        System.out.println(a.equals(b));  
        System.out.println(set);  
    }  
}  


这个输出的结果：







[plain] view
 plain copy






true  
false  
[com.ubs.sae.test.HashTest@1, com.ubs.sae.test.HashTest@1]  


以上这个示例，我们只是重写了hashCode方法，从上面的结果可以看出，虽然两个对象的hashCode相等，但是实际上两个对象并不是相等；，我们没有重写equals方法，那么就会调用object默认的equals方法，是比较两个对象的引用是不是相同，显示这是两个不同的对象，两个对象的引用肯定是不定的。这里我们将生成的对象放到了HashSet中，而HashSet中只能够存放唯一的对象，也就是相同的（适用于equals方法）的对象只会存放一个，但是这里实际上是两个对象a,b都被放到了HashSet中，这样HashSet就失去了他本身的意义了。



此时我们把equals方法给加上：





[java] view
 plain copy






public class HashTest {  
    private int i;  
  
    public int getI() {  
        return i;  
    }  
  
    public void setI(int i) {  
        this.i = i;  
    }  
  
    &lt;span style="color:#3366FF;"&gt;&lt;strong&gt;public boolean equals(Object object) {  
        if (object == null) {  
            return false;  
        }  
        if (object == this) {  
            return true;  
        }  
        if (!(object instanceof HashTest)) {  
            return false;  
        }  
        HashTest other = (HashTest) object;  
        if (other.getI() == this.getI()) {  
            return true;  
        }  
        return false;  
    }&lt;/strong&gt;&lt;/span&gt;  
  
    public int hashCode() {  
        return i % 10;  
    }  
  
    public final static void main(String[] args) {  
        HashTest a = new HashTest();  
        HashTest b = new HashTest();  
        a.setI(1);  
        b.setI(1);  
        Set&lt;HashTest&gt; set = new HashSet&lt;HashTest&gt;();  
        set.add(a);  
        set.add(b);  
        System.out.println(a.hashCode() == b.hashCode());  
        System.out.println(a.equals(b));  
        System.out.println(set);  
    }  
}  

此时得到的结果就会如下：







[plain] view
 plain copy






true  
true  
[com.ubs.sae.test.HashTest@1]  


从结果我们可以看出，现在两个对象就完全相等了，HashSet中也只存放了一份对象。

1、CentOS 7 上安装 Docker
yum install -y docker


2、启动docker服务
systemctl start docker.service


3、下载官方的centos镜像到本地
docker pull centos


4、确认centos已经被获取
docker images centos


5、运行一个docker容器
docker run -i -t centos /bin/bash


6、显示当前正在运行的容器列表
docker ps


CentOS 7.0系统安装配置步骤详解

说明：

截止目前CentOS 7.x最新版本为CentOS 7.0，下面介绍CentOS 7.0的具体安装配置过程

服务器相关设置如下：

操作系统：CentOS 7.0 64位

IP地址：192.168.21.128

网关：192.168.21.2

DNS：8.8.8.8 8.8.4.4

备注：

生产服务器如果是大内存（4G以上内存），建议安装64位版本CentOS-7.0-1406-x86_64-DVD.iso



一、安装CentOS 7.0

成功引导系统后，会出现下面的界面



界面说明：

Install CentOS 7 安装CentOS 7

Test this media &amp; install CentOS  7 测试安装文件并安装CentOS  7

Troubleshooting 修复故障

这里选择第一项，安装CentOS  7，回车，进入下面的界面





系统运维  www.111cn.net  温馨提醒：qihang01原创内容?版权所有,转载请注明出处及原文链

选择语言：中文-简体中文（中国）  #正式生产服务器建议安装英文版本



继续



选择-系统-安装位置，进入磁盘分区界面



选择-其它存储选项-分区-我要配置分区，点左上角的“完成”，进入下面的界面



系统运维  www.111cn.net  温馨提醒：qihang01原创内容?版权所有,转载请注明出处及原文链

分区前先规划好

swap #交换分区，一般设置为内存的2倍

/ #剩余所有空间

备注：生产服务器建议单独再划分一个/data分区存放数据



点左下角的“+”号

挂载点：swap

期望容量：2048

添加挂载点，如下图所示



系统运维  www.111cn.net  温馨提醒：qihang01原创内容?版权所有,转载请注明出处及原文链

继续点左下角的“+”号

挂载点：/

期望容量：18.43GB #剩余所有空间

添加挂载点，如下图所示





点左上角的“完成”，进入下面的界面



接受更改，进入下面的界面



开始安装  #注意“软件”-“软件选择”，默认是最小安装，即不安装桌面环境，可以自己设置。

进入下面的界面



选择-用户设置-ROOT密码，进入下面的界面



设置Root密码

如果密码长度少于8位，会提示要按“完成”两次来确认，安装继续



安装完成之后，会进入下面的界面



点重启



系统重新启动



进入登录界面



账号输入root 回车

再输入上面设置的root密码回车

系统登录成功

二、设置IP地址、网关DNS

说明：CentOS 7.0默认安装好之后是没有自动开启网络连接的！

cd  /etc/sysconfig/network-scripts/  #进入网络配置文件目录



vi  ifcfg-eno16777736  #编辑配置文件，添加修改以下内容



HWADDR=00:0C:29:8D:24:73

TYPE=Ethernet

BOOTPROTO=static  #启用静态IP地址

DEFROUTE=yes

PEERDNS=yes

PEERROUTES=yes

IPV4_FAILURE_FATAL=no

IPV6INIT=yes

IPV6_AUTOCONF=yes

IPV6_DEFROUTE=yes

IPV6_PEERDNS=yes

IPV6_PEERROUTES=yes

IPV6_FAILURE_FATAL=no

NAME=eno16777736

UUID=ae0965e7-22b9-45aa-8ec9-3f0a20a85d11

ONBOOT=yes  #开启自动启用网络连接

IPADDR0=192.168.21.128  #设置IP地址

PREFIXO0=24  #设置子网掩码

GATEWAY0=192.168.21.2  #设置网关

DNS1=8.8.8.8  #设置主DNS

DNS2=8.8.4.4  #设置备DNS

:wq!  #保存退出

service network restart   #重启网络

ping www.baidu.com  #测试网络是否正常



ip addr  #查看IP地址



三、设置主机名为www

hostname  www  #设置主机名为www

vi /etc/hostname #编辑配置文件

www   #修改localhost.localdomain为www

:wq!  #保存退出

vi /etc/hosts #编辑配置文件

127.0.0.1   localhost  www   #修改localhost.localdomain为www

:wq!  #保存退出

shutdown -r now  #重启系统

java7发布时，大多数开发人员都关注与新的语言特性，有一些被更改了的API很少被人发现，但在我们的日常工作中却使用比较频繁。
1、异常处理改进 
a、try-with-resource语句
java7提供了一个简单、实用的代码格式如下：
打开一个资源
try{
使用该资源
}finally{
关闭该资源
}
其中资源所属的类必须实现了AutoCloseable接口。该接口只有一个方法：
void close() throws Exception
改进后的处理方式可以写成如下的形式：
try(Resource res = ...){
使用res
}
当try语句块退出时，会自动调用res.close()方法。try-with-resource语句自己也可以含有cath和finally分支。它们都会在关闭资源后执行。在实践中，不建议在单个try语句中放置太多的逻辑代码。
b、忽略异常
无论何时使用输入或者输出，在产生异常后如何关闭资源都是一个麻烦的问题。假设产生了一个IOException，接下来在关闭资源时，close方法又抛出了另一个异常。那么实际上会捕获哪个异常呢？在java中，finally分支中抛出的异常会丢弃到之前的异常。这不仅听上去不合理，实际上也确实不太合理。毕竟，用户对原始的异常会更感兴趣。
try-with-resource语句修改了这个行为。当AutoCloseable对象的close方法抛出异常时，原来的异常会被重新抛出，而调用close方法产生的异常会被捕获，并被标注为“被忽略”的异常。
c、捕获多个异常
在javase7中，你可以在同一个catch分支中捕获多个异常类型。捕获多个异常不仅能让你的代码看起来更简洁，而且效率也更高。生成的字节码会包含一个含有共享catch分支的代码块。
当捕获多个异常时，异常变量会被隐式设置为final类型。
2、实现equals、hashCode和compareTo方法
a、安全的null值相等测试
在java7之后，提供了Objects。equals(a,b)方法，如果a和b都是null，返回true；如果只有其中一个为null，返回false；其他情况返回a.equals(b)。从使用习惯和代码的规范性上讲，应该讲之前使用的a.equals(b)的地方更改为这种方式。
b、计算哈希码
对于null，Objects.hashCode方法会返回0。java7中引入的可变参数方法Objects.hash允许你指定任意个对象，并且它们的哈希码会被自动组合起来。
c、比较数值类型对象
当通过比较器来比较整型值时，因为允许返回任意负值或正值，所以它会试图返回二者之间相差的大小，但是实际上只需要知道符号就足够了。
在java7之后，可以使用静态方法Integer.compare来实现。过去，有开发人员会用new Integer(x).compareTo(other.x)的方式，但是这会创建两个会自动装箱/拆箱的整型对象。相比之下，静态方法compare使用的是int参数。此外，Long、Short、Byte和Boolean也都提供了各自的静态方法compare。如果你需要比较两个字符型值（char），可以直接将它们相减，结果不会溢出。Double和Float中的静态方法compare从java1.2开始就存在了。
3、其他改动
a、将字符串转换为数字
在jdk7之前，下面的代码的结果是什么
double x = Double.parseDouble("+1.0");
如果你知道结果，应该给自己一点奖励：+1.0一直都表示一个有效的浮点数，但是在java7之前，+1一直不是一个有效的整数。这个问题已经在所有通过字符串来构造int、long、short、byte和BigInteger的方法中被修复了。
b、全局Logger
为了鼓励在一些简单的程序中使用日志框架，Logger类现在提供了一个全局的Logger实例。因为它为了尽可能的简化使用，所以你可以在任何时候都使用Logger.global.finest("x=" + x);来代替System.out.println("x" + x);。
java7中提供了一直更简单的形式——Logger.getGlobal()。
c、Null检查
Objects类提供了requireNonNull方法以便于检查参数是否为null。




1. MySQL Workbench

MySQL Workbench 为数据库管理员、程序开发者和系统规划师提供可视化的Sql开发、数据库建模、以及数据库管理功能。

2.MySQL Workbench 的下载和安装

  （1）安装最新MySql时，有是否安装MySql Workbench的选项，可选择安装。

  （2）可以独立安装MySql Workbench。官方下载地址：http://dev.mysql.com/downloads/workbench/   安装很简单，基本就是一路Next。

3.MySQL Workbench的功能使用

功能界面：



分为三个主要功能模块：Sql Development(Sql开发 相当于Sql2000中的查询分析器), Data Modeling(数据库建模), Server Administration(服务器管理 相当于Sql2000中的企业管理器)

 

(1) Sql Development的使用



对应的操作分别是：Connection列表(供选择已经建好的数据库连接)，新建一个Connection，编辑数据库表，编辑SQL脚本，Connections管理

点击New Connection 会弹出如下操作界面



输入服务器的名称，端口，用户名，和密码 即可。

连接后的操作界面如下：



具体操作SQL2005 SQL2008中的差不多，这里不再描述。

（2） Data Modeling的使用

   Workbench中的数据库建模我还没有用到 这里略过 以后用到了再补充上

（3）Server Administration的使用



对应的功能分别是：服务器实例列表，新建一个服务实例，数据库的导入导出，安全管理，服务器列表管理

创建一个服务实例，创建的操作和Sql Development中的创建Connection一样 输入服务器的名称，端口，用户名，和密码 即可。

创建进入服务实例管理的功能界面如下：



Management中的功能主要有：

查看服务器状态，包括 连接数量， CUP使用率等

开启关闭服务器实例  可以开启或关闭服务器实例，查看运行日志

查看服务实例日志 包括存储日志，错误日志，通知日志 等

 

Configuration 服务器配置   这里的功能我还没有研究  略过

 

Security 服务实例安全 这里设置用户权限，角色，架构 和MS SQL的安全一样

 

Data Export/Restore 数据库的导入导出和恢复功能

数据导出的操作：



可以选择要导出的数据库和数据表，已经导出选项。这里的导出选项有 导入到一个文件夹中每个表对应一个sql脚本文件还是所有表导入到一个sql文件中，是否丢弃存储过程，是否丢弃Event定时器，是否清空数据

 数据导入操作：



 数据导入操作只有两个选择 一是导入一个文件夹中的所有Sql脚本 还是导入一个单独的Sql脚文件 (分别对应导出的两个选项)

在设置之前，首先了解一下什么是cookie？
cookies是一种WEB服务器通过浏览器在访问者的硬盘上存储信息的手段。IE浏览器把Cookie信息保存在类似于C://windows//cookies的目录下。
当用户再次访问某个站点时，服务端将要求浏览器查找并返回先前发送的Cookie信息，来识别这个用户。
cookies给网站和用户带来的好处非常多： 
1、Cookie能使站点跟踪特定访问者的访问次数、最后访问时间和访问者进入站点的路径 
2、Cookie能告诉在线广告商广告被点击的次数，从而可以更精确的投放广告 
3、Cookie有效期限未到时，Cookie能使用户在不键入密码和用户名的情况下进入曾经浏览过的一些站点 
4、Cookie能帮助站点统计用户个人资料以实现各种各样的个性化服务 
cookie过期时间设置方式：
cookie.setMaxAge(0);//不记录cookie
cookie.setMaxAge(-1);//会话级cookie，关闭浏览器失效
cookie.setMaxAge(60*60);//过期时间为1小时


除了lambda表达式，stream以及几个小的改进之外，Java 8还引入了一套全新的时间日期API，在本篇教程中我们将通过几个简单的任务示例来学习如何使用Java 8的这套API。Java对日期，日历及时间的处理一直以来都饱受诟病，尤其是它决定将java.util.Date定义为可修改的以及将SimpleDateFormat实现成非线程安全的。看来Java已经意识到需要为时间及日期功能提供更好的支持了，这对已经习惯使用Joda时间日期库的社区而言也是件好事。关于这个新的时间日期库的最大的优点就在于它定义清楚了时间日期相关的一些概念，比方说，瞬时时间（Instant）,持续时间（duration），日期（date）,时间（time），时区（time-zone）以及时间段（Period）。同时它也借鉴了Joda库的一些优点，比如将人和机器对时间日期的理解区分开的。Java
 8仍然延用了ISO的日历体系，并且与它的前辈们不同，java.time包中的类是不可变且线程安全的。新的时间及日期API位于java.time包中，下面是里面的一些关键的类：

Instant——它代表的是时间戳LocalDate——不包含具体时间的日期，比如2014-01-14。它可以用来存储生日，周年纪念日，入职日期等。LocalTime——它代表的是不含日期的时间LocalDateTime——它包含了日期及时间，不过还是没有偏移信息或者说时区。ZonedDateTime——这是一个包含时区的完整的日期时间，偏移量是以UTC/格林威治时间为基准的。

新的库还增加了ZoneOffset及Zoned，可以为时区提供更好的支持。有了新的DateTimeFormatter之后日期的解析及格式化也变得焕然一新了。随便提一句，我是在去年这个时候Java正要推出这个新功能时写的这篇文章，所以你会发现示例中的时间都还是去年的。你运行下这些例子，它们返回的值肯定都是正确的。
Java 8是如何处理时间及日期的

有人问我学习一个新库的最佳途径是什么？我的回答是，就是在实际项目中那样去使用它。在一个真实的项目中会有各种各样的需求，这会促使开发人员去探索和研究这个新库。简言之，只有任务本身才会真正促使你去探索及学习。java 8的新的日期及时间API也是一样。为了学习Java 8的这个新库，这里我创建了20个以任务为导向的例子。我们先从一个简单的任务开始，比如说如何用Java 8的时间日期库来表示今天，接着再进一步生成一个带时间及时区的完整日期，然后再研究下如何完成一些更实际的任务，比如说开发一个提醒类的应用，来找出距离一些特定日期比如生日，周日纪念日，下一个帐单日，下一个溢价日或者信用卡过期时间还有多少天。
示例1 如何 在Java 8中获取当天的日期

Java 8中有一个叫LocalDate的类，它能用来表示今天的日期。这个类与java.util.Date略有不同，因为它只包含日期，没有时间。因此，如果你只需要表示日期而不包含时间，就可以使用它。
LocalDate today = LocalDate.now(); System.out.println("Today's Local date : " + today); 

Output 
Today's Local date : 2014-01-14

你可以看到它创建了今天的日期却不包含时间信息。它还将日期格式化完了再输出出来，不像之前的Date类那样，打印出来的数据都是未经格式化的。
示例2 如何在Java 8中获取当前的年月日

LocalDate类中提供了一些很方便的方法可以用于提取出年月日以及其它的日期属性。使用这些方法，你可以获取到任何你所需要的日期属性，而不再需要使用java.util.Calendar这样的类了：
LocalDate today = LocalDate.now(); 
int year = today.getYear(); 
int month = today.getMonthValue(); 
int day = today.getDayOfMonth(); 
System.out.printf("Year : %d Month : %d day : %d \t %n", year, month, day); 

Output 
Today's Local date : 2014-01-14 
Year : 2014 Month : 1 day : 14

可以看到，在Java 8中获取年月信息非常简单，只需使用对应的getter方法就好了，无需记忆，非常直观。你可以拿它和Java中老的获取当前年月日的写法进行一下比较。
示例3 在Java 8中如何获取某个特定的日期

在第一个例子中，我们看到通过静态方法now()来生成当天日期是非常简单的，不过通过另一个十分有用的工厂方法LocalDate.of()，则可以创建出任意一个日期，它接受年月日的参数，然后返回一个等价的LocalDate实例。关于这个方法还有一个好消息就是它没有再犯之前API中的错，比方说，年只能从1900年开始，月必须从0开始，等等。这里的日期你写什么就是什么，比如说，下面这个例子中它代表的就是1月14日，没有什么隐藏逻辑。
LocalDate dateOfBirth = LocalDate.of(2010, 01, 14); 
System.out.println("Your Date of birth is : " + dateOfBirth); 

Output : Your Date of birth is : 2010-01-14

可以看出，创建出来的日期就是我们所写的那样，2014年1月14日。
示例4 在Java 8中如何检查两个日期是否相等

如果说起现实中实际的处理时间及日期的任务，有一个常见的就是要检查两个日期是否相等。你可能经常会碰到要判断今天是不是某个特殊的日子，比如生日啊，周年纪念日啊，或者假期之类。有的时候，会给你一个日期，让你检查它是不是某个日子比方说假日。下面这个例子将会帮助你在Java 8中完成这类任务。正如你所想的那样，LocalDate重写了equals方法来进行日期的比较，如下所示：
LocalDate date1 = LocalDate.of(2014, 01, 14); if(date1.equals(today)){ 
    System.out.printf("Today %s and date1 %s are same date %n", today, date1); 
} 

Output 
today 2014-01-14 and date1 2014-01-14 are same date

在本例中我们比较的两个日期是相等的。同时，如果在代码中你拿到了一个格式化好的日期串，你得先将它解析成日期然后才能比较。你可以将这个例子与Java之前比较日期的方式进行下比较，你会发现它真是爽多了。
示例5 在Java 8中如何检查重复事件，比如说生日

在Java中还有一个与时间日期相关的实际任务就是检查重复事件，比如说每月的帐单日，结婚纪念日，每月还款日或者是每年交保险费的日子。如果你在一家电商公司工作的话，那么肯定会有这么一个模块，会去给用户发送生日祝福并且在每一个重要的假日给他们捎去问候，比如说圣诞节，感恩节，在印度则可能是万灯节（Deepawali）。如何在Java中判断是否是某个节日或者重复事件？使用MonthDay类。这个类由月日组合，不包含年信息，也就是说你可以用它来代表每年重复出现的一些日子。当然也有一些别的组合，比如说YearMonth类。它和新的时间日期库中的其它类一样也都是不可变且线程安全的，并且它还是一个值类（value
 class）。我们通过一个例子来看下如何使用MonthDay来检查某个重复的日期：
LocalDate dateOfBirth = LocalDate.of(2010, 01, 14); 
MonthDay birthday = MonthDay.of(dateOfBirth.getMonth(), dateOfBirth.getDayOfMonth()); 
MonthDay currentMonthDay = MonthDay.from(today); 
if(currentMonthDay.equals(birthday)){ 
    System.out.println("Many Many happy returns of the day !!"); 
}else{ 
    System.out.println("Sorry, today is not your birthday"); 
} 

Output: Many Many happy returns of the day !!

虽然年不同，但今天就是生日的那天，所以在输出那里你会看到一条生日祝福。你可以调整下系统的时间再运行下这个程序看看它是否能提醒你下一个生日是什么时候，你还可以试着用你的下一个生日来编写一个JUnit单元测试看看代码能否正确运行。
示例6 如何在Java 8中获取当前时间

这与第一个例子中获取当前日期非常相似。这次我们用的是一个叫LocalTime的类，它是没有日期的时间，与LocalDate是近亲。这里你也可以用静态工厂方法now()来获取当前时间。默认的格式是hh:mm:ss:nnn，这里的nnn是纳秒。可以和Java 8以前如何获取当前时间做一下比较。
LocalTime time = LocalTime.now(); System.out.println("local time now : " + time);

Output 
local time now : 16:33:33.369 // in hour, minutes, seconds, nano seconds

可以看到，当前时间是不包含日期的，因为LocalTime只有时间，没有日期。
示例7 如何增加时间里面的小时数

很多时候我们需要增加小时，分或者秒来计算出将来的时间。Java 8不仅提供了不可变且线程安全的类，它还提供了一些更方便的方法譬如plusHours()来替换原来的add()方法。顺便说一下，这些方法返回的是一个新的LocalTime实例的引用，因为LocalTime是不可变的，可别忘了存储好这个新的引用。
LocalTime time = LocalTime.now(); 
LocalTime newTime = time.plusHours(2); // adding two hours 
System.out.println("Time after 2 hours : " + newTime); 

Output : 
Time after 2 hours : 18:33:33.369

可以看到当前时间2小时后是16:33:33.369。现在你可以将它和Java中增加或者减少小时的老的方式进行下比较。一看便知哪种方式更好。
示例8 如何获取1周后的日期

这与前一个获取2小时后的时间的例子类似，这里我们将学会如何获取到1周后的日期。LocalDate是用来表示无时间的日期的，它有一个plus()方法可以用来增加日，星期，或者月，ChronoUnit则用来表示这个时间单位。由于LocalDate也是不可变的，因此任何修改操作都会返回一个新的实例，因此别忘了保存起来。
LocalDate nextWeek = today.plus(1, ChronoUnit.WEEKS); 
System.out.println("Today is : " + today); 
System.out.println("Date after 1 week : " + nextWeek); 

Output: 
Today is : 2014-01-14 
Date after 1 week : 2014-01-21

可以看到7天也就是一周后的日期是什么。你可以用这个方法来增加一个月，一年，一小时，一分钟，甚至是十年，查看下Java API中的ChronoUnit类来获取更多选项。
示例9 一年前后的日期

这是上个例子的续集。上例中，我们学习了如何使用LocalDate的plus()方法来给日期增加日，周或者月，现在我们来学习下如何用minus()方法来找出一年前的那天。
LocalDate previousYear = today.minus(1, ChronoUnit.YEARS); 
System.out.println("Date before 1 year : " + previousYear); 
LocalDate nextYear = today.plus(1, YEARS); 
System.out.println("Date after 1 year : " + nextYear); 

Output: 
Date before 1 year : 2013-01-14 
Date after 1 year : 2015-01-14

可以看到现在一共有两年，一个是2013年，一个是2015年，分别是2014的前后那年。
示例10 在Java 8中使用时钟

Java 8中自带了一个Clock类，你可以用它来获取某个时区下当前的瞬时时间，日期或者时间。可以用Clock来替代System.currentTimeInMillis()与 TimeZone.getDefault()方法。
// Returns the current time based on your system clock and set to UTC. 
Clock clock = Clock.systemUTC(); 
System.out.println("Clock : " + clock); 

// Returns time based on system clock zone Clock defaultClock = 
Clock.systemDefaultZone(); 
System.out.println("Clock : " + clock); 

Output: 
Clock : SystemClock[Z] 
Clock : SystemClock[Z]

你可以用指定的日期来和这个时钟进行比较，比如下面这样：
public class MyClass { 
    private Clock clock; // dependency inject ... 

    public void process(LocalDate eventDate) { 

        if(eventDate.isBefore(LocalDate.now(clock)) { 
            ... 
        } 
    } 
}

如果你需要对不同时区的日期进行处理的话这是相当方便的。
示例11 在Java中如何判断某个日期是在另一个日期的前面还是后面

这也是实际项目中常见的一个任务。你怎么判断某个日期是在另一个日期的前面还是后面，或者正好相等呢？在Java 8中，LocalDate类有一个isBefore()和isAfter()方法可以用来比较两个日期。如果调用方法的那个日期比给定的日期要早的话，isBefore()方法会返回true。
LocalDate tomorrow = LocalDate.of(2014, 1, 15); 、if(tommorow.isAfter(today)){ 
    System.out.println("Tomorrow comes after today"); 
} 
LocalDate yesterday = today.minus(1, DAYS); 
if(yesterday.isBefore(today)){ 
    System.out.println("Yesterday is day before today"); 
} 

Output: 
Tomorrow comes after today 
Yesterday is day before today

可以看到在Java 8中进行日期比较非常简单。不需要再用像Calendar这样的另一个类来完成类似的任务了。
示例12 在Java 8中处理不同的时区

Java 8不仅将日期和时间进行了分离，同时还有时区。现在已经有好几组与时区相关的类了，比如ZonId代表的是某个特定的时区，而ZonedDateTime代表的是带时区的时间。它等同于Java 8以前的GregorianCalendar类。使用这个类，你可以将本地时间转换成另一个时区中的对应时间，比如下面这个例子：
// Date and time with timezone in Java 8 ZoneId america = ZoneId.of("America/New_York"); 
LocalDateTime localtDateAndTime = LocalDateTime.now(); 
ZonedDateTime dateAndTimeInNewYork = ZonedDateTime.of(localtDateAndTime, america ); 
System.out.println("Current date and time in a particular timezone : " + dateAndTimeInNewYork); 

Output : 
Current date and time in a particular timezone : 2014-01-14T16:33:33.373-05:00[America/New_York]

可以拿它跟之前将本地时间转换成GMT时间的方式进行下比较。顺便说一下，正如Java 8以前那样，对应时区的那个文本可别弄错了，否则你会碰到这么一个异常：
Exception in thread "main" java.time.zone.ZoneRulesException: Unknown time-zone ID: ASIA/Tokyo
        at java.time.zone.ZoneRulesProvider.getProvider(ZoneRulesProvider.java:272)
        at java.time.zone.ZoneRulesProvider.getRules(ZoneRulesProvider.java:227)
        at java.time.ZoneRegion.ofId(ZoneRegion.java:120)
        at java.time.ZoneId.of(ZoneId.java:403)
        at java.time.ZoneId.of(ZoneId.java:351)
示例13 如何表示固定的日期，比如信用卡过期时间

正如MonthDay表示的是某个重复出现的日子的，YearMonth又是另一个组合，它代表的是像信用卡还款日，定期存款到期日，options到期日这类的日期。你可以用这个类来找出那个月有多少天，lengthOfMonth()这个方法返回的是这个YearMonth实例有多少天，这对于检查2月到底是28天还是29天可是非常有用的。
YearMonth currentYearMonth = YearMonth.now(); System.out.printf("Days in month year %s: %d%n", currentYearMonth, currentYearMonth.lengthOfMonth()); 
YearMonth creditCardExpiry = YearMonth.of(2018, Month.FEBRUARY); 
System.out.printf("Your credit card expires on %s %n", creditCardExpiry); 

Output: 
Days in month year 2014-01: 31 
Your credit card expires on 2018-02
示例14 如何在Java 8中检查闰年

这并没什么复杂的，LocalDate类有一个isLeapYear()的方法能够返回当前LocalDate对应的那年是否是闰年。如果你还想重复造轮子的话，可以看下这段代码，这是纯用Java编写的判断某年是否是闰年的逻辑。
if(today.isLeapYear()){ 
    System.out.println("This year is Leap year"); 
}else { 
    System.out.println("2014 is not a Leap year"); 
} 

Output: 2014 is not a Leap year

你可以多检查几年看看结果是否正确，最好写一个单元测试来对正常年份和闰年进行下测试。
示例15 两个日期之间包含多少天，多少个月

还有一个常见的任务就是计算两个给定的日期之间包含多少天，多少周或者多少年。你可以用java.time.Period类来完成这个功能。在下面这个例子中，我们将计算当前日期与将来的一个日期之前一共隔着几个月。
LocalDate java8Release = LocalDate.of(2014, Month.MARCH, 14); 
Period periodToNextJavaRelease = 
Period.between(today, java8Release); 
System.out.println("Months left between today and Java 8 release : " + periodToNextJavaRelease.getMonths() ); 

Output: 
Months left between today and Java 8 release : 2

可以看到，本月是1月，而Java 8的发布日期是3月，因此中间隔着2个月。
示例16 带时区偏移量的日期与时间

在Java 8里面，你可以用ZoneOffset类来代表某个时区，比如印度是GMT或者UTC5：30，你可以使用它的静态方法ZoneOffset.of()方法来获取对应的时区。只要获取到了这个偏移量，你就可以拿LocalDateTime和这个偏移量创建出一个OffsetDateTime。
LocalDateTime datetime = LocalDateTime.of(2014, Month.JANUARY, 14, 19, 30); 
ZoneOffset offset = ZoneOffset.of("+05:30"); 
OffsetDateTime date = OffsetDateTime.of(datetime, offset); 
System.out.println("Date and Time with timezone offset in Java : " + date); 

Output : 
Date and Time with timezone offset in Java : 2014-01-14T19:30+05:30

可以看到现在时间日期与时区是关联上了。还有一点就是，OffSetDateTime主要是给机器来理解的，如果是给人看的，可以使用ZoneDateTime类。
示例17 在Java 8中如何获取当前时间戳

如果你还记得在Java 8前是如何获取当前时间戳的，那现在这简直就是小菜一碟了。Instant类有一个静态的工厂方法now()可以返回当前时间戳，如下：
Instant timestamp = Instant.now(); 
System.out.println("What is value of this instant " + timestamp); 

Output : 
What is value of this instant 2014-01-14T08:33:33.379Z

可以看出，当前时间戳是包含日期与时间的，与java.util.Date很类似，事实上Instant就是Java 8前的Date，你可以使用这两个类中的方法来在这两个类型之间进行转换，比如Date.from(Instant)是用来将Instant转换成java.util.Date的，而Date.toInstant()是将Date转换成Instant的。
示例18 如何在Java 8中使用预定义的格式器来对日期进行解析/格式化

在Java 8之前，时间日期的格式化可是个技术活，我们的好伙伴SimpleDateFormat并不是线程安全的，而如果用作本地变量来格式化的话又显得有些笨重。多亏了线程本地变量，这使得它在多线程环境下也算有了用武之地，但Java维持这一状态也有很长一段时间了。这次它引入了一个全新的线程安全的日期与时间格式器。它还自带了一些预定义好的格式器，包含了常用的日期格式。比如说，本例 中我们就用了预定义的BASICISODATE格式，它会将2014年2月14日格式化成20140114。
String dayAfterTommorrow = "20140116"; 
LocalDate formatted = LocalDate.parse(dayAfterTommorrow, 
DateTimeFormatter.BASIC_ISO_DATE); 
System.out.printf("Date generated from String %s is %s %n", dayAfterTommorrow, formatted); 

Output : 
Date generated from String 20140116 is 2014-01-16

你可以看到生成的日期与指定字符串的值是匹配的，就是日期格式上略有不同。
示例19 如何在Java中使用自定义的格式器来解析日期

在上例中，我们使用了内建的时间日期格式器来解析日期字符串。当然了，预定义的格式器的确不错但有时候你可能还是需要使用自定义的日期格式，这个时候你就得自己去创建一个自定义的日期格式器实例了。下面这个例子中的日期格式是”MMM dd yyyy”。你可以给DateTimeFormatter的ofPattern静态方法()传入任何的模式，它会返回一个实例，这个模式的字面量与前例中是相同的。比如说M还是代表月，而m仍是分。无效的模式会抛出DateTimeParseException异常，但如果是逻辑上的错误比如说该用M的时候用成m，这样就没办法了。
String goodFriday = "Apr 18 2014"; 
try { 
    DateTimeFormatter formatter = DateTimeFormatter.ofPattern("MMM dd yyyy");     
    LocalDate holiday = LocalDate.parse(goodFriday, formatter); 
    System.out.printf("Successfully parsed String %s, date is %s%n", goodFriday, holiday); 
} catch (DateTimeParseException ex) { 
    System.out.printf("%s is not parsable!%n", goodFriday); 
    ex.printStackTrace(); 
} 

Output : 
Successfully parsed String Apr 18 2014, date is 2014-04-18

可以看到日期的值与传入的字符串的确是相符的，只是格式不同。
示例20 如何在Java 8中对日期进行格式化，转换成字符串

在上两个例子中，尽管我们用到了DateTimeFormatter类但我们主要是进行日期字符串的解析。在这个例子中我们要做的事情正好相反。这里我们有一个LocalDateTime类的实例，我们要将它转换成一个格式化好的日期串。这是目前为止Java中将日期转换成字符串最简单便捷的方式了。下面这个例子将会返回一个格式化好的字符串。与前例相同的是，我们仍需使用指定的模式串去创建一个DateTimeFormatter类的实例，但调用的并不是LocalDate类的parse方法，而是它的format()方法。这个方法会返回一个代表当前日期的字符串，对应的模式就是传入的DateTimeFormatter实例中所定义好的。
LocalDateTime arrivalDate = LocalDateTime.now(); 
try { 
    DateTimeFormatter format = DateTimeFormatter.ofPattern("MMM dd yyyy hh:mm a"); 
    String landing = arrivalDate.format(format); 
    System.out.printf("Arriving at : %s %n", landing); 
    } catch (DateTimeException ex) { 
    System.out.printf("%s can't be formatted!%n", arrivalDate); 
    ex.printStackTrace(); 
} 

Output : Arriving at : Jan 14 2014 04:33 PM

可以看到，当前时间是用给定的”MMM dd yyyy hh:mm a”模式来表示的，它包含了三个字母表示的月份以及用AM及PM来表示的时间。
Java 8中日期与时间API的几个关键点

看完了这些例子后，我相信你已经对Java 8这套新的时间日期API有了一定的了解了。现在我们来回顾下关于这个新的API的一些关键的要素。

它提供了javax.time.ZoneId用来处理时区。它提供了LocalDate与LocalTime类Java 8中新的时间与日期API中的所有类都是不可变且线程安全的，这与之前的Date与Calendar API中的恰好相反，那里面像java.util.Date以及SimpleDateFormat这些关键的类都不是线程安全的。新的时间与日期API中很重要的一点是它定义清楚了基本的时间与日期的概念，比方说，瞬时时间，持续时间，日期，时间，时区以及时间段。它们都是基于ISO日历体系的。每个Java开发人员都应该至少了解这套新的API中的这五个类：

Instant 它代表的是时间戳，比如2014-01-14T02:20:13.592Z，这可以从java.time.Clock类中获取，像这样： Instant current = Clock.system(ZoneId.of(“Asia/Tokyo”)).instant();LocalDate 它表示的是不带时间的日期，比如2014-01-14。它可以用来存储生日，周年纪念日，入职日期等。LocalTime – 它表示的是不带日期的时间LocalDateTime – 它包含了时间与日期，不过没有带时区的偏移量ZonedDateTime – 这是一个带时区的完整时间，它根据UTC/格林威治时间来进行时区调整
这个库的主包是java.time，里面包含了代表日期，时间，瞬时以及持续时间的类。它有两个子package，一个是java.time.foramt，这个是什么用途就很明显了，还有一个是java.time.temporal，它能从更低层面对各个字段进行访问。时区指的是地球上共享同一标准时间的地区。每个时区都有一个唯一标识符，同时还有一个地区/城市(Asia/Tokyo)的格式以及从格林威治时间开始的一个偏移时间。比如说，东京的偏移时间就是+09:00。OffsetDateTime类实际上包含了LocalDateTime与ZoneOffset。它用来表示一个包含格林威治时间偏移量（+/-小时：分，比如+06:00或者 -08：00）的完整的日期（年月日）及时间（时分秒，纳秒）。DateTimeFormatter类用于在Java中进行日期的格式化与解析。与SimpleDateFormat不同，它是不可变且线程安全的，如果需要的话，可以赋值给一个静态变量。DateTimeFormatter类提供了许多预定义的格式器，你也可以自定义自己想要的格式。当然了，根据约定，它还有一个parse()方法是用于将字符串转换成日期的，如果转换期间出现任何错误，它会抛出DateTimeParseException异常。类似的，DateFormatter类也有一个用于格式化日期的format()方法，它出错的话则会抛出DateTimeException异常。再说一句，“MMM d yyyy”与“MMm dd yyyy”这两个日期格式也略有不同，前者能识别出”Jan 2 2014″与”Jan 14 2014″这两个串，而后者如果传进来的是”Jan 2 2014″则会报错，因为它期望月份处传进来的是两个字符。为了解决这个问题，在天为个位数的情况下，你得在前面补0，比如”Jan 2 2014″应该改为”Jan 02 2014″。

关于Java 8这个新的时间日期API就讲到这了。这几个简短的示例 对于理解这套新的API中的一些新增类已经足够了。由于它是基于实际任务来讲解的，因此后面再遇到Java中要对时间与日期进行处理的工作时，就不用再四处寻找了。我们学习了如何创建与修改日期实例。我们还了解了纯日期，日期加时间，日期加时区的区别，知道如何比较两个日期，如何找到某天到指定日期比如说下一个生日，周年纪念日或者保险日还有多少天。我们还学习了如何在Java 8中用线程安全的方式对日期进行解析及格式化，而无需再使用线程本地变量或者第三方库这种取巧的方式。新的API能胜任任何与时间日期相关的任务。

一、cookie机制和session机制的区别
　　具体来说cookie机制采用的是在客户端保持状态的方案，而session机制采用的是在服务器端保持状态的方案。
　　同时我们也看到，由于才服务器端保持状态的方案在客户端也需要保存一个标识，所以session
　　机制可能需要借助于cookie机制来达到保存标识的目的，但实际上还有其他选择

　　二、会话cookie和持久cookie的区别
　　如果不设置过期时间，则表示这个cookie生命周期为浏览器会话期间，只要关闭浏览器窗口，cookie就消失了。这种生命期为浏览会话期的 cookie被称为会话cookie。会话cookie一般不保存在硬盘上而是保存在内存里。
　　如果设置了过期时间，浏览器就会把cookie保存到硬盘上，关闭后再次打开浏览器，这些cookie依然有效直到超过设定的过期时间。
　　存储在硬盘上的cookie可以在不同的浏览器进程间共享，比如两个IE窗口。而对于保存在内存的cookie，不同的浏览器有不同的处理方式。

　　三、如何利用实现自动登录
　　当用户在某个网站注册后，就会收到一个惟一用户ID的cookie。客户后来重新连接时，这个
　　用户ID会自动返回，服务器对它进行检查，确定它是否为注册用户且选择了自动登录，从而使用户务需给出明确的用户名和密码，就可以访问服务器上的资源。

　　四、如何根据用户的爱好定制站点
　　网站可以使用cookie记录用户的意愿。对于简单的设置，网站可以直接将页面的设置存储在cookie中完成定制。然而对于更复杂的定制，网站只需仅将一个惟一的标识符发送给用户，由服务器端的数据库存储每个标识符对应的页面设置。

　　五、cookie的发送
　　1.创建Cookie对象
　　2.设置最大时效
　　3.将Cookie放入到HTTP响应报头

　　如果你创建了一个cookie，并将他发送到浏览器，默认情况下它是一个会话级别的cookie:存储在浏览器的内存中，用户退出浏览器之后被删除。如果你希望浏览器将该cookie存储在磁盘上，则
　　需要使用maxAge，并给出一个以秒为单位的时间。将最大时效设为0则是命令浏览器删除该cookie。
　　发送cookie需要使用HttpServletResponse的addCookie方法，将cookie插入到一个Set-Cookie　 HTTP请求报头中。由于这个方法并不修改任何之前指定的Set-Cookie报头，而是创建新的报头，因此我们将这个方法称为是addCookie，而非setCookie。同样要记住响应报头必须在任何文档内容发送到客户端之前设置。

　　六、cookie的读取
　　1.调用request.getCookie
　　要获取有浏览器发送来的cookie，需要调用HttpServletRequest的getCookies方法，这个调用返回Cookie对象的数组，对应由HTTP请求中Cookie报头输入的值。

　　2.对数组进行循环，调用每个cookie的getName方法，直到找到感兴趣的cookie为止
　　cookie与你的主机(域)相关，而非你的servlet或JSP页面。因而，尽管你的servlet可能只发送了单个cookie，你也可能会得到许多不相关的cookie。

　　例如：
　　String cookieName = “userID”;
　　Cookie cookies[] = request.getCookies();
　　if (cookies!=null){
　　    for(int
 i=0;i&lt;cookies.length;i++){
　　        Cookie
 cookie = cookies[i];
　　        if
 (cookieName.equals(cookie.getName())){
　　            doSomethingWith(cookie.getValue());
　　        }
　　    }
　　}

　　七、如何使用cookie检测初访者
　　A.调用HttpServletRequest.getCookies()获取Cookie数组
　　B.在循环中检索指定名字的cookie是否存在以及对应的值是否正确
　　C.如果是则退出循环并设置区别标识
　　D.根据区别标识判断用户是否为初访者从而进行不同的操作

　　八、使用cookie检测初访者的常见错误
　　不能仅仅因为cookie数组中不存在在特定的数据项就认为用户是个初访者。如果cookie数组为null，客户可能是一个初访者，也可能是由于用户将cookie删除或禁用造成的结果。
　　但是，如果数组非null,也不过是显示客户曾经到过你的网站或域，并不能说明他们曾经访问过你的servlet。其它servlet、JSP 页面以及非Java Web应用都可以设置cookie，依据路径的设置，其中的任何cookie都有可能返回给用户的浏览器。
　　正确的做法是判断cookie数组是否为空且是否存在指定的Cookie对象且值正确。

　　九、使用cookie属性的注意问题
　　属性是从服务器发送到浏览器的报头的一部分；但它们不属于由浏览器返回给服务器的报头。
　　因此除了名称和值之外，cookie属性只适用于从服务器输出到客户端的cookie；服务器端来自于浏览器的cookie并没有设置这些属性。
　　因而不要期望通过request.getCookies得到的cookie中可以使用这个属性。这意味着，你不能仅仅通过设置cookie的最大时效，发出它，在随后的输入数组中查找适当的cookie,读取它的值，修改它并将它存回Cookie，从而实现不断改变的cookie值。

　　十、如何使用cookie记录各个用户的访问计数
　　1.获取cookie数组中专门用于统计用户访问次数的cookie的值
　　2.将值转换成int型
　　3.将值加1并用原来的名称重新创建一个Cookie对象
　　4.重新设置最大时效
　　5.将新的cookie输出

十一、session在不同环境下的不同含义
　　session，中文经常翻译为会话，其本来的含义是指有始有终的一系列动作/消息，比如打电话是从拿起电话拨号到挂断电话这中间的一系列过程可以称之为一个session。
　　然而当session一词与网络协议相关联时，它又往往隐含了“面向连接”和/或“保持状态”这样两个含义。
　　session在Web开发环境下的语义又有了新的扩展，它的含义是指一类用来在客户端与服务器端之间保持状态的解决方案。有时候 Session也用来指这种解决方案的存储结构。

　　十二、session的机制
　　session机制是一种服务器端的机制，服务器使用一种类似于散列表的结构(也可能就是使用散列表)来保存信息。

　　但程序需要为某个客户端的请求创建一个session的时候，服务器首先检查这个客户端的请求里是否包含了一个session标识－称为
 session id,如果已经包含一个session id则说明以前已经为此客户创建过session，服务器就按照session id把这个session检索出来使用(如果检索不到，可能会新建一个，这种情况可能出现在服务端已经删除了该用户对应的session对象，但用户人为地在请求的URL后面附加上一个JSESSION的参数)。

　　如果客户请求不包含session id，则为此客户创建一个session并且生成一个与此session相关联的session id，这个session id将在本次响应中返回给客户端保存。

　　十三、保存session id的几种方式
　　A．保存session id的方式可以采用cookie，这样在交互过程中浏览器可以自动的按照规则把这个标识发送给服务器。
　　B．由于cookie可以被人为的禁止，必须有其它的机制以便在cookie被禁止时仍然能够把session id传递回服务器，经常采用的一种技术叫做URL重写，就是把session id附加在URL路径的后面，附加的方式也有两种，一种是作为URL路径的附加信息，另一种是作为查询字符串附加在URL后面。网络在整个交互过程中始终保持状态，就必须在每个客户端可能请求的路径后面都包含这个session
 id。
　　C．另一种技术叫做表单隐藏字段。就是服务器会自动修改表单，添加一个隐藏字段，以便在表单提交时能够把session
 id传递回服务器。

　　十四、session什么时候被创建
　　一个常见的错误是以为session在有客户端访问时就被创建，然而事实是直到某server端程序(如Servlet)调用 HttpServletRequest.getSession(true)这样的语句时才会被创建。

　　十五、session何时被删除
　　session在下列情况下被删除：
　　A．程序调用HttpSession.invalidate()
　　B．距离上一次收到客户端发送的session id时间间隔超过了session的最大有效时间
　　C．服务器进程被停止

　　再次注意关闭浏览器只会使存储在客户端浏览器内存中的session cookie失效，不会使服务器端的session对象失效。

　　十六、URL重写有什么缺点
　　对所有的URL使用URL重写，包括超链接，form的action，和重定向的URL。每个引用你的站点的URL，以及那些返回给用户的 URL(即使通过间接手段，比如服务器重定向中的Location字段)都要添加额外的信息。

　　这意味着在你的站点上不能有任何静态的HTML页面(至少静态页面中不能有任何链接到站点动态页面的链接)。因此，每个页面都必须使用 servlet或JSP动态生成。即使所有的页面都动态生成，如果用户离开了会话并通过书签或链接再次回来，会话的信息都会丢失，因为存储下来的链接含有错误的标识信息－该URL后面的SESSION
 ID已经过期了。

　　十七、使用隐藏的表单域有什么缺点
　　仅当每个页面都是有表单提交而动态生成时，才能使用这种方法。单击常规的&lt;A HREF..&gt;超文本链接并不产生表单提交，因此隐藏的表单域不能支持通常的会话跟踪，只能用于一系列特定的操作中，比如在线商店的结账过程

　　十八、会话跟踪的基本步骤
　　1．访问与当前请求相关的会话对象

　　2．查找与会话相关的信息

　　3．存储会话信息

　　4．废弃会话数据

　　十九、getSession()/getSession(true)、getSession(false)的区别
　　getSession()/getSession(true)：当session存在时返回该session，否则新建一个session并返回该对象
　　getSession(false)：当session存在时返回该session，否则不会新建session，返回null

　　二十、如何将信息于会话关联起来

　　setAttribute会替换任何之前设定的值；如果想要在不提供任何代替的情况下移除某个值，则应使用removeAttribute。这个方法会触发所有实现了HttpSessionBindingListener接口的值的valueUnbound

　　方法。
二十一、会话属性的类型有什么限制吗

　　通常会话属性的类型只要是Object就可以了。除了null或基本类型，如int,double,boolean。

　　如果要使用基本类型的值作为属性，必须将其转换为相应的封装类对象。

　　二十二、如何废弃会话数据
　　A．只移除自己编写的servlet创建的数据：
　　调用removeAttribute(“key”)将指定键关联的值废弃

　　B．删除整个会话(在当前Web应用中)：
　　调用invalidate，将整个会话废弃掉。这样做会丢失该用户的所有会话数据，而非仅仅由我们
　　servlet或JSP页面创建的会话数据

　　C．将用户从系统中注销并删除所有属于他(或她)的会话
　　调用logOut，将客户从Web服务器中注销，同时废弃所有与该用户相关联的会话(每个Web应用至多一个)。这个操作有可能影响到服务器上多个不同的Web应用

　　二十三、使用isNew来判断用户是否为新旧用户的错误做法
　　public boolean isNew()方法如果会话尚未和客户程序(浏览器)发生任何联系，则这个方法返回true，这一般是因为会话是新建的，不是由输入的客户请求所引起的。

　　但如果isNew返回false，只不过是说明他之前曾经访问该Web应用，并不代表他们曾访问过我们的servlet或JSP页面。

　　因为session是与用户相关的，在用户之前访问的每一个页面都有可能创建了会话。因此isNew为false只能说用户之前访问过该Web 应用，session可以是当前页面创建，也可能是由用户之前访问过的页面创建的。

　　正确的做法是判断某个session中是否存在某个特定的key且其value是否正确

　　二十四、Cookie的过期和Session的超时有什么区别
　　会话的超时由服务器来维护，它不同于Cookie的失效日期。首先，会话一般基于驻留内存的cookie

　　不是持续性的cookie，因而也就没有截至日期。即使截取到JSESSIONID cookie，并为它设定一个失效日期发送出去。浏览器会话和服务器会话也会截然不同。

　　二十五、session cookie和session对象的生命周期是一样的吗
　　当用户关闭了浏览器虽然session cookie已经消失，但session对象仍然保存在服务器端

　　二十六、是否只要关闭浏览器，session就消失了
　　程序一般都是在用户做log off的时候发个指令去删除session，然而浏览器从来不会主动在关闭之前通知服务器它将要被关闭，因此服务器根本不会有机会知道浏览器已经关闭。服务器会一直保留这个会话对象直到它处于非活动状态超过设定的间隔为止。

　　之所以会有这种错误的认识，是因为大部分session机制都使用会话cookie来保存session id，而关闭浏览器后这个session id就消失了，再次连接到服务器时也就无法找到原来的session。

　　如果服务器设置的cookie被保存到硬盘上，或者使用某种手段改写浏览器发出的HTTP请求报头，把原来的session id发送到服务器，则再次打开浏览器仍然能够找到原来的session。

　　恰恰是由于关闭浏览器不会导致session被删除，迫使服务器为session设置了一个失效时间，当距离客户上一次使用session的时间超过了这个失效时间时，服务器就可以认为客户端已经停止了活动，才会把session删除以节省存储空间。

　　由此我们可以得出如下结论：
　　关闭浏览器，只会是浏览器端内存里的session cookie消失，但不会使保存在服务器端的session对象消失，同样也不会使已经保存到硬盘上的持久化cookie消失。

　　二十七、打开两个浏览器窗口访问应用程序会使用同一个session还是不同的session
　　通常session cookie是不能跨窗口使用的，当你新开了一个浏览器窗口进入相同页面时，系统会赋予你一个新的session id，这样我们信息共享的目的就达不到了。

　　此时我们可以先把session id保存在persistent cookie中(通过设置session的最大有效时间)，然后在新窗口中读出来，就可以得到上一个窗口的session id了，这样通过session cookie和persistent cookie的结合我们就可以实现了跨窗口的会话跟踪。

　　二十八、如何使用会话显示每个客户的访问次数
　　由于客户的访问次数是一个整型的变量，但session的属性类型中不能使用int，double，boolean等基本类型的变量，所以我们要用到这些基本类型的封装类型对象作为session对象中属性的值

　　但像Integer是一种不可修改(Immutable)的数据结构：构建后就不能更改。这意味着每个请求都必须创建新的Integer对象，之后使用setAttribute来代替之前存在的老的属性的值。例如：
　　HttpSession session = request.getSession();
　　SomeImmutalbeClass value = (SomeImmutableClass)session.getAttribute(“SomeIdentifier”);
　　if (value == null){
　　   value
 = new SomeImmutableClass(…);　//新创建一个不可更改对象
　　}else{
　　   value
 = new SomeImmutableClass(calculatedFrom(value)); // 对value重新计算后创建新的对象
　　}
　　session.setAttribute(“someIdentifier”,value); //
 使用新创建的对象覆盖原来的老的对象

　　二十九、如何使用会话累计用户的数据
　　使用可变的数据结构，比如数组、List、Map或含有可写字段的应用程序专有的数据结构。通过这种方式，除非首次分配对象，否则不需要调用 setAttribute。例如:
　　HttpSession session = request.getSession();
　　SomeMutableClass value = (SomeMutableClass)session.getAttribute(“someIdentifier”);
　　if(value = = null){
　　   value
 = new SomeMutableClass(…);
　　   session.setAttribute(“someIdentifier”,value);
　　}else{
　　   value.updateInternalAttribute(…);     //
 如果已经存在该对象则更新其属性而不需重新设置属性
　　}

　　三十、不可更改对象和可更改对象在会话数据更新时的不同处理
　　不可更改对象因为一旦创建之后就不能更改，所以每次要修改会话中属性的值的时候，都需要调用 setAttribute(“someIdentifier”,newValue)来代替原有的属性的值，否则属性的值不会被更新可更改对象因为其自身一般提供了修改自身属性的方法，所以每次要修改会话中属性的值的时候，只要调用该可更改对象的相关修改自身属性的方法就可以了。这意味着我们就不需要调用
 setAttribute方法了。

如何通过创建自己的库来使用lambda表达式和函数式接口。
所有的lambda表达式都是延迟执行的。如果你希望一段代码立即执行，那必须要使用lambda表达式。延迟执行的一些原因如下：
a、在另一个线程中运行代码。
b、多次运行代码。
c、在某个算法正确的时间点上运行代码。
d、当某些情况发生时才运行代码。
e、只有在需要的时候才运行代码。
当使用lambda编程时，需要事先考虑一下希望达到什么样的效果。
如果你想要延时处理，你的AP需要能够区分出哪些是积累已完成任务的中间操作，哪些是用来产生结果的终止操作。
当表达式操作作为函数接口时，调用者就放弃了对处理细节的控制。只要应用了操作，就好得到正确的结果，有开发者可能会抱怨，但其带来的好处是对并发支持会相对的好一些。在过程中需要考虑如何处理和报告在lambda表达式执行过程中可能会发生的异常。
一般来说，lambda表达式可以与泛型很好地一起工作。但有一些问题需要谨记，如类型擦除会导致无法在运行时创建一个泛型数组。

Stream是java8中处理计划的关键抽象概念，它可以指定你希望对集合进行的操作，但是将执行操作的时间交给具体实现来决定。
1、从迭代器到Stream操作
Stream表面上看与一个集合很类似，允许你改变和获取数据。但是实际上它与集合有很大区别：
a、它自己不会存储元素。元素被存储在底层的集合中，或根据需要产生出来。
b、Stream操作符不会改变源对象。它会返回一个持有结果的新Stream。
c、Stream操作符可能是延迟执行的。它会等到需要结果时才执行。
Stream表达式比循环的可读性好，并发很容易进行，只要用parallelStream方法，就可以让Stream API并行执行过滤和统计操作。
Stream遵循“做什么，而不是怎么去做”的原则。当使用Stream时，会通过三个阶段来建立一个操作流水线：
a、创建一个Stream。
b、在一个或多个步骤中，指定将初始Stream转换为另一个Stream的中间操作。
c、使用一个终止操作来产生一个结果。该操作会强制它之前的延迟操作立即执行。在这之后，该Stream就不会再被使用了。


2、创建Stream
通过java8在Collection接口中新添加的stream方法，可以将任何集合转化为一个stream。如果你面对的是一个数组，也可以使用静态的Stream.of方法将它转化为一个Stream。of方法接受可变长的参数，因此你可以构造一个含有任意个参数的Stream。
使用Arrays.stream（array，from，to）方法将数组的一部分转化为Stream。
要创建一个不含任何元素的Stream，可以使用静态的Stream.empty方法。
Stream接口有两个用来创建无限Stream的静态方法。generate方法接受一个无参的函数。要创建一个形如0 1 2 3 ...的无限序列，可以使用iterate方法。Stream接口有一个父接口AutoCloseable。当在某个Stream上调用close方法时，底层的文件也会被关闭。为了确保关闭文件，最好使用java7中提供的try-with-resource语句，使得当try语句块或者抛出异常时，Stream与其关联的底层文件都将被关闭。


3、filter、map和flatMap方法
流转换是指从一个流中读取数据，并将转换后的数据写入到另一个流中。
filter方法的参数是一个Predicate&lt;T&gt;对象——即一个从T到boolean的函数。我们经常需要对一个流中的值进行某种形式的转换，可以考虑使用map方法，并传递给它一个执行转换的函数。


4、提取子流和组合流
Stream.limit（n）会返回一个包含n个元素的新流（如果原始流的长度小于n，则会返回原始的流）。这个方法特别适用于裁剪指定长度的流。
Stream.skip（n）则会丢弃前面的n个元素。


5、有状态的转换
前面介绍的流都是无状态的。当从一个已过滤或已映射的流中获取某个元素时，结果并不依赖于之前的元素。除此之外，java8中也提供了有状态的转换。例如distinct方法会根据原始流中的元素返回一个具有相同顺心、预制了重复元素的新流，该流须记住之前已读取的元素。Collects.sort会对原有的集合进行排序，而Stream.sorted会返回一个新的已排序的流。


6、简单的聚合方法
聚合方法都是终止操作，当一个流应用了终止操作后，它就不能再应用其他的操作了。


7、Optional类型
Optional&lt;T&gt;对象或者是一个T类型对象的封装，或者表示不是任何对象。它比一般指向T类型的引用更安全，因为它不会返回null——在你正确使用它的前提下才会更安全。
高效使用Optional的关键在于，使用一个或者接受正确值、或者返回另一个替代值的方法。创建可选值。使用flatMap来组合可选值函数。


8、聚合操作
如果你希望对元素求和，或者以其他方式将流中的元素组合为一个值，可以使用聚合方法。


9、收集结果
当你处理完流之后，你通常只是想查看一下结果，而不是将他们聚合为一个值。可以调用iterator方法来生成一个传统风格的迭代器，用于访问元素。

1、为什么要使用lambda表达式
lambda表达式是一段可以传递的代码，因此它可以被执行一次或多次。
在jdk8之前，向其他代码传递一段代码不是很容易，我们不能将代码块到处传递。我们需要构建一个属于某个类的对象，由它的某个方法来包含所需的代码。在其他一些语言中可以直接使用代码块。在过去的很长一段时间里，java设计者们都拒绝加入这一特性。java的优势本就在于他的简单和一致性。如果加入可以略微简化的代码，其将不易于维护。当然，还有一方面是，其他语言有大量的简单、一致、强大的API，java中的API却没有能达到这种效果。
基于以上，最近一段时间，大家不再讨论是否需要使用了，而是在讨论该怎么实现。并且很可喜的是，在jdk8中已经做了实现。


2、lambda表达式的语法
其格式为：参数、箭头-&gt;，以及一个表达式。如果相关代码无法用一个表达式表示，可以用编写方法的方式编写：既可以使用{}包裹代码并明确使用return语句。
如一个做比较的表达式可以这么写：
Comparator&lt;String&gt; comp = (String first, String second) -&gt; Integer.compare(first.length(), second.length()); 如果lambda表达式没有参数，可以提供一对空的小括号，如同不含参数的方法那样。

如果一个表达式的参数类型是可以被推导是，可以省略它们的类型。比如上面的String fisrt及后面的second的String参数都是可以不要的。
永远不需要为lambda表达式执行返回类型，它总是会从上下文中被推导出来。


3、函数式接口
对于只包含一个抽象方法的接口，可以通过lamba表达式来创建该接口的对象。


4、方法引用
当想要传递给其他代码的操作已经有了实现的方法，就可以使用方法引用。方法引用有三种主要的使用情况：
a、对象：：实例方法
b、类：：静态方法
c、类：：实例方法


5、构造器引用
构造器引用同方法引用类似，不同的是在构造器引用中方法名是new。
如Button::new表示Button类的构造器引用。对于拥有多个构造器的类，选择使用哪个构造器取决于上下文。


6、变量作用域
通常，我们希望可以在lambda表达式的闭合方法或类中访问其他的变量。
一个lambda表达式包括三个部分：
a、一段代码；b、参数；c、自由变量的值，自由指的是那些不是参数并且没有在代码中定义的变量。
lambda表达式可以捕获闭合作用域中的变量值，由此需要遵守一个约束，在lambda表达式中被引用的变量的值不可以被更改。更改lambda表达式中的变量不是线程安全的。
lambda表达式的方法体与嵌套代码块有着相同的作用域。也适用于同样的命名冲突和屏蔽规则。即不允许声明一个与局部变量同名的参数或者局部变量。不能有两个同名的局部变量。在lambda中使用this关键字时，会引用创建该lambda表达式的方法的this关键字。


7、默认方法
许多开发语言都将函数表达式集成到了其集合库中。
如果一个接口中定义了一个默认方法，而另外一个父类或接口中又定义一个同名的方法，该选择哪个？java中的规则如下：
a、选择父类中的方法。如果一个父类提供了具体的实现方法，那么接口中具有相同名称和参数的默认方法会被忽略。
b、接口冲突。如果一个父接口提供了一个默认方法，而另一个接口也提供了一个具有相同名称和参数类型的方法（不管该方法是否是默认方法），那么你必须通过覆盖该方法类解决冲突。
如此设计是为了实现“类优先”的规则，并且可以和之前的设计相兼容，不会因为在新接口中添加了一个默认方法，就导致跟之前版本不兼容了。


8、接口中的静态方法
在jdk8中，可以为接口添加静态方法。从技术角度来说，这是完全合法的。只是它看起来违反了接口作为一个抽象定义的理念。
在jdk8中，很多接口已经添加了静态方法。c



[笔记]eclipse中批量修改Java类文件中引入的package包路径 - [工具使用]



问题：

当复制其他工程中的包到新工程的目录中时，由于包路径不同，出现红叉，下面的类要一个一个修改包路径，类文件太多的话就比较麻烦了，如何批量改变包路径解决这个问题？

解决方法：
方法一：


Ctrl+h &gt;&gt; file serach &gt;&gt; 输入原包名(类型为*.java)&gt;&gt;Replace&gt;&gt;找到后输入要替换的包名 然后自己选择是全部替换还是部分替换. 


方法二：


直接修改出错的类所在的包的名称再改回来，这样就可以统一修改所有出错的类的package包名称。

一、语法形式：
    Java2在1.4中新增了一个关键字：assert。在程序开发过程中使用它创建一个断言(assertion)，它的
语法形式有如下所示的两种形式：
1、assert condition;
    这里condition是一个必须为真(true)的表达式。如果表达式的结果为true，那么断言为真，并且无任何行动
如果表达式为false，则断言失败，则会抛出一个AssertionError对象。这个AssertionError继承于Error对象，
而Error继承于Throwable，Error是和Exception并列的一个错误对象，通常用于表达系统级运行错误。
2、asser condition:expr;
    这里condition是和上面一样的，这个冒号后跟的是一个表达式，通常用于断言失败后的提示信息，说白了，它是一个传到AssertionError构造函数的值，如果断言失败，该值被转化为它对应的字符串，并显示出来。

二、使用示例：
    下面是一个使用assert的例子：


public class TestAssert{
     public static void main(String[] args){
         String name = "abner chai";
         //String name = null;
         assert (name!=null):"变量name为空null";
         System.out.println(name);
     }
}



    上面程序中，当变量name为null时，将会抛出一个AssertionError，并输出错误信息。
要想让上面的程序中的断言有效并且正确编译，在编译程序时，必须使用-source 1.4选项。如：

javac -source 1.4 TestAssert.java

在Eclipse(3.0M9)开发环境中，必须在window-&gt;preferences 中，左边选中"Java-&gt;Compiler"，右边选择
“Compliance and ClassFiles”页面下的将"Compiler Compliance Level"选择为1.4；同时，将
"Use Default Compiler Settings"前的勾去掉。并将下面的
"Generated .class file compatibility"和"Source compatibility"均选择为1.4，才能正确编译。

同时，要想让断言起效用，即让断言语句在运行时确实检查，在运行含有assert的程序时，必须指定-ea选项
如：为了能够让上面的程序运行，我们执行下面代码：

java -ea TestAssert

在在Eclipse(3.0M9)开发环境中，运行时，我们必须配置运行时的选项"Run"，在Arguments页面中的
"VM Arguments" 中填入-ea选项。才能让断言在运行时起作用。

三、注意事项：
    理解断言最重要的一点是必须不依赖它们完成任何程序实际所需的行为。理由是正常发布的代码都是断言无效的，即正常发布的代码中断言语句都不不执行的（或不起作用的），如果一不小心，我们可以错误地使用断言，如：


public class TestPerson{
    private String name = null;
    public TestPerson(String name){
        this.name = name;
    }
    public void setName(String nameStr){
        this.name = nameStr;
    }
    public String getName(){
         return this.name;
    }
    public static void main(String[] args){
        TestPerson personObj = new TestPerson("Abner Chai");
        String personName = null;
        assert (personName=personObj.getName())!=null;
        System.out.println(personName.length());
    }
}



这个程序中，对personName的赋值被转移到assert6语句中，尽管断言有效时它可以很好地运行（即使用-ea运行
时可以有效地运行）但如果断言失效，则它会运行时报空指针错误。因为断言无效时，
personName=personObj.getName()一句永远不会执行！
    断言对Java来说是一个好的条件，因为它们使开发过程中错误类型检查流线化，例如，在没有assert之前，
上面的程序要想确认personName 不空，则必须：

if(personName!=null){
    System.out.println(personName.length());
}
才行。有了assert后，使用assert，只需一行代码，并且不必从发布的代码中删除assert语句。
于是，上面的那个程序，经改正后，我们可以这么样来正确的使用assert，如下：



public class TestPerson{
    private String name = null;
    public TestPerson(String name){
        this.name = name;
    }
    public void setName(String nameStr){
        this.name = nameStr;
    }
    public String getName(){
         return this.name;
    }
    public static void main(String[] args){
        TestPerson personObj = new TestPerson("Abner Chai");
        String personName = null;
        personName=personObj.getName();
        assert personName!=null;
        System.out.println(personName.length());
    }
}



四、其它选项：
    当执行代码时，使用-ea选项使断言有效，也可以使用-da选项使断言无效（默认为无效）
同样，也可以通过在-ea或-da后面指定包名来使一个包的断言有效或无效。例如，要使一个com.test包中的断言
无效，可以使用：
-da:com.test
要使一个包中的所有子包中的断言能够有效或无效，在包名后加上三个点。例如：
-ea:com.test...
即可使com.test包及其子包中的断言无效。


我们先看2个类的定义





[java] view
 plain copy






public class Hashtable  
    extends Dictionary  
    implements Map, Cloneable, java.io.Serializable  







[java] view
 plain copy






public class HashMap  
    extends AbstractMap  
    implements Map, Cloneable, Serializable  



可见Hashtable 继承自 Dictiionary 而 HashMap继承自AbstractMap

 

Hashtable的put方法如下





[java] view
 plain copy






public synchronized V put(K key, V value) {  //###### 注意这里1  
  // Make sure the value is not null  
  if (value == null) { //###### 注意这里 2  
    throw new NullPointerException();  
  }  
  // Makes sure the key is not already in the hashtable.  
  Entry tab[] = table;  
  int hash = key.hashCode(); //###### 注意这里 3  
  int index = (hash &amp; 0x7FFFFFFF) % tab.length;  
  for (Entry e = tab[index]; e != null; e = e.next) {  
    if ((e.hash == hash) &amp;&amp; e.key.equals(key)) {  
      V old = e.value;  
      e.value = value;  
      return old;  
    }  
  }  
  modCount++;  
  if (count &gt;= threshold) {  
    // Rehash the table if the threshold is exceeded  
    rehash();  
    tab = table;  
    index = (hash &amp; 0x7FFFFFFF) % tab.length;  
  }  
  // Creates the new entry.  
  Entry e = tab[index];  
  tab[index] = new Entry(hash, key, value, e);  
  count++;  
  return null;  
}  



 

注意1 方法是同步的
注意2 方法不允许value==null
注意3 方法调用了key的hashCode方法，如果key==null,会抛出空指针异常 HashMap的put方法如下




[java] view
 plain copy






public V put(K key, V value) { //###### 注意这里 1  
  if (key == null)  //###### 注意这里 2  
    return putForNullKey(value);  
  int hash = hash(key.hashCode());  
  int i = indexFor(hash, table.length);  
  for (Entry e = table[i]; e != null; e = e.next) {  
    Object k;  
    if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) {  
      V oldValue = e.value;  
      e.value = value;  
      e.recordAccess(this);  
      return oldValue;  
    }  
  }  
  modCount++;  
  addEntry(hash, key, value, i);  //###### 注意这里   
  return null;  
}  



 

注意1 方法是非同步的
注意2 方法允许key==null
注意3 方法并没有对value进行任何调用，所以允许为null

补充： 
Hashtable 有一个 contains方法，容易引起误会，所以在HashMap里面已经去掉了
当然，2个类都用containsKey和containsValue方法。

 

                           HashMap                Hashtable

父类                  AbstractMap          Dictiionary

是否同步            否                            是

k，v可否null     是                            否

 

 

 

 

HashMap是Hashtable的轻量级实现（非线程安全的实现），他们都完成了Map接口，

主要区别在于HashMap允许空（null）键值（key）,由于非线程安全，效率上可能高于Hashtable。





 
HashMap允许将null作为一个entry的key或者value，而Hashtable不允许。









 
HashMap把Hashtable的contains方法去掉了，改成containsvalue和containsKey。因为contains方法容易让人引起误解。 









 
Hashtable继承自Dictionary类，而HashMap是Java1.2引进的Map interface的一个实现。







 
最大的不同是，Hashtable的方法是Synchronize的，而HashMap不是，在多个线程访问Hashtable时，不需要自己为它的方法实现同步，而HashMap 就必须为之提供外同步(Collections.synchronizedMap)。 




Hashtable和HashMap采用的hash/rehash算法都大概一样，所以性能不会有很大的差异。


JVM调优工具

Jconsole，jProfile，VisualVM



Jconsole : jdk自带，功能简单，但是可以在系统有一定负荷的情况下使用。对垃圾回收算法有很详细的跟踪。详细说明参考这里

 

JProfiler：商业软件，需要付费。功能强大。详细说明参考这里

 

VisualVM：JDK自带，功能强大，与JProfiler类似。推荐。

 

如何调优

观察内存释放情况、集合类检查、对象树

上面这些调优工具都提供了强大的功能，但是总的来说一般分为以下几类功能

 

堆信息查看



 


可查看堆空间大小分配（年轻代、年老代、持久代分配）

提供即时的垃圾回收功能

垃圾监控（长时间监控回收情况）

 




 


查看堆内类、对象信息查看：数量、类型等

 




 


对象引用情况查看

 


有了堆信息查看方面的功能，我们一般可以顺利解决以下问题：

  --年老代年轻代大小划分是否合理

  --内存泄漏

  --垃圾回收算法设置是否合理

 

线程监控



 


线程信息监控：系统线程数量。

线程状态监控：各个线程都处在什么样的状态下

 




 


Dump线程详细信息：查看线程内部运行情况

死锁检查

 


热点分析



 

 

 

    CPU热点：检查系统哪些方法占用的大量CPU时间

    内存热点：检查哪些对象在系统中数量最大（一定时间内存活对象和销毁对象一起统计）

 

    这两个东西对于系统优化很有帮助。我们可以根据找到的热点，有针对性的进行系统的瓶颈查找和进行系统优化，而不是漫无目的的进行所有代码的优化。

 

 

快照

    快照是系统运行到某一时刻的一个定格。在我们进行调优的时候，不可能用眼睛去跟踪所有系统变化，依赖快照功能，我们就可以进行系统两个不同运行时刻，对象（或类、线程等）的不同，以便快速找到问题

    举例说，我要检查系统进行垃圾回收以后，是否还有该收回的对象被遗漏下来的了。那么，我可以在进行垃圾回收前后，分别进行一次堆情况的快照，然后对比两次快照的对象情况。

 

内存泄漏检查

    内存泄漏是比较常见的问题，而且解决方法也比较通用，这里可以重点说一下，而线程、热点方面的问题则是具体问题具体分析了。

    内存泄漏一般可以理解为系统资源（各方面的资源，堆、栈、线程等）在错误使用的情况下，导致使用完毕的资源无法回收（或没有回收），从而导致新的资源分配请求无法完成，引起系统错误。

    内存泄漏对系统危害比较大，因为他可以直接导致系统的崩溃。

    需要区别一下，内存泄漏和系统超负荷两者是有区别的，虽然可能导致的最终结果是一样的。内存泄漏是用完的资源没有回收引起错误，而系统超负荷则是系统确实没有那么多资源可以分配了（其他的资源都在使用）。

 

 

年老代堆空间被占满

异常： java.lang.OutOfMemoryError: Java heap space

说明：





 

    这是最典型的内存泄漏方式，简单说就是所有堆空间都被无法回收的垃圾对象占满，虚拟机无法再在分配新空间。

    如上图所示，这是非常典型的内存泄漏的垃圾回收情况图。所有峰值部分都是一次垃圾回收点，所有谷底部分表示是一次垃圾回收后剩余的内存。连接所有谷底的点，可以发现一条由底到高的线，这说明，随时间的推移，系统的堆空间被不断占满，最终会占满整个堆空间。因此可以初步认为系统内部可能有内存泄漏。（上面的图仅供示例，在实际情况下收集数据的时间需要更长，比如几个小时或者几天）

 

解决：

    这种方式解决起来也比较容易，一般就是根据垃圾回收前后情况对比，同时根据对象引用情况（常见的集合对象引用）分析，基本都可以找到泄漏点。

 

 

持久代被占满

异常：java.lang.OutOfMemoryError: PermGen space

说明：

    Perm空间被占满。无法为新的class分配存储空间而引发的异常。这个异常以前是没有的，但是在Java反射大量使用的今天这个异常比较常见了。主要原因就是大量动态反射生成的类不断被加载，最终导致Perm区被占满。

    更可怕的是，不同的classLoader即便使用了相同的类，但是都会对其进行加载，相当于同一个东西，如果有N个classLoader那么他将会被加载N次。因此，某些情况下，这个问题基本视为无解。当然，存在大量classLoader和大量反射类的情况其实也不多。

解决：

    1. -XX:MaxPermSize=16m

    2. 换用JDK。比如JRocket。

 

 

堆栈溢出

异常：java.lang.StackOverflowError

说明：这个就不多说了，一般就是递归没返回，或者循环调用造成

 

 

线程堆栈满

异常：Fatal: Stack size too small

说明：java中一个线程的空间大小是有限制的。JDK5.0以后这个值是1M。与这个线程相关的数据将会保存在其中。但是当线程空间满了以后，将会出现上面异常。

解决：增加线程栈大小。-Xss2m。但这个配置无法解决根本问题，还要看代码部分是否有造成泄漏的部分。

 

系统内存被占满

异常：java.lang.OutOfMemoryError: unable to create new native thread

说明：

    这个异常是由于操作系统没有足够的资源来产生这个线程造成的。系统创建线程时，除了要在Java堆中分配内存外，操作系统本身也需要分配资源来创建线程。因此，当线程数量大到一定程度以后，堆中或许还有空间，但是操作系统分配不出资源来了，就出现这个异常了。

分配给Java虚拟机的内存愈多，系统剩余的资源就越少，因此，当系统内存固定时，分配给Java虚拟机的内存越多，那么，系统总共能够产生的线程也就越少，两者成反比的关系。同时，可以通过修改-Xss来减少分配给单个线程的空间，也可以增加系统总共内生产的线程数。

解决：

    1. 重新设计系统减少线程数量。

    2. 线程数量不能减少的情况下，通过-Xss减小单个线程大小。以便能生产更多的线程。

配置方式一：
        将${maven install path}\conf下的settings.xml文件复制到${user.home}/.m2/下，修改${user.home}/.m2/settings.xml ，在settings.xml文件中添加如下配置：
&lt;settings&gt;  
  ...  
  &lt;localRepository&gt;D:\java\repository&lt;/localRepository&gt;  
  ...  
&lt;/settings&gt;  
修改后，本地私服就对应到localRepository指定的位置了。


配置方式二：
方式一需要拷贝settings文件，本方式不需要拷贝settings文件，只需要在eclipse中将maven中的settings的位置指定即可。具体如下：
eclipse-&gt;window-&gt;preferences-&gt;maven-&gt;user settings，在user settings下的选择框中将${maven install path}\conf\settings.xml的路径选上（settings文件中也需要加入localRepository的配置），点击update
 settings，选择apply、ok，本地私服就对应到在settings文件对应的位置了。




摘要：本问总结了25个Java机器学习工具&amp;库：Weka集成了数据挖掘工作的机器学习算法、面向数据流挖掘的流行开源框架（MOA）、新型的柔性工作流引擎ADAMS、基于Java的面向文本文件的机器学习工具包Mallet等。


本列表总结了25个Java机器学习工具&amp;库：

1. Weka集成了数据挖掘工作的机器学习算法。这些算法可以直接应用于一个数据集上或者你可以自己编写代码来调用。Weka包括一系列的工具，如数据预处理、分类、回归、聚类、关联规则以及可视化。

2.Massive Online Analysis（MOA）是一个面向数据流挖掘的流行开源框架，有着非常活跃的成长社区。它包括一系列的机器学习算法（分类、回归、聚类、异常检测、概念漂移检测和推荐系统）和评估工具。关联了WEKA项目，MOA也是用Java编写的，其扩展性更强。

3.MEKA项目提供了一个面向多标签学习和评价方法的开源实现。在多标签分类中，我们要预测每个输入实例的多个输出变量。这与“普通”情况下只涉及一个单一目标变量的情形不同。此外，MEKA基于WEKA的机器学习工具包。

4. Advanced Data mining And Machine learning System（ADAMS）是一种新型的柔性工作流引擎，旨在迅速建立并保持真实世界的复杂知识流，它是基于GPLv3发行的。

5. Environment for Developing KDD-Applications Supported by Index-Structure（ELKI）是一款基于Java的开源（AGPLv3）数据挖掘软件。ELKI主要集中于算法研究，重点研究聚类分析中的无监督方法和异常检测。

6. Mallet是一个基于Java的面向文本文件的机器学习工具包。Mallet支持分类算法，如最大熵、朴素贝叶斯和决策树分类。

7. Encog是一个先进的机器学习框架，集成了支持向量机（SVM）、人工神经网络、遗传算法、贝叶斯网络、隐马尔可夫模型（HMM）、遗传编程和遗传算法。

8. Datumbox机器学习框架是一个用Java编写的开源框架，允许快速地开发机器学习和统计应用。该框架的核心重点包括大量的机器学习算法以及统计测试，能够处理中等规模的数据集。

9. Deeplearning4j是使用Java和Scala编写的第一个商业级的、开源的、分布式深入学习库。其设计的目的是用于商业环境中，而不是作为一个研究工具。

10. Mahout是一个内置算法的机器学习框架。Mahout-Samsara帮助人们创建他们自己的数学，并提供了一些现成的算法实现。

11.Rapid Miner是德国多特蒙特技术大学开发的。它为开发者开发应用程序提供了一个GUI（图形用户界面）和Java API。它还提供了一些机器学习算法，用来做数据处理、可视化以及建模。

12. Apache SAMOA是一个机器学习（ML）框架，内嵌面向分布式流ML算法的编程抽象，并且允许在没有直接处理底层分布式流处理引擎（DSPEe，如Apache Storm、Apache S4和Apache samza）复杂性的情况下，开发新的ML算法。用户可以开发分布式流ML算法，而且可以在多个DSPEs上执行。

13. Neuroph通过提供支持创建、训练和保存神经网络的Java网络库和GUI工具，简化了神经网络开发。

14. Oryx 2是一个建立在Apache Spark和Apache Kafka的Lambda架构实现，但随着实时大规模机器学习而逐渐开始专业化。这是一个用于构建应用程序的框架，但也包括打包，以及面向协同过滤、分类、回归和聚类的端到端的应用程序。

15. Stanford Classifier是一个机器学习工具，它可以将数据项归置到一个类别。一个概率分类器，比如这个，它可以对一个数据项给出类分配的概率分布。该软件是最大熵分类器的一个Java实现。

16.io是一个Retina API，有着快速精确的类似大脑的自然语言处理算法。

17.JSAT是一个快速入门的机器学习库。该库是我在业余时间开发的，基于GPL3发行的。库中的一部分内容可自主学习，例如所有的代码都是独立的。JSAT没有外部依赖，而且是纯Java编写的。

18. N-Dimensional Arrays for Java(ND4J)是一个用于JVM的科学计算库。它们是用来在生产环境中使用的，这表明例程的设计是以最小的内存需求来运行的。

19. Java Machine Learning Library（Java机器学习库）是一系列机器学习算法的相关实现。这些算法，无论是源代码还是文档，都编写的很出色。其主要语言是Java。

20. Java-ML是一个使用Java编写的一系列机器学习算法的Java API。它只提供了一个标准的算法接口。

21. MLlib (Spark)是Apache Spark的可扩展机器学习库。虽然是Java，但该库与平台还支持Java，Scala和Python绑定。此库是最新的，并且算法很多。

22. H2O是用于智能应用的机器学习API。它在大数据上对统计学、机器学习和数学进行了规模化。H2O可扩展，开发者可以在核心部分使用简单的数学知识。

23. WalnutiQ是人脑部分面向对象模型，有着理论常用的学习算法（正在向简单强烈的情感人工智能模型方向研究）。

24. RankLib是一个排名学习算法库。目前已经实现八种流行的算法。

25. htm.java（基于Java的Hierarchical Temporal Memory算法实现）是一个面向智能计算的Numenta平台的Java接口。源码

原文地址：25 Java Machine Learning Tools &amp; Libraries（译者/刘帝伟 审校/刘翔宇 责编/仲浩）



对程序员来说，编程语言就是武器，但有的武器好用，有的武器不好用，有的武器甚至会杀了自己。









C语言是M1式加兰德步枪，很老但可靠。










C++是双截棍，挥舞起来很强悍，很吸引人，但需要你多年的磨练来掌握，很多人希望改用别的武器。









Perl语言是燃烧弹，曾经在战场上很有用，但现在很少人使用它。









Java是M240通用弹夹式自动机枪，有时它的弹夹是圆的，但有时候不是，如果不是，当你开火时，会遇到NullPointerException问题，枪就会爆炸，你被炸死。









Scala是M240通用机枪的变种，但它的使用手册是用一种看不懂的方言写的，很多人怀疑那只是一些梦话。









JavaScript是一把宝剑，但没有剑柄。









Go语言是一种自制的“if err != nil”发令枪，每一次发射后，你都必须要检查它是否真的发射了。









Rust语言是一种3D打印出的枪。将来也许真的能派上用场。









bash是一个十分碍手的锤子，你抡起它时会发现所有东西看起来都像钉子，尤其是你的指头。









Python是一种“v2/v3”双管枪，每次只能用一个管子发射，你永远不知道该用哪个管子发射好。









Ruby是一把外嵌红宝石的宝刀，人们使用它通常是因为看起来很炫。









PHP是水管子，你通常会把它的一段接到汽车的排气管，另一端插进车窗里，然后你坐进车里，开动引擎。









Mathematica是一种地球低轨道粒子大炮，它也许能够干出很神奇的事情，但只有付得起费用的人才能使用它。









C#是一种强悍的激光大炮，架子一头驴子上，如果从驴子上卸下来，它好像就发不出激光。









Prolog语言是一种人工智能武器，你告诉它要做什么，它会照做不误，但之后，它会弄几个终结者出来，烧掉你的房子。









Lisp语言是一把剃须刀，有很多款式。只有寻求刺激和危险的人才会使用它。






本文属翻译作品，英文原文标题是：If programming languages were weapons。若无特别说明，英文原文及其衍生作品均使用知识共享署名-相同方式共享（Creative Commons）协议。您可以自由复制、散布、展示及演出本作品；若您改变、转变或更改本作品，仅在遵守与本作品相同的授权条款下，您才能散布由本作品产生的派生作品。

本文是在程序师网首次发表。文章内容属作者个人观点，不代表本站立场。


00 缘起 

之所以有这个话题，是因为周末加班中午吃饭与一个同行朋友聊起了这个话题，之后再细细地结合一些其他接触的东西，确实是有些感触的。


并且对于行业的一些现状，也的确有些自己的看法，对不对先不论，这玩意儿也没有对错之分，每个人都有自己想法，当然也包括我博客虫了。

所以，有些东西、有些想法我还是愿意分享出来的，畅所欲言吧~~



BigData


01 我眼中的大数据现状!

其实个人在大数据在大数据这个坑中，细细算来时间也有3+年年了，从一开始做大数据中心平台开发构建，到现在关注的数据上层应用挖掘。所以，基本上从数据收集-&gt;数据处理(离线实时，并且还勉强算是国内实时处理早期的实践者)-&gt;数据上层应用挖掘，这个链路都走了一遍。

并且加上手里一千多人的大数据圈子，发起组织线下技术沙龙等等经历，坑内里的做的并不算十分的多，但是通过一些交流，接触过的这方面的东西还是不少的。

所以，不至于有资格说对这个技术方向有啥定论，但是一些自己的看法见解还是有滴。

说起大数据，有个成语可以来形容一下它的现状：遍地开花！

如今，在国内，只要是个IT公司(说的是非传统行业)，出去的时候，感觉要是说自己公司没有涉足大数据都不好意思。

所以，现在的情况大部分是这样的：一个创业公司哪怕只有十多人的开发团队，也非得整一个大数据小组出来，我们不止要做大数据离线处理，还要做离线处理，不止有数据分析报表，我们还得进行深度的数据挖掘，做到精准的个性化推荐，流弊的数据预测！

偶滴娘亲啊，寥寥数人，不止要搭起一整套完整的数据收集、数据传输、数据离线实时处理，不止要维护hadoop集群、spark集群、storm集群的稳定性，抽空还要做深层数据挖掘，还要研究工业化流弊的算法。

你们招的这些人不是攻城狮啊，是神啊！这么流弊！

其实我并没有说这种做法一定是错的，只是行业现状真心很多这种情况。如今，大数据确实是异常略微畸形的火爆！

至于说大数据这个技术方向为何会如此的爆炸，个人的观点可能和大部分的观点一样：一方面是数据积累到一定程度了；另一方面是大规模数据处理技术的日渐成熟，其中当然以hadoop生态为代表。

但在不久前，我曾和一个创业公司的COE聊过这个话题，他的观点很新颖。他反驳了我的观点，他说中国现在之所以大数据遍地开花，是由于赚钱模式变了。

他说，在以前，随便搞点啥都能拉到一大堆投资，但现在经济形势不一样了，必须想其他新的触发点，那就是数据，并且围绕数据而产生新的利益点，这样，投资人才愿意投钱进来，所以是个公司都愿意和大数据沾点边，不然都不好意思出去说。

就个人而言，其实感觉他说的也挺有道理的，不过我依然保持自己的看法，只是两人看待事情的角度有些不一样，我是从技术的角度去解析这个情况，而他则更多从创业者的角度试图去解释这个事情。无关对错！

就目前来说，业内大数据遍地开花这个情况确实是存在的，个人感觉大体上有如下的具体变化：


(1)涉足的数据处理方式上来说，大规模离线处理已经被玩坏了，稍微有点实力的公司都已经开始离线、实时并行了(近一两年Storm、Spark强势崛起)；

(2)而在数据来源上，已经不再局限于自个的数据了，越来越多的公司开始爬取互联网上的公共数据(我曾在《DT时代变革的反思》一文中比较详细的分析过这个数据新来源)；


而在数据的上层应用上，也已经不再局限于多维统计分析，渐渐得向用户画像、精准个性化推荐、业务的预测等方向靠拢(但实际上深层挖掘方面，国内还是很low的)；

002 大数据年份这东西!

之前和朋友吃饭时聊的时候，他说到大数据这个技术方向的积累问题。他曾感叹到，大数据这个方向还是缺少底蕴。

我问他为何这么说，他说你见过十年以上的大数据专家么？其他行业方向，比比皆是！我顿时无语，大数据这个技术方向满打满算才发展不到六七年吧，上哪找十年以上的大数据专家去。

情况确实是这样的，基本可以分这几种情况吧：


(1)在这个坑里，真正五年以上的大数据背景的人，已经可以算的上是半个专家了，业内绝对是稀有动物(所以，经常看到那种招聘简历写到十年以上大数据行业背景，我就笑了)；

(2)而诸如三四年的，会点数据架构，又会点上层数据应用挖掘的，估计至少也能算的是半个中坚了，这种人不算太少，但也绝对不算多；

(3)最多的是那种不到两年大数据行业背景的，特别是那种听闻大数据行情好，纷纷转过来一两年左右的，再就是那种一毕业就立志投身大数据行业的新人朋友，这类型的人应该是占据大数据从业人士中的绝大部分。


这个方向却是缺少累积的，经常在群中(storm-分布式-IT技术 191321336)遇到那种号称是搞大数据的，然后问到：hadoop和storm哪个比较好？

我的天呐，为何他们那么喜欢把两个不是一类东西放在一起比较？！我都无力吐槽了，就目前来说，大数据这个方向确实缺少底蕴，还略显浮夸，需要时间去积累。

003 企业在招什么样的大数据工程师？


(1)刚洗白一两年的，或者立志为大数据行业做贡献的毕业生。


刚才说大数据行业遍地开花，人员稀缺，从个人经历来说，这真心是这种状况。

业务重心逐渐偏移到数据部，所以部门急剧扩招(当然也有老员工离职的问题)，近三个月来，我陆陆续续面试了大约有7个人左右吧。

面试的人中有两三年工作经验的，也有四五年工作经验的，当然也有刚毕业的本科生或者硕士生。

看年份感觉都还不错是吧，但是如果你翻一翻简历就会哭了。就说说三到五年工作经验的吧。

简历中，项目经历一项一大溜啥XX管理系统、XX电商后端开发项目，翻了八九个项目，终于在最后看到辣么一两个大数据有关的项目。而掌握的技术中是各种的什么Spring MVC啊、SSH啊、js啊、甚至是php之类的，只有寥寥数个什么hadoop啥的，还不敢放在前头，当时我就哭了/(ㄒoㄒ)/~~。

情况真是这样的，工作经验足的，很多都是刚从其他技术领域转过来的，其中以开发java后端，诸如精通什么MVC框架的人群为主体。

能说上hadoop是怎么回事，会点MapReduce、Hive之类的是常态；会点Spark，能写Scala，知道Storm的，少之又少；能把整个数据框架流程说清楚的都是奇才了；至于说到大规模数据的深层挖掘，他们是这样说的“没怎么接触，但有这个兴趣去学”。

行情确实是这样的，大数据的坑挖的太大，所以各个公司都缺人，而且还是奇缺，所以也就有了上面我说的现象，各个行业，特别是传统IT行业的从业人士，纷纷转入互联网，投身大数据。而有点大数据经验的，大部分都是香馍馍似得供着，不愿意放手。

所以，最终我们这边实际情况就是，问HR咋回事，HR说JD发出去无数份，能拉过来面试的就酱紫了。

最终大老板发话了，说到：经验差点没关系，只要脑子活愿意学，就要！所以，7个人，offer就发出去4份。

但更悲剧还在后头，两个有大概平均1.5大数据经验的人，拿到offer后根本不鸟之，也也不知道后来去了哪个公司，而最后进来的是两个本科以及硕士应届毕业生。

所以，就目前来看，大数据行业的火爆带来的一个现状就是，大量的java开发人员转行，大数据行业背景平均在一年多，虽然如此，依然是供不应求的。


(2)我们来看看一些“喜人”的招聘需求。


随便翻一翻招聘网站的职位需求，每天都有大量的大数据相关职位被刷新。然后结合刚才我们所说的一些混乱现状，你会发现很多“喜人”的招聘说明。

我希望的是，用人的公司也好、企业也好，看完这个之后，能对招人有个更清晰的定位。

我们要的是大数据行业专家！

JD中是这么描述的，十年以上大数据领域经验，然后会XX，然后又得会XX。再多的俺就不多说了，结合刚才我们说的大数据行业历史。十年？我就呵呵了~~

我所看到的这种JD，大部分出自于传统IT行业(看到没，传统IT行业也开始追赶潮流了)，而互联网公司职位描述就含蓄多了，最起码他们不会动不动就要十年以上“砖家”。

而且还有一点个人想吐槽的就是，你说十年就十年吧，给待遇还奇低无比。关于这一点，互联网公司就比较明白事理的。

关于大数据薪酬这一块，我们再进行分析分析~~

我们要的是能进行大规模数据挖掘的人才！

关于数据挖掘，上面也稍微提到过一点，数据的上层应用挖掘，这个需求随着数据处理流程日益完善，数据的应用已经从简单的多维统计分析，慢慢得向深层挖掘过渡。

不说大规模数据，就说传统的数据挖掘，其实这块就国内的情况来看，还是处于比较初级的状态的。

我们经常看到这样的职位JD描述，Title写的是“数据挖掘工程师招聘”，然后附加条件是，熟悉大数据领域，会MapReduce、kafka、hadoop、storm、spark，熟悉ETL，对若干NoSQL了解熟悉，能够进行平台搭建，平台开发，能够进行数据处理，会分类、聚类、用户画像、个性化推荐各种算法。

最后在工作年限上写着“1-3年”(年份太足是很贵的嘛)。我的天啊，他们看样子不止是想招数据挖掘工程师啊。

他们像是在招ETL工程师；不对，应该是大数据平台开发工程师；也不对，好像确实是在招数据挖掘工程师，没看到有算法需求吗。

我赶脚呀，他们不是在招数据挖掘工程师，他们是在招一个全能工程师，是在招一个神啊。


(3)说了不少，对于大数据人才招聘这块，简单的总结一下吧！


其实个人感觉，企业还是需要对自己岗位定位要有一个比较清楚的定位的。

如果你的资金足，想招一个业内权威点的，专家级人物，没关系，但你也别睁着眼瞎说十年呐。上哪去给你找十年专家啊！

所以，个人建议就是，瞄准在大数据领域真正玩过五年以上的，基本上就是牛人了，也足够你用的了。

然后针对刚才说的“数据挖掘”招聘现象，其实定位也很重要了，真心想要招一个类似“全能”的人，至少也要找一个在这个领域待过3+年的。

至少三年以上的时间，这种人会对数据架构，数据处理流程，甚至是上层数据应用挖掘，都有相应的经验，而不至于空白一片，并且容易带动其他一年半年的大数据经验的人，做方向导向，团队就能快速形成大数据战斗力。

所以，如果真心想要类似这种“全能”，真心实意点，把年份改到3+吧，并且要求实打实的3+大数据技术背景，估计差不多。

接下来就是那种一两年的大数据技术背景的，这种以java后端开发转行大军为代表。如果你的预算瞄准的是这个市场，那你也别玩虚的，对口招聘吧。

要做大规模离线处理，你就招会hadoop的；需要实时处理，你就招会Storm或者会Spark Streaming的；需要做ETL，你就招熟悉ETL流程的；招数据挖掘，就找会点算法的。这才是实在的！

而对于应届生来说，个人赶紧项目经验都是其次的，哪怕是一些实验室项目经验来说，也没啥大用。好歹算是接触过一些内幕的，所以实验室项目的质量，咱就不多说了，呵呵就行了。

所以，我们看的一是基础能力。就个人的感觉来说，基础能力当然不必说，我更偏向于对大数据技术感兴趣，并且思维敏捷的应届生。

为什么这么说呢？因为大数据技术这个领域会涉及大量的新事物，各种开源的东西，经验少没关系，只有思维够敏捷，有强大的快速学习能力，那就没有问题！

004 我们真的需要算法工程师吗？

接着刚才的话题，不少企业公司打着招数据挖掘工程师，算法工程师，我在想他们是真的需要算法工程师么？

答案显然是否定的！

我曾关于数据挖掘工程师与算法工程师的区别问题，跟不少人讨论过，我的个人看法是，算法工程师的范围显然是小于数据挖掘工程师的。

数据挖掘工程师需要了解整套数据流入的过程，包括数据的接入、预处理，然后需要知道怎么用数据解决实际的业务问题，说白就是想办法让数据产生价值。

他需要知道一整个数据到业务输出的机制或者说是系统，可能涉及到复杂的算法转化，也可能只是简单的规则转化，或者多个模型的转化组合输出等等，他是一个比较全面而概括性定位。

而算法工程师则不一样，他们的职责我认为更纯粹，他们需要知道如何把现实问题转化为数学的模型，并且把模型调到极致，从而解决问题。所以，算法工程师工作内容更单一，但是更专，需要更好的数学功底。

这也就是为何我不敢对外说是算法工程师的原因了，我怕被揍，哈哈~~

OK，有点绕远了。我们回过头来说说，目前大部分公司企业在找大数据的人，同时也在找数据挖掘工程师或者算法工程师。

那么，企业或者公司如何在数据挖掘这块进行定位呢？我个人认为，大部分中小公司是不具备找纯算法工程师条件的。如果，有小公司说要招算法工程师，要么是金多任性，要么是打着招算法工程师的幌子，招会点数据挖掘的人。

至于原因呢，一方面是算法这块，在国内属于稀缺资源，所以成本都比较高；另一方面就是在实际的业务操作中，高深的算法模型难以工业化(所以，大部分论文上的东西离工业化生产是很远的，别被骗了)；再者就是在数据挖掘领域，一些很初级容易工业生产化算法，甚至是简单的规则定制，都在现阶段已经能达到业务目的了，我们又何必费那个劲呢？！

所以，我认为企业在这种阶段，你们需求是这种能够进行大批量数据处理，然后又知道怎么进行数据工业转化的人。因为，算法工程师在这种阶段难以获得你需要的性价转换。

包括我们大数据部门内部也是同样如此，算法小组冠着“算法”的头衔，干着数据处理的杂活。这需要时间去过渡！

当然，如果你一定要养那么一群专业的算法工程师，辣么，我只能说，你拿的天使投资太多了，估计是不知道怎么花了，养着就养着吧。

005 谈一谈薪酬，谈一谈人生吧！

最后，谈一谈薪酬，谈一谈人生，谈一谈理想吧！

说到谈薪酬，谈人生谈理想这个环节，我想大部分都是比较喜欢的，我也不例外，我也很喜欢，哈哈~~

正如之前所说的，大数据这个领域，有点略微畸形的火爆，导致了这个方向很缺人，也正是大量java后端开发人员转行的直接原因。

因为缺人，他们就转行么？显然是扯的！大伙儿都是有理想的人，要向“钱”看的。缺人，找不到人怎么办？提高待遇，自然就有了。

我看到过一份2014年的职业薪酬统计报告，其中大数据方向绝对是属于偏高的。就我所知，除去金融行业的高玩们。

接下来就是玩数据挖掘的，特别是会大规模数据挖掘的人，如果是专业的算法工程师，那么，就更赞了，麻麻再也不用担心我的工资了。

然后就是游戏行业的开发着，游戏是个保利行业，所以他们薪酬高一些是很正常的。

再接下来就是冠以“大数据”称号的攻城狮们。这类的，要么是做平台构建的，要么是做大数据架构，要么是做数据处理的等等。工资也比纯Java后端开发、C开发、C++开发等高那么半档一档的。

接下来跟大数据没有半毛钱关系的职位啥的，我就不多说了~~

006 写在最后

所以，总体来看，整个大数据行业还是比较混乱的，企业对自己需求定位很混乱，虽然如此，依然是难以招到人。

对于投身大数据这个坑的人来说，我个人的建议就是，要入行没问题，但是找准自己的兴趣G点，别想着啥都想掌握。找准一个切入点，比如就是平台搭建、就是ETL、就是写离线处理程序、就是研究实时等等，然后，慢慢再往大领域中扩充自己的大数据知识库存。

就我个人来说，从数据架构到数据上层应用挖掘，目前依然在坑内，也没有打算从大数据的这个坑中脱身。

大数据这个方向是个技术快速更新、迭代的技术领域，所以，个人鼓励坑中人士多多交流、多多分享才能跟上这个时代潮流。

我一直坚持着技术的分享与交流，所以也经常写点伪技术文章，只是希望能够把这个思想传递给更多的人。

说一件比较可喜的事，1月9号左右，我将再次发起组织“米特吧大数据技术沙龙”，这是第二期了，地点依然是会在北京。我已经不满足于线上的交流了，哈哈，我要“占领”线下~~

真心的，技术是需要传播交流以及分享的，特别是大数据领域，更是需要及时掌握最新的技术导向以及行业变化。

最后，以一句我坚持三年的话结束这篇文章：“进步始于交流，收获源于分享！”


摘要：由于云计算应用的不断深入，以及对大数据处理需求的不断扩大，用户要求功能丰富、性能强大、高可用性的产品，云计算厂商们也推陈出新，不断地推出新产品，本文就盘点了业内翘楚阿里云在2015年那些有价值的新产品。


作为云计算产业热土的中国，2015年产业规模依旧保持高速增长，且国内的公有云服务领域有几十家企业在角逐，经过几年的发展，目前市场逐渐明朗，有些公有云企业已经遥遥领先，而有些企业很可惜，已经开始掉队。


下面，我们一起盘点下国内云计算生态系统中公认的翘楚阿里云在2015年那些有价值的新产品。

互联网安全的下一个关键技术量子加密

在今年10月中旬的云栖大会上，阿里云与中国科学院旗下的国盾量子联合发布了量子加密通信产品，志着全球互联网迈入量子时代。目前量子加密已在阿里云网络环境建立了多个量子安全传输域，通过量子传送门实现同城数据中心互联组网，能够为客户提供无条件安全数据传输服务，而这是全球首家云服务商提供量子安全传输产品落地服务。另外，阿里云通过复杂的算法和软件（特别是更为复杂地对网络和终端进行管控的软件）将加密技术链接到云中，从而实现更高的性价比。

从成本上来说，当下量子计算主要沿京沪干线展开，基于已有光纤，其主成本主要表现在光纤上附加的设备，主要分为两个部分：第一是发送和接收部分；第二是中继设备，这点主要是受限于单光子传播的可靠距离，在这里当下使用的可靠传输距离是50公里。

中国首个可视化机器学习平台DTPAI

今年下半年，阿里云宣布推出国内首个人工智能平台DTPAI，开发者可通过简单拖拽的方式完成对海量数据的分析挖掘，以及对用户行为、行业走势等的预测。而且，该平台还集成了阿里核心算法库，包括特征工程、大规模机器学习、深度学习等。

DTPAI基于阿里云大数据处理平台ODPS构建（后者可在6小时内处理100PB数据，相当于1亿部高清电影），目前主要支持鼠标拖拽的编程可视化（Visual Programming），用户可以实现0代码的算法应用开发；同时也支持的据可视化和模型可视化，让用户更直观的了解数据与算法。此外，用户还可以基于阿里云计算平台提供的开发语言和框架来搭建应用或者组件。阿里云计算平台提供自研的计算框架，例如ODPS（SQL、Open MapReduce等）和一些常见的开源产品例如Spark。同时针对机器学习，阿里云也对接了开源的例如DMLC等框架和自研的Parameter
 Server开发框架。







DTPAI的机器学习核心库

DTPAI开放的算法支持对ODPS上的数据集上的数据处理和分析的一些基本功能，包括统计、采样、拆分、标准化等。在机器学习建模和预测的算法有分类和聚类的算法，包括Kmeans、逻辑回归、随机森林、GBDT等。另外用户也可以使用R脚本来封装一个节点逻辑。除此之外，还支持ISV或者用户提供自己开发的第二方或第三方算法。

读写性能超群的高性能存储服务SSD云盘，提升原ECS存储性能20倍。

在证券交易、实时航空预定、搜索引擎等IO密集型应用中，存储系统的IO吞吐量瓶颈已成为许多机构不得不攻克的难题。阿里今年发布的又一亮眼新品SSD云盘，该产品采用了全新的底层架构与全面优化的技术，完全基于SSD介质的SSD云盘可为虚拟机提供随机I/O访问的高性能和高可靠块存储。

为了完全发挥SSD硬件的全部性能，阿里团队做了多个优化，其中包括：RPC优化，小报性能从20万增加到50万；内存拷贝优化，EC2优化少掉1 Core CPU；同步转异步，CPU消耗降低2个Core；锁优化，CPU消耗降低2个Core。同时，为了保障异常情况下的IO性能稳定性，大量的场景同样被考虑到，比如：网络抖动、服务器硬件故障等不可避免的异常情况；如何在假死、真死情况下同时保证可靠性和IO性能的稳定性；Chase/replication机制等。当然，为了发挥SSD云盘的全部性能，用户需要采用阿里提供的IO优化实例。

十万核并发处理的基因测序与渲染等行业的批量计算

阿里云今年还发布了支持十万核级别并发的批量计算，该计算适用于影视渲染、生物基因分析、多媒体转码、科学计算、金融保险分析等行业；以真实动画渲染为例，此前单机需要工作520天的计算量可节省至18小时。此外，阿里云批量计算服务能够在PaaS层平台服务提供批量计算框架，帮助用户专注业务逻辑本身。

使用阿里云批量计算的基本方法是：首先用户开通阿里云批量计算服务，创建、上传自定义镜像到OSS，再由OSS注册自定义镜像到阿里云批量计算。注册成功后，用户就可以上传程序数据到OSS，并创建作业描述（JSon格式）到算法中，待算法完成任务提交给阿里云批量计算，最后由OSS把作业结果反馈回用户。

据悉，阿里云批量计算是基于阿里云飞天开放平台而实现的。在这种大规模并发读取共享文件的场景上，用到了阿里特色的OSS数据动态挂载。OSS数据基于NFS协议挂载到虚拟机上，用户无须修改程序接口，且采用了分布式缓存加速，实现500个节点并发性能达到50MB/S。几个广泛的案例都应用了此技术，如昆塔渲染、视觉云平台、人类全基因组测序分析等。

兼得公共和专用优势的VPC融合网络

经长期测试后，阿里云今年也推出了可构建混合云的VPC服务，通过在公共云上构建一个安全的隔离环境，并且通过专线与已有的客户自有数据中心打通，基于阿里云遍布各地的公有云集群以及顶级的基础网络环境，VPC的推出为客户提供了统一了安全与便捷的混合云体验。

VPC还可以帮助用户构建一个隔离的网络环境，从而实现虚拟网络的完全控制，包括选择自由IP范围、划分网段、配置路由别和网管等。通过VPC构建的融合网络将具备以下几大特性：成本，专线/VPN的就近接入能力、按需开通和使用、丰富的解决方案和合作伙伴；稳定性，多线容灾和可控网络延时；安全，传输通道的安全保障。

兼容Redis的KV数据库

在7月22日的阿里云分享日上，阿里云宣布正式推出KVStore for Redis，它是第一个完全基于Open API实现控制台的阿里云产品。它也支持即开即用，不需要客户自行部署，同时产品提供了完善的可视化统计监控与报警功能。KVStore也支持弹性扩容，当用户数据量随业务发展而增多时，用户只需通过KVStore控制台进行在线扩容即可，服务本身不中断。

值得一提的是，KVStore支持分布式集群，最大规格可以达到1TB，它提供的内存是完全归用户来存储有效数据的，快照等额外的内存占用是由阿里云服务器预留公用内存来解决的，不会占用用户配额，对用户更加实惠。另外，KV数据库采取主从双节点架构，实现了主从透明切换。当主节点出现故障时，可以自动切换至从节点，整个过程对用户完全透明。

RDS for PostgreSQL服务：支持MySQL、SQL Server 和PostgreSQL三大关系数据库

年中，阿里云正式推出RDS for PostgreSQL服务，成为国内首家同时支持MySQL、SQL Server 和PostgreSQL关系型数据库的云计算服务商，并有如XML、IP、MONEY等丰富的数据类型支持，拥有对复杂查询支持的强大引擎。此外，嵌套事务、分布事物、分析函数、规划试图、递归查询等高级功能也一样不落。现在，用户在云上就能享受PostgreSQL引擎带来的对SQL标准和NoSQL的高度兼容、强大的处理复杂查询能力、以及丰富的插件支持等特性，同时还能大幅节省运维成本和硬件投入。

云盾安全网络Quick Shield

阿里今年推出的云盾安全网络是一款针对中小企业的产品，提供了安全的动态CDN服务，负载均衡SLB也将具备七层WAF和CC防护能力。云盾拥有东半球最大的高防中心，可以轻松应对大流量攻击，确保云服务稳定正常。

对于经典的DDoS防护服务，阿里云将根据客户的安全信誉实施智能黑洞策略，更好地保护客户。同时，用户在选择云盾的时候，不需要再做多次配置，更简单、更便捷。

云计算已经成为备受看好的发展重点，国内外众多企业都投入技术和资金研发云计算及相关产品，不管云计算的发展道路通顺或者坎坷都好，云计算的发展前景无疑是光明的。最终，我们也期待阿里云有更多满足企业新业务需求的云服务出现。




摘要：本文是刘奇在SDCC 2015数据库实践论坛上分享的《HBase分布式事务与SQL实现》主题内容。文中分享了Goolge Percolator内部实现、雅虎的OMID实现、TiDB的内部架构、技术选型以及如何使用HBase构建NewSQL。


本文是刘奇在SDCC 2015数据库实践论坛上分享的《HBase分布式事务与SQL实现》主题内容。

目前主流的数据库或者NoSQL要么在CAP里面选择AP，比较典型的例子是Cassandra，要么选择CP比如HBase，这两个是目前用得非常多的NoSQL的实现。我们的价值观一定认为未来是分布式的，一定是尽量倾向于全部都拥有，大部分情况下取舍都是HA，主流的比较顶级的数据库都会选择C，分布式系统一定逃不过P，所以A就只能选择HA。现在主要领域是数据库的开发，完全分布式，主要方向和谷歌的F1方向非常类似。

目前看NewSQL代表未来(Google Spanner、F1、FoundationDB)，HBase在国内有六个Committer，在目前主流的开源数据库里面几乎是最强的阵容。大家选型的时候会有一个犹豫，到底应该选择HBase还是选Cassandra。根据应用场景，如果需要一致性，HBase一定是你最好的选择，我推荐HBase。它始终保持强一致，我们非常喜欢一致性，丧失一致性的时候有些错误会特别诡异，很难查。对于Push-down特性的设计其实比较好，全局上是一个巨大的分布式数据库，但是逻辑上是分成了一个个Region，Region在哪台机器上是明确的。

比如要统计记录的条数，假设数据分布在整个系统里面，对数十亿记录做一个求和操作，就是说不同的机器上都要做一个sum，把条件告诉他要完成哪些任务，他给你任务你再汇总，这是典型的分布式的 MPP，做加速的时候是非常有效的。

2015年HBaseConf 上面有一句总结: “Nothing is hotter than SQL-on-Hadoop, and now SQL-on- HBase is fast approaching equal hotness status”， 实际上SQL-on-HBase 也是非常火。因为 Schema Less 没有约束其实是很吓人的一件事情，当然没有约束也比较爽，就是后期维护十分痛苦，规模进一步扩大了之后又需要迁移到 SQL。

现在无论从品质还是速度上要求已经越来越高，拥有SQL的同时还希望有ACID的东西(OLAP一般不追求一致性)。所以TiDB在设计时就强调这样的特点：始终保持分布式事务的支持，兼容MySQL协议。无数公司在SQL遇到Scale问题的时候很痛苦地做出了选择，比如迁移到HBase，Cassandra MongoDB已经看过太多的公司做这种无比痛苦的事情，现在不用痛苦了，直接迁过来，直接把数据导进来就OK了。TiDB最重要的是关注OLTP，对于互联网业务来说通常是在毫秒级内就需要返回一个结果。

我们到目前为止开发了六个月，开源了两个月。昨天晚上TiDB达到了第一个Alpha的阶段，现在可以拥有一个强大的数据库：支持分布式事务，始终保持同步的复制，强大的按需Scale能力，无阻塞的Schema变更。发布第一个Alpha版本的时候以前的质疑都会淡定下来，因为你可以阅读每一行代码，体验每个功能。选择这个领域也是非常艰难的决定，实在太Hardcore了，当初Google Spanner也做了5年。不过我们是真爱，我们就是技术狂，就是要解决问题，就是要挑大家最头痛的问题去解决。好在目前阿里的OceanBase给我们服了颗定心丸，大家也不会质疑分布式关系型数据库是否可行。

TiDB名字由来 


为什么叫TiDB？大家起名字的时候特别喜欢用希腊神话里面的人物，但几乎所有的希腊神话人物的名字都被别的项目使用了，后来我们就找了化学元素周期表（理工科男与生俱来的特征），化学元素周期表里找到一个不俗且又能代表我们数据库特性的元素-Ti 。Ti是航空航天及航海里面很重要的设备都会用到的，特别稳定，也比较贵。

 


TiDB的系统架构图


TiDB怎么支持MySQL这个协议？这里会有一个协议解析层，它的作用就是去分析MySQL协议，转成内部可以识别的分发给自己的SQL Layer。当SQL Layer 拿到这个语句之后会把它拆成对应的分布式KV操作，所以这里会有一个Transactional KV Storage。接下来是在KV基础上增加事务的支持，再往上是普通的KV操作，理论上KV选什么都可以，如果选的是HBase有一个好处，它本身就是分布式，省掉分布式的工作。目前我们在小米的Themis基础上做了些优化和改进，和我们TiDB做了一个很好的结合。后期我们有一个计划，准备自己重写一套底层的分布式KV，把HBase换掉。因为HBase对于Container不友好，加上GC也是让人比较讨厌的问题，压力比较大的时候GC延迟会加长。

Google Percolator实现方式 


 HBase上面分布式事务典型的设计，先来说一下Goolge Percolator 内部实现，看架构图：

 


Goolge Percolator内部实现 


分布式事务基本设计是在上面这个 Percolator层，Timestamp Oracle 可以保证严格的递增。Percolator是在KV上的实现，它对于SQL的角度考虑比较少，有一个隔离级别的问题，很典型的是Snapshot Isolation, SQL 语句落在KV上的实现，如果只有Snapshot Isolation的话隔离级别就太低了。此外，这个模型还有其它的问题。比如，它每秒能分配多少个递增的Timestamp？Google分享的一个slides的数据，每秒200万，小米也开源了自己的实现，每秒60万，我们前一阵也写了一个每秒400万，优化一下可以达到800万。因为Timestamp业务特别简单，所以可以做针对性的优化，当然很少有业务能跑到这个级别的事务。

Yahoo OMID的实现


雅虎的OMID实现，架构图如下：




雅虎的OMID实现 


除了Timestamp的职能，TSO还维护更多信息用于检测事务冲突。TSO是整个Omid系统的单点，如果一个系统只需要一个单点，单点做得越少就能获得越多的性能，也更容易优化。

下图是它的分布式事务的执行过程：




假设现在要发起一个分布式事务，第一个事情是拿Start TS，再去做你的读写操作，做读写操作的时候会把Key都记下来。Commit的时候要先冲突检测，这就是TSO 要做的更多的事情，更具体的细节请参考Omid 的论文或者 &lt;&lt;从零开始写分布式数据库&gt;&gt;一书。

谷歌的Spanner，细节非常多，引用的论文有40多篇，很吓人，有些引用的论文也非常经典，很值得一读。Spanner已经不再使用NTP了，需要用一个有信心的靠谱的方式来同步时间。内部也说不再用NTP做时间的维护，GPS是非常简单便宜的方式，GPS是大家使用滴滴打车时用于得到定位信息的。GPS还给了当前精确的时钟信息，有软件可以把这个检测出来，可以直接使用它的这个信号来同步时间。使用GPS信号的好处很明显，随便在哪个山区都有GPS信号，但不一定能收到基站的信号，同时它的精度也非常高。

TiDB的技术选型


再来说说TiDB的一些技术选型的例子。选择MySQL协议后会做一些取舍，有些地方不完全按Google F1去做设计的。Google F1里做的比较好的是非常经典的Non-blocking schema changes。比如现在要加一个索引，如果横跨数十台机器，数十亿条记录，加索引的速度是非常慢的，那么这个过程必须是不阻塞的，不影响正在运行的业务的。因为在建立索引的同时需要修改别的地方，所以要做一个原子的提交，细节上还要处理事务冲突的错误。F1有并发的图，我们刚才提到HBase里通过Push-down可以把一些计算下推到对应的节点上去。但由于F1依赖Spanner，而Spanner会频繁地做Reblancing，会把数据不断的移动，所以它在上面很难基于range信息一次做最优的决策。

SQL如何映射分布式KV？ 


SQL到底是怎么映射到分布式KV上？现在HBase分层分得更加清楚，SQL层不太关心下面到底用什么，在乎的是接口。映射的过程，假设User Table里面有个Email，我们存储的时候是用ID做它的标识，这有很多的好处，比如删掉再重新添加一样的，它要生成不同的ID。在数十亿条记录的情况下删除一个Table，删除的过程完全可以由Map-Reduce异步去做。

为什么提供MySQL协议的支持？如果重新写一个数据库会遇到一个很大的问题，大家凭什么相信你是对的，数据库需要时间需要测试，好在你接入MySQL协议，你可以经过和MySQL一样严谨的测试。但如果是自己完全写一个，不借用它的协议，不借用它的语法，没有测试，大家凭什么相信你是对的。现在这个时代没有Communit是很可怕的，闭门造车很容易走偏。TiDB现在可以让用户一行代码都不改，跑WordPress等，还支持很多的ORM，这些ORM可以直接用，用户的代码一行不改可以直接迁过来，完全拥有水平扩展的能力，完全拥有分布式事务的支持。前TiDB在Github上2800+star。



摘要：2015中国大数据技术大会12月10日在北京新云南皇冠假日酒店盛大开幕，IBM副总裁、大中华区硬件系统部总经理郭仁声发表了主题为《未来的认知 工作负载需要全新的IT基础架构》的演讲。


【CSDN现场报道】2015年12月10-12日，由中国计算机学会（CCF）主办，CCF大数据专家委员会承办，中国科学院计算技术研究所、北京中科天玑科技有限公司与CSDN共同协办，以“数据安全、深度分析、行业应用”为主题的 2015中国大数据技术大会 （Big Data Technology Conference 2015，BDTC 2015）在北京新云南皇冠假日酒店盛大开幕。


IBM副总裁、大中华区硬件系统部总经理郭仁声演讲的主题聚焦在未来的认知工作负载需要全新的IT基础架构，他首先介绍了认知时代的大数据平台和大数据基础设施，而Watson就是认知时代的典型代表，他认为认知时代需要创新的整合，对开源技术持续贡献，使IBM在Spark领域持续领先。随后，他介绍了认知时代的IBM分析解决方案并且演示了IBM的认知计算示例：创新Linux on power结合FPGA的CIFAR-10图像归类测试。




IBM副总裁、大中华区硬件系统部总经理 郭仁声


以下为演讲实录：

郭仁声：各位尊敬的来宾，大家早上好！很高兴代表IBM公司跟大家做大数据方面的交流。介绍前请大家看一段小的录像，有个小恐龙给大家做个介绍。（视频播放）

这个恐龙跟市面上玩具不太一样，这个小恐龙叫迪诺，帮助小朋友学习不同的知识，交流过程中是通过无线网络连接到后台，主动学习小朋友感兴趣的知识。同时也适应小朋友的习惯，语言的习惯、生活的习惯，感兴趣的方面等等，不断完善知识的架构，跟小朋友一起成长。把老师、家长感兴趣的模块加载进去，更好的完成小朋友在成长过程中一个很好的学习和陪伴的伙伴。这个产品是通过IBM的一个合作伙伴生产出来的，网上12月份可以预定了，我准备订购一个给我的小朋友，跟他一起成长。

这个演示代表我们进入了不同的时代，就是现在我们面对的计算外界环境，进入了认知计算的时代，有这么几个重要的特性：

第一个特征，大量的数据正在推动各个行业和各个专业的变革。为什么这样说？举个跟国计民生相关的行业，像医疗、政府、教育，像媒体的数据，在过去几年包括在未来几年都是飞速成长。业界估计到2017年，这几个行业的数据基本都是翻番的成长，其中超过80%的新成长数据都是非结构化的数据，包括语音，包括影像等等，这样的形式来出现。

第二个特征，无论是产品也好，服务也好，背后有各种大量计算机代码在重新塑造这个世界，举个例子，像新出来的汽车，无论是全电动的特斯拉也好，还是传统引擎的汽车，当你加载很多先进功能的时候，典型的一台新出厂的汽车上面有超过10亿行的代码，帮助驾驶者去管理汽车过程中，比如导航、音响、空调、灯光等等不同汽车上面的功能。所有这些代码都是在帮助大家把不同的设备更好的利用和管理起来。大家手机上普通的智能手机超过100万代码运行在上面，大量的数据、计算机代码推动计算时代演变非常快，计算技术已经从过去单纯的计算，或者今天大部分在使用编程的计算时代，进入到一个认知计算的时代。

这样一个认知计算的时代，我们能够通过各种不同的手段，物联网、手持设备、终端设备，通过互动去理解世界的规律，它能够使用不同的数据模型，或者自己演变的模式和假设去进行论证和推理，而且能够通过互联网或者专业的系统，海量的专家和研究数据进行自己的学习和完善。

刚才演示的小恐龙后台驱动的Watson系统就是认知时代计算系统的代表。Watson这个系统最早被大家知道应该是在2001年的时候，当时参加电视问答游戏，从2001年获得问答冠军，击败人类以后，在过去几年里面Watson系统又进行飞速的进步和演变。比如这几个开放平台，本身是强大的认知能力平台，而且计算的平台是基于云和开放标准，它上面几个主要的功能模块，比如问答游戏中用到的自然语言的识别技术，比如它的深度问答技术，包括它自己不断完善机器学习的技术，以及它平台构建的高性能运算基础架构等等，今天已经成为一个很重要的开放或服务模式，提供给不同的合作伙伴。

到今天为止，我们在全球有超过350个合作伙伴和公司，已经加入到Watson这样一个开放的计算平台上来，其中超过100多个产品，像刚才说的小恐龙已经面市，背后通过开放式的认知计算平台，为不同行业用户或个人用户提供这样一个服务。这些认知计算的平台就是围绕着五个很重要的技术领域进行研究的，一个是大数据分析，就是今天我们这个大会重要的主题，第二个方向是人工智能，第三个方向是认知的体验，包括语言的理解、读、看图、图像识别等等，第四个方向是认知的知识，怎么样获取专业的知识跟技能，最后一个研究领域是计算的基础架构平台，怎么样能够用最节能、最高效的计算平台去获得计算的能力。

这个Watson系统强调的是专业平台的能力，除了跟现在市场上不同领域公司都在研究人工智能系统、语言识别等等，和面向的通用的或者大众化的人机交互相比，Watson更注重专业技能的平台，而且我们认为它是进入未来认知商业模式很重要的一环。为什么这样说？我后面会详细的稍微做讲解。但是进入这个详细讲解之前，有一点我们想稍微解释一下，就是在这个认知计算的时代，从不同的层面都对计算模式等等提出新的要求，所以我们认为不能够简单套用今天大家成熟使用的计算模式，或者采用的工具和产品把它简单搬过来应用在未来大数据认知计算的平台上面，我们必须要有从端到端，从最底层的基础科学到最上层的商业应用，全面的创新和整合，这样才能够看到完善的全面支持认知时代的计算能力所要求的平台。

在这些方面IBM作为一个注重科研投入的公司，我们在不同层次做了相当多不同的尝试，像这个图上各位可以看到非常多的公司。从最底层的基础科学的研究，芯片的技术今天发展到22纳米普遍使用，14纳米正在出来，摩尔定律的突破一直是个问题，我们今年刚刚宣布7纳米芯片的原型已经制造出来，可以完全从技术的角度迎接下一代商用，能够继续沿袭摩尔定律往前推进，把计算的能力和芯片做进一步提升。

除了传统架构的芯片以外，我们认为当进入到一个认知计算的时代，需要更多模拟人脑计算要求的时候，你需要有一些不一样的基础技术去实现，这里面就出现了比如我们一直在研究的神经元芯片，和量子计算研究方面的突出成就，像量子计算研究在国内有非常多科研机构开始投入进来，但IBM在这方面做得比较早，也走得比较快，我们有一些最新成果，大家可以在网上看得到。包括神经元芯片，当对人脑进行模拟的时候，用传统架构不是不可以，但是能耗、占地和处理速度都满足不了我们希望要求的计算规模。神经元的芯片今天可以做到非常低的功耗，70毫瓦功耗芯片，但是组织起来，今天所能能够处理的模拟能力能相当于一只小白鼠智力的水平。

往上一层是需要有不同的计算平台，比如IBM把P服务器放在Linux，利用P多线程的技术、高带宽，让大数据走得更快，包括闪存技术消除读取瓶颈，IOPS更快等等。再往上，家务应用，传统的GPU应用，包括POWER对内存直接的存储存取，配合市场上FPGA加速卡，跟等等这样一些厂商合作，进行加速技术的研究。再往上，我们前面对大数据开源平台，特别是Spark的支持，是很重要的一环。更重要的是在这上面怎么样用大数据平台，搭建出来一个可以商用的模式，像刚才联通的范总做了介绍，旅游指数、天气指数等等这样的应用，是很重要的一环，怎么样让大数据平台和传统的企业或行业结合起来，真正变成认知商业的模式。

IBM在这方面做了一些不同的尝试和投入，除了Watson以外，我们举了另外两个公司，在刚刚过去10月份投资20亿美元收购Weather这家天气公司，雅虎等天气服务都是通过这个公司提供天气的数据。我们希望通过对直接天气大量数据的获得，在这个基础上依托大数据的分析、认知计算的能力，把它变成商业的服务提供出去。举个例子，我们可以和保险公司合作，当我们看到极端天气有可能出现的时候，道路安全方面有可能出现更多交通意外，这时候保险公司可以做相应的预防措施。或者我们跟电网公司合作，现在很多电网公司都在做智能电网项目，利用各种清洁能源，像风电、太阳能、潮汐发电，并到一个大的电网里面，进行智能的调度。这种天气信息的预测，能够帮助这些电力发电公司更好的去预估不同来源发电的情况，智能的去预先估计或者调解并网电力调度的情况，最大化它的产出。这些就是我们为什么觉得把这些传统的东西结合起来的一个原因，这样才能形成商业模式。

还有一个例子是这家医学影像投资MERGE，我们把这家公司并购进来，加入到我们医学部门。这个东西跟Watson系统结合起来，有些什么样的能力？大家可能之前也有听过Watson，我们通过它跟美国几个最先进的研究癌症方面的医学机构合作，对癌症案例进行分析、进行学习，为医生提供不同专业的指导。MERGE是在影像方面做的另一个尝试，利用Watson的技术，包括Watson里面本身拥有大量医疗影像的数据，我们通过专业的培训，希望让Watson系统具有医学影像读取的专业能力，我们正在培训这个系统，希望通过美国医生影像方面资质考试具备这个技能，成为很有利的工具去辅助医院一生对患者医疗影像数据进行分析。有时候由于人的专注度、情绪等方面，让患者影像方面不一定看得那么仔细，可能忽略了中间的一些重要特征，但是我们希望通过人工智能、认知计算系统，更好的帮助医生对患者影像进行读取，最大限度帮助医生更加准确判断病人的病情。这是在一个完整的认知时代端到端，怎么样把最底层的技术到最上层的应用进行充分的综合、整合、创新，提出不一样的商业模式和新的计算能力。

我们在各个层次创新能力都具备，那么怎么应用出来？这就提到热门的API经济话题，像我们Watson平台完全是基于云上的开放平台，我们今天是把Watson甚至作为一个surface，构建在我们这个Bluemix平台上，开放给更多合作伙伴去使用。Watson今天有大概16个不同的API接口，可以在网上跟大量的开发者结合，让开发者可以利用Watson的API，把他的计算能力变成surface去使用，把能力结合到行业应用。这是未来很重要的认知计算能力应用的方式，构建在开放平台上，被更多开发者和合作伙伴所使用。

为了去达成这个目标，我们投入了非常多，去支持认知时代的生态系统，就像刚才讲的，我们要把它开放出来，重要的一点是各个层面的东西，从操作系统，从中间开发的工具、数据库等，尽可能的开放，尽可能符合开源的标准。特别是我们有针对性的把IBM基于大数据运算或者未来计算时代的平台，从硬件刚才说到的服务器到闪存、到中间件等等，都做了各种针对开源平台的优化。这样希望在生态系统方面是全线的，IBM硬件平台、中间件、软件平台是完全可以配合开发者的需求。

这里面重要一环是对Spark技术的持续贡献，IBM是最早一批加入开源技术的公司，我们在1999年的时候投入了五位开发人员，进入这个开源的领域。但发展到今天，我们在全球已经有超过5万位开发人员，投入在各种不同开源的组织里面。参加了全球超过150个开源的项目，为这个平台去做贡献。针对Spark方面是未来战略性的投入方向，所以我们也在加州宣布成立Spark这样一个技术中心，不单只是投入开发人员，重要的是把我们机器学习等方面技术贡献出来，开源给这个社区。还有一点是跟中国研发相关的，6月份候刘延东访问美国时，跟我们全球董事长罗睿兰女士共同见证了一个合作项目的签署，IBM作为一个重要的科技公司，会支持国家留学基金会推动的“双百计划”，未来几年帮助中国培养超过100位在这大数据和云计算方面的科学家，增强中国在这方面的整体能力。这方面能够看到对开源项目的支持，包括对中国在大数据能力培养方面，我们在不遗余力做一系列的贡献。

除了这个开源的技术以外，我们本身自己的产品，像针对业务分析方面全系列的产品，从商业智能的工具，到分析开发，到整体的行业解决方案，我们有很多工具，SPSS等等一系列工具基于Spark进行整体优化，大幅度提升产品的计算速度和大数据环境下折分析能力。

刚才说了那么多，说要全面的优化，端到端的整合，到底能体现出来什么不同的优势？我们再看一段不同的演示。从这个演示可以看到，当我们点一个键之后出现很多不同的图片，这是什么意思？它的速度非常快，这是IBM在高性能运算2015上展示的一个支持大数据分析和认知计算的DEMO，一个能力。这里面后台是5万张图片，完全没有索引标识的图片，我们通过认知计算平台，用开源的这个框架，中间计算平台的硬件我们采用Linux on Power服务器，利用它高并发性、高带宽的处理能力，重要的是我们结合针对这种图形识别的技术所设计的FPGA加速卡，这样的话当我们按比如“飞机”按键，从5万张图片里面它自动识别是飞机的图片，按“鸟”，它自动把所有它认为是鸟的图片识别出来，算法本身没有什么特别，都是这些开源的算法，但是实现的方式跟以前有所不同。

当我们利用了这种FPGA针对算法加速的功能以后，获得了几乎是实时的图片识别和分类能力。很重要的一点是，相比今天比如在现成的X86平台跟GPU芯片模式都可以实现，但是用FPGA这种方式能耗只是原来的三分之一，但是处理的速度可能提升了3倍，一来一往大概是9倍能耗比的提升。这种新技术的结合和创新的采用，在未来很多有大量计算需要用到这类图形识别的时候，就会体现出非常大的价值。

我最近在媒体上有看到一些介绍，阿里巴巴马云先生介绍，说在阿里巴巴数据中心方面采用非常多的绿色节能技术，以前用煮四个鸡蛋的能量完成一个交易，今天用煮一个鸡蛋就可以了，未来我们也看看能不能和阿里巴巴有合作，用煮一个鸡蛋的能量未来完成50个、100个交易，在环保节能方面有更多的成功体现。

这是一个小的案例，去看我们怎么样落地刚才所说的概念。刚才也讲了，这些大数据的平台技术、认知计算技术，都要跟行业本身传统数据、应用结合在一起，才能获得新的价值。很多传统企业今天已经大量采用的是这种记录的系统，比如说银行的帐户系统、通信公司的计费系统，等等这些都是记录系统。但是怎么样在不同的平台上去搭建一个洞察系统，大数据分析的这样一个系统，而且跟现在用不同的终端技术所形成的交互系统，包括手机这种不同的物联网设备等等，去形成个整体的开放平台，从而去推动整个企业转型成为一个认知商业的模式。就像刚才我们说到的，跟医疗影像的结合、跟天气数据的结合，这是很长的旅程，不是一夜之间就能达到的。

我们为了实现这种业务或商业模式，要满足这样一种认知工作的负载，在基础架构方面需要一个完全不一样的构建方向，其中有三个重要的指标，一个是生态系统的整合，刚才我们也谈到面向开源等等更多更开放的整合，第二个是我们对事务分析处理方面能力怎么样尽可能优化更快、更节能，用更多技术去实现，第三个是进入到认知计算时，对基础架构的要求是7*24，而且是不间断的，不但具有容灾，而且有丰富的动态调配系统，去应付突然发生的波峰波谷的计算能力要求，这都是基础设施出现的不同要求。我们希望形成端到端的解决方案，从IBM角度持续投入到这几个方面:

第一，更快的平台，刚才说到无论是Linux on Power利用它高线程技术、高带宽技术、并发能力，还是闪存的技术解决客户IO方面的瓶颈。

第二，对开源方面的拥抱，刚才介绍了Spark方面的投入和承诺。加速技术的使用，不单只是加速，而是需要更低的能耗，这里面牵涉到不同的技术，像CAPI、FPGA等技术。最重要的是未来我们希望用更开放的心态，跟不同的合作伙伴一起搭建开放API的接口平台，无论是Watson作为一个服务提供出去，还是今天在Bluemix云平台上为开发者提供的能力，这都是我们希望搭建端到端解决方案所做的努力和尝试。

中国企业已经做了非常多不同的尝试，这是一个通信公司，通过Linux on Power把X86移植过来，性能提升2倍多。这个是公安系统，通过方案把它存储平台不同的数据整合在一起，跨平台的做一个整合，更灵活的在一个平台上去实时的，对处理、大数据作业、管理和调度等动态利用这些系统资源。保险公司使用车载的远程信息的处理，出现问题之后怎么样自动分析汽车行驶状况，决定理赔能力，通过更快的速度，原来不到一半的确时间响应Spark，这都是国内很成功的案例。

最后，用我们做的这个项目结束今天的介绍，我出门时候阳光出来了，报道也说北京的限行今天结束了。雾霾这个事情大家很关注，IBM在2014年7月份在北京宣布成立“绿色地平线”的项目，为期十年，跟国家环保部门和地方政府一起合作，用认知计算、大数据技术，帮助环保单位和企业，更好的管理、预测大气质量水平。经过一段时间的努力，在北京从最早只能提前3天去预测雾霾污染状况，到今天可以做到大概提前10天做出预测估计，而且管理的精度也已经缩小到一平方公里的范围。更好的作为决策支持平台，帮助环保部门、政府部门更迅速更好制定措施，去管理大气的质量。把所有的工厂关了、所有的车停了可以获得很快的环境，但是这都有代价的，那怎么样通过大数据的分析，用最优的模式达到一个标准，这就是我们希望做到的平台。最新我们也宣布会跟更多地方政府合作，包括跟保定、张家口一起合作，针对2020年冬奥会方面天气情况的预测和保障，做出我们的贡献。

在这里，我们也希望把这个项目介绍出来，这个项目是我们跟CSDN合作的项目，欢迎各位开发者加入到我们Linux开源社区活动，通过简单的登记方案就可以加入进来，希望广大开发者一起跟开源社区贡献自己的力量，我们往大数据认知时代转变方向上走得更快更稳，谢谢大家！



摘要：BDTC 2015全体会议上午最后一场由华为IT产品线大数据解决方案规划总监徐兴海和华为电信软件大数据首席技术规划区波共同完成，期间他们表示，华为正在以平台牵引应用和服务合作的方式致力于大数据生态体系构建。


【CSDN现场报道】2015年12月10-12日，由中国计算机学会（CCF）主办，CCF大数据专家委员会承办，中国科学院计算技术研究所、北京中科天玑科技有限公司与CSDN共同协办，以“数据安全、深度分析、行业应用”为主题的 2015中国大数据技术大会 （Big Data Technology Conference 2015，BDTC 2015）在北京新云南皇冠假日酒店盛大开幕。

2015中国大数据技术大会首日全体会议中，华为IT产品线大数据解决方案规划总监徐兴海和华为电信软件大数据首席技术规划区波共同带来了名为“面向业务创新的大数据平台及商业实践”的主题演讲。




华为IT产品线大数据解决方案规划总监 徐兴海 


期间，徐兴海在演讲中首先表示，大数据已从炒作走向企业应用，从试点走向生产，其主要表现在：初步完成历史数据大集中；半/非结构化开始采用；进入数仓、征信、风控等关键业务；新的独立组织，新的服务模式；开始重视数据分析师的培养。随后，他表示，未来大数据将全面与云融合，其主要需求在于：平台统一化，线上线下同构；引擎多样化，真正打通；地域分布化，逻辑与物理；能力服务化，与云结合。 




华为电信软件大数据首席技术规划 区波

针对华为大数据平台的未来发展，华为电信软件大数据首席技术规划区波表示，首先，华为希望将新技术和传统技术进行有效整合，并且这种整合能力可以在客户间快速地复制；其次，希望这种整合能力能够相对固化，使这些能力在不同的客户快速的复制；第三，华为希望这个平台上能够有一个相对完备的数据资产治理的平台，使得用户真正了解数据、用好数据。

以下为演讲实录

徐兴海：

今天很高兴跟大家分享一下面向业务创新的大数据平台及华为的商业实践，其实大数据从09年开始逐渐变热，这两年大数据的风头明显盖过了云计算。大家觉得是好事吗？不是好事！因为云计算已经走过了炒作的高峰，已经在公有云的带动下规模落地了，人家已经开始赚钱了，现在不是炒作了，大数据去年的报告说还是波峰的下滑当中，泡沫的破灭当中，今年大数据已经开始有走入了企业的应用的苗头，而不仅仅是炒作。
大数据从试点走入应用

这张片子可以看出来大数据从试点走向真正广泛的部署有哪些条件或者哪些标志性的条件，其中第一个标志性的事件是平台厂家的出现和平台厂家的集中度，为什么？你做一个新产业，如果这个新产业需要平台，提供这个平台的厂家全球有一百家这个产定一定做不好，大数据的平台在未来一定存活两到三家，在全球之内，当年虚拟化和云计算兴起的时候有多少个厂家宣称自己是云计算提供商，自己是虚拟化提供商，今天回头看还有多少家，今天已经发展起来了。厂家要集中，这是第一个标志。

第二个更多还是从企业客户的角度来看，企业客户哪些标志着大数据走向真正的广泛部署，第一个标志是数据的大集中，原来的数据都是分散在各个部门，今天这个片子里面每一个关键词，每一个观点背后都有华为的案例，尽量以案例的角度分享，我们可以从银行的角度，我跟一个客户做项目的时候，银行的数据历史上也是非常分散的，最开始大机器系统里面还有大量的查询工作要做，大机是非常贵的，做一次查询要几块钱，现在已经广泛用大数据的卸载，把借记卡、信用卡、理财、信贷、风控这些基础的数据都集中出来，这是第一个标志，第二个半结构化和非结构化场景的使用，银行有很多的客服，经常给银行打电话，一般的客服小姐记录下来的是33字左右，我们每次打电话说了很多话，大量的信息在语音里面，这个语音如何转变成有效的文本，被数据所利用，这是第二个重要的标志。

第三个过了前两个阶段以后，第三个大数据还要进入企业的关键应用，始终在外围做应用还没有标志着它已经从试点走向真正的生产。关键应用有三类，一个是数据仓库，从05年开始在国内大企业广泛的部署形成了ODS、EDW几种形态，在大客户里面分的很清晰。今天移动数据上来的时候很多企业受不了，交易是几何增长，如果还用传统的方式，首先收仓方式非常高，必须用新技术降低对海量数据的处理。 第二个是收仓的扩展性，一个标志是有些大企业对技术掌控比较强的企业已经开始利用大数据改造收仓，卸载收仓，还有用大数据做事实的风控，信用卡被盗刷，原来是事后发现的，如何从事后走向事中甚至事前，需要对每个人做360度的洞察和全网数据的时时监控，这个挑战非常大，有一个长传口技术，很少能找到15天的长传口的监测，需要多大的内存，肯定有新技术在里面。还有成立新的独立的组织移大数据一定是跨部门的，数据联动起来才有价值，现在有一些大客户，包括银行，在上海成立了全行的大数据分析中心，汇集全行的数据分析需求，为什么不把数据分析这个部门成立在每个业务部门里面，因为数据是要打通的，新组织的成立，新的服务模式的出现，也是一个大数据走向企业应用的标志，另外一个是数据分析师在培养，数据分析师在拥有数据的大企业非常重要，这一点很多嘉宾也都讲过了。
企业对大数据的需求

走向了广泛部署以后，现在的企业需要的是什么样的大数据，企业需要是大数据平台，有三类企业。

第一类是大客户，是跨国的公司。他给我的关键词是第一我需要大数据平台要可持续，一定要平台的可持续，要能保证三到五年甚至十年的持续供应，不能跟我合作一两年以后你这个公司不存在。可持续对大客户非常重要，因为心里技术变化非常快，社区开源新技术变化非常快，客户的消化能力也非常限，客户的主业不在技术，可持续是非常重要。另外一个是云化，一个是内部的云化，为什么，因为大客户内部有很多部门，上百部门都需要数据分析来做支撑，如果你的数据平台是烟囱式的不能做云化，内部做服务化的支撑，内部云化的混合化的提供，对他负担非常重。

第二个是国内零售的银行。跟他们CTO讲的时候，他讲原来的数据确实是烟囱式的，每个子系统都有整个的系统，在12年开始采用华为公司的产品，在各条业务线已经开展了很多的大数据集群，从去年华为就把20多个大数据汇集到统一的平面，形成了第二经营平面，大数据已经作为经营平面支撑企业日常分析活动。

第三是中小企业。技术变化这么快，新技术处在混战的实地，这些中小企业的主业，这个能源公司主要是搞能源，不是搞技术，每天风机在转，风机转跟天气的关系是什么关系，如何做到提前预测，这种公司难道搭建一个大数据平台吗？不可能，IT人员可能一两个人，这种客户迫切需要的是大数据云服务，大数据云服务对中小企业来说也是非常重要的。
面向业务创新的大数据平台

未来第一阶段从传统的收仓交易为中心，第二是数据为中心，第三阶段是以人为中心的全渠道数据的整合，这个时候非常重要的一个标志就是数据处理和云服务的结合，跨地域。这个架构多样化的引擎，现在社区有很多的技术，你的平台框架能否引入新的引擎来处理不同的场景，因为现在不是一个引擎包大天下的时代，未来引擎的多样化和大数据云服务非常重要，这是华为FusionInsight大数据平台，简单来说最底层有两个产品，一个是ITD，做一个统一入口，让客户不用关心数据在哪里，可以做一个全量全局的查询，上面这一层非常重要，因为Hadoop1.0（阶段）是给开发者用，2.0（阶段）是期望给分析师用，明年开始大数据的数据分析一定走入业务人员，他是没有办法看到底层这么复杂的技术，他需要是做交互式探索的，大数据不是做定量的分析，是做关联分析，就是在不断的探索过程当中发现数据的价值，不断的修整和反馈，我们提供这个产品能做全量数据的探索，就是没有模式，没有西格玛，可以自动识别出有哪些模式供你选择，你不需要很多搜索条件，给你提供很多自动的（英语）的识别，这是非常重要的。

另外提供一个Farmer的产品，这个产品非常重要，因为客户关键应用，比如征信、审计类的实时应用，跟Hadoop有距离，不能直接用，需要在Hadoop托管之上使用的平台，包括能处理事件和流的决策平台，这个平台架构在Hadoop之上，客户只需要关心自己的应用逻辑，在上面写逻辑就可以了，华为的Farmer已经完成了数据位置到服务的管理，同时也做实时决策的分析，比如你要关心我需要什么样的客户，我推荐什么样的商品，这个逻辑就会运算到下面的大数据平台，这是华为这一层的产品。

从开源的重要性再谈一下，华为持续回馈开源社区，从09年开始在Hadoop、Spark社区辛勤的耕耘，华为在两个社区都是排名第四，Spark排名在上升，很重要的几个标志事件，是今年6月份我们获得了国内首张Spark的 商用发行版认证，而Spark的图算法，华为在社区里有核心的贡献，今年11月份，PrefixSpan算法发布。

最后看一下案例，华为的大数据平台分两个交互模式，一个是线上，一个是线下，线下主要跟企业客户提供大数据平台，跟合作伙伴来开发应用，一起为支撑客户的应用创新。

第一个是招商银行信用卡的案例，从周到分钟，之前客户发信用卡以周为单位，申请以后需要做很多要素的审核，你的消费习惯，你有没有上黑名单，你的风险承受能力，你的信贷情况，其中有很多环节是要人工参与的，采用华为大数据平台，以后发卡周期变成以分钟为单位，当场就可以发卡，华为的平台给他提供了一条非常容易的多条规则并行的计算，给客户提供非常真实的征信情况，当时可以发临时卡，这是一个变化。

还有一个在精准营销，传统收仓做专家系统精准营销的时候我们每个人感受到是群发担心的方式，无法为每个客户做精准营销，比如银行客户量非常大，一个分行900万客户以上，如果为每个客户做个性化的画像，运算速度和成本非常高，采用大数据的技术做到了个性化的推荐，可以知道这个用户喜好是什么，他的行为习惯，当你走进商场的时候不见得一定给你发短信，如果这个厂商的商品没有你喜欢的就不会给你发短信，这就是个性化推荐，采用这种方式担心发送量下降了82%，实际上效果命中率提高了95%，这是非常可观的。从1到5到15，我们原来在银行历史明细数据查一年，后来逐渐扩展到5年，为什么？现在到了7年，我们的一些影像数据实现时时在线查询的重要性，如果你申请贷款，你过去十几年的交易情况，包括你的影像，因为每做一个交易会产生6张图片，影像上时时查询，这个对贷款的审批加速非常重要，数据大集中历史数据集中其中一个体现就是历史数据的周期增长，周期的加长。

另外就是交通行业，我们原来发现套牌车的时候，我们的车套牌在另外一个城市出现，需要很长的时间，现在通过对卡口数据的分析，可以秒级发现套牌车，包括对交通出行公交车排班，包括人流的分析，这都是对我们人为的促进。

还有就是7倍和96%。7倍指的是在客户维挽方面，对于电信运营商来说客户的维挽非常重要，我们国家的电信行业的竞争还是非常充分的，我们每个人从一个运营商切换到另外一个运营商非常容易，电信运营商压力很大，挽留住离网的客户是非常重要的，第一步就是哪些客户有离网的倾向，这有很多的倾向，包括他最近充值减少了，他最近通话时长等等很多的数据进行融合以后，我们给这个客户建立一个平台，做到了一次采集一次存储，多次分析，通过离网的模型发现离网客户的识别率提升了原来的7倍以上，这是非常可观的。通过去关怀，包括使用一些送积分，甚至送流量等等，然后客户的再次充值率也是提升了3倍以上，这是大数据在商业实践方面给客户带来的改变。

我在这里也给大家介绍一下华为企业的云服务，这里面已经有了刚才说的大数据各种服务的上线，大家可以体验，华为大数据在云上还有一个特点，跟电信运营商合作，帮他们建设云化的大数据中心，在上面合营共同提供大数据的服务。

我今天就讲到这里，华为在电信运营商里耕耘了20多年，在电信行业有自己大数据的理解下面请我的同事区波分享一下电信行业大数据的经验，有请区波。

区波：

谢谢大家，因为大数据作为一个新的技术有比较新的突破，这些技术的引用对运营商对数据的处理更好的提供服务，也提供了新的技术，运营商承载着整个电信的运营和互联网的基础网络，之前阿里的王博士举了很形象的例子，如果把互联网比作一个高速公路的通道，数据是在整个公路上走过的一些痕迹，运营商是主要的承载着这个高速公路的建设和提供服务的主要承担者，所以我们生活当中的很多数据，绝大部分数据在云这个管道里面都有，以前很多数据并没有做深入的分析，一方面是因为我们的技术，一方面是对这些数据的需求来自于哪儿。大数据的引入让我们能够有机会重新去看这些数据，以及这些数据可能带来的新价值。从这个图上可以看到运营商原来自己手里面有数据，包括业务处理系统，像POSS系统，这里面已经对原来的数据有一些处理。另外一些是网络数据，这些数据过去运营商比较少做处理，而今天看随着我们要对数据进一步的了解，包括除了支撑运营商内部的业务，同时也会支撑一些企业的应用以及消费者的市场，这些数据会越来越多的被关注。
电信运营商大数据平台建设面临的挑战

 另外一个角度来看对于运营商相对于互联网的企业比较传统的企业来说，原来已经建立了自己相对比较完整的一套IT的环境，也建立了他自己相对比较大的数据环境，比如像移动运营商他们过去数据仓库的建立已经经历了十多年，他们自己有自己的数据环境，有自己的数据架构，也有自己的数据应用，新的大数据的技术引入，新的数据的引入的时候，我们除了考虑怎么去用好这些数据，同时也需要考虑这些数据和原有IT环境的整合。因为这里面面临的困难，新的技术和IT技术的整合，运营商也在看自己业务的转型，比如国外的运营商已经提出过自己要从一个传统的CT的服务商变成一个DT的服务商，他们在数据化转型的要求，之前也谈到了我们有很多的用户真的是谈需要数据，大家谈了我需要数据，真正谁能够提供数据，这里面有很多的数据没有办法提供，这里面一方面是你有没有这个数据，运营商其实有数据。另外一个角度来看你有这个数据你有不能能力把这个数据合规合法，并且满足我的业务需求提供出来，所以这里面来看对平台的要求也进一提出要求。
电信运营商大数据平台的演进

我们可以看一下运营商建立大数据的利用演进的过程，最早运营商会看大数据的数据引入过来使得原来历史的数据进一步的做处理和分析，去发现，最早引入运营商大数据的应用比较多的会看到我们做详单的查询，详单我们呼叫的记录详单保存在记录里面量非常大，以前过一段时间我们就把它归档或者从业务系统里面拿掉。但是这些数据其实在以后我们还需要对它进行查询访问，甚至更进一步的分析，而大数据的技术应用使得第一步从一个简单的应用，我们可以对历史数据进行访问和分析，第二块我们也会建一些客户深入的洞察，把原来业务系统里面的数据，跟我们网络上客户的行为数据去做关联，去做客户深度的洞察。但是从这种角度来看，每一个系统或者每一个应用基本上都是垂直在建的。所以接下来我们到了第二个阶段，其实就是要看运营商希望把整个基础的架构，包括原有的业务数据，包括网络运营的这些数据，包括对外部支撑的数据，希望能够有一个公共的平台，所以第二个阶段建一个公共平台，通过公共平台支撑上面的数据分析和业务应用。第二个阶段是有限的一些开发商或者服务商提供，运营商为了更广泛的让更多的人使用他的平台和数据，同时让他的数据价值得到更大程度的发挥，希望有更多的合作伙伴在平台上做数据价值的发现，做数据应用的开发。所以第三个阶段更多看到平台需要有一个更开放的环境，有一个统一的平台，有一个统一的数据治理的环境，有一个开放的数据，使众多的开发商和运营伙伴在这个平台做产品开发和数据使用。

这是基于前面的构想的一个生态环境的描述，最下面可以看到我们有一个数据的提供者，过去这里面更多会谈到运营商自己的一些数据，我的业务系统的网络数据，未来有第三方的数据接入。第二层可以看到有一个数据的统一的基础架构，上面会构建一些公共的服务，并且把这些服务开放出来，这里面包括平台本身自己的服务，包括一些深度计算，数据处理，技术分析的服务，我们把这些服务能够在扁平化的平台上开放出来，而这些开放的是基于相对的标准，不同的开发商不同的消费者可以在这个上面基于这样的标准开发他们的应用。这里面会有数据的开发者，他们基于运营商的数据做数据的加工和处理，会有应用的开发者他们基于这些数据，基于平台的能力开发适合特定的需求的应用，也会有一些工具的开发者，这些工具开发者包括传统工具的提供者，也包括基于今天新兴大数据底层的数据，做二次开发。最上面是我们看到的一些服务的最终数据消费，他们有可能是运营商内部的客户，也有可能是外部的客户。
面向运营商的大数据分析平台

从这个上面我们推导出来我们需要平台的架构，底层我们可能接入这些数据，包括传统的从运营商自己的业务系统里面的数据，也包括网络上的数据，网络上的数据其实以前在运营商的分析环境里面是接触比较少的，因为这些数据如果要去采集的话，会对网络本身有一些影响，所以我们在构建这样平台的时候，从采集到数据的存储和加工，除了考虑我们对数据本身使用的需求以外，由于这个本身IT环境和CT的环境已经在那里，有他自己的一套架构，同时还需要考虑的是，对这些数据进行采集处理、加工，同时要考虑到怎么样减少对原有系统的影响，以及保持这个系统的稳定性。

绿色既包括我们对传统IT的数据仓库，数据库的集成，也包括像Hadoop新兴大数据的集成，在整个平台上我们还会考虑构建一个统一的数据治理，因为随着Hadoop和非结构化数据的应用，这些数据如何变成运营商或者一个企业客户的数据资产的角度来对他有效的管理，这个里面也是很重要的，因为我们知道数据仓库和Hadoop数据的形态可能都是不一样，需要有一个统计的数据治理。我们还需要考虑在现有的环境里面，如何去跟已有的环境去做整合和集成，运营商这样一个企业IT的环境比较复杂，我们也会考虑到跟数据来源提供者和数据消费提供者的关系。通过能力开放去提供第三方的服务的使用。

在整个平台的设计和构想后，我们已经在一些客户那面得到了一些试点和使用，在这里面就列举了一些，由于引入新的数据处理的手段，新的数据感觉的手段以及分析手段以后，我们能够进一步做哪些分析是我们原来产生的经营分析系统没有办法做。另外我们也可以知道通过网络侧的深入分析我们可以知道，比如说没有人拿了同一个CM卡在不同的地方，一个CM卡被复制，同时在打电话，如果这两个CM卡在不同的基站使用肯定能体现出来。另外一个领域可以看到，可以服务运营商做网络的优化，我通过时时分析知道，在我这个网络和基站里面有哪些用户，这些用户如果基站的某些指标对那些用户产生什么样的影响，从而做网络的优化。

第三块我们基于套餐的优化，比如我用手机上网，流量使用到一定的阶段之后，我可以推荐适合你的套餐，而不是结完账单才发现我上网产生了很高的费用，然后再设立套餐，这样套餐设计更合理。因为运营商有很多通过手机的信息，可以做一些位置的分析，从而这些信息可以对某一个领域里面人流的情况进行深入的分析，这里面也是当一个新的商户要去选他的店址的时候，我们可以通过分析知道某一些时间在某个区域人流分布的情况，从而为商户选址有更精准的定位。
总结

总的来看现在华为来考虑这个平台，其实主要几点：第一个是把大数据的新的技术和原有传统的技术能够有效的整合；第二个是希望这种整合是它的能力能够相对固化，使这些能力在不同的客户快速的复制，今天大数据的技术相对来说非常碎片化化，对于传统的企业如何引入这些技术并且得到持续的能力，这是我们构建这个平台的初衷；第三是希望在这个平台上能够有一个相对完备的数据资产治理的平台，使得用户真正的知道它的数据，了解它的数据，用好它的数据。

更多精彩内容，请关注直播专题 2015中国大数据技术大会(BDTC)，新浪微博@CSDN云计算，订阅CSDN大数据微信号。 



摘要：星环科技创始人兼CTO孙元浩详细介绍了逻辑数据仓库需具备的特性：数据、计算均分布化；对多种关系数据库和Hadoop数据源进行交叉查询，聚合，以及关联操作等能力；混合负载和多租户SLA管理能力。


【CSDN现场报道】2015年12月10-12日，由中国计算机学会（CCF）主办，CCF大数据专家委员会承办，中国科学院计算技术研究所、北京中科天玑科技有限公司与CSDN共同协办，以“数据安全、深度分析、行业应用”为主题的 2015中国大数据技术大会 （Big Data Technology Conference 2015，BDTC 2015）在北京新云南皇冠假日酒店盛大开幕。

2015中国大数据 技术大会首日全体会议中，星环科技创始人兼CTO孙元浩带来了名为“现代数据仓库的技术演变和关键特性”的主题演讲。期间，星环科技创始人兼CTO孙元浩首先介绍了传统数据仓库面临的问题： 数据量增长过快，导致运算效率下降；数据抽取处理的代价过高，无法在统一的视图下处理；无法处理多种类型的数据；不具备进行搜索或关联分析以发现隐藏关系的能力；不具备数据挖掘等高级分析的能力。随后，他详细介绍了新时代逻辑数据仓库需要具备的特性：数据、计算均分布化；需要具备对多种关系数据库和Hadoop数据源进行交叉查询、聚合、以及关联操作等能力；混合负载和多租户SLA管理能力。在多租户资源管理用例中，孙元浩指出2014到2015资源调度框架之争，Mesos和Kubernetes逐渐占据优势，YARN被边缘化。 





星环科技创始人兼CTO 孙元浩 


以下为演讲实录

孙元浩：


首先，一句话介绍一下星环科技——一家专门做Hoddp发行和基础软件的公司。目前来讲，在Hadoop之上的数据引擎和流处理引擎在技术上远远领先于国外的同行。首先，看什么是数据仓库，这张图也在帮助企业客户建设数据仓库，有的是数据库，或者是一个数据库管理系统，也有企业是用一体机来建造数据仓库。按照这个是表现形态而言，是表象，实质不一定是数据库的形态，这里就像这张图一样，左边这张图大家可以看到，有的人看出来是一个酒杯，有的人看出来是两个人脸的侧面，如果只从表面看数据仓库就是一个数据库，数据仓库的本质可以看成是一个集中化的数据平台，把所有数据全部集中在一个平台上面进行数据的加工、处理和挖掘。这一块使得现在Gartner把数据仓库慢慢开始改了一个名称，2015年改成了数据仓库和数据管理的魔力象限，意味着在数据仓库当中引入一些的技术，尤其像Hadoop的技术作为数据仓库。为什么要引入这个，一个重要的原因是传统数据仓库已经碰到各种瓶颈。
传统数据库所遭遇的瓶颈

数据量增长过快，导致运算效率下降；数据抽取处理的代价过高，无法在统一的视图下处理；无法处理多种类型的数据；不具备进行搜索或关联分析以发现隐藏关系的能力；不具备数据挖掘等高级分析的能力。具体来看，在一个银行风险分析、客户精细化营销的案例中，各种类型数据库往往会有以下表现。


传统数据仓库——本使用案例涉及管理来自多种结构化数据源的历史数据。该数据主要通过批量载入。传统数据仓库使用案例可管理大量数据，主要用于标准报表和仪表盘。其次，该使用案例还用于自由模式查询和挖掘或操作型查询。考虑到用于查询的混合工作负载能力和使用者的技能差异，传统数据仓库使用案例需要系统高可用性以及强大的执行和管理能力。

操作型数据仓库——本使用案例管理连续载入的结构化数据，以支持应用、实时数据仓库和操作型数据存储内的嵌入式分析。本使用案例主要支持报表和自动化查询，以支持操作需求。本使用案例将需要高可用性与灾难性恢复能力，以满足操作需要。由于操作型数据仓库使用案例的主要目的是实现卓越的操作性能，所以管理不同类型使用者或即席查询（ad hoc querying）、挖掘等不同类型工作负载的重要性较低。

逻辑数据仓库——本使用案例需要针对结构化数据和其它内容数据类型，管理数据多样性和数据量。除来自交易应用的结构化数据外，本使用案例还包括机器数据、文本文档、图片和视频等其它内容数据类型。因为其它内容类型能够产生大量数据，所以管理大量数据成为重要标准。逻辑数据仓库还能够满足不同查询能力的需求，并支持不同的使用者技能。本使用案例支持数据仓库数据库管理系统及其它数据源的查询。 

上下文独立式(context-independent)数据仓库 – 本使用案例体现出新的数据价值、数据形式变种(variants)和新的数据关系。它支持搜索、图表和其它高级功能，以发现新的信息模型。本使用案例主要用于自由模式的查询，以支持预测、预测性建模或其它挖掘形式，以及支持多种数据类型和数据源的查询。它没有操作性要求，可帮助数据科学家或商业分析师等高级用户实现未来多种数据类型的自由模式查询。 

逻辑数据库需具备的四个特性

总结了一下在全新的数据仓库当中包括逻辑数据仓库当中需要四个特性，这四个特性也是构建罗列数据仓库来讲是至关重要的。

第一点我们认为必须要采用分布式计算，在数据库领域计算模式已经演变成了好几次，从最早单机版计算，再到计算引擎分布，到最后计算和存储全部被分布式，像Hadoop这种方式，是全分布式的计算方式，这种方式带来两个好处，一个好处是扩展性是非常好的，可以完全扩展，完全可以横向扩展，其次因为Hadoop更好一些这也是它扩展性更好的原因。现在基本上都是采用分布式的方式，同时可以看到右边一张图是最新的报告，这里为什么是100T，大型企业数据仓库通常在100左右，中型企业数据量通常在30T以下，小型企业数量不会超过10个T，我们从1T到100T都跑了一遍用了29台机器，这个性能从1个小时40个小时都有，这个数据也是证明了用Hoddp可以完全胜任数据仓库的任务，这是一个非常有技术挑战性的工作。在Hadoop搜索引擎以后完全能够跑完100T，在Hadoop技术的应用客户数量越来越大，在一些客户当中单一数量已经到20个GP。这个也就证明了分布式计算已经开始成熟到取代关联性的数据仓库来做复杂的大容量的统计分析。

第二个是刚才提到的我们需要一个数据联邦技术，需要能够通过SQL引擎访问多个数据库，这个是产品的架构图，这里数据不是简单的看成是一个数据源的抽象，会给每个数据源一个驱动，主要的目的是，首先我们做这一层把计算分布式化，本身计算引擎是分布式的，会把一些计算场景，本来数据源的特性，这些特性会放到数据源上做，可以减少数据传输量，这种方式可以使多种数据源进行交叉分析，能够把甲骨文的表和Hadoop格式的表能够进行交易，为什么有这种需求，一家企业数据源是非常多，几百个，通常有客户是两百多个数据库，很难把所有的数据实时到同一个仓库当中，需要实时的访问原来数据源。其实在这个领域有两个流派，传统的数据库厂商希望用连接器覆盖Hadoop，可以看到甲骨文，他们这种方法希望把Hadoop掩隐藏在他们的执行引擎上面，
 他们只是把Hadoop作为一个存储。但是这种方式没有把计算完全分布出来。我们是完全反过来，我们希望用Hadoop原先的搜索引擎覆盖原来的数据库，使原来的数据库和Hoddp都作为同一种数据源进行完全分布式的计算。我们认为这种方式会更符合未来的技术趋势，因为我的计算可以被完全分布式化，我的扩展性比原来的好很多，混合架构在未来三年会小时掉。




明年我们看到这种技术会成为一种PK状态，同时有了这个技术以后，其实对数据仓库的开发和运维，甚至对整个开发软件的模式发生一些重要的变化，这时我们看到基于Docker的方式出现，今天可以把整个应用系统、运营系统通常分为三个架构：前端、中间件和数据库层，这三层完全可以变成微服务，应用系统其实都是用微服务的模块组建的，只要描述依赖性就可以了，把这个依赖性告诉底下的系统，你的应用就像打包一个集装箱一样的所有的模块都可以组建，这种方式对现在的应用开发方式产生非常大的变化，对应用迁移带来非常巨大的便捷性。

我们在这边重新开发了一个调度器，而且调度的功能也超过了YARN的调动能力。这种调度器我们同时支持CPU网络内存的调度，上面可以一键式的启动平台层的服务，包括数据库、Hadoop，，未来数据库的方式可以通过这种方式。再往上你的应用层可以直接我们都可以一键式的上传上去进行部署，而且想把一个服务扩展的话，可以在很早的时间内扩展到上万个。有了这套系统以后可以轻易的建造一个有几万个容器应用系统，在上面可以跑几千个应用，扩展性可以在扩展到上千，也可以下线非常短的应用，在上面可以跑上千个应用。

第四个关键特性应该具备预测性分析的能力。预测非常难，今天很难有人预测08年经济危机，可能从来没有成功过预测过经济危机，这里面其实有很多的原因，包括现在的企业他们想做预测性的工作，特别是大数据当时讲很多的故事可以预测，但是这种寓言的准确度是至关重要的，其中的准确度从来没有高过，这里也有一些重要的原因，过去是因为没有大规模软件系统来存放大量的数据，也无法对数据进行分析。其次计算模型过于简单，过去的计算能力不能进行一种复杂的计算复习。

除此以外，我们认为做分析还要具备一些特征，首先是需要三个工具，第一个是通过一种方式在大量的数据中作出一个特征出来；第二个需要分布式的算法库，今天的分布式算法库数量仍然不够多和全，我们需要有更完整的算法列表；第三是需要应用工具帮我建造完整的（英语），让我能够方便的做数据分析，我们才能解决方案。今天我们初步探索这个领域，发现该领域成功的案例非常少，不管是国内还是国外，现在尝试的方法把R语言作为Hadoop的一等公民跟（英语）一样，我们会自动把R语言的算法自动化掉，所有的数据科学家不需要学习新的语言，用原生的R就可以了，我们会自动编译。同时我们也提供像HUE简易的工具做数据特征抽取，但是这些东西仍然只是尝试，仍然没有得到大规模的应用，这是大数据真正成功的一个关键特性，也是数据仓库在未来想用大数据做分析挖掘的必不可少的功能。

今天我介绍是数据仓库的四大特性，我们也看到数据仓库的技术演变速度非常快，但未来三年当中数据仓库技术会发生非常大的变化，与此同时，我们看到在未来三年当中，大部分企业级客户会把传统的数据仓库变成罗列数仓，Hadoop会扮演重要的角色，现在很多企业客户把Hoddp作为最基础的数据平台，而且完全可以不用管理数据库。

更多精彩内容，请关注直播专题 2015中国大数据技术大会(BDTC)，新浪微博@CSDN云计算，订阅CSDN大数据微信号。 



摘要：该研究团队还使用了一个“残差学习”原则来指导神经网络结构的设计。“残差学习”最重要的突破在于重构了学习的过程，并重新定向了深层神经网络中的信息流，很好地解决了此前深层神经网络层级与准确度之间的矛盾。


美国东部时间2015年12月10日，微软亚洲研究院视觉计算组在2015 ImageNet计算机识别挑战赛中凭借深层神经网络技术的最新突破，以绝对优势获得图像分类、图像定位以及图像检测全部三个主要项目的冠军。同一时刻，他们在另一项图像识别挑战赛MS COCO（Microsoft Common Objects in Context challenges，常见物体图像识别）中同样成功登顶，在图像检测和图像分割项目上击败了来自学界、企业和研究机构的众多参赛者。

在此次挑战赛中，微软亚洲研究院的研究团队使用了一种前所未有的深度高达百层的神经网络，这比以往任何成功使用的神经网络层数多5倍以上，从而在照片和视频物体识别等技术方面实现了重大突破。

ImageNet挑战赛去年获胜的系统错误率为6.6%，而今年微软亚洲研究院视觉计算组的系统错误率已经低至3.57%。事实上，该研究团队早在今年一月就首先实现了对人类视觉能力的突破。当时，在题为“Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification”的论文中，他们系统的错误率已降低至4.94%。此前同样的实验中，人眼辨识的错误率大概为5.1%。

微软全球资深副总裁、微软亚太研发集团主席兼微软亚洲研究院院长洪小文博士表示：“微软亚洲研究院视觉计算组在此次ImageNet挑战赛中所取得的出色成绩，不仅是微软在深层神经网络的研究和应用上所取得的科学突破，同时也代表着计算机视觉技术在目标识别方面的又一次飞跃。我对研究组多年来的技术积累、探索和成果倍感骄傲，同时也对这一突破对其它研究领域的推动以及相关产品的转化充满期待。”

微软亚洲研究院视觉计算组首席研究员孙剑博士带领的团队在深层神经网络方面进行了算法的更新，并称之为“深层残差网络”（deep residual networks）。目前普遍使用的神经网络层级能够达到20到30层，在此次挑战赛中该团队应用的神经网络系统实现了152层。该研究团队还使用了一个全新的“残差学习”原则来指导神经网络结构的设计。“残差学习”最重要的突破在于重构了学习的过程，并重新定向了深层神经网络中的信息流。它很好地解决了此前深层神经网络层级与准确度之间的矛盾。孙剑表示：“从我们极深的深层神经网络中可以看出，‘深层残差网络’力量强大且极为通用，可以预见它还能极大地改善其它计算机视觉问题。”

微软亚洲研究院多年来在计算机视觉领域的研究成果已经转化到众多微软的智能产品和服务中，包括微软牛津计划中的人脸识别和图像识别API、Windows 10中的Windows Hello“刷脸”开机功能、必应的图像搜索、微软小冰的多个图像“技能”，OneDrive中的图片分类功能，以及广受好评的口袋扫描仪Office Lens等等。

ImageNet是一个计算机视觉系统识别项目，也是目前世界上图像识别最大的数据库。ImageNet挑战赛每年举办一次，由来自全球顶尖高校、企业及研究机构的研究员组织举办，近年来已经成为计算机视觉领域的标杆。MS COCO数据库由微软资助建立，其挑战赛目前由学术界几所高校联合组织，独立运行。



eclipse创建maevn web项目，在选择maven_archetype_web原型后，默认只有src/main/resources这个Source Floder。

    按照maven目录结构，添加src/main/java、src/test/java等Source Floder时，会报目The folder is already a source folder的错误。

    解决办法：右键项目根目录点击New -&gt; Source Folder，建出这三个文件，在建立时，src/main/java、src/test/java这两个直接建立不了，可以选择建立src/main/jav、src/test/jav（不要是这两个原名的source
 Floder），再选中对应目录，右键对应目录-&gt;refactor-&gt;Rename，将其更改为需要的目录即可。


 为了方便各位网友学习以及方便自己复习之用，将Java并发编程系列内容系列内容按照由浅入深的学习顺序总结如下，点击相应的标题即可跳转到对应的文章

 

   【Java并发编程】实现多线程的两种方法

   【Java并发编程】线程的中断

   【Java并发编程】正确挂起、恢复、终止线程

   【Java并发编程】守护线程和线程阻塞

   【Java并发编程】Volatile关键字（上）

   【Java并发编程】Volatile关键字（下）

   【Java并发编程】synchronized关键字

   【Java并发编程】synchronized的另个一重要作用：内存可见性

   【Java并发编程】实现内存可见性的两种方法比较：synchronized和Volatile

   【Java并发编程】多线程环境下安全使用集合API

   【Java并发编程】死锁

   【Java并发编程】可重入内置锁

   【Java并发编程】线程间协作：wait、notify、notifyAll

   【Java并发编程】notify通知的遗漏

   【Java并发编程】notifyAll造成的早期通知问题

   【Java并发编程】生产者—消费者模型

   【Java并发编程】深入Java内存模型（1）——happen—before规则及其对DCL问题的分析

   【Java并发编程】深入Java内存模型（2）——内存操作规则总结

   【Java并发编程】并发新特性—Executor框架与线程池

   【Java并发编程】并发新特性—Lock锁与条件变量

   【Java并发编程】并发新特性—阻塞队列与阻塞栈

   【Java并发编程】并发新特性—障碍器CyclicBarrier

   【Java并发编程】并发新特性—信号量Semaphore


在操作系统中，信号量是个很重要的概念，它在控制进程间的协作方面有着非常重要的作用，通过对信号量的不同操作，可以分别实现进程间的互斥与同步。当然它也可以用于多线程的控制，我们完全可以通过使用信号量来自定义实现类似Java中的synchronized、wait、notify机制。

    Java并发包中的信号量Semaphore实际上是一个功能完毕的计数信号量，从概念上讲，它维护了一个许可集合，对控制一定资源的消费与回收有着很重要的意义。Semaphore可以控制某个资源被同时访问的任务数，它通过acquire（）获取一个许可，release（）释放一个许可。如果被同时访问的任务数已满，则其他acquire的任务进入等待状态，直到有一个任务被release掉，它才能得到许可。

    下面给出一个采用Semaphore控制并发访问数量的示例程序：





[java] view
 plaincopy






import java.util.concurrent.ExecutorService;  
import java.util.concurrent.Executors;  
import java.util.concurrent.Semaphore;  
public class SemaphoreTest{  
    public static void main(String[] args) {  
    //采用新特性来启动和管理线程——内部使用线程池  
    ExecutorService exec = Executors.newCachedThreadPool();  
    //只允许5个线程同时访问  
    final Semaphore semp = new Semaphore(5);  
    //模拟10个客户端访问  
    for (int index = 0; index &lt; 10; index++){  
        final int num = index;  
        Runnable run = new Runnable() {  
            public void run() {  
                try {  
                    //获取许可  
                    semp.acquire();  
                    System.out.println("线程" +   
                        Thread.currentThread().getName() + "获得许可："  + num);  
                    //模拟耗时的任务  
                    for (int i = 0; i &lt; 999999; i++) ;  
                    //释放许可  
                    semp.release();  
                    System.out.println("线程" +   
                        Thread.currentThread().getName() + "释放许可："  + num);  
                    System.out.println("当前允许进入的任务个数：" +  
                        semp.availablePermits());  
                }catch(InterruptedException e){  
                    e.printStackTrace();  
                }  
            }  
        };  
          exec.execute(run);  
    }  
    //关闭线程池  
    exec.shutdown();  
    }  
}  

    某次执行的结果如下：



线程pool-1-thread-1获得许可：0
线程pool-1-thread-1释放许可：0
当前允许进入的任务个数：5
线程pool-1-thread-2获得许可：1
线程pool-1-thread-6获得许可：5
线程pool-1-thread-4获得许可：3
线程pool-1-thread-8获得许可：7
线程pool-1-thread-2释放许可：1
当前允许进入的任务个数：2
线程pool-1-thread-5获得许可：4
线程pool-1-thread-8释放许可：7
线程pool-1-thread-3获得许可：2
线程pool-1-thread-4释放许可：3
线程pool-1-thread-10获得许可：9
线程pool-1-thread-6释放许可：5
线程pool-1-thread-10释放许可：9
当前允许进入的任务个数：2
线程pool-1-thread-3释放许可：2
当前允许进入的任务个数：1
线程pool-1-thread-5释放许可：4
当前允许进入的任务个数：3
线程pool-1-thread-7获得许可：6
线程pool-1-thread-9获得许可：8
线程pool-1-thread-7释放许可：6
当前允许进入的任务个数：5
当前允许进入的任务个数：3
当前允许进入的任务个数：3
当前允许进入的任务个数：3
线程pool-1-thread-9释放许可：8
当前允许进入的任务个数：5


    可以看出，Semaphore允许并发访问的任务数一直为5，当然，这里还很容易看出一点，就是Semaphore仅仅是对资源的并发访问的任务数进行监控，而不会保证线程安全，因此，在访问的时候，要自己控制线程的安全访问。


 CyclicBarrier（又叫障碍器）同样是Java 5中加入的新特性，使用时需要导入java.util.concurrent.CylicBarrier。它适用于这样一种情况：你希望创建一组任务，它们并发地执行工作，另外的一个任务在这一组任务并发执行结束前一直阻塞等待，直到该组任务全部执行结束，这个任务才得以执行。这非常像CountDownLatch，只是CountDownLatch是只触发一次的事件，而CyclicBarrier可以多次重用。

    下面给出一个简单的实例来说明其用法：





[java] view
 plaincopy






import java.util.concurrent.BrokenBarrierException;   
import java.util.concurrent.CyclicBarrier;   
  
public class CyclicBarrierTest {   
        public static void main(String[] args) {   
                //创建CyclicBarrier对象，  
                //并设置执行完一组5个线程的并发任务后，再执行MainTask任务  
                CyclicBarrier cb = new CyclicBarrier(5, new MainTask());   
                new SubTask("A", cb).start();   
                new SubTask("B", cb).start();   
                new SubTask("C", cb).start();   
                new SubTask("D", cb).start();   
                new SubTask("E", cb).start();  
        }   
}   
  
/**  
* 最后执行的任务 
*/   
class MainTask implements Runnable {   
        public void run() {   
                System.out.println("......终于要执行最后的任务了......");   
        }   
}   
  
/**  
* 一组并发任务  
*/   
class SubTask extends Thread {   
        private String name;   
        private CyclicBarrier cb;   
  
        SubTask(String name, CyclicBarrier cb) {   
                this.name = name;   
                this.cb = cb;   
        }   
  
        public void run() {   
                System.out.println("[并发任务" + name + "]  开始执行");   
                for (int i = 0; i &lt; 999999; i++) ;    //模拟耗时的任务   
                System.out.println("[并发任务" + name + "]  开始执行完毕，通知障碍器");   
                try {   
                        //每执行完一项任务就通知障碍器   
                        cb.await();   
                } catch (InterruptedException e) {   
                        e.printStackTrace();   
                } catch (BrokenBarrierException e) {   
                        e.printStackTrace();   
                }   
        }   
}  

    某次执行的结果如下：



[并发任务A]  开始执行
[并发任务B]  开始执行
[并发任务D]  开始执行
[并发任务E]  开始执行
[并发任务A]  开始执行完毕，通知障碍器
[并发任务E]  开始执行完毕，通知障碍器
[并发任务D]  开始执行完毕，通知障碍器
[并发任务C]  开始执行
[并发任务B]  开始执行完毕，通知障碍器
[并发任务C]  开始执行完毕，通知障碍器
......终于要执行最后的任务了......


    从结果可以看出：MainTask任务在一组中的5个任务执行完后才开始执行。


阻塞队列

    阻塞队列是Java 5并发新特性中的内容，阻塞队列的接口是java.util.concurrent.BlockingQueue，它有多个实现类：ArrayBlockingQueue、DelayQueue、LinkedBlockingQueue、PriorityBlockingQueue、SynchronousQueue等，用法大同小异，具体可查看JDK文档，这里简单举例看下ArrayBlockingQueue，它实现了一个有界队列，当队列满时，便会阻塞等待，直到有元素出队，后续的元素才可以被加入队列。

    看下面的例子：





[java] view
 plaincopy






import java.util.concurrent.BlockingQueue;   
import java.util.concurrent.ArrayBlockingQueue;   
  
public class BlockingQueueTest{   
        public static void main(String[] args) throws InterruptedException {   
                BlockingQueue&lt;String&gt; bqueue = new ArrayBlockingQueue&lt;String&gt;(20);   
                for (int i = 0; i &lt; 30; i++) {   
                        //将指定元素添加到此队列中   
                        bqueue.put("加入元素" + i);   
                        System.out.println("向阻塞队列中添加了元素:" + i);   
                }   
                System.out.println("程序到此运行结束，即将退出----");   
        }   
}  

    输出结果如下：





    从执行结果中可以看出，由于队列中元素的数量限制在了20个，因此添加20个元素后，其他元素便在队列外阻塞等待，程序并没有终止。

    如果队列已满后，我们将队首元素移出，并可以继续向阻塞队列中添加元素，修改代码如下：





[java] view
 plaincopy






import java.util.concurrent.BlockingQueue;   
import java.util.concurrent.ArrayBlockingQueue;   
  
public class BlockingQueueTest{   
        public static void main(String[] args) throws InterruptedException {   
                BlockingQueue&lt;String&gt; bqueue = new ArrayBlockingQueue&lt;String&gt;(20);   
                for (int i = 0; i &lt; 30; i++) {   
                        //将指定元素添加到此队列中   
                        bqueue.put("" + i);   
                        System.out.println("向阻塞队列中添加了元素:" + i);   
                        if(i &gt; 18){  
                            //从队列中获取队头元素，并将其移出队列  
                            System.out.println("从阻塞队列中移除元素：" + bqueue.take());  
                        }  
                }   
                System.out.println("程序到此运行结束，即将退出----");   
        }   
}  

    执行结果如下：






    从结果中可以看出，当添加了第20个元素后，我们从队首移出一个元素，这样便可以继续向队列中添加元素，之后每添加一个元素，便从将队首元素移除，这样程序便可以执行结束。



     



阻塞栈



   阻塞栈与阻塞队列相似，只是它是Java 6中加入的新特性，阻塞栈的接口java.util.concurrent.BlockingDeque也有很多实现类，使用方法也比较相似，具体查看JDK文档。

    下面同样给出一个简单的例子：





[java] view
 plaincopy






import java.util.concurrent.BlockingDeque;   
import java.util.concurrent.LinkedBlockingDeque;   
  
public class BlockingDequeTest {   
    public static void main(String[] args) throws InterruptedException {   
            BlockingDeque&lt;String&gt; bDeque = new LinkedBlockingDeque&lt;String&gt;(20);   
            for (int i = 0; i &lt; 30; i++) {   
                //将指定元素添加到此阻塞栈中  
                bDeque.putFirst("" + i);   
                System.out.println("向阻塞栈中添加了元素:" + i);   
            }   
            System.out.println("程序到此运行结束，即将退出----");   
    }   
}  

    执行结果如下：






    程序依然会阻塞等待，我们改为如下代码：





[java] view
 plaincopy






import java.util.concurrent.BlockingDeque;   
import java.util.concurrent.LinkedBlockingDeque;   
  
public class BlockingDequeTest {   
    public static void main(String[] args) throws InterruptedException {   
            BlockingDeque&lt;String&gt; bDeque = new LinkedBlockingDeque&lt;String&gt;(20);   
            for (int i = 0; i &lt; 30; i++) {   
                //将指定元素添加到此阻塞栈中  
                bDeque.putFirst("" + i);   
                System.out.println("向阻塞栈中添加了元素:" + i);   
                if(i &gt; 18){  
                    //从阻塞栈中取出栈顶元素，并将其移出  
                    System.out.println("从阻塞栈中移出了元素：" + bDeque.pollFirst());  
                }  
            }   
            System.out.println("程序到此运行结束，即将退出----");   
    }   
}  

    执行结果如下：









    从结果中可以看出，当添加了第20个元素后，我们从将栈顶元素移处，这样便可以继续向栈中添加元素，之后每添加一个元素，便将栈顶元素移出，这样程序便可以执行结束。


简单使用Lock锁

    Java 5中引入了新的锁机制——java.util.concurrent.locks中的显式的互斥锁：Lock接口，它提供了比synchronized更加广泛的锁定操作。Lock接口有3个实现它的类：ReentrantLock、ReetrantReadWriteLock.ReadLock和ReetrantReadWriteLock.WriteLock，即重入锁、读锁和写锁。lock必须被显式地创建、锁定和释放，为了可以使用更多的功能，一般用ReentrantLock为其实例化。为了保证锁最终一定会被释放（可能会有异常发生），要把互斥区放在try语句块内，并在finally语句块中释放锁，尤其当有return语句时，return语句必须放在try字句中，以确保unlock（）不会过早发生，从而将数据暴露给第二个任务。因此，采用lock加锁和释放锁的一般形式如下：





[java] view
 plaincopy






Lock lock = new ReentrantLock();//默认使用非公平锁，如果要使用公平锁，需要传入参数true  
........  
lock.lock();  
try {  
     //更新对象的状态  
    //捕获异常，必要时恢复到原来的不变约束  
   //如果有return语句，放在这里  
 finally {  
       lock.unlock();        //锁必须在finally块中释放  





ReetrankLock与synchronized比较




    性能比较



    在JDK1.5中，synchronized是性能低效的。因为这是一个重量级操作，它对性能最大的影响是阻塞的是实现，挂起线程和恢复线程的操作都需要转入内核态中完成，这些操作给系统的并发性带来了很大的压力。相比之下使用Java提供的Lock对象，性能更高一些。Brian Goetz对这两种锁在JDK1.5、单核处理器及双Xeon处理器环境下做了一组吞吐量对比的实验，发现多线程环境下，synchronized的吞吐量下降的非常严重，而ReentrankLock则能基本保持在同一个比较稳定的水平上。但与其说ReetrantLock性能好，倒不如说synchronized还有非常大的优化余地，于是到了JDK1.6，发生了变化，对synchronize加入了很多优化措施，有自适应自旋，锁消除，锁粗化，轻量级锁，偏向锁等等。导致在JDK1.6上synchronize的性能并不比Lock差。官方也表示，他们也更支持synchronize，在未来的版本中还有优化余地，所以还是提倡在synchronized能实现需求的情况下，优先考虑使用synchronized来进行同步。


    下面浅析以下两种锁机制的底层的实现策略。

    互斥同步最主要的问题就是进行线程阻塞和唤醒所带来的性能问题，因而这种同步又称为阻塞同步，它属于一种悲观的并发策略，即线程获得的是独占锁。独占锁意味着其他线程只能依靠阻塞来等待线程释放锁。而在CPU转换线程阻塞时会引起线程上下文切换，当有很多线程竞争锁的时候，会引起CPU频繁的上下文切换导致效率很低。synchronized采用的便是这种并发策略。

    随着指令集的发展，我们有了另一种选择：基于冲突检测的乐观并发策略，通俗地讲就是先进性操作，如果没有其他线程争用共享数据，那操作就成功了，如果共享数据被争用，产生了冲突，那就再进行其他的补偿措施（最常见的补偿措施就是不断地重拾，直到试成功为止），这种乐观的并发策略的许多实现都不需要把线程挂起，因此这种同步被称为非阻塞同步。ReetrantLock采用的便是这种并发策略。

    在乐观的并发策略中，需要操作和冲突检测这两个步骤具备原子性，它靠硬件指令来保证，这里用的是CAS操作（Compare and Swap）。JDK1.5之后，Java程序才可以使用CAS操作。我们可以进一步研究ReentrantLock的源代码，会发现其中比较重要的获得锁的一个方法是compareAndSetState，这里其实就是调用的CPU提供的特殊指令。现代的CPU提供了指令，可以自动更新共享数据，而且能够检测到其他线程的干扰，而compareAndSet()
 就用这些代替了锁定。这个算法称作非阻塞算法，意思是一个线程的失败或者挂起不应该影响其他线程的失败或挂起。

    Java 5中引入了注入AutomicInteger、AutomicLong、AutomicReference等特殊的原子性变量类，它们提供的如：compareAndSet（）、incrementAndSet（）和getAndIncrement（）等方法都使用了CAS操作。因此，它们都是由硬件指令来保证的原子方法。




   用途比较
    基本语法上，ReentrantLock与synchronized很相似，它们都具备一样的线程重入特性，只是代码写法上有点区别而已，一个表现为API层面的互斥锁（Lock），一个表现为原生语法层面的互斥锁（synchronized）。ReentrantLock相对synchronized而言还是增加了一些高级功能，主要有以下三项：

    1、等待可中断：当持有锁的线程长期不释放锁时，正在等待的线程可以选择放弃等待，改为处理其他事情，它对处理执行时间非常上的同步块很有帮助。而在等待由synchronized产生的互斥锁时，会一直阻塞，是不能被中断的。

    2、可实现公平锁：多个线程在等待同一个锁时，必须按照申请锁的时间顺序排队等待，而非公平锁则不保证这点，在锁释放时，任何一个等待锁的线程都有机会获得锁。synchronized中的锁时非公平锁，ReentrantLock默认情况下也是非公平锁，但可以通过构造方法ReentrantLock（ture）来要求使用公平锁。

    3、锁可以绑定多个条件：ReentrantLock对象可以同时绑定多个Condition对象（名曰：条件变量或条件队列），而在synchronized中，锁对象的wait（）和notify（）或notifyAll（）方法可以实现一个隐含条件，但如果要和多于一个的条件关联的时候，就不得不额外地添加一个锁，而ReentrantLock则无需这么做，只需要多次调用newCondition（）方法即可。而且我们还可以通过绑定Condition对象来判断当前线程通知的是哪些线程（即与Condition对象绑定在一起的其他线程）。




可中断锁

    ReetrantLock有两种锁：忽略中断锁和响应中断锁。忽略中断锁与synchronized实现的互斥锁一样，不能响应中断，而响应中断锁可以响应中断。

    如果某一线程A正在执行锁中的代码，另一线程B正在等待获取该锁，可能由于等待时间过长，线程B不想等待了，想先处理其他事情，我们可以让它中断自己或者在别的线程中中断它，如果此时ReetrantLock提供的是忽略中断锁，则它不会去理会该中断，而是让线程B继续等待，而如果此时ReetrantLock提供的是响应中断锁，那么它便会处理中断，让线程B放弃等待，转而去处理其他事情。

  获得响应中断锁的一般形式如下：





[java] view
 plaincopy






ReentrantLock lock = new ReentrantLock();  
...........  
lock.lockInterruptibly();//获取响应中断锁  
try {  
      //更新对象的状态  
      //捕获异常，必要时恢复到原来的不变约束  
      //如果有return语句，放在这里  
}finally{  
    lock.unlock();        //锁必须在finally块中释放  
}  


    这里有一个不错的分析中断的示例代码（摘自网上）

    当用synchronized中断对互斥锁的等待时，并不起作用，该线程依然会一直等待，如下面的实例：



[java] view
 plaincopy






public class Buffer {  
  
    private Object lock;  
  
    public Buffer() {  
        lock = this;  
    }  
  
    public void write() {  
        synchronized (lock) {  
            long startTime = System.currentTimeMillis();  
            System.out.println("开始往这个buff写入数据…");  
            for (;;)// 模拟要处理很长时间      
            {  
                if (System.currentTimeMillis()  
                        - startTime &gt; Integer.MAX_VALUE) {  
                    break;  
                }  
            }  
            System.out.println("终于写完了");  
        }  
    }  
  
    public void read() {  
        synchronized (lock) {  
            System.out.println("从这个buff读数据");  
        }  
    }  
  
    public static void main(String[] args) {  
        Buffer buff = new Buffer();  
  
        final Writer writer = new Writer(buff);  
        final Reader reader = new Reader(buff);  
  
        writer.start();  
        reader.start();  
  
        new Thread(new Runnable() {  
  
            @Override  
            public void run() {  
                long start = System.currentTimeMillis();  
                for (;;) {  
                    //等5秒钟去中断读      
                    if (System.currentTimeMillis()  
                            - start &gt; 5000) {  
                        System.out.println("不等了，尝试中断");  
                        reader.interrupt();  //尝试中断读线程  
                        break;  
                    }  
  
                }  
  
            }  
        }).start();  
        // 我们期待“读”这个线程能退出等待锁，可是事与愿违，一旦读这个线程发现自己得不到锁，  
        // 就一直开始等待了，就算它等死，也得不到锁，因为写线程要21亿秒才能完成 T_T ，即使我们中断它，  
        // 它都不来响应下，看来真的要等死了。这个时候，ReentrantLock给了一种机制让我们来响应中断，  
        // 让“读”能伸能屈，勇敢放弃对这个锁的等待。我们来改写Buffer这个类，就叫BufferInterruptibly吧，可中断缓存。  
    }  
}  
  
class Writer extends Thread {  
  
    private Buffer buff;  
  
    public Writer(Buffer buff) {  
        this.buff = buff;  
    }  
  
    @Override  
    public void run() {  
        buff.write();  
    }  
}  
  
class Reader extends Thread {  
  
    private Buffer buff;  
  
    public Reader(Buffer buff) {  
        this.buff = buff;  
    }  
  
    @Override  
    public void run() {  
  
        buff.read();//这里估计会一直阻塞      
  
        System.out.println("读结束");  
  
    }  
}  


    执行结果如下：







    我们等待了很久，后面依然没有输出，说明读线程对互斥锁的等待并没有被中断，也就是该户吃锁没有响应对读线程的中断。

    我们再将上面代码中synchronized的互斥锁改为ReentrantLock的响应中断锁，即改为如下代码： 





[java] view
 plaincopy






import java.util.concurrent.locks.ReentrantLock;  
  
public class BufferInterruptibly {  
  
    private ReentrantLock lock = new ReentrantLock();  
  
    public void write() {  
        lock.lock();  
        try {  
            long startTime = System.currentTimeMillis();  
            System.out.println("开始往这个buff写入数据…");  
            for (;;)// 模拟要处理很长时间      
            {  
                if (System.currentTimeMillis()  
                        - startTime &gt; Integer.MAX_VALUE) {  
                    break;  
                }  
            }  
            System.out.println("终于写完了");  
        } finally {  
            lock.unlock();  
        }  
    }  
  
    public void read() throws InterruptedException {  
        lock.lockInterruptibly();// 注意这里，可以响应中断      
        try {  
            System.out.println("从这个buff读数据");  
        } finally {  
            lock.unlock();  
        }  
    }  
  
    public static void main(String args[]) {  
        BufferInterruptibly buff = new BufferInterruptibly();  
  
        final Writer2 writer = new Writer2(buff);  
        final Reader2 reader = new Reader2(buff);  
  
        writer.start();  
        reader.start();  
  
        new Thread(new Runnable() {  
  
            @Override  
            public void run() {  
                long start = System.currentTimeMillis();  
                for (;;) {  
                    if (System.currentTimeMillis()  
                            - start &gt; 5000) {  
                        System.out.println("不等了，尝试中断");  
                        reader.interrupt();  //此处中断读操作  
                        break;  
                    }  
                }  
            }  
        }).start();  
  
    }  
}  
  
class Reader2 extends Thread {  
  
    private BufferInterruptibly buff;  
  
    public Reader2(BufferInterruptibly buff) {  
        this.buff = buff;  
    }  
  
    @Override  
    public void run() {  
  
        try {  
            buff.read();//可以收到中断的异常，从而有效退出      
        } catch (InterruptedException e) {  
            System.out.println("我不读了");  
        }  
  
        System.out.println("读结束");  
  
    }  
}  
  
class Writer2 extends Thread {  
  
    private BufferInterruptibly buff;  
  
    public Writer2(BufferInterruptibly buff) {  
        this.buff = buff;  
    }  
  
    @Override  
    public void run() {  
        buff.write();  
    }  
      
}  


    执行结果如下：








    从结果中可以看出，尝试中断后输出了catch语句块中的内容，也输出了后面的“读结束”，说明线程对互斥锁的等待被中断了，也就是该互斥锁响应了对读线程的中断。




条件变量实现线程间协作


    在生产者——消费者模型一文中，我们用synchronized实现互斥，并配合使用Object对象的wait（）和notify（）或notifyAll（）方法来实现线程间协作。Java
 5之后，我们可以用Reentrantlock锁配合Condition对象上的await（）和signal（）或signalAll（）方法来实现线程间协作。在ReentrantLock对象上newCondition（）可以得到一个Condition对象，可以通过在Condition上调用await（）方法来挂起一个任务（线程），通过在Condition上调用signal（）来通知任务，从而唤醒一个任务，或者调用signalAll（）来唤醒所有在这个Condition上被其自身挂起的任务。另外，如果使用了公平锁，signalAll（）的与Condition关联的所有任务将以FIFO队列的形式获取锁，如果没有使用公平锁，则获取锁的任务是随机的，这样我们便可以更好地控制处在await状态的任务获取锁的顺序。与notifyAll（）相比，signalAll（）是更安全的方式。另外，它可以指定唤醒与自身Condition对象绑定在一起的任务。




    下面将生产者——消费者模型一文中的代码改为用条件变量实现，如下：





[java] view
 plaincopy






import java.util.concurrent.*;  
import java.util.concurrent.locks.*;  
  
class Info{ // 定义信息类  
    private String name = "name";//定义name属性，为了与下面set的name属性区别开  
    private String content = "content" ;// 定义content属性，为了与下面set的content属性区别开  
    private boolean flag = true ;   // 设置标志位,初始时先生产  
    private Lock lock = new ReentrantLock();    
    private Condition condition = lock.newCondition(); //产生一个Condition对象  
    public  void set(String name,String content){  
        lock.lock();  
        try{  
            while(!flag){  
                condition.await() ;  
            }  
            this.setName(name) ;    // 设置名称  
            Thread.sleep(300) ;  
            this.setContent(content) ;  // 设置内容  
            flag  = false ; // 改变标志位，表示可以取走  
            condition.signal();  
        }catch(InterruptedException e){  
            e.printStackTrace() ;  
        }finally{  
            lock.unlock();  
        }  
    }  
  
    public void get(){  
        lock.lock();  
        try{  
            while(flag){  
                condition.await() ;  
            }     
            Thread.sleep(300) ;  
            System.out.println(this.getName() +   
                " --&gt; " + this.getContent()) ;  
            flag  = true ;  // 改变标志位，表示可以生产  
            condition.signal();  
        }catch(InterruptedException e){  
            e.printStackTrace() ;  
        }finally{  
            lock.unlock();  
        }  
    }  
  
    public void setName(String name){  
        this.name = name ;  
    }  
    public void setContent(String content){  
        this.content = content ;  
    }  
    public String getName(){  
        return this.name ;  
    }  
    public String getContent(){  
        return this.content ;  
    }  
}  
class Producer implements Runnable{ // 通过Runnable实现多线程  
    private Info info = null ;      // 保存Info引用  
    public Producer(Info info){  
        this.info = info ;  
    }  
    public void run(){  
        boolean flag = true ;   // 定义标记位  
        for(int i=0;i&lt;10;i++){  
            if(flag){  
                this.info.set("姓名--1","内容--1") ;    // 设置名称  
                flag = false ;  
            }else{  
                this.info.set("姓名--2","内容--2") ;    // 设置名称  
                flag = true ;  
            }  
        }  
    }  
}  
class Consumer implements Runnable{  
    private Info info = null ;  
    public Consumer(Info info){  
        this.info = info ;  
    }  
    public void run(){  
        for(int i=0;i&lt;10;i++){  
            this.info.get() ;  
        }  
    }  
}  
public class ThreadCaseDemo{  
    public static void main(String args[]){  
        Info info = new Info(); // 实例化Info对象  
        Producer pro = new Producer(info) ; // 生产者  
        Consumer con = new Consumer(info) ; // 消费者  
        new Thread(pro).start() ;  
        //启动了生产者线程后，再启动消费者线程  
        try{  
            Thread.sleep(500) ;  
        }catch(InterruptedException e){  
            e.printStackTrace() ;  
        }  
  
        new Thread(con).start() ;  
    }  
}  

    执行后，同样可以得到如下的结果：

姓名--1 --&gt; 内容--1
姓名--2 --&gt; 内容--2
姓名--1 --&gt; 内容--1
姓名--2 --&gt; 内容--2
姓名--1 --&gt; 内容--1
姓名--2 --&gt; 内容--2
姓名--1 --&gt; 内容--1
姓名--2 --&gt; 内容--2
姓名--1 --&gt; 内容--1
姓名--2 --&gt; 内容--2
    从以上并不能看出用条件变量的await（）、signal（）、signalAll（）方法比用Object对象的wait（）、notify（）、notifyAll（）方法实现线程间协作有多少优点，但它在处理更复杂的多线程问题时，会有明显的优势。所以，Lock和Condition对象只有在更加困难的多线程问题中才是必须的。


    




读写锁



    另外，synchronized获取的互斥锁不仅互斥读写操作、写写操作，还互斥读读操作，而读读操作时不会带来数据竞争的，因此对对读读操作也互斥的话，会降低性能。Java 5中提供了读写锁，它将读锁和写锁分离，使得读读操作不互斥，获取读锁和写锁的一般形式如下：





[java] view
 plaincopy






ReadWriteLock rwl = new ReentrantReadWriteLock();      
rwl.writeLock().lock()  //获取写锁  
rwl.readLock().lock()  //获取读锁  

   用读锁来锁定读操作，用写锁来锁定写操作，这样写操作和写操作之间会互斥，读操作和写操作之间会互斥，但读操作和读操作就不会互斥。



   《Java并发编程实践》一书给出了使用 ReentrantLock的最佳时机：

    当你需要以下高级特性时，才应该使用：可定时的、可轮询的与可中断的锁获取操作，公平队列，或者非块结构的锁。否则，请使用synchronized。     




Executor框架简介

    在Java 5之后，并发编程引入了一堆新的启动、调度和管理线程的API。Executor框架便是Java
 5中引入的，其内部使用了线程池机制，它在java.util.cocurrent 包下，通过该框架来控制线程的启动、执行和关闭，可以简化并发编程的操作。因此，在Java 5之后，通过Executor来启动线程比使用Thread的start方法更好，除了更易管理，效率更好（用线程池实现，节约开销）外，还有关键的一点：有助于避免this逃逸问题——如果我们在构造器中启动一个线程，因为另一个任务可能会在构造器结束之前开始执行，此时可能会访问到初始化了一半的对象用Executor在构造器中。




    Executor框架包括：线程池，Executor，Executors，ExecutorService，CompletionService，Future，Callable等。




    Executor接口中之定义了一个方法execute（Runnable command），该方法接收一个Runable实例，它用来执行一个任务，任务即一个实现了Runnable接口的类。ExecutorService接口继承自Executor接口，它提供了更丰富的实现多线程的方法，比如，ExecutorService提供了关闭自己的方法，以及可为跟踪一个或多个异步任务执行状况而生成
 Future 的方法。 可以调用ExecutorService的shutdown（）方法来平滑地关闭 ExecutorService，调用该方法后，将导致ExecutorService停止接受任何新的任务且等待已经提交的任务执行完成(已经提交的任务会分两类：一类是已经在执行的，另一类是还没有开始执行的)，当所有已经提交的任务执行完毕后将会关闭ExecutorService。因此我们一般用该接口来实现和管理多线程。




    ExecutorService的生命周期包括三种状态：运行、关闭、终止。创建后便进入运行状态，当调用了shutdown（）方法时，便进入关闭状态，此时意味着ExecutorService不再接受新的任务，但它还在执行已经提交了的任务，当素有已经提交了的任务执行完后，便到达终止状态。如果不调用shutdown（）方法，ExecutorService会一直处在运行状态，不断接收新的任务，执行新的任务，服务器端一般不需要关闭它，保持一直运行即可。







    Executors提供了一系列工厂方法用于创先线程池，返回的线程池都实现了ExecutorService接口。   

    public static ExecutorService newFixedThreadPool(int nThreads)

    创建固定数目线程的线程池。

    public static ExecutorService newCachedThreadPool()

    创建一个可缓存的线程池，调用execute将重用以前构造的线程（如果线程可用）。如果现有线程没有可用的，则创建一个新线   程并添加到池中。终止并从缓存中移除那些已有 60 秒钟未被使用的线程。

    public static ExecutorService newSingleThreadExecutor()

    创建一个单线程化的Executor。

    public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize)

    创建一个支持定时及周期性的任务执行的线程池，多数情况下可用来替代Timer类。




    这四种方法都是用的Executors中的ThreadFactory建立的线程，下面就以上四个方法做个比较








newCachedThreadPool()                                                                                                                                         


-缓存型池子，先查看池中有没有以前建立的线程，如果有，就 reuse.如果没有，就建一个新的线程加入池中
-缓存型池子通常用于执行一些生存期很短的异步型任务
 因此在一些面向连接的daemon型SERVER中用得不多。但对于生存期短的异步任务，它是Executor的首选。
-能reuse的线程，必须是timeout IDLE内的池中线程，缺省     timeout是60s,超过这个IDLE时长，线程实例将被终止及移出池。
  注意，放入CachedThreadPool的线程不必担心其结束，超过TIMEOUT不活动，其会自动被终止。






newFixedThreadPool(int)                                                      


-newFixedThreadPool与cacheThreadPool差不多，也是能reuse就用，但不能随时建新的线程
-其独特之处:任意时间点，最多只能有固定数目的活动线程存在，此时如果有新的线程要建立，只能放在另外的队列中等待，直到当前的线程中某个线程终止直接被移出池子
-和cacheThreadPool不同，FixedThreadPool没有IDLE机制（可能也有，但既然文档没提，肯定非常长，类似依赖上层的TCP或UDP IDLE机制之类的），所以FixedThreadPool多数针对一些很稳定很固定的正规并发线程，多用于服务器
-从方法的源代码看，cache池和fixed 池调用的是同一个底层 池，只不过参数不同:
fixed池线程数固定，并且是0秒IDLE（无IDLE）    
cache池线程数支持0-Integer.MAX_VALUE(显然完全没考虑主机的资源承受能力），60秒IDLE  




newScheduledThreadPool(int)


-调度型线程池
-这个池子里的线程可以按schedule依次delay执行，或周期执行




SingleThreadExecutor()


-单例线程，任意时间池中只能有一个线程
-用的是和cache池和fixed池相同的底层池，但线程数目是1-1,0秒IDLE（无IDLE）









    一般来说，CachedTheadPool在程序执行过程中通常会创建与所需数量相同的线程，然后在它回收旧线程时停止创建新线程，因此它是合理的Executor的首选，只有当这种方式会引发问题时（比如需要大量长时间面向连接的线程时），才需要考虑用FixedThreadPool。（该段话摘自《Thinking
 in Java》第四版）



                         

Executor执行Runnable任务

    通过Executors的以上四个静态工厂方法获得 ExecutorService实例，而后调用该实例的execute（Runnable command）方法即可。一旦Runnable任务传递到execute（）方法，该方法便会自动在一个线程上执行。下面是是Executor执行Runnable任务的示例代码：





[java] view
 plaincopy






import java.util.concurrent.ExecutorService;   
import java.util.concurrent.Executors;   
  
public class TestCachedThreadPool{   
    public static void main(String[] args){   
        ExecutorService executorService = Executors.newCachedThreadPool();   
//      ExecutorService executorService = Executors.newFixedThreadPool(5);  
//      ExecutorService executorService = Executors.newSingleThreadExecutor();  
        for (int i = 0; i &lt; 5; i++){   
            executorService.execute(new TestRunnable());   
            System.out.println("************* a" + i + " *************");   
        }   
        executorService.shutdown();   
    }   
}   
  
class TestRunnable implements Runnable{   
    public void run(){   
        System.out.println(Thread.currentThread().getName() + "线程被调用了。");   
    }   
}  

   某次执行后的结果如下：










   从结果中可以看出，pool-1-thread-1和pool-1-thread-2均被调用了两次，这是随机的，execute会首先在线程池中选择一个已有空闲线程来执行任务，如果线程池中没有空闲线程，它便会创建一个新的线程来执行任务。






Executor执行Callable任务

    在Java 5之后，任务分两类：一类是实现了Runnable接口的类，一类是实现了Callable接口的类。两者都可以被ExecutorService执行，但是Runnable任务没有返回值，而Callable任务有返回值。并且Callable的call()方法只能通过ExecutorService的submit(Callable&lt;T&gt; task) 方法来执行，并且返回一个 &lt;T&gt;Future&lt;T&gt;，是表示任务等待完成的
 Future。




    Callable接口类似于Runnable，两者都是为那些其实例可能被另一个线程执行的类设计的。但是 Runnable 不会返回结果，并且无法抛出经过检查的异常而Callable又返回结果，而且当获取返回结果时可能会抛出异常。Callable中的call()方法类似Runnable的run()方法，区别同样是有返回值，后者没有。




    当将一个Callable的对象传递给ExecutorService的submit方法，则该call方法自动在一个线程上执行，并且会返回执行结果Future对象。同样，将Runnable的对象传递给ExecutorService的submit方法，则该run方法自动在一个线程上执行，并且会返回执行结果Future对象，但是在该Future对象上调用get方法，将返回null。




    下面给出一个Executor执行Callable任务的示例代码：





[java] view
 plaincopy






import java.util.ArrayList;   
import java.util.List;   
import java.util.concurrent.*;   
  
public class CallableDemo{   
    public static void main(String[] args){   
        ExecutorService executorService = Executors.newCachedThreadPool();   
        List&lt;Future&lt;String&gt;&gt; resultList = new ArrayList&lt;Future&lt;String&gt;&gt;();   
  
        //创建10个任务并执行   
        for (int i = 0; i &lt; 10; i++){   
            //使用ExecutorService执行Callable类型的任务，并将结果保存在future变量中   
            Future&lt;String&gt; future = executorService.submit(new TaskWithResult(i));   
            //将任务执行结果存储到List中   
            resultList.add(future);   
        }   
  
        //遍历任务的结果   
        for (Future&lt;String&gt; fs : resultList){   
                try{   
                    while(!fs.isDone);//Future返回如果没有完成，则一直循环等待，直到Future返回完成  
                    System.out.println(fs.get());     //打印各个线程（任务）执行的结果   
                }catch(InterruptedException e){   
                    e.printStackTrace();   
                }catch(ExecutionException e){   
                    e.printStackTrace();   
                }finally{   
                    //启动一次顺序关闭，执行以前提交的任务，但不接受新任务  
                    executorService.shutdown();   
                }   
        }   
    }   
}   
  
  
class TaskWithResult implements Callable&lt;String&gt;{   
    private int id;   
  
    public TaskWithResult(int id){   
        this.id = id;   
    }   
  
    /**  
     * 任务的具体过程，一旦任务传给ExecutorService的submit方法， 
     * 则该方法自动在一个线程上执行 
     */   
    public String call() throws Exception {  
        System.out.println("call()方法被自动调用！！！    " + Thread.currentThread().getName());   
        //该返回结果将被Future的get方法得到  
        return "call()方法被自动调用，任务返回的结果是：" + id + "    " + Thread.currentThread().getName();   
    }   
}  

    某次执行结果如下：



   




    从结果中可以同样可以看出，submit也是首先选择空闲线程来执行任务，如果没有，才会创建新的线程来执行任务。另外，需要注意：如果Future的返回尚未完成，则get（）方法会阻塞等待，直到Future完成返回，可以通过调用isDone（）方法判断Future是否完成了返回。









自定义线程池
    自定义线程池，可以用ThreadPoolExecutor类创建，它有多个构造方法来创建线程池，用该类很容易实现自定义的线程池，这里先贴上示例程序：







[java] view
 plaincopy






import java.util.concurrent.ArrayBlockingQueue;   
import java.util.concurrent.BlockingQueue;   
import java.util.concurrent.ThreadPoolExecutor;   
import java.util.concurrent.TimeUnit;   
  
public class ThreadPoolTest{   
    public static void main(String[] args){   
        //创建等待队列   
        BlockingQueue&lt;Runnable&gt; bqueue = new ArrayBlockingQueue&lt;Runnable&gt;(20);   
        //创建线程池，池中保存的线程数为3，允许的最大线程数为5  
        ThreadPoolExecutor pool = new ThreadPoolExecutor(3,5,50,TimeUnit.MILLISECONDS,bqueue);   
        //创建七个任务   
        Runnable t1 = new MyThread();   
        Runnable t2 = new MyThread();   
        Runnable t3 = new MyThread();   
        Runnable t4 = new MyThread();   
        Runnable t5 = new MyThread();   
        Runnable t6 = new MyThread();   
        Runnable t7 = new MyThread();   
        //每个任务会在一个线程上执行  
        pool.execute(t1);   
        pool.execute(t2);   
        pool.execute(t3);   
        pool.execute(t4);   
        pool.execute(t5);   
        pool.execute(t6);   
        pool.execute(t7);   
        //关闭线程池   
        pool.shutdown();   
    }   
}   
  
class MyThread implements Runnable{   
    @Override   
    public void run(){   
        System.out.println(Thread.currentThread().getName() + "正在执行。。。");   
        try{   
            Thread.sleep(100);   
        }catch(InterruptedException e){   
            e.printStackTrace();   
        }   
    }   
}  

    运行结果如下：







    从结果中可以看出，七个任务是在线程池的三个线程上执行的。这里简要说明下用到的ThreadPoolExecuror类的构造方法中各个参数的含义。 
  



public ThreadPoolExecutor (int corePoolSize, int maximumPoolSize, long         keepAliveTime, TimeUnit unit,BlockingQueue&lt;Runnable&gt;
 workQueue)



corePoolSize：线程池中所保存的核心线程数，包括空闲线程。

maximumPoolSize：池中允许的最大线程数。

keepAliveTime：线程池中的空闲线程所能持续的最长时间。

unit：持续时间的单位。

workQueue：任务执行前保存任务的队列，仅保存由execute方法提交的Runnable任务。

    根据ThreadPoolExecutor源码前面大段的注释，我们可以看出，当试图通过excute方法讲一个Runnable任务添加到线程池中时，按照如下顺序来处理：

    1、如果线程池中的线程数量少于corePoolSize，即使线程池中有空闲线程，也会创建一个新的线程来执行新添加的任务；

    2、如果线程池中的线程数量大于等于corePoolSize，但缓冲队列workQueue未满，则将新添加的任务放到workQueue中，按照FIFO的原则依次等待执行（线程池中有线程空闲出来后依次将缓冲队列中的任务交付给空闲的线程执行）；

    3、如果线程池中的线程数量大于等于corePoolSize，且缓冲队列workQueue已满，但线程池中的线程数量小于maximumPoolSize，则会创建新的线程来处理被添加的任务；

    4、如果线程池中的线程数量等于了maximumPoolSize，有4种才处理方式（该构造方法调用了含有5个参数的构造方法，并将最后一个构造方法为RejectedExecutionHandler类型，它在处理线程溢出时有4种方式，这里不再细说，要了解的，自己可以阅读下源码）。

    总结起来，也即是说，当有新的任务要处理时，先看线程池中的线程数量是否大于corePoolSize，再看缓冲队列workQueue是否满，最后看线程池中的线程数量是否大于maximumPoolSize。

    另外，当线程池中的线程数量大于corePoolSize时，如果里面有线程的空闲时间超过了keepAliveTime，就将其移除线程池，这样，可以动态地调整线程池中线程的数量。

    我们大致来看下Executors的源码，newCachedThreadPool的不带RejectedExecutionHandler参数（即第五个参数，线程数量超过maximumPoolSize时，指定处理方式）的构造方法如下：





[java] view
 plaincopy






public static ExecutorService newCachedThreadPool() {  
    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,  
                                  60L, TimeUnit.SECONDS,  
                                  new SynchronousQueue&lt;Runnable&gt;());  
}  

    它将corePoolSize设定为0，而将maximumPoolSize设定为了Integer的最大值，线程空闲超过60秒，将会从线程池中移除。由于核心线程数为0，因此每次添加任务，都会先从线程池中找空闲线程，如果没有就会创建一个线程（SynchronousQueue&lt;Runnalbe&gt;决定的，后面会说）来执行新的任务，并将该线程加入到线程池中，而最大允许的线程数为Integer的最大值，因此这个线程池理论上可以不断扩大。



    再来看newFixedThreadPool的不带RejectedExecutionHandler参数的构造方法，如下：





[java] view
 plaincopy






public static ExecutorService newFixedThreadPool(int nThreads) {  
    return new ThreadPoolExecutor(nThreads, nThreads,  
                                  0L, TimeUnit.MILLISECONDS,  
                                  new LinkedBlockingQueue&lt;Runnable&gt;());  
}  

    它将corePoolSize和maximumPoolSize都设定为了nThreads，这样便实现了线程池的大小的固定，不会动态地扩大，另外，keepAliveTime设定为了0，也就是说线程只要空闲下来，就会被移除线程池，敢于LinkedBlockingQueue下面会说。



    下面说说几种排队的策略：

    1、直接提交。缓冲队列采用 SynchronousQueue，它将任务直接交给线程处理而不保持它们。如果不存在可用于立即运行任务的线程（即线程池中的线程都在工作），则试图把任务加入缓冲队列将会失败，因此会构造一个新的线程来处理新添加的任务，并将其加入到线程池中。直接提交通常要求无界 maximumPoolSizes（Integer.MAX_VALUE） 以避免拒绝新提交的任务。newCachedThreadPool采用的便是这种策略。

    2、无界队列。使用无界队列（典型的便是采用预定义容量的 LinkedBlockingQueue，理论上是该缓冲队列可以对无限多的任务排队）将导致在所有 corePoolSize 线程都工作的情况下将新任务加入到缓冲队列中。这样，创建的线程就不会超过 corePoolSize，也因此，maximumPoolSize 的值也就无效了。当每个任务完全独立于其他任务，即任务执行互不影响时，适合于使用无界队列。newFixedThreadPool采用的便是这种策略。

    3、有界队列。当使用有限的 maximumPoolSizes 时，有界队列（一般缓冲队列使用ArrayBlockingQueue，并制定队列的最大长度）有助于防止资源耗尽，但是可能较难调整和控制，队列大小和最大池大小需要相互折衷，需要设定合理的参数。


在《Java并发编程学习笔记之五：volatile变量修饰符—意料之外的问题》一文中遗留了一个问题，就是volatile只修饰了missedIt变量，而没修饰value变量，但是在线程读取value的值的时候，也读到的是最新的数据。但是在网上查了很多资料都无果，看来很多人对volatile的规则并不是太清晰，或者说只停留在很表面的层次，一知半解。

    这两天看《深入Java虚拟机——JVM高级特性与最佳实践》第12章：Java内存模型与线程，并在网上查阅了Java内存模型相关资料，学到了不少东西，尤其在看这篇文章的volatile部分的讲解之后，算是确定了问题出现的原因。

    首先明确一点：假如有两个线程分别读写volatile变量时，线程A写入了某volatile变量，线程B在读取该volatile变量时，便能看到线程A对该volatile变量的写入操作，关键在这里，它不仅会看到对该volatile变量的写入操作，A线程在写volatile变量之前所有可见的共享变量，在B线程读同一个volatile变量后，都将立即变得对B线程可见。

   回过头来看文章中出现的问题，由于程序中volatile变量missedIt的写入操作在value变量写入操作之后，而且根据volatile规则，又不能重排序，因此，在线程B读取由线程A改变后的missedIt之后，它之前的value变量在线程A的改变也对线程B变得可见了。

     我们颠倒一下value=50和missedIt=true这两行代码试下，即missedIt=true在前，value=50在后，这样便会得到我们想要的结果：value值的改变不会被看到。

    这应该是JDK1.2之后对volatile规则做了一些修订的结果。




    修改后的代码如下：





[java] view
 plaincopy






public class Volatile extends Object implements Runnable {  
    //value变量没有被标记为volatile  
    private int value;    
    //missedIt变量被标记为volatile  
    private volatile boolean missedIt;  
    //creationTime不需要声明为volatile，因为代码执行中它没有发生变化  
    private long creationTime;   
  
    public Volatile() {  
        value = 10;  
        missedIt = false;  
        //获取当前时间，亦即调用Volatile构造函数时的时间  
        creationTime = System.currentTimeMillis();  
    }  
  
    public void run() {  
        print("entering run()");  
  
        //循环检查value的值是否不同  
        while ( value &lt; 20 ) {  
            //如果missedIt的值被修改为true，则通过break退出循环  
            if  ( missedIt ) {  
                //进入同步代码块前，将value的值赋给currValue  
                int currValue = value;  
                //在一个任意对象上执行同步语句，目的是为了让该线程在进入和离开同步代码块时，  
                //将该线程中的所有变量的私有拷贝与共享内存中的原始值进行比较，  
                //从而发现没有用volatile标记的变量所发生的变化  
                Object lock = new Object();  
                synchronized ( lock ) {  
                    //不做任何事  
                }  
                //离开同步代码块后，将此时value的值赋给valueAfterSync  
                int valueAfterSync = value;  
                print("in run() - see value=" + currValue +", but rumor has it that it changed!");  
                print("in run() - valueAfterSync=" + valueAfterSync);  
                break;   
            }  
        }  
        print("leaving run()");  
    }  
  
    public void workMethod() throws InterruptedException {  
        print("entering workMethod()");  
        print("in workMethod() - about to sleep for 2 seconds");  
        Thread.sleep(2000);  
        //仅在此改变value的值  
        missedIt = true;  
//      value = 50;  
        print("in workMethod() - just set value=" + value);  
        print("in workMethod() - about to sleep for 5 seconds");  
        Thread.sleep(5000);  
        //仅在此改变missedIt的值  
//      missedIt = true;  
        value = 50;  
        print("in workMethod() - just set missedIt=" + missedIt);  
        print("in workMethod() - about to sleep for 3 seconds");  
        Thread.sleep(3000);  
        print("leaving workMethod()");  
    }  
  
/* 
*该方法的功能是在要打印的msg信息前打印出程序执行到此所化去的时间，以及打印msg的代码所在的线程 
*/  
    private void print(String msg) {  
        //使用java.text包的功能，可以简化这个方法，但是这里没有利用这一点  
        long interval = System.currentTimeMillis() - creationTime;  
        String tmpStr = "    " + ( interval / 1000.0 ) + "000";       
        int pos = tmpStr.indexOf(".");  
        String secStr = tmpStr.substring(pos - 2, pos + 4);  
        String nameStr = "        " + Thread.currentThread().getName();  
        nameStr = nameStr.substring(nameStr.length() - 8, nameStr.length());      
        System.out.println(secStr + " " + nameStr + ": " + msg);  
    }  
  
    public static void main(String[] args) {  
        try {  
            //通过该构造函数可以获取实时时钟的当前时间  
            Volatile vol = new Volatile();  
  
            //稍停100ms，以让实时时钟稍稍超前获取时间，使print（）中创建的消息打印的时间值大于0  
            Thread.sleep(100);    
  
            Thread t = new Thread(vol);  
            t.start();  
  
            //休眠100ms，让刚刚启动的线程有时间运行  
            Thread.sleep(100);    
            //workMethod方法在main线程中运行  
            vol.workMethod();  
        } catch ( InterruptedException x ) {  
            System.err.println("one of the sleeps was interrupted");  
        }  
    }  
}  

    执行结果如下：










   很明显，这其实并不符合使用volatile的第二个条件：该变量要没有包含在具有其他变量的不变式中。因此，在这里使用volatile是不安全的。


主内存与工作内存

    Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。此处的变量主要是指共享变量，存在竞争问题的变量。Java内存模型规定所有的变量都存储在主内存中，而每条线程还有自己的工作内存，线程的工作内存中保存了该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的变量（根据Java虚拟机规范的规定，volatile变量依然有共享内存的拷贝，但是由于它特殊的操作顺序性规定——从工作内存中读写数据前，必须先将主内存中的数据同步到工作内存中，所有看起来如同直接在主内存中读写访问一般，因此这里的描述对于volatile也不例外）。不同线程之间也无法直接访问对方工作内存中的变量，线程间变量值得传递均需要通过主内存来完成。






内存间交互操作



    Java内存模型中定义了以下8中操作来完成主内存与工作内存之间交互的实现细节：






    1、luck（锁定）：作用于主内存的变量，它把一个变量标示为一条线程独占的状态。

    2、unlock（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。

    3、read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到工作内存中，以便随后的load动作使用。

    4、load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。

    5、use（使用）：作用于工作内存的变量，它把工作内存中的一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值得字节码指令时将会执行这个操作。

    6、assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。

    7、store（存储）：作用于工作内存的变量，它把工作内存中的一个变量的值传递到主内存中，以便随后的write操作使用。

    8、write（写入）：作用于主内存的变量，它把store操作从工作内存中得到的变量值放入主内存的变量中。




   Java内存模型还规定了执行上述8种基本操作时必须满足如下规则：





    1、不允许read和load、store和write操作之一单独出现，以上两个操作必须按顺序执行，但没有保证必须连续执行，也就是说，read与load之间、store与write之间是可插入其他指令的。

    2、不允许一个线程丢弃它的最近的assign操作，即变量在工作内存中改变了之后必须把该变化同步回主内存。

    3、不允许一个线程无原因地（没有发生过任何assign操作）把数据从线程的工作内存同步回主内存中。

    4、一个新的变量只能从主内存中“诞生”，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量，换句话说就是对一个变量实施use和store操作之前，必须先执行过了assign和load操作。

    5、一个变量在同一个时刻只允许一条线程对其执行lock操作，但lock操作可以被同一个条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。

    6、如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行load或assign操作初始化变量的值。

    7、如果一个变量实现没有被lock操作锁定，则不允许对它执行unlock操作，也不允许去unlock一个被其他线程锁定的变量。

    8、对一个变量执行unlock操作之前，必须先把此变量同步回主内存（执行store和write操作）。






volatile型变量的特殊规则



    Java内存模型对volatile专门定义了一些特殊的访问规则，当一个变量被定义成volatile之后，他将具备两种特性：



    1、保证此变量对所有线程的可见性。这里不具体解释了。需要注意，volatile变量的写操作除了对它本身的读操作可见外，volatile写操作之前的所有共享变量均对volatile读操作之后的操作可见，另外注意其适用场景，详见http://blog.csdn.net/ns_code/article/details/17290021和http://blog.csdn.net/ns_code/article/details/17101369这两篇博文。

    2、禁止指令重排序优化。普通的变量仅仅会保证在该方法的执行过程中所有依赖赋值结果的地方都能获得正确的结果，而不能保证变量赋值操作的顺序与程序中的执行顺序一致，在单线程中，我们是无法感知这一点的。




    补充：Java语言规范规定了JVM线程内部维持顺序化语义，也就是说只要程序的最终结果等同于它在严格的顺序化环境下的结果，那么指令的执行顺序就可能与代码的顺序不一致，这个过程通过叫做指令的重排序。指令重排序存在的意义在于：JVM能够根据处理器的特性（CPU的多级缓存系统、多核处理器等）适当的重新排序机器指令，使机器指令更符合CPU的执行特点，最大限度的发挥机器的性能。在没有同步的情况下，编译器、处理器以及运行时等都可能对操作的执行顺序进行一些意想不到的调整






final域
    final类型的域是不能修改的，除了这一点外，在Java内存模型中，final域还有着特殊的语义，final域能确保初始化过程的安全性，从而可以不受限制地访问不可变对象，并在共享这些对象时无须同步。具体而言，就是被final修饰的字段在构造器中一旦被初始化完成，并且构造器没有把“this”的引用传递出去（this引用逃逸是一件很危险的事情，其他线程有可能通过这个引用访问到“初始化了一半”的对象），那么在其他线程中就能看到final字段的值，而且其外、外部可见状态永远也不会改变。它所带来的安全性是最简单最纯粹的。








long和double型变量的特殊规则



    Java内存模型要求lock、unlock、read、load、assign、use、store和write这8个操作都具有原子性，但是对于64位的数据类型long和double，在模型中特别定义了一条宽松的规定：允许虚拟机将没有被volatile修饰的64位数据的读写操作划分为两次32位的操作来进行。这样，如果有多个线程共享一个未被声明为volatile的long或double类型的变量，并且同时对它们进行读取和修改操作，那么某些线程可能会读到一个既非原值，也非其他线程修改值得代表了“半个变量”的数值。不过这种读取到“半个变量”的情况非常罕见，因为Java内存模型虽然允许虚拟机不把long和double变量的读写实现成原子操作，但允许迅疾选择把这些操作实现为具有原子性的操作，而且还“强烈建议”虚拟机这样实现。目前各种平台下的商用虚拟机几乎都选择吧64位数据的读写操作作为原子操作来对待，因此在编码时，不需要将long和double变量专门声明为volatile。


happen—before规则介绍

    Java语言中有一个“先行发生”（happen—before）的规则，它是Java内存模型中定义的两项操作之间的偏序关系，如果操作A先行发生于操作B，其意思就是说，在发生操作B之前，操作A产生的影响都能被操作B观察到，“影响”包括修改了内存中共享变量的值、发送了消息、调用了方法等，它与时间上的先后发生基本没有太大关系。这个原则特别重要，它是判断数据是否存在竞争、线程是否安全的主要依据。

    举例来说，假设存在如下三个线程，分别执行对应的操作:

---------------------------------------------------------------------------

线程A中执行如下操作：i=1

线程B中执行如下操作：j=i

线程C中执行如下操作：i=2


---------------------------------------------------------------------------


    假设线程A中的操作”i=1“ happen—before线程B中的操作“j=i”，那么就可以保证在线程B的操作执行后，变量j的值一定为1，即线程B观察到了线程A中操作“i=1”所产生的影响；现在，我们依然保持线程A和线程B之间的happen—before关系，同时线程C出现在了线程A和线程B的操作之间，但是C与B并没有happen—before关系，那么j的值就不确定了，线程C对变量i的影响可能会被线程B观察到，也可能不会，这时线程B就存在读取到不是最新数据的风险，不具备线程安全性。


    下面是Java内存模型中的八条可保证happen—before的规则，它们无需任何同步器协助就已经存在，可以在编码中直接使用。如果两个操作之间的关系不在此列，并且无法从下列规则推导出来的话，它们就没有顺序性保障，虚拟机可以对它们进行随机地重排序。




    1、程序次序规则：在一个单独的线程中，按照程序代码的执行流顺序，（时间上）先执行的操作happen—before（时间上）后执行的操作。

    2、管理锁定规则：一个unlock操作happen—before后面（时间上的先后顺序，下同）对同一个锁的lock操作。

    3、volatile变量规则：对一个volatile变量的写操作happen—before后面对该变量的读操作。

    4、线程启动规则：Thread对象的start（）方法happen—before此线程的每一个动作。

    5、线程终止规则：线程的所有操作都happen—before对此线程的终止检测，可以通过Thread.join（）方法结束、Thread.isAlive（）的返回值等手段检测到线程已经终止执行。

    6、线程中断规则：对线程interrupt（）方法的调用happen—before发生于被中断线程的代码检测到中断时事件的发生。

    7、对象终结规则：一个对象的初始化完成（构造函数执行结束）happen—before它的finalize（）方法的开始。

    8、传递性：如果操作A happen—before操作B，操作B happen—before操作C，那么可以得出A happen—before操作C。






时间上先后顺序和happen—before原则



    ”时间上执行的先后顺序“与”happen—before“之间有何不同呢？



    1、首先来看操作A在时间上先与操作B发生，是否意味着操作A happen—before操作B？

    一个常用来分析的例子如下：





[java] view
 plaincopy






private int value = 0;  
  
public int get(){  
    return value;  
}  
public void set(int value){  
    this.value = value;  
}  

    假设存在线程A和线程B，线程A先（时间上的先）调用了setValue（3）操作，然后（时间上的后）线程B调用了同一对象的getValue（）方法，那么线程B得到的返回值一定是3吗？



    对照以上八条happen—before规则，发现没有一条规则适合于这里的value变量，从而我们可以判定线程A中的setValue（3）操作与线程B中的getValue（）操作不存在happen—before关系。因此，尽管线程A的setValue（3）在操作时间上先于操作B的getvalue（），但无法保证线程B的getValue（）操作一定观察到了线程A的setValue（3）操作所产生的结果，也即是getValue（）的返回值不一定为3（有可能是之前setValue所设置的值）。这里的操作不是线程安全的。

    因此，”一个操作时间上先发生于另一个操作“并不代表”一个操作happen—before另一个操作“。

    解决方法：可以将setValue（int）方法和getValue（）方法均定义为synchronized方法，也可以把value定义为volatile变量（value的修改并不依赖value的原值，符合volatile的使用场景），分别对应happen—before规则的第2和第3条。注意，只将setValue（int）方法和getvalue（）方法中的一个定义为synchronized方法是不行的，必须对同一个变量的所有读写同步，才能保证不读取到陈旧的数据，仅仅同步读或写是不够的 。




    2、其次来看，操作A happen—before操作B，是否意味着操作A在时间上先与操作B发生？

    看有如下代码：



[java] view
 plaincopy






x = 1；  
y = 2;  

    假设同一个线程执行上面两个操作：操作A：x=1和操作B：y=2。根据happen—before规则的第1条，操作A happen—before 操作B，但是由于编译器的指令重排序（Java语言规范规定了JVM线程内部维持顺序化语义，也就是说只要程序的最终结果等同于它在严格的顺序化环境下的结果，那么指令的执行顺序就可能与代码的顺序不一致。这个过程通过叫做指令的重排序。指令重排序存在的意义在于：JVM能够根据处理器的特性（CPU的多级缓存系统、多核处理器等）适当的重新排序机器指令，使机器指令更符合CPU的执行特点，最大限度的发挥机器的性能。在没有同步的情况下，编译器、处理器以及运行时等都可能对操作的执行顺序进行一些意想不到的调整）等原因，操作A在时间上有可能后于操作B被处理器执行，但这并不影响happen—before原则的正确性。



    因此，”一个操作happen—before另一个操作“并不代表”一个操作时间上先发生于另一个操作“。




    最后，一个操作和另一个操作必定存在某个顺序，要么一个操作或者是先于或者是后于另一个操作，或者与两个操作同时发生。同时发生是完全可能存在的，特别是在多CPU的情况下。而两个操作之间却可能没有happen-before关系，也就是说有可能发生这样的情况，操作A不happen-before操作B，操作B也不happen-before操作A，用数学上的术语happen-before关系是个偏序关系。两个存在happen-before关系的操作不可能同时发生，一个操作A
 happen-before操作B，它们必定在时间上是完全错开的，这实际上也是同步的语义之一（独占访问）。







利用happen—before规则分析DCL




   DCL即双重检查加锁，关于单例模式的DCL机制，可以参看：http://blog.csdn.net/ns_code/article/details/17359719一文，这里不再详细介绍。下面是一个典型的在单例模式中使用DCL的例子：






[java] view
 plaincopy






public class LazySingleton {  
    private int someField;  
      
    private static LazySingleton instance;  
      
    private LazySingleton() {  
        this.someField = new Random().nextInt(200)+1;         // (1)  
    }  
      
    public static LazySingleton getInstance() {  
        if (instance == null) {                               // (2)  
            synchronized(LazySingleton.class) {               // (3)  
                if (instance == null) {                       // (4)  
                    instance = new LazySingleton();           // (5)  
                }  
            }  
        }  
        return instance;                                      // (6)  
    }  
      
    public int getSomeField() {  
        return this.someField;                                // (7)  
    }  
}  




    这里得到单一的instance实例是没有问题的，问题的关键在于尽管得到了Singleton的正确引用，但是却有可能访问到其成员变量的不正确值。具体来说Singleton.getInstance().getSomeField()有可能返回someField的默认值0。如果程序行为正确的话，这应当是不可能发生的事，因为在构造函数里设置的someField的值不可能为0。为也说明这种情况理论上有可能发生，我们只需要说明语句(1)和语句(7)并不存在happen-before关系。




   假设线程Ⅰ是初次调用getInstance()方法，紧接着线程Ⅱ也调用了getInstance()方法和getSomeField()方法，我们要说明的是线程Ⅰ的语句(1)并不happen-before线程Ⅱ的语句(7)。线程Ⅱ在执行getInstance()方法的语句(2)时，由于对instance的访问并没有处于同步块中，因此线程Ⅱ可能观察到也可能观察不到线程Ⅰ在语句(5)时对instance的写入，也就是说instance的值可能为空也可能为非空。我们先假设instance的值非空，也就观察到了线程Ⅰ对instance的写入，这时线程Ⅱ就会执行语句(6)直接返回这个instance的值，然后对这个instance调用getSomeField()方法，该方法也是在没有任何同步情况被调用，因此整个线程Ⅱ的操作都是在没有同步的情况下调用 ，这时我们便无法利用上述8条happen-before规则得到线程Ⅰ的操作和线程Ⅱ的操作之间的任何有效的happen-before关系（主要考虑规则的第2条，但由于线程Ⅱ没有在进入synchronized块，因此不存在lock与unlock锁的问题），这说明线程Ⅰ的语句(1)和线程Ⅱ的语句(7)之间并不存在happen-before关系，这就意味着线程Ⅱ在执行语句(7)完全有可能观测不到线程Ⅰ在语句(1)处对someFiled写入的值，这就是DCL的问题所在。很荒谬，是吧？DCL原本是为了逃避同步，它达到了这个目的，也正是因为如此，它最终受到惩罚，这样的程序存在严重的bug，虽然这种bug被发现的概率绝对比中彩票的概率还要低得多，而且是转瞬即逝，更可怕的是，即使发生了你也不会想到是DCL所引起的。




    前面我们说了，线程Ⅱ在执行语句(2)时也有可能观察空值，如果是种情况，那么它需要进入同步块，并执行语句(4)。在语句(4)处线程Ⅱ还能够读到instance的空值吗？不可能。这里因为这时对instance的写和读都是发生在同一个锁确定的同步块中，这时读到的数据是最新的数据。为也加深印象，我再用happen-before规则分析一遍。线程Ⅱ在语句(3)处会执行一个lock操作，而线程Ⅰ在语句(5)后会执行一个unlock操作，这两个操作都是针对同一个锁--Singleton.class，因此根据第2条happen-before规则，线程Ⅰ的unlock操作happen-before线程Ⅱ的lock操作，再利用单线程规则，线程Ⅰ的语句(5)
 -&gt; 线程Ⅰ的unlock操作，线程Ⅱ的lock操作 -&gt; 线程Ⅱ的语句(4)，再根据传递规则，就有线程Ⅰ的语句(5) -&gt; 线程Ⅱ的语句(4)，也就是说线程Ⅱ在执行语句(4)时能够观测到线程Ⅰ在语句(5)时对Singleton的写入值。接着对返回的instance调用getSomeField()方法时，我们也能得到线程Ⅰ的语句(1) -&gt; 线程Ⅱ的语句(7)（由于线程Ⅱ有进入synchronized块，根据规则2可得），这表明这时getSomeField能够得到正确的值。但是仅仅是这种情况的正确性并不妨碍DCL的不正确性，一个程序的正确性必须在所有的情况下的行为都是正确的，而不能有时正确，有时不正确。





    对DCL的分析也告诉我们一条经验原则：对引用（包括对象引用和数组引用）的非同步访问，即使得到该引用的最新值，却并不能保证也能得到其成员变量（对数组而言就是每个数组元素）的最新值。




   解决方案：

    1、最简单而且安全的解决方法是使用static内部类的思想，它利用的思想是：一个类直到被使用时才被初始化，而类初始化的过程是非并行的，这些都有JLS保证。

如下述代码：




[java] view
 plaincopy






public class Singleton {  
  
  private Singleton() {}  
  
  // Lazy initialization holder class idiom for static fields  
  private static class InstanceHolder {  
   private static final Singleton instance = new Singleton();  
  }  
  
  public static Singleton getSingleton() {   
    return InstanceHolder.instance;   
  }  
}  




 

    2、另外，可以将instance声明为volatile，即

private volatile static LazySingleton instance; 


 

    这样我们便可以得到，线程Ⅰ的语句(5) -&gt; 语线程Ⅱ的句(2)，根据单线程规则，线程Ⅰ的语句(1) -&gt; 线程Ⅰ的语句(5)和语线程Ⅱ的句(2) -&gt; 语线程Ⅱ的句(7)，再根据传递规则就有线程Ⅰ的语句(1) -&gt; 语线程Ⅱ的句(7)，这表示线程Ⅱ能够观察到线程Ⅰ在语句(1)时对someFiled的写入值，程序能够得到正确的行为。




   注：

    1、volatile屏蔽指令重排序的语义在JDK1.5中才被完全修复，此前的JDK中及时将变量声明为volatile，也仍然不能完全避免重排序所导致的问题（主要是volatile变量前后的代码仍然存在重排序问题），这点也是在JDK1.5之前的Java中无法安全使用DCL来实现单例模式的原因。

    2、把volatile写和volatile读这两个操作综合起来看，在读线程B读一个volatile变量后，写线程A在写这个volatile变量之前，所有可见的共享变量的值都将立即变得对读线程B可见。

 

   3、 在java5之前对final字段的同步语义和其它变量没有什么区别，在java5中，final变量一旦在构造函数中设置完成（前提是在构造函数中没有泄露this引用)，其它线程必定会看到在构造函数中设置的值。而DCL的问题正好在于看到对象的成员变量的默认值，因此我们可以将LazySingleton的someField变量设置成final，这样在java5中就能够正确运行了。










参考资料：http://www.iteye.com/topic/260515/

                 《深入理解Java虚拟机——JVM高级特性与最佳实践》第12章


这里比较下同步实现内存可见性的方法和通过volatile变量实现内存可见性的方法的区别。

 

    1、volatile变量是一种稍弱的同步机制在访问volatile变量时不会执行加锁操作，因此也就不会使执行线程阻塞，因此volatile变量是一种比synchronized关键字更轻量级的同步机制。

    2、从内存可见性的角度看，写入volatile变量相当于退出同步代码块，而读取volatile变量相当于进入同步代码块。

    3、在代码中如果过度依赖volatile变量来控制状态的可见性，通常会比使用锁的代码更脆弱，也更难以理解。仅当volatile变量能简化代码的实现以及对同步策略的验证时，才应该使用它。一般来说，用同步机制会更安全些。

    4、加锁机制（即同步机制）既可以确保可见性又可以确保原子性，而volatile变量只能确保可见性，原因是声明为volatile的简单变量如果当前值与该变量以前的值相关，那么volatile关键字不起作用，也就是说如下的表达式都不是原子操作：“count++”、“count
 = count+1”。

 

     当且仅当满足以下所有条件时，才应该使用volatile变量：

     1、对变量的写入操作不依赖变量的当前值，或者你能确保只有单个线程更新变量的值。

     2、该变量没有包含在具有其他变量的不变式中。




总结：在需要同步的时候，第一选择应该是synchronized关键字，这是最安全的方式，尝试其他任何方式都是有风险的。尤其在、jdK1.5之后，对synchronized同步机制做了很多优化，如：自适应的自旋锁、锁粗化、锁消除、轻量级锁等，使得它的性能明显有了很大的提升。


加锁（synchronized同步）的功能不仅仅局限于互斥行为，同时还存在另外一个重要的方面：内存可见性。我们不仅希望防止某个线程正在使用对象状态而另一个线程在同时修改该状态，而且还希望确保当一个线程修改了对象状态后，其他线程能够看到该变化。而线程的同步恰恰也能够实现这一点。

     内置锁可以用于确保某个线程以一种可预测的方式来查看另一个线程的执行结果。为了确保所有的线程都能看到共享变量的最新值，可以在所有执行读操作或写操作的线程上加上同一把锁。下图示例了同步的可见性保证。



     当线程A执行某个同步代码块时，线程B随后进入由同一个锁保护的同步代码块，这种情况下可以保证，当锁被释放前，A看到的所有变量值（锁释放前，A看到的变量包括y和x）在B获得同一个锁后同样可以由B看到。换句话说，当线程B执行由锁保护的同步代码块时，可以看到线程A之前在同一个锁保护的同步代码块中的所有操作结果。如果在线程A
 unlock M之后，线程B才进入lock M，那么线程B都可以看到线程A unlock M之前的操作，可以得到i=1，j=1。如果在线程B unlock M之后，线程A才进入lock M，那么线程B就不一定能看到线程A中的操作，因此j的值就不一定是1。

     现在考虑如下代码：



[java] view
 plaincopy






public class  MutableInteger  
{  
    private int value;  
  
    public int get(){  
        return value;  
    }  
    public void set(int value){  
        this.value = value;  
    }  
}  



     以上代码中，get和set方法都在没有同步的情况下访问value。如果value被多个线程共享，假如某个线程调用了set，那么另一个正在调用get的线程可能会看到更新后的value值，也可能看不到。

     通过对set和get方法进行同步，可以使MutableInteger成为一个线程安全的类，如下：



[java] view
 plaincopy






public class  SynchronizedInteger  
{  
    private int value;  
  
    public synchronized int get(){  
        return value;  
    }  
    public synchronized void set(int value){  
        this.value = value;  
    }  
}  



     对set和get方法进行了同步，加上了同一把对象锁，这样get方法可以看到set方法中value值的变化，从而每次通过get方法取得的value的值都是最新的value值。


生产者消费者问题是线程模型中的经典问题：生产者和消费者在同一时间段内共用同一存储空间，生产者向空间里生产数据，而消费者取走数据。

    这里实现如下情况的生产--消费模型：

    生产者不断交替地生产两组数据“姓名--1 --&gt; 内容--1”，“姓名--2--&gt; 内容--2”，消费者不断交替地取得这两组数据，这里的“姓名--1”和“姓名--2”模拟为数据的名称，“内容--1
 ”和“内容--2 ”模拟为数据的内容。

     由于本程序中牵扯到线程运行的不确定性，因此可能会出现以下问题：

     1、假设生产者线程刚向数据存储空间添加了数据的名称，还没有加入该信息的内容，程序就切换到了消费者线程，消费者线程将把信息的名称和上一个信息的内容联系在一起；

     2、生产者生产了若干次数据，消费者才开始取数据，或者是，消费者取完一次数据后，还没等生产者放入新的数据，又重复取出了已取过的数据。

 

     问题1很明显要靠同步来解决，问题2则需要线程间通信，生产者线程放入数据后，通知消费者线程取出数据，消费者线程取出数据后，通知生产者线程生产数据，这里用wait/notify机制来实现。

 

     详细的实现代码如下：



[java] view
 plaincopy






class Info{ // 定义信息类  
    private String name = "name";//定义name属性，为了与下面set的name属性区别开  
    private String content = "content" ;// 定义content属性，为了与下面set的content属性区别开  
    private boolean flag = true ;   // 设置标志位,初始时先生产  
    public synchronized void set(String name,String content){  
        while(!flag){  
            try{  
                super.wait() ;  
            }catch(InterruptedException e){  
                e.printStackTrace() ;  
            }  
        }  
        this.setName(name) ;    // 设置名称  
        try{  
            Thread.sleep(300) ;  
        }catch(InterruptedException e){  
            e.printStackTrace() ;  
        }  
        this.setContent(content) ;  // 设置内容  
        flag  = false ; // 改变标志位，表示可以取走  
        super.notify();  
    }  
    public synchronized void get(){  
        while(flag){  
            try{  
                super.wait() ;  
            }catch(InterruptedException e){  
                e.printStackTrace() ;  
            }  
        }  
        try{  
            Thread.sleep(300) ;  
        }catch(InterruptedException e){  
            e.printStackTrace() ;  
        }  
        System.out.println(this.getName() +   
            " --&gt; " + this.getContent()) ;  
        flag  = true ;  // 改变标志位，表示可以生产  
        super.notify();  
    }  
    public void setName(String name){  
        this.name = name ;  
    }  
    public void setContent(String content){  
        this.content = content ;  
    }  
    public String getName(){  
        return this.name ;  
    }  
    public String getContent(){  
        return this.content ;  
    }  
}  
class Producer implements Runnable{ // 通过Runnable实现多线程  
    private Info info = null ;      // 保存Info引用  
    public Producer(Info info){  
        this.info = info ;  
    }  
    public void run(){  
        boolean flag = true ;   // 定义标记位  
        for(int i=0;i&lt;10;i++){  
            if(flag){  
                this.info.set("姓名--1","内容--1") ;    // 设置名称  
                flag = false ;  
            }else{  
                this.info.set("姓名--2","内容--2") ;    // 设置名称  
                flag = true ;  
            }  
        }  
    }  
}  
class Consumer implements Runnable{  
    private Info info = null ;  
    public Consumer(Info info){  
        this.info = info ;  
    }  
    public void run(){  
        for(int i=0;i&lt;10;i++){  
            this.info.get() ;  
        }  
    }  
}  
public class ThreadCaseDemo03{  
    public static void main(String args[]){  
        Info info = new Info(); // 实例化Info对象  
        Producer pro = new Producer(info) ; // 生产者  
        Consumer con = new Consumer(info) ; // 消费者  
        new Thread(pro).start() ;  
        //启动了生产者线程后，再启动消费者线程  
        try{  
            Thread.sleep(500) ;  
        }catch(InterruptedException e){  
            e.printStackTrace() ;  
        }  
  
        new Thread(con).start() ;  
    }  
}  



     执行结果如下：



 

     另外，在run方法中，二者循环的次数要相同，否则，当一方的循环结束时，另一方的循环依然继续，它会阻塞在wait（）方法处，而等不到对方的notify通知。


如果线程在等待时接到通知，但线程等待的条件还不满足，此时，线程接到的就是早期通知，如果条件满足的时间很短，但很快又改变了，而变得不再满足，这时也将发生早期通知。这种现象听起来很奇怪，下面通过一个示例程序来说明问题。

    很简单，两个线程等待删除List中的元素，同时另外一个线程正要向其中添加项目。代码如下：



[java] view
 plaincopy






import java.util.*;  
  
public class EarlyNotify extends Object {  
    private List list;  
  
    public EarlyNotify() {  
        list = Collections.synchronizedList(new LinkedList());  
    }  
  
    public String removeItem() throws InterruptedException {  
        print("in removeItem() - entering");  
  
        synchronized ( list ) {  
            if ( list.isEmpty() ) {  //这里用if语句会发生危险  
                print("in removeItem() - about to wait()");  
                list.wait();  
                print("in removeItem() - done with wait()");  
            }  
  
            //删除元素  
            String item = (String) list.remove(0);  
  
            print("in removeItem() - leaving");  
            return item;  
        }  
    }  
  
    public void addItem(String item) {  
        print("in addItem() - entering");  
        synchronized ( list ) {  
            //添加元素  
            list.add(item);  
            print("in addItem() - just added: '" + item + "'");  
  
            //添加后，通知所有线程  
            list.notifyAll();  
            print("in addItem() - just notified");  
        }  
        print("in addItem() - leaving");  
    }  
  
    private static void print(String msg) {  
        String name = Thread.currentThread().getName();  
        System.out.println(name + ": " + msg);  
    }  
  
    public static void main(String[] args) {  
        final EarlyNotify en = new EarlyNotify();  
  
        Runnable runA = new Runnable() {  
                public void run() {  
                    try {  
                        String item = en.removeItem();  
                        print("in run() - returned: '" +   
                                item + "'");  
                    } catch ( InterruptedException ix ) {  
                        print("interrupted!");  
                    } catch ( Exception x ) {  
                        print("threw an Exception!!!\n" + x);  
                    }  
                }  
            };  
  
        Runnable runB = new Runnable() {  
                public void run() {  
                    en.addItem("Hello!");  
                }  
            };  
  
        try {  
            //启动第一个删除元素的线程  
            Thread threadA1 = new Thread(runA, "threadA1");  
            threadA1.start();  
  
            Thread.sleep(500);  
      
            //启动第二个删除元素的线程  
            Thread threadA2 = new Thread(runA, "threadA2");  
            threadA2.start();  
  
            Thread.sleep(500);  
            //启动增加元素的线程  
            Thread threadB = new Thread(runB, "threadB");  
            threadB.start();  
  
            Thread.sleep(10000); // wait 10 seconds  
  
            threadA1.interrupt();  
            threadA2.interrupt();  
        } catch ( InterruptedException x ) {}  
    }  
}  


    执行结果如下：



    

     分析：首先启动threadA1，threadA1在removeItem（）中调用wait（），从而释放list上的对象锁。再过500ms，启动threadA2，threadA2调用removeItem（），获取list上的对象锁，也发现列表为空，从而在wait（）方法处阻塞，释放list上的对象锁。再过500ms后，启动threadB，并调用addItem，获得list上的对象锁，并在list中添加一个元素，同时用notifyAll通知所有线程。

    threadA1和threadA2都从wait（）返回，等待获取list对象上的对象锁，并试图从列表中删除添加的元素，这就会产生麻烦，只有其中一个操作能成功。假设threadA1获取了list上的对象锁，并删除元素成功，在退出synchronized代码块时，它便会释放list上的对象锁，此时threadA2便会获取list上的对象锁，会继续删除list中的元素，但是list已经为空了，这便会抛出IndexOutOfBoundsException。

 

    要避免以上问题只需将wait外围的if语句改为while循环即可，这样当list为空时，线程便会继续等待，而不会继续去执行删除list中元素的代码。

    修改后的执行结果如下：



 

     总结：在使用线程的等待/通知机制时，一般都要在while循环中调用wait（）方法，满足条件时，才让while循环退出，这样一般也要配合使用一个boolean变量（或其他能判断真假的条件，如本文中的list.isEmpty()），满足while循环的条件时，进入while循环，执行wait（）方法，不满足while循环的条件时，跳出循环，执行后面的代码。


notify通知的遗漏很容易理解，即threadA还没开始wait的时候，threadB已经notify了，这样，threadB通知是没有任何响应的，当threadB退出synchronized代码块后，threadA再开始wait，便会一直阻塞等待，直到被别的线程打断。

 

遗漏通知的代码

    下面给出一段代码演示通知是如何遗漏的，如下：



[java] view
 plaincopy






public class MissedNotify extends Object {  
    private Object proceedLock;  
  
    public MissedNotify() {  
        print("in MissedNotify()");  
        proceedLock = new Object();  
    }  
  
    public void waitToProceed() throws InterruptedException {  
        print("in waitToProceed() - entered");  
  
        synchronized ( proceedLock ) {  
            print("in waitToProceed() - about to wait()");  
            proceedLock.wait();  
            print("in waitToProceed() - back from wait()");  
        }  
  
        print("in waitToProceed() - leaving");  
    }  
  
    public void proceed() {  
        print("in proceed() - entered");  
  
        synchronized ( proceedLock ) {  
            print("in proceed() - about to notifyAll()");  
            proceedLock.notifyAll();  
            print("in proceed() - back from notifyAll()");  
        }  
  
        print("in proceed() - leaving");  
    }  
  
    private static void print(String msg) {  
        String name = Thread.currentThread().getName();  
        System.out.println(name + ": " + msg);  
    }  
  
    public static void main(String[] args) {  
        final MissedNotify mn = new MissedNotify();  
  
        Runnable runA = new Runnable() {  
                public void run() {  
                    try {  
                        //休眠1000ms，大于runB中的500ms，  
                        //是为了后调用waitToProceed，从而先notifyAll，后wait，  
                        //从而造成通知的遗漏  
                        Thread.sleep(1000);  
                        mn.waitToProceed();  
                    } catch ( InterruptedException x ) {  
                        x.printStackTrace();  
                    }  
                }  
            };  
  
        Thread threadA = new Thread(runA, "threadA");  
        threadA.start();  
  
        Runnable runB = new Runnable() {  
                public void run() {  
                    try {  
                        //休眠500ms，小于runA中的1000ms，  
                        //是为了先调用proceed，从而先notifyAll，后wait，  
                        //从而造成通知的遗漏  
                        Thread.sleep(500);  
                        mn.proceed();  
                    } catch ( InterruptedException x ) {  
                        x.printStackTrace();  
                    }  
                }  
            };  
  
        Thread threadB = new Thread(runB, "threadB");  
        threadB.start();  
  
        try {   
            Thread.sleep(10000);  
        } catch ( InterruptedException x ) {}  
  
        //试图打断wait阻塞  
        print("about to invoke interrupt() on threadA");  
        threadA.interrupt();  
    }  
}  



    执行结果如下：



 

    分析：由于threadB在执行mn.proceed（）之前只休眠了500ms，而threadA在执行mn.waitToProceed（）之前休眠了1000ms，因此，threadB会先苏醒，继而执行mn.proceed（），获取到proceedLock的对象锁，继而执行其中的notifyAll（），当退出proceed（）方法中的synchronized代码块时，threadA才有机会获取proceedLock的对象锁，继而执行其中的wait（）方法，但此时notifyAll（）方法已经执行完毕，threadA便漏掉了threadB的通知，便会阻塞下去。后面主线程休眠10秒后，尝试中断threadA线程，使其抛出InterruptedException。

   

修正后的代码

    为了修正MissedNotify，需要添加一个boolean指示变量，该变量只能在同步代码块内部访问和修改。修改后的代码如下：



[java] view
 plaincopy






public class MissedNotifyFix extends Object {  
    private Object proceedLock;  
    //该标志位用来指示线程是否需要等待  
    private boolean okToProceed;  
  
    public MissedNotifyFix() {  
        print("in MissedNotify()");  
        proceedLock = new Object();  
        //先设置为false  
        okToProceed = false;  
    }  
  
    public void waitToProceed() throws InterruptedException {  
        print("in waitToProceed() - entered");  
  
        synchronized ( proceedLock ) {  
            print("in waitToProceed() - entered sync block");  
            //while循环判断，这里不用if的原因是为了防止早期通知  
            while ( okToProceed == false ) {  
                print("in waitToProceed() - about to wait()");  
                proceedLock.wait();  
                print("in waitToProceed() - back from wait()");  
            }  
  
            print("in waitToProceed() - leaving sync block");  
        }  
  
        print("in waitToProceed() - leaving");  
    }  
  
    public void proceed() {  
        print("in proceed() - entered");  
  
        synchronized ( proceedLock ) {  
            print("in proceed() - entered sync block");  
            //通知之前，将其设置为true，这样即使出现通知遗漏的情况，也不会使线程在wait出阻塞  
            okToProceed = true;  
            print("in proceed() - changed okToProceed to true");  
            proceedLock.notifyAll();  
            print("in proceed() - just did notifyAll()");  
  
            print("in proceed() - leaving sync block");  
        }  
  
        print("in proceed() - leaving");  
    }  
  
    private static void print(String msg) {  
        String name = Thread.currentThread().getName();  
        System.out.println(name + ": " + msg);  
    }  
  
    public static void main(String[] args) {  
        final MissedNotifyFix mnf = new MissedNotifyFix();  
  
        Runnable runA = new Runnable() {  
                public void run() {  
                    try {  
                        //休眠1000ms，大于runB中的500ms，  
                        //是为了后调用waitToProceed，从而先notifyAll，后wait，  
                        Thread.sleep(1000);  
                        mnf.waitToProceed();  
                    } catch ( InterruptedException x ) {  
                        x.printStackTrace();  
                    }  
                }  
            };  
  
        Thread threadA = new Thread(runA, "threadA");  
        threadA.start();  
  
        Runnable runB = new Runnable() {  
                public void run() {  
                    try {  
                        //休眠500ms，小于runA中的1000ms，  
                        //是为了先调用proceed，从而先notifyAll，后wait，  
                        Thread.sleep(500);  
                        mnf.proceed();  
                    } catch ( InterruptedException x ) {  
                        x.printStackTrace();  
                    }  
                }  
            };  
  
        Thread threadB = new Thread(runB, "threadB");  
        threadB.start();  
  
        try {   
            Thread.sleep(10000);  
        } catch ( InterruptedException x ) {}  
  
        print("about to invoke interrupt() on threadA");  
        threadA.interrupt();  
    }  
}  


    执行结果如下：



    注意代码中加了注释的部分，在threadB进行通知之前，先将okToProceed置为true，这样如果threadA将通知遗漏，那么就不会进入while循环，也便不会执行wait方法，线程也就不会阻塞。如果通知没有被遗漏，wait方法返回后，okToProceed已经被置为true，下次while循环判断条件不成立，便会退出循环。

    这样，通过标志位和wait、notifyAll的配合使用，便避免了通知遗漏而造成的阻塞问题。

 

   总结：在使用线程的等待/通知机制时，一般都要配合一个boolean变量值（或者其他能够判断真假的条件），在notify之前改变该boolean变量的值，让wait返回后能够退出while循环（一般都要在wait方法外围加一层while循环，以防止早期通知），或在通知被遗漏后，不会被阻塞在wait方法处。这样便保证了程序的正确性。


在Java中，可以通过配合调用Object对象的wait（）方法和notify（）方法或notifyAll（）方法来实现线程间的通信。在线程中调用wait（）方法，将阻塞等待其他线程的通知（其他线程调用notify（）方法或notifyAll（）方法），在线程中调用notify（）方法或notifyAll（）方法，将通知其他线程从wait（）方法处返回。




      Object是所有类的超类，它有5个方法组成了等待/通知机制的核心：notify（）、notifyAll（）、wait（）、wait（long）和wait（long，int）。在Java中，所有的类都从Object继承而来，因此，所有的类都拥有这些共有方法可供使用。而且，由于他们都被声明为final，因此在子类中不能覆写任何一个方法。

 

     这里详细说明一下各个方法在使用中需要注意的几点：

 

      1、wait（）

      public final void wait()  throws InterruptedException,IllegalMonitorStateException

     该方法用来将当前线程置入休眠状态，直到接到通知或被中断为止。在调用wait（）之前，线程必须要获得该对象的对象级别锁，即只能在同步方法或同步块中调用wait（）方法。进入wait（）方法后，当前线程释放锁。在从wait（）返回前，线程与其他线程竞争重新获得锁。如果调用wait（）时，没有持有适当的锁，则抛出IllegalMonitorStateException，它是RuntimeException的一个子类，因此，不需要try-catch结构。

 

     2、notify（）

     public final native void notify() throws IllegalMonitorStateException

        该方法也要在同步方法或同步块中调用，即在调用前，线程也必须要获得该对象的对象级别锁，的如果调用notify（）时没有持有适当的锁，也会抛出IllegalMonitorStateException。

     该方法用来通知那些可能等待该对象的对象锁的其他线程。如果有多个线程等待，则线程规划器任意挑选出其中一个wait（）状态的线程来发出通知，并使它等待获取该对象的对象锁（notify后，当前线程不会马上释放该对象锁，wait所在的线程并不能马上获取该对象锁，要等到程序退出synchronized代码块后，当前线程才会释放锁，wait所在的线程也才可以获取该对象锁），但不惊动其他同样在等待被该对象notify的线程们。当第一个获得了该对象锁的wait线程运行完毕以后，它会释放掉该对象锁，此时如果该对象没有再次使用notify语句，则即便该对象已经空闲，其他wait状态等待的线程由于没有得到该对象的通知，会继续阻塞在wait状态，直到这个对象发出一个notify或notifyAll。这里需要注意：它们等待的是被notify或notifyAll，而不是锁。这与下面的notifyAll（）方法执行后的情况不同。 

 

     3、notifyAll（）

     public final native void notifyAll() throws IllegalMonitorStateException

      该方法与notify（）方法的工作方式相同，重要的一点差异是：

      notifyAll使所有原来在该对象上wait的线程统统退出wait的状态（即全部被唤醒，不再等待notify或notifyAll，但由于此时还没有获取到该对象锁，因此还不能继续往下执行），变成等待获取该对象上的锁，一旦该对象锁被释放（notifyAll线程退出调用了notifyAll的synchronized代码块的时候），他们就会去竞争。如果其中一个线程获得了该对象锁，它就会继续往下执行，在它退出synchronized代码块，释放锁后，其他的已经被唤醒的线程将会继续竞争获取该锁，一直进行下去，直到所有被唤醒的线程都执行完毕。

 

     4、wait（long）和wait（long,int）

     显然，这两个方法是设置等待超时时间的，后者在超值时间上加上ns，精度也难以达到，因此，该方法很少使用。对于前者，如果在等待线程接到通知或被中断之前，已经超过了指定的毫秒数，则它通过竞争重新获得锁，并从wait（long）返回。另外，需要知道，如果设置了超时时间，当wait（）返回时，我们不能确定它是因为接到了通知还是因为超时而返回的，因为wait（）方法不会返回任何相关的信息。但一般可以通过设置标志位来判断，在notify之前改变标志位的值，在wait（）方法后读取该标志位的值来判断，当然为了保证notify不被遗漏，我们还需要另外一个标志位来循环判断是否调用wait（）方法。

 




       深入理解：

   如果线程调用了对象的wait（）方法，那么线程便会处于该对象的等待池中，等待池中的线程不会去竞争该对象的锁。

   当有线程调用了对象的notifyAll（）方法（唤醒所有wait线程）或notify（）方法（只随机唤醒一个wait线程），被唤醒的的线程便会进入该对象的锁池中，锁池中的线程会去竞争该对象锁。

   优先级高的线程竞争到对象锁的概率大，假若某线程没有竞争到该对象锁，它还会留在锁池中，唯有线程再次调用wait（）方法，它才会重新回到等待池中。而竞争到对象锁的线程则继续往下执行，直到执行完了synchronized代码块，它会释放掉该对象锁，这时锁池中的线程会继续竞争该对象锁。


当线程需要同时持有多个锁时，有可能产生死锁。考虑如下情形：

      线程A当前持有互斥所锁lock1，线程B当前持有互斥锁lock2。接下来，当线程A仍然持有lock1时，它试图获取lock2，因为线程B正持有lock2，因此线程A会阻塞等待线程B对lock2的释放。如果此时线程B在持有lock2的时候，也在试图获取lock1，因为线程A正持有lock1，因此线程B会阻塞等待A对lock1的释放。二者都在等待对方所持有锁的释放，而二者却又都没释放自己所持有的锁，这时二者便会一直阻塞下去。这种情形称为死锁。

      下面给出一个两个线程间产生死锁的示例，如下：





[java] view
 plaincopy






public class Deadlock extends Object {  
    private String objID;  
  
    public Deadlock(String id) {  
        objID = id;  
    }  
  
    public synchronized void checkOther(Deadlock other) {  
        print("entering checkOther()");  
        try { Thread.sleep(2000); }   
        catch ( InterruptedException x ) { }  
        print("in checkOther() - about to " + "invoke 'other.action()'");  
  
        //调用other对象的action方法，由于该方法是同步方法，因此会试图获取other对象的对象锁  
        other.action();  
        print("leaving checkOther()");  
    }  
  
    public synchronized void action() {  
        print("entering action()");  
        try { Thread.sleep(500); }   
        catch ( InterruptedException x ) { }  
        print("leaving action()");  
    }  
  
    public void print(String msg) {  
        threadPrint("objID=" + objID + " - " + msg);  
    }  
  
    public static void threadPrint(String msg) {  
        String threadName = Thread.currentThread().getName();  
        System.out.println(threadName + ": " + msg);  
    }  
  
    public static void main(String[] args) {  
        final Deadlock obj1 = new Deadlock("obj1");  
        final Deadlock obj2 = new Deadlock("obj2");  
  
        Runnable runA = new Runnable() {  
                public void run() {  
                    obj1.checkOther(obj2);  
                }  
            };  
  
        Thread threadA = new Thread(runA, "threadA");  
        threadA.start();  
  
        try { Thread.sleep(200); }   
        catch ( InterruptedException x ) { }  
  
        Runnable runB = new Runnable() {  
                public void run() {  
                    obj2.checkOther(obj1);  
                }  
            };  
  
        Thread threadB = new Thread(runB, "threadB");  
        threadB.start();  
  
        try { Thread.sleep(5000); }   
        catch ( InterruptedException x ) { }  
  
        threadPrint("finished sleeping");  
  
        threadPrint("about to interrupt() threadA");  
        threadA.interrupt();  
  
        try { Thread.sleep(1000); }   
        catch ( InterruptedException x ) { }  
  
        threadPrint("about to interrupt() threadB");  
        threadB.interrupt();  
  
        try { Thread.sleep(1000); }   
        catch ( InterruptedException x ) { }  
  
        threadPrint("did that break the deadlock?");  
    }  
}  


     运行结果如下：






     从结果中可以看出，在执行到other.action（）时，由于两个线程都在试图获取对方的锁，但对方都没有释放自己的锁，因而便产生了死锁，在主线程中试图中断两个线程，但都无果。




     大部分代码并不容易产生死锁，死锁可能在代码中隐藏相当长的时间，等待不常见的条件地发生，但即使是很小的概率，一旦发生，便可能造成毁灭性的破坏。避免死锁是一件困难的事，遵循以下原则有助于规避死锁： 

     1、只在必要的最短时间内持有锁，考虑使用同步语句块代替整个同步方法；

     2、尽量编写不在同一时刻需要持有多个锁的代码，如果不可避免，则确保线程持有第二个锁的时间尽量短暂；

     3、创建和使用一个大锁来代替若干小锁，并把这个锁用于互斥，而不是用作单个对象的对象级别锁；


在集合API中，最初设计的Vector和Hashtable是多线程安全的。例如：对于Vector来说，用来添加和删除元素的方法是同步的。如果只有一个线程与Vector的实例交互，那么，要求获取和释放对象锁便是一种浪费，另外在不必要的时候如果滥用同步化，也有可能会带来死锁。因此，对于更改集合内容的方法，没有一个是同步化的。集合本质上是非多线程安全的，当多个线程与集合交互时，为了使它多线程安全，必须采取额外的措施。

     在Collections类 中有多个静态方法，它们可以获取通过同步方法封装非同步集合而得到的集合：

     public static Collection synchronizedCollention(Collection c)

     public static List synchronizedList(list l)

     public static Map synchronizedMap(Map m)

     public static Set synchronizedSet(Set s)

     public static SortedMap synchronizedSortedMap(SortedMap sm)

     public static SortedSet synchronizedSortedSet(SortedSet ss)

     这些方法基本上返回具有同步集合方法版本的新类。比如，为了创建多线程安全且由ArrayList支持的List，可以使用如下代码：

List list = Collection.synchronizedList(new ArrayList());

     注意，ArrayList实例马上封装起来，不存在对未同步化ArrayList的直接引用（即直接封装匿名实例）。这是一种最安全的途径。如果另一个线程要直接引用ArrayList实例，它可以执行非同步修改。




     下面给出一段多线程中安全遍历集合元素的示例。我们使用Iterator逐个扫描List中的元素，在多线程环境中，当遍历当前集合中的元素时，一般希望阻止其他线程添加或删除元素。安全遍历的实现方法如下：





[java] view
 plaincopy






import java.util.*;  
  
public class SafeCollectionIteration extends Object {  
    public static void main(String[] args) {  
        //为了安全起见，仅使用同步列表的一个引用，这样可以确保控制了所有访问  
        //集合必须同步化，这里是一个List  
        List wordList = Collections.synchronizedList(new ArrayList());  
  
        //wordList中的add方法是同步方法，会获取wordList实例的对象锁  
        wordList.add("Iterators");  
        wordList.add("require");  
        wordList.add("special");  
        wordList.add("handling");  
  
        //获取wordList实例的对象锁，  
        //迭代时，阻塞其他线程调用add或remove等方法修改元素  
        synchronized ( wordList ) {  
            Iterator iter = wordList.iterator();  
            while ( iter.hasNext() ) {  
                String s = (String) iter.next();  
                System.out.println("found string: " + s + ", length=" + s.length());  
            }  
        }  
    }  
}  



     这里需要注意的是：在Java语言中，大部分的线程安全类都是相对线程安全的，它能保证对这个对象单独的操作时线程安全的，我们在调用的时候不需要额外的保障措施，但是对于一些特定的连续调用，就可能需要在调用端使用额外的同步手段来保证调用的正确性。例如Vector、HashTable、Collections的synchronizedXxxx（）方法包装的集合等。


在并发编程中，多线程同时并发访问的资源叫做临界资源，当多个线程同时访问对象并要求操作相同资源时，分割了原子操作就有可能出现数据的不一致或数据不完整的情况，为避免这种情况的发生，我们会采取同步机制，以确保在某一时刻，方法内只允许有一个线程。

      采用synchronized修饰符实现的同步机制叫做互斥锁机制，它所获得的锁叫做互斥锁。每个对象都有一个monitor(锁标记)，当线程拥有这个锁标记时才能访问这个资源，没有锁标记便进入锁池。任何一个对象系统都会为其创建一个互斥锁，这个锁是为了分配给线程的，防止打断原子操作。每个对象的锁只能分配给一个线程，因此叫做互斥锁。

 

      这里就使用同步机制获取互斥锁的情况，进行几点说明：




      1、如果同一个方法内同时有两个或更多线程，则每个线程有自己的局部变量拷贝。




      2、类的每个实例都有自己的对象级别锁。当一个线程访问实例对象中的synchronized同步代码块或同步方法时，该线程便获取了该实例的对象级别锁，其他线程这时如果要访问synchronized同步代码块或同步方法，便需要阻塞等待，直到前面的线程从同步代码块或方法中退出，释放掉了该对象级别锁。




      3、访问同一个类的不同实例对象中的同步代码块，不存在阻塞等待获取对象锁的问题，因为它们获取的是各自实例的对象级别锁，相互之间没有影响。




      4、持有一个对象级别锁不会阻止该线程被交换出来，也不会阻塞其他线程访问同一示例对象中的非synchronized代码。当一个线程A持有一个对象级别锁（即进入了synchronized修饰的代码块或方法中）时，线程也有可能被交换出去，此时线程B有可能获取执行该对象中代码的时间，但它只能执行非同步代码（没有用synchronized修饰），当执行到同步代码时，便会被阻塞，此时可能线程规划器又让A线程运行，A线程继续持有对象级别锁，当A线程退出同步代码时（即释放了对象级别锁），如果B线程此时再运行，便会获得该对象级别锁，从而执行synchronized中的代码。




     5、持有对象级别锁的线程会让其他线程阻塞在所有的synchronized代码外。例如，在一个类中有三个synchronized方法a，b，c，当线程A正在执行一个实例对象M中的方法a时，它便获得了该对象级别锁，那么其他的线程在执行同一实例对象（即对象M）中的代码时，便会在所有的synchronized方法处阻塞，即在方法a，b，c处都要被阻塞，等线程A释放掉对象级别锁时，其他的线程才可以去执行方法a，b或者c中的代码，从而获得该对象级别锁。




     6、使用synchronized（obj）同步语句块，可以获取指定对象上的对象级别锁。obj为对象的引用，如果获取了obj对象上的对象级别锁，在并发访问obj对象时时，便会在其synchronized代码处阻塞等待，直到获取到该obj对象的对象级别锁。当obj为this时，便是获取当前对象的对象级别锁。




     7、类级别锁被特定类的所有示例共享，它用于控制对static成员变量以及static方法的并发访问。具体用法与对象级别锁相似。




    8、互斥是实现同步的一种手段，临界区、互斥量和信号量都是主要的互斥实现方式。synchronized关键字经过编译后，会在同步块的前后分别形成monitorenter和monitorexit这两个字节码指令。根据虚拟机规范的要求，在执行monitorenter指令时，首先要尝试获取对象的锁，如果获得了锁，把锁的计数器加1，相应地，在执行monitorexit指令时会将锁计数器减1，当计数器为0时，锁便被释放了。由于synchronized同步块对同一个线程是可重入的，因此一个线程可以多次获得同一个对象的互斥锁，同样，要释放相应次数的该互斥锁，才能最终释放掉该锁。


Java中实现多线程有两种方法：继承Thread类、实现Runnable接口，在程序开发中只要是多线程，肯定永远以实现Runnable接口为主，因为实现Runnable接口相比继承Thread类有如下优势：

    1、可以避免由于Java的单继承特性而带来的局限；

    2、增强程序的健壮性，代码能够被多个线程共享，代码与数据是独立的；

    3、适合多个相同程序代码的线程区处理同一资源的情况。




    下面以典型的买票程序（基本都是以这个为例子）为例，来说明二者的区别。

    首先通过继承Thread类实现，代码如下：





[java] view
 plaincopy






class MyThread extends Thread{  
    private int ticket = 5;  
    public void run(){  
        for (int i=0;i&lt;10;i++)  
        {  
            if(ticket &gt; 0){  
                System.out.println("ticket = " + ticket--);  
            }  
        }  
    }  
}  
  
public class ThreadDemo{  
    public static void main(String[] args){  
        new MyThread().start();  
        new MyThread().start();  
        new MyThread().start();  
    }  
}  

    某次的执行结果如下：











    从结果中可以看出，每个线程单独卖了5张票，即独立地完成了买票的任务，但实际应用中，比如火车站售票，需要多个线程去共同完成任务，在本例中，即多个线程共同买5张票。


    下面是通过实现Runnable接口实现的多线程程序，代码如下：





[java] view
 plaincopy






class MyThread implements Runnable{  
    private int ticket = 5;  
    public void run(){  
        for (int i=0;i&lt;10;i++)  
        {  
            if(ticket &gt; 0){  
                System.out.println("ticket = " + ticket--);  
            }  
        }  
    }  
}  
  
public class RunnableDemo{  
    public static void main(String[] args){  
        MyThread my = new MyThread();  
        new Thread(my).start();  
        new Thread(my).start();  
        new Thread(my).start();  
    }  
}  

    某次的执行结果如下:






    从结果中可以看出，三个线程一共卖了5张票，即它们共同完成了买票的任务，实现了资源的共享。




   针对以上代码补充三点：

    1、在第二种方法（Runnable）中，ticket输出的顺序并不是54321，这是因为线程执行的时机难以预测，ticket--并不是原子操作。

    2、在第一种方法中，我们new了3个Thread对象，即三个线程分别执行三个对象中的代码，因此便是三个线程去独立地完成卖票的任务；而在第二种方法中，我们同样也new了3个Thread对象，但只有一个Runnable对象，3个Thread对象共享这个Runnable对象中的代码，因此，便会出现3个线程共同完成卖票任务的结果。如果我们new出3个Runnable对象，作为参数分别传入3个Thread对象中，那么3个线程便会独立执行各自Runnable对象中的代码，即3个线程各自卖5张票。

    3、在第二种方法中，由于3个Thread对象共同执行一个Runnable对象中的代码，因此可能会造成线程的不安全，比如可能ticket会输出-1（如果我们System.out....语句前加上线程休眠操作，该情况将很有可能出现），这种情况的出现是由于，一个线程在判断ticket为1&gt;0后，还没有来得及减1，另一个线程已经将ticket减1，变为了0，那么接下来之前的线程再将ticket减1，便得到了-1。这就需要加入同步操作（即互斥锁），确保同一时刻只有一个线程在执行每次for循环中的操作。而在第一种方法中，并不需要加入同步操作，因为每个线程执行自己Thread对象中的代码，不存在多个线程共同执行同一个方法的情况。


volatile用处说明

    在JDK1.2之前，Java的内存模型实现总是从主存（即共享内存）读取变量，是不需要进行特别的注意的。而随着JVM的成熟和优化，现在在多线程环境下volatile关键字的使用变得非常重要。



在当前的Java内存模型下，线程可以把变量保存在本地内存（比如机器的寄存器）中，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，造成数据的不一致。

要解决这个问题，就需要把变量声明为volatile（也可以使用同步，参见http://blog.csdn.net/ns_code/article/details/17288243），这就指示JVM，这个变量是不稳定的，每次使用它都到主存中进行读取。一般说来，多任务环境下，各任务间共享的变量都应该加volatile修饰符。

Volatile修饰的成员变量在每次被线程访问时，都强迫从共享内存中重读该成员变量的值。而且，当成员变量发生变化时，强迫线程将变化值回写到共享内存。这样在任何时刻，两个不同的线程总是看到某个成员变量的同一个值。

Java语言规范中指出：为了获得最佳速度，允许线程保存共享成员变量的私有拷贝，而且只当线程进入或者离开同步代码块时才将私有拷贝与共享内存中的原始值进行比较。

这样当多个线程同时与某个对象交互时，就必须注意到要让线程及时的得到共享成员变量的变化。而volatile关键字就是提示JVM：对于这个成员变量，不能保存它的私有拷贝，而应直接与共享成员变量交互。

volatile是一种稍弱的同步机制，在访问volatile变量时不会执行加锁操作，也就不会执行线程阻塞，因此volatilei变量是一种比synchronized关键字更轻量级的同步机制。

使用建议：在两个或者更多的线程需要访问的成员变量上使用volatile。当要访问的变量已在synchronized代码块中，或者为常量时，没必要使用volatile。

由于使用volatile屏蔽掉了JVM中必要的代码优化，所以在效率上比较低，因此一定在必要时才使用此关键字。





示例程序
下面给出一段代码，通过其运行结果来说明使用关键字volatile产生的差异，但实际上遇到了意料之外的问题：




[java] view
 plaincopy






public class Volatile extends Object implements Runnable {  
    //value变量没有被标记为volatile  
    private int value;    
    //missedIt变量被标记为volatile  
    private volatile boolean missedIt;  
    //creationTime不需要声明为volatile，因为代码执行中它没有发生变化  
    private long creationTime;   
  
    public Volatile() {  
        value = 10;  
        missedIt = false;  
        //获取当前时间，亦即调用Volatile构造函数时的时间  
        creationTime = System.currentTimeMillis();  
    }  
  
    public void run() {  
        print("entering run()");  
  
        //循环检查value的值是否不同  
        while ( value &lt; 20 ) {  
            //如果missedIt的值被修改为true，则通过break退出循环  
            if  ( missedIt ) {  
                //进入同步代码块前，将value的值赋给currValue  
                int currValue = value;  
                //在一个任意对象上执行同步语句，目的是为了让该线程在进入和离开同步代码块时，  
                //将该线程中的所有变量的私有拷贝与共享内存中的原始值进行比较，  
                //从而发现没有用volatile标记的变量所发生的变化  
                Object lock = new Object();  
                synchronized ( lock ) {  
                    //不做任何事  
                }  
                //离开同步代码块后，将此时value的值赋给valueAfterSync  
                int valueAfterSync = value;  
                print("in run() - see value=" + currValue +", but rumor has it that it changed!");  
                print("in run() - valueAfterSync=" + valueAfterSync);  
                break;   
            }  
        }  
        print("leaving run()");  
    }  
  
    public void workMethod() throws InterruptedException {  
        print("entering workMethod()");  
        print("in workMethod() - about to sleep for 2 seconds");  
        Thread.sleep(2000);  
        //仅在此改变value的值  
        value = 50;  
        print("in workMethod() - just set value=" + value);  
        print("in workMethod() - about to sleep for 5 seconds");  
        Thread.sleep(5000);  
        //仅在此改变missedIt的值  
        missedIt = true;  
        print("in workMethod() - just set missedIt=" + missedIt);  
        print("in workMethod() - about to sleep for 3 seconds");  
        Thread.sleep(3000);  
        print("leaving workMethod()");  
    }  
  
/* 
*该方法的功能是在要打印的msg信息前打印出程序执行到此所化去的时间，以及打印msg的代码所在的线程 
*/  
    private void print(String msg) {  
        //使用java.text包的功能，可以简化这个方法，但是这里没有利用这一点  
        long interval = System.currentTimeMillis() - creationTime;  
        String tmpStr = "    " + ( interval / 1000.0 ) + "000";       
        int pos = tmpStr.indexOf(".");  
        String secStr = tmpStr.substring(pos - 2, pos + 4);  
        String nameStr = "        " + Thread.currentThread().getName();  
        nameStr = nameStr.substring(nameStr.length() - 8, nameStr.length());      
        System.out.println(secStr + " " + nameStr + ": " + msg);  
    }  
  
    public static void main(String[] args) {  
        try {  
            //通过该构造函数可以获取实时时钟的当前时间  
            Volatile vol = new Volatile();  
  
            //稍停100ms，以让实时时钟稍稍超前获取时间，使print（）中创建的消息打印的时间值大于0  
            Thread.sleep(100);    
  
            Thread t = new Thread(vol);  
            t.start();  
  
            //休眠100ms，让刚刚启动的线程有时间运行  
            Thread.sleep(100);    
            //workMethod方法在main线程中运行  
            vol.workMethod();  
        } catch ( InterruptedException x ) {  
            System.err.println("one of the sleeps was interrupted");  
        }  
    }  
}  


按照以上的理论来分析，由于value变量不是volatile的，因此它在main线程中的改变不会被Thread-0线程（在main线程中新开启的线程）马上看到，因此Thread-0线程中的while循环不会直接退出，它会继续判断missedIt的值，由于missedIt是volatile的，当main线程中改变了missedIt时，Thread-0线程会立即看到该变化，那么if语句中的代码便得到了执行的机会，由于此时Thread-0依然没有看到value值的变化，因此，currValue的值为10，继续向下执行，进入同步代码块，因为进入前后要将该线程内的变量值与共享内存中的原始值对比，进行校准，因此离开同步代码块后，Thread-0便会察觉到value的值变为了50，那么后面的valueAfterSync的值便为50，最后从break跳出循环，结束Thread-0线程。



意料之外的问题

但实际的执行结果如下：


从结果中可以看出，Thread-0线程并没有进入while循环，说明Thread-0线程在value的值发生变化后，missedIt的值发生变化前，便察觉到了value值的变化，从而退出了while循环。这与理论上的分析不符，我便尝试注释掉value值发生改变与missedIt值发生改变之间的线程休眠代码Thread.sleep(5000)，以确保Thread-0线程在missedIt的值发生改变前，没有时间察觉到value值的变化。但执行的结果与上面大同小异（可能有一两行顺序不同，但依然不会打印出if语句中的输出信息）。



问题分析

在JDK1.7~JDK1.3之间的版本上输出结果与上面基本大同小异，只有在JDK1.2上才得到了预期的结果，即Thread-0线程中的while循环是从if语句中退出的，这说明Thread-0线程没有及时察觉到value值的变化。
这里需要注意：volatile是针对JIT带来的优化，因此JDK1.2以前的版本基本不用考虑，另外，在JDK1.3.1开始，开始运用HotSpot虚拟机，用来代替JIT。因此，是不是HotSpot的问题呢？这里需要再补充一点：
JIT或HotSpot编译器在server模式和client模式编译不同，server模式为了使线程运行更快，如果其中一个线程更改了变量boolean flag 的值，那么另外一个线程会看不到，因为另外一个线程为了使得运行更快所以从寄存器或者本地cache中取值，而不是从内存中取值，那么使用volatile后，就告诉不论是什么线程，被volatile修饰的变量都要从内存中取值。《内存栅栏》

但看了这个帖子http://segmentfault.com/q/1010000000147713（也有人遇到同样的问题了）说，尝试了HotSpot的server和client两种模式，以及JDK1.3的classic，都没有效果，只有JDK1.2才能得到预期的结果。
哎！看来自己知识还是比较匮乏，看了下网友给出的答案，对于非volatile修饰的变量，尽管jvm的优化，会导致变量的可见性问题，但这种可见性的问题也只是在短时间内高并发的情况下发生，CPU执行时会很快刷新Cache，一般的情况下很难出现，而且出现这种问题是不可预测的，与jvm,
 机器配置环境等都有关。

姑且先这么理解吧！一点点积累。。。


正确的分析在这里：http://blog.csdn.net/ns_code/article/details/17382679




这里附上分析结果时参考的帖子及文章
http://segmentfault.com/q/1010000000147713

http://www.iteye.com/problems/98213

http://www.oldcaptain.cc/articles/2013/08/21/1377092100971.html



守护线程




  Java中有两类线程：User Thread(用户线程)、Daemon Thread(守护线程) 




    用户线程即运行在前台的线程，而守护线程是运行在后台的线程。 守护线程的作用是为其他前台线程的运行提供便利服务，而且仅在普通、非守护线程仍然运行时才需要，比如垃圾回收线程就是一个守护线程。当VM检测仅剩一个守护线程，而用户线程都已经退出运行时，VM就会退出，因为如果没有了被守护线程，也就没有继续运行程序的必要了。如果有非守护线程仍然存活，VM就不会退出。




     守护线程并非只有虚拟机内部提供，用户在编写程序时也可以自己设置守护线程。用户可以用Thread的setDaemon（true）方法设置当前线程为守护线程。




    虽然守护线程可能非常有用，但必须小心确保其他所有非守护线程消亡时，不会由于它的终止而产生任何危害。因为你不可能知道在所有的用户线程退出运行前，守护线程是否已经完成了预期的服务任务。一旦所有的用户线程退出了，虚拟机也就退出运行了。 因此，不要在守护线程中执行业务逻辑操作（比如对数据的读写等）。




    另外有几点需要注意：

    1、setDaemon(true)必须在调用线程的start（）方法之前设置，否则会跑出IllegalThreadStateException异常。

    2、在守护线程中产生的新线程也是守护线程。  
    3、 不要认为所有的应用都可以分配给守护线程来进行服务，比如读写操作或者计算逻辑。 





线程阻塞




    线程可以阻塞于四种状态：


    1、当线程执行Thread.sleep（）时，它一直阻塞到指定的毫秒时间之后，或者阻塞被另一个线程打断；

    2、当线程碰到一条wait（）语句时，它会一直阻塞到接到通知（notify（））、被中断或经过了指定毫秒时间为止（若制定了超时值的话）

    3、线程阻塞与不同I/O的方式有多种。常见的一种方式是InputStream的read（）方法，该方法一直阻塞到从流中读取一个字节的数据为止，它可以无限阻塞，因此不能指定超时时间；

    4、线程也可以阻塞等待获取某个对象锁的排他性访问权限（即等待获得synchronized语句必须的锁时阻塞）。




    注意，并非所有的阻塞状态都是可中断的，以上阻塞状态的前两种可以被中断，后两种不会对中断做出反应


挂起和恢复线程

    Thread 的API中包含两个被淘汰的方法，它们用于临时挂起和重启某个线程，这些方法已经被淘汰，因为它们是不安全的，不稳定的。如果在不合适的时候挂起线程（比如，锁定共享资源时），此时便可能会发生死锁条件——其他线程在等待该线程释放锁，但该线程却被挂起了，便会发生死锁。另外，在长时间计算期间挂起线程也可能导致问题。

    下面的代码演示了通过休眠来延缓运行，模拟长时间运行的情况，使线程更可能在不适当的时候被挂起：





[java] view
 plaincopy






public class DeprecatedSuspendResume extends Object implements Runnable{  
  
    //volatile关键字，表示该变量可能在被一个线程使用的同时，被另一个线程修改  
    private volatile int firstVal;  
    private volatile int secondVal;  
  
    //判断二者是否相等  
    public boolean areValuesEqual(){  
        return ( firstVal == secondVal);  
    }  
  
    public void run() {  
        try{  
            firstVal = 0;  
            secondVal = 0;  
            workMethod();  
        }catch(InterruptedException x){  
            System.out.println("interrupted while in workMethod()");  
        }  
    }  
  
    private void workMethod() throws InterruptedException {  
        int val = 1;  
        while (true){  
            stepOne(val);  
            stepTwo(val);  
            val++;  
            Thread.sleep(200);  //再次循环钱休眠200毫秒  
        }  
    }  
      
    //赋值后，休眠300毫秒，从而使线程有机会在stepOne操作和stepTwo操作之间被挂起  
    private void stepOne(int newVal) throws InterruptedException{  
        firstVal = newVal;  
        Thread.sleep(300);  //模拟长时间运行的情况  
    }  
  
    private void stepTwo(int newVal){  
        secondVal = newVal;  
    }  
  
    public static void main(String[] args){  
        DeprecatedSuspendResume dsr = new DeprecatedSuspendResume();  
        Thread t = new Thread(dsr);  
        t.start();  
  
        //休眠1秒，让其他线程有机会获得执行  
        try {  
            Thread.sleep(1000);}   
        catch(InterruptedException x){}  
        for (int i = 0; i &lt; 10; i++){  
            //挂起线程  
            t.suspend();  
            System.out.println("dsr.areValuesEqual()=" + dsr.areValuesEqual());  
            //恢复线程  
            t.resume();  
            try{   
                //线程随机休眠0~2秒  
                Thread.sleep((long)(Math.random()*2000.0));  
            }catch(InterruptedException x){  
                //略  
            }  
        }  
        System.exit(0); //中断应用程序  
    }  
}  

    某次运行结果如下：



  

    从areValuesEqual（）返回的值有时为true，有时为false。以上代码中，在设置firstVal之后，但在设置secondVal之前，挂起新线程会产生麻烦，此时输出的结果会为false（情况1），这段时间不适宜挂起线程，但因为线程不能控制何时调用它的suspend方法，所以这种情况是不可避免的。

    当然，即使线程不被挂起（注释掉挂起和恢复线程的两行代码），如果在main线程中执行asr.areValuesEqual（）进行比较时，恰逢stepOne操作执行完，而stepTwo操作还没执行，那么得到的结果同样可能是false（情况2）。


     下面我们给出不用上述两个方法来实现线程挂起和恢复的策略——设置标志位。通过该方法实现线程的挂起和恢复有一个很好的地方，就是可以在线程的指定位置实现线程的挂起和恢复，而不用担心其不确定性。  

     对于上述代码的改进代码如下：





[java] view
 plaincopy






public class AlternateSuspendResume extends Object implements Runnable {  
  
    private volatile int firstVal;  
    private volatile int secondVal;  
    //增加标志位，用来实现线程的挂起和恢复  
    private volatile boolean suspended;  
  
    public boolean areValuesEqual() {  
        return ( firstVal == secondVal );  
    }  
  
    public void run() {  
        try {  
            suspended = false;  
            firstVal = 0;  
            secondVal = 0;  
            workMethod();  
        } catch ( InterruptedException x ) {  
            System.out.println("interrupted while in workMethod()");  
        }  
    }  
  
    private void workMethod() throws InterruptedException {  
        int val = 1;  
  
        while ( true ) {  
            //仅当贤臣挂起时，才运行这行代码  
            waitWhileSuspended();   
  
            stepOne(val);  
            stepTwo(val);  
            val++;  
  
            //仅当线程挂起时，才运行这行代码  
            waitWhileSuspended();   
  
            Thread.sleep(200);    
        }  
    }  
  
    private void stepOne(int newVal)   
                    throws InterruptedException {  
  
        firstVal = newVal;  
        Thread.sleep(300);    
    }  
  
    private void stepTwo(int newVal) {  
        secondVal = newVal;  
    }  
  
    public void suspendRequest() {  
        suspended = true;  
    }  
  
    public void resumeRequest() {  
        suspended = false;  
    }  
  
    private void waitWhileSuspended()   
                throws InterruptedException {  
  
        //这是一个“繁忙等待”技术的示例。  
        //它是非等待条件改变的最佳途径，因为它会不断请求处理器周期地执行检查，   
        //更佳的技术是：使用Java的内置“通知-等待”机制  
        while ( suspended ) {  
            Thread.sleep(200);  
        }  
    }  
  
    public static void main(String[] args) {  
        AlternateSuspendResume asr =   
                new AlternateSuspendResume();  
  
        Thread t = new Thread(asr);  
        t.start();  
  
        //休眠1秒，让其他线程有机会获得执行  
        try { Thread.sleep(1000); }   
        catch ( InterruptedException x ) { }  
  
        for ( int i = 0; i &lt; 10; i++ ) {  
            asr.suspendRequest();  
  
            //让线程有机会注意到挂起请求  
            //注意：这里休眠时间一定要大于  
            //stepOne操作对firstVal赋值后的休眠时间，即300ms，  
            //目的是为了防止在执行asr.areValuesEqual（）进行比较时,  
            //恰逢stepOne操作执行完，而stepTwo操作还没执行  
            try { Thread.sleep(350); }   
            catch ( InterruptedException x ) { }  
  
            System.out.println("dsr.areValuesEqual()=" +   
                    asr.areValuesEqual());  
  
            asr.resumeRequest();  
  
            try {   
                //线程随机休眠0~2秒  
                Thread.sleep(  
                        ( long ) (Math.random() * 2000.0) );  
            } catch ( InterruptedException x ) {  
                //略  
            }  
        }  
  
        System.exit(0); //退出应用程序  
    }  
}  

    运行结果如下：






    由结果可以看出，输出的所有结果均为true。首先，针对情况1（线程挂起的位置不确定），这里确定了线程挂起的位置，不会出现线程在stepOne操作和stepTwo操作之间挂起的情况；针对情况2（main线程中执行asr.areValuesEqual（）进行比较时，恰逢stepOne操作执行完，而stepTwo操作还没执行），在发出挂起请求后，还没有执行asr.areValuesEqual（）操作前，让main线程休眠450ms（&gt;300ms），如果挂起请求发出时，新线程正执行到或即将执行到stepOne操作（如果在其前面的话，就会响应挂起请求，从而挂起线程），那么在stepTwo操作执行前，main线程的休眠还没结束，从而main线程休眠结束后执行asr.areValuesEqual（）操作进行比较时，stepTwo操作已经执行完，因此也不会出现输出结果为false的情况。

    可以将ars.suspendRequest（）代码后的sleep代码去掉，或将休眠时间改为200（明显小于300即可）后，查看执行结果，会发现结果中依然会有出现false的情况。如下图所示：







   总结：线程的挂起和恢复实现的正确方法是：通过设置标志位，让线程在安全的位置挂起






终止线程



   当调用Thread的start（）方法，执行完run（）方法后，或在run（）方法中return，线程便会自然消亡。另外Thread API中包含了一个stop（）方法，可以突然终止线程。但它在JDK1.2后便被淘汰了，因为它可能导致数据对象的崩溃。一个问题是，当线程终止时，很少有机会执行清理工作；另一个问题是，当在某个线程上调用stop（）方法时，线程释放它当前持有的所有锁，持有这些锁必定有某种合适的理由——也许是阻止其他线程访问尚未处于一致性状态的数据，突然释放锁可能使某些对象中的数据处于不一致状态，而且不会出现数据可能崩溃的任何警告。

   终止线程的替代方法：同样是使用标志位，通过控制标志位来终止线程。


使用interrupt（）中断线程

    当一个线程运行时，另一个线程可以调用对应的Thread对象的interrupt（）方法来中断它，该方法只是在目标线程中设置一个标志，表示它已经被中断，并立即返回。这里需要注意的是，如果只是单纯的调用interrupt（）方法，线程并没有实际被中断，会继续往下执行。

    下面一段代码演示了休眠线程的中断:





[java] view
 plaincopy






public class SleepInterrupt extends Object implements Runnable{  
    public void run(){  
        try{  
            System.out.println("in run() - about to sleep for 20 seconds");  
            Thread.sleep(20000);  
            System.out.println("in run() - woke up");  
        }catch(InterruptedException e){  
            System.out.println("in run() - interrupted while sleeping");  
            //处理完中断异常后，返回到run（）方法人口，  
            //如果没有return，线程不会实际被中断，它会继续打印下面的信息  
            return;    
        }  
        System.out.println("in run() - leaving normally");  
    }  
  
  
    public static void main(String[] args) {  
        SleepInterrupt si = new SleepInterrupt();  
        Thread t = new Thread(si);  
        t.start();  
        //主线程休眠2秒，从而确保刚才启动的线程有机会执行一段时间  
        try {  
            Thread.sleep(2000);   
        }catch(InterruptedException e){  
            e.printStackTrace();  
        }  
        System.out.println("in main() - interrupting other thread");  
        //中断线程t  
        t.interrupt();  
        System.out.println("in main() - leaving");  
    }  
}  

    运行结果如下：






     主线程启动新线程后，自身休眠2秒钟，允许新线程获得运行时间。新线程打印信息“about to sleep for 20 seconds”后，继而休眠20秒钟，大约2秒钟后，main线程通知新线程中断，那么新线程的20秒的休眠将被打断，从而抛出InterruptException异常，执行跳转到catch块，打印出“interrupted while sleeping”信息，并立即从run（）方法返回，然后消亡，而不会打印出catch块后面的“leaving
 normally”信息。

    请注意：由于不确定的线程规划，上图运行结果的后两行可能顺序相反，这取决于主线程和新线程哪个先消亡。但前两行信息的顺序必定如上图所示。

    另外，如果将catch块中的return语句注释掉，则线程在抛出异常后，会继续往下执行，而不会被中断，从而会打印出”leaving normally“信息。







待决中断



    在上面的例子中，sleep（）方法的实现检查到休眠线程被中断，它会相当友好地终止线程，并抛出InterruptedException异常。另外一种情况，如果线程在调用sleep（）方法前被中断，那么该中断称为待决中断，它会在刚调用sleep（）方法时，立即抛出InterruptedException异常。

    下面的代码演示了待决中断:





[java] view
 plaincopy






public class PendingInterrupt extends Object {  
    public static void main(String[] args){  
        //如果输入了参数，则在mian线程中中断当前线程（亦即main线程）  
        if( args.length &gt; 0 ){  
            Thread.currentThread().interrupt();  
        }   
        //获取当前时间  
        long startTime = System.currentTimeMillis();  
        try{  
            Thread.sleep(2000);  
            System.out.println("was NOT interrupted");  
        }catch(InterruptedException x){  
            System.out.println("was interrupted");  
        }  
        //计算中间代码执行的时间  
        System.out.println("elapsedTime=" + ( System.currentTimeMillis() - startTime));  
    }  
}  

    如果PendingInterrupt不带任何命令行参数，那么线程不会被中断，最终输出的时间差距应该在2000附近（具体时间由系统决定，不精确），如果PendingInterrupt带有命令行参数，则调用中断当前线程的代码，但main线程仍然运行，最终输出的时间差距应该远小于2000，因为线程尚未休眠，便被中断，因此，一旦调用sleep（）方法，会立即打印出catch块中的信息。执行结果如下:






    这种模式下，main线程中断它自身。除了将中断标志（它是Thread的内部标志）设置为true外，没有其他任何影响。线程被中断了，但main线程仍然运行，main线程继续监视实时时钟，并进入try块，一旦调用sleep（）方法，它就会注意到待决中断的存在，并抛出InterruptException。于是执行跳转到catch块，并打印出线程被中断的信息。最后，计算并打印出时间差。








使用isInterrupted（）方法判断中断状态

   可以在Thread对象上调用isInterrupted（）方法来检查任何线程的中断状态。这里需要注意：线程一旦被中断，isInterrupted（）方法便会返回true，而一旦sleep（）方法抛出异常，它将清空中断标志，此时isInterrupted（）方法将返回false。


   下面的代码演示了isInterrupted（）方法的使用：






[java] view
 plaincopy






public class InterruptCheck extends Object{  
    public static void main(String[] args){  
        Thread t = Thread.currentThread();  
        System.out.println("Point A: t.isInterrupted()=" + t.isInterrupted());  
        //待决中断，中断自身  
        t.interrupt();  
        System.out.println("Point B: t.isInterrupted()=" + t.isInterrupted());  
        System.out.println("Point C: t.isInterrupted()=" + t.isInterrupted());  
  
        try{  
            Thread.sleep(2000);  
            System.out.println("was NOT interrupted");  
        }catch( InterruptedException x){  
            System.out.println("was interrupted");  
        }  
        //抛出异常后，会清除中断标志，这里会返回false  
        System.out.println("Point D: t.isInterrupted()=" + t.isInterrupted());  
    }  
}  

    运行结果如下：







 

使用Thread.interrupted（）方法判断中断状态

    可以使用Thread.interrupted（）方法来检查当前线程的中断状态（并隐式重置为false）。又由于它是静态方法，因此不能在特定的线程上使用，而只能报告调用它的线程的中断状态，如果线程被中断，而且中断状态尚不清楚，那么，这个方法返回true。与isInterrupted（）不同，它将自动重置中断状态为false，第二次调用Thread.interrupted（）方法，总是返回false，除非中断了线程。

    如下代码演示了Thread.interrupted（）方法的使用：





[java] view
 plaincopy






public class InterruptReset extends Object {  
    public static void main(String[] args) {  
        System.out.println(  
            "Point X: Thread.interrupted()=" + Thread.interrupted());  
        Thread.currentThread().interrupt();  
        System.out.println(  
            "Point Y: Thread.interrupted()=" + Thread.interrupted());  
        System.out.println(  
            "Point Z: Thread.interrupted()=" + Thread.interrupted());  
    }  
}  

    运行结果如下：






    从结果中可以看出，当前线程中断自身后，在Y点，中断状态为true，并由Thread.interrupted（）自动重置为false，那么下次调用该方法得到的结果便是false。










补充

    这里补充下yield和join方法的使用。


    join方法用线程对象调用，如果在一个线程A中调用另一个线程B的join方法，线程A将会等待线程B执行完毕后再执行。

    yield可以直接用Thread类调用，yield让出CPU执行权给同等级的线程，如果没有相同级别的线程在等待CPU的执行权，则该线程继续执行。


每个Java对象都可以用做一个实现同步的锁，这些锁被称为内置锁或监视器锁。线程在进入同步代码块之前会自动获取锁，并且在退出同步代码块时会自动释放锁。获得内置锁的唯一途径就是进入由这个锁保护的同步代码块或方法。

    当某个线程请求一个由其他线程持有的锁时，发出请求的线程就会阻塞。然而，由于内置锁是可重入的，因此如果某个线程试图获得一个已经由它自己持有的锁，那么这个请求就会成功。“重入”意味着获取锁的操作的粒度是“线程”，而不是调用。重入的一种实现方法是，为每个锁关联一个获取计数值和一个所有者线程。当计数值为0时，这个锁就被认为是没有被任何线程所持有，当线程请求一个未被持有的锁时，JVM将记下锁的持有者，并且将获取计数值置为1，如果同一个线程再次获取这个锁，计数值将递增，而当线程退出同步代码块时，计数器会相应地递减。当计数值为0时，这个锁将被释放。

    重入进一步提升了加锁行为的封装性，因此简化了面向对象并发代码的开发。分析如下程序：



[java] view
 plaincopy






public class Father  
{  
    public synchronized void doSomething(){  
        ......  
    }  
}  
  
public class Child extends Father  
{  
    public synchronized void doSomething(){  
        ......  
        super.doSomething();  
    }  
}  


    子类覆写了父类的同步方法，然后调用父类中的方法，此时如果没有可重入的锁，那么这段代码将产生死锁。

     由于Fither和Child中的doSomething方法都是synchronized方法，因此每个doSomething方法在执行前都会获取Child对象实例上的锁。如果内置锁不是可重入的，那么在调用super.doSomething时将无法获得该Child对象上的互斥锁，因为这个锁已经被持有，从而线程会永远阻塞下去，一直在等待一个永远也无法获取的锁。重入则避免了这种死锁情况的发生。

    同一个线程在调用本类中其他synchronized方法、块或父类中的synchronized方法/块时，都不会阻碍该线程的执行，因为互斥锁是可重入的。


对象引用



    Java中的垃圾回收一般是在Java堆中进行，因为堆中几乎存放了Java中所有的对象实例。谈到Java堆中的垃圾回收，自然要谈到引用。在JDK1.2之前，Java中的引用定义很很纯粹：如果reference类型的数据中存储的数值代表的是另外一块内存的起始地址，就称这块内存代表着一个引用。但在JDK1.2之后，Java对引用的概念进行了扩充，将其分为强引用（Strong Reference）、软引用（Soft Reference）、弱引用（Weak Reference）、虚引用（Phantom Reference）四种，引用强度依次减弱。



强引用：如“Object obj = new Object（）”，这类引用是Java程序中最普遍的。只要强引用还存在，垃圾收集器就永远不会回收掉被引用的对象。软引用：它用来描述一些可能还有用，但并非必须的对象。在系统内存不够用时，这类引用关联的对象将被垃圾收集器回收。JDK1.2之后提供了SoftReference类来实现软引用。弱引用：它也是用来描述非需对象的，但它的强度比软引用更弱些，被弱引用关联的对象只能生存岛下一次垃圾收集发生之前。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。在JDK1.2之后，提供了WeakReference类来实现弱引用。虚引用：最弱的一种引用关系，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的是希望能在这个对象被收集器回收时收到一个系统通知。JDK1.2之后提供了PhantomReference类来实现虚引用。




垃圾对象的判定

    Java堆中存放着几乎所有的对象实例，垃圾收集器对堆中的对象进行回收前，要先确定这些对象是否还有用，判定对象是否为垃圾对象有如下算法：

    引用计数算法



    给对象添加一个引用计数器，每当有一个地方引用它时，计数器值就加1，当引用失效时，计数器值就减1，任何时刻计数器都为0的对象就是不可能再被使用的。

    引用计数算法的实现简单，判定效率也很高，在大部分情况下它都是一个不错的选择，当Java语言并没有选择这种算法来进行垃圾回收，主要原因是它很难解决对象之间的相互循环引用问题。

    根搜索算法



    Java和C#中都是采用根搜索算法来判定对象是否存活的。这种算法的基本思路是通过一系列名为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连时，就证明此对象是不可用的。在Java语言里，可作为GC Roots的兑现包括下面几种：

虚拟机栈（栈帧中的本地变量表）中引用的对象。方法区中的类静态属性引用的对象。方法区中的常量引用的对象。本地方法栈中JNI（Native方法）的引用对象。



    实际上，在根搜索算法中，要真正宣告一个对象死亡，至少要经历两次标记过程：如果对象在进行根搜索后发现没有与GC Roots相连接的引用链，那它会被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行finalize（）方法。当对象没有覆盖finalize（）方法，或finalize（）方法已经被虚拟机调用过，虚拟机将这两种情况都视为没有必要执行。如果该对象被判定为有必要执行finalize（）方法，那么这个对象将会被放置在一个名为F-Queue队列中，并在稍后由一条由虚拟机自动建立的、低优先级的Finalizer线程去执行finalize（）方法。finalize（）方法是对象逃脱死亡命运的最后一次机会（因为一个对象的finalize（）方法最多只会被系统自动调用一次），稍后GC将对F-Queue中的对象进行第二次小规模的标记，如果要在finalize（）方法中成功拯救自己，只要在finalize（）方法中让该对象重引用链上的任何一个对象建立关联即可。而如果对象这时还没有关联到任何链上的引用，那它就会被回收掉。




垃圾收集算法

    判定除了垃圾对象之后，便可以进行垃圾回收了。下面介绍一些垃圾收集算法，由于垃圾收集算法的实现涉及大量的程序细节，因此这里主要是阐明各算法的实现思想，而不去细论算法的具体实现。

    标记—清除算法

    标记—清除算法是最基础的收集算法，它分为“标记”和“清除”两个阶段：首先标记出所需回收的对象，在标记完成后统一回收掉所有被标记的对象，它的标记过程其实就是前面的根搜索算法中判定垃圾对象的标记过程。标记—清除算法的执行情况如下图所示：

    回收前状态：



    回收后状态：

 

 

    该算法有如下缺点：



标记和清除过程的效率都不高。标记清除后会产生大量不连续的内存碎片，空间碎片太多可能会导致，当程序在以后的运行过程中需要分配较大对象时无法找到足够的连续内存而不得不触发另一次垃圾收集动作。


    复制算法

    复制算法是针对标记—清除算法的缺点，在其基础上进行改进而得到的，它讲课用内存按容量分为大小相等的两块，每次只使用其中的一块，当这一块的内存用完了，就将还存活着的对象复制到另外一块内存上面，然后再把已使用过的内存空间一次清理掉。复制算法有如下优点：



每次只对一块内存进行回收，运行高效。只需移动栈顶指针，按顺序分配内存即可，实现简单。内存回收时不用考虑内存碎片的出现。
    它的缺点是：可一次性分配的最大内存缩小了一半。



    复制算法的执行情况如下图所示：

    回收前状态：



    回收后状态：






    标记—整理算法

    复制算法比较适合于新生代，在老年代中，对象存活率比较高，如果执行较多的复制操作，效率将会变低，所以老年代一般会选用其他算法，如标记—整理算法。该算法标记的过程与标记—清除算法中的标记过程一样，但对标记后出的垃圾对象的处理情况有所不同，它不是直接对可回收对象进行清理，而是让所有的对象都向一端移动，然后直接清理掉端边界以外的内存。标记—整理算法的回收情况如下所示：
    回收前状态：







    回收后状态：











    分代收集



    当前商业虚拟机的垃圾收集 都采用分代收集，它根据对象的存活周期的不同将内存划分为几块，一般是把Java堆分为新生代和老年代。在新生代中，每次垃圾收集时都会发现有大量对象死去，只有少量存活，因此可选用复制算法来完成收集，而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用标记—清除算法或标记—整理算法来进行回收。




垃圾收集器
    垃圾收集器是内存回收算法的具体实现，Java虚拟机规范中对垃圾收集器应该如何实现并没有任何规定，因此不同厂商、不同版本的虚拟机所提供的垃圾收集器都可能会有很大的差别。Sun  HotSpot虚拟机1.6版包含了如下收集器：Serial、ParNew、Parallel Scavenge、CMS、Serial Old、Parallel Old。这些收集器以不同的组合形式配合工作来完成不同分代区的垃圾收集工作。







垃圾回收分析   

    在用代码分析之前，我们对内存的分配策略明确以下三点：


对象优先在Eden分配。大对象直接进入老年代。长期存活的对象将进入老年代。
    对垃圾回收策略说明以下两点：



新生代GC（Minor GC）：发生在新生代的垃圾收集动作，因为Java对象大多都具有朝生夕灭的特性，因此Minor GC非常频繁，一般回收速度也比较快。老年代GC（Major GC/Full GC）：发生在老年代的GC，出现了Major GC，经常会伴随至少一次Minor GC。由于老年代中的对象生命周期比较长，因此Major GC并不频繁，一般都是等待老年代满了后才进行Full GC，而且其速度一般会比Minor GC慢10倍以上。另外，如果分配了Direct Memory，在老年代中进行Full
 GC时，会顺便清理掉Direct Memory中的废弃对象。


    下面我们来看如下代码:




[java] view
 plaincopy






public class SlotGc{  
    public static void main(String[] args){  
        byte[] holder = new byte[32*1024*1024];  
        System.gc();  
    }  
}  


    代码很简单，就是向内存中填充了32MB的数据，然后通过虚拟机进行垃圾收集。在Javac编译后，我们执行如下指令：java -verbose:gc SlotGc来查看垃圾收集的结果，得到如下输出信息：
    [GC 208K-&gt;134K(5056K), 0.0017306 secs]
    [Full GC 134K-&gt;134K(5056K), 0.0121194 secs]
    [Full GC 32902K-&gt;32902K(37828K), 0.0094149 sec
    注意第三行，“-&gt;”之前的数据表示垃圾回收前堆中存活对象所占用的内存大小，“-&gt;”之后的数据表示垃圾回收堆中存活对象所占用的内存大小，括号中的数据表示堆内存的总容量，0.0094149 sec 表示垃圾回收所用的时间。
    从结果中可以看出，System.gc(（）运行后并没有回收掉这32MB的内存，这应该是意料之中的结果，因为变量holder还处在作用域内，虚拟机自然不会回收掉holder引用的对象所占用的内存。
    我们把代码修改如下：



[java] view
 plaincopy






public class SlotGc{  
    public static void main(String[] args){  
        {  
        byte[] holder = new byte[32*1024*1024];  
        }  
        System.gc();  
    }  
}  

    加入花括号后，holder的作用域被限制在了花括号之内，因此，在执行System.gc（）时，holder引用已经不能再被访问，逻辑上来讲，这次应该会回收掉holder引用的对象所占的内存。但查看垃圾回收情况时，输出信息如下：
    [GC 208K-&gt;134K(5056K), 0.0017100 secs]
    [Full GC 134K-&gt;134K(5056K), 0.0125887 secs]
    [Full GC 32902K-&gt;32902K(37828K), 0.0089226 secs]
    很明显，这32MB的数据并没有被回收。下面我们再做如下修改：



[java] view
 plaincopy






public class SlotGc{  
    public static void main(String[] args){  
        {  
        byte[] holder = new byte[32*1024*1024];  
        holder = null;  
        }  
        System.gc();  
    }  
}  

    这次得到的垃圾回收信息如下：
    [GC 208K-&gt;134K(5056K), 0.0017194 secs]
    [Full GC 134K-&gt;134K(5056K), 0.0124656 secs]
    [Full GC 32902K-&gt;134K(37828K), 0.0091637 secs]
    说明这次holder引用的对象所占的内存被回收了。我们慢慢来分析。
    首先明确一点：holder能否被回收的根本原因是局部变量表中的Slot是否还存有关于holder数组对象的引用。
在第一次修改中，虽然在holder作用域之外进行回收，但是在此之后，没有对局部变量表的读写操作，holder所占用的Slot还没有被其他变量所复用（回忆Java内存区域与内存溢出一文中关于Slot的讲解），所以作为GC Roots一部分的局部变量表仍保持者对它的关联。这种关联没有被及时打断，因此GC收集器不会将holder引用的对象内存回收掉。 在第二次修改中，在GC收集器工作前，手动将holder设置为null值，就把holder所占用的局部变量表中的Slot清空了，因此，这次GC收集器工作时将holder之前引用的对象内存回收掉了。
    当然，我们也可以用其他方法来将holder引用的对象内存回收掉，只要复用holder所占用的slot即可，比如在holder作用域之外执行一次读写操作。
    为对象赋null值并不是控制变量回收的最好方法，以恰当的变量作用域来控制变量回收时间才是最优雅的解决办法。另外，赋null值的操作在经过虚拟机JIT编译器优化后会被消除掉，经过JIT编译后，System.gc（）执行时就可以正确地回收掉内存，而无需赋null值。






性能调优 

    Java虚拟机的内存管理与垃圾收集是虚拟机结构体系中最重要的组成部分，对程序（尤其服务器端）的性能和稳定性有着非常重要的影响。性能调优需要具体情况具体分析，而且实际分析时可能需要考虑的方面很多，这里仅就一些简单常用的情况作简要介绍。 
  

我们可以通过给Java虚拟机分配超大堆（前提是物理机的内存足够大）来提升服务器的响应速度，但分配超大堆的前提是有把握把应用程序的Full GC频率控制得足够低，因为一次Full GC的时间造成比较长时间的停顿。控制Full GC频率的关键是保证应用中绝大多数对象的生存周期不应太长，尤其不能产生批量的、生命周期长的大对象，这样才能保证老年代的稳定。Direct Memory在堆内存外分配，而且二者均受限于物理机内存，且成负相关关系，因此分配超大堆时，如果用到了NIO机制分配使用了很多的Direct Memory，则有可能导致Direct Memory的OutOfMemoryError异常，这时可以通过-XX:MaxDirectMemorySize参数调整Direct Memory的大小。
除了Java堆和永久代以及直接内存外，还要注意下面这些区域也会占用较多的内存，这些内存的总和会受到操作系统进程最大内存的限制：

1、线程堆栈：可通过-Xss调整大小，内存不足时抛出StackOverflowError（纵向无法分配，即无法分配新的栈帧）或OutOfMemoryError（横向无法分配，即无法建立新的线程）。
2、Socket缓冲区：每个Socket连接都有Receive和Send两个缓冲区，分别占用大约37KB和25KB的内存。如果无法分配，可能会抛出IOException：Too many open files异常。
3、JNI代码：如果代码中使用了JNI调用本地库，那本地库使用的内存也不在堆中。
4、虚拟机和GC：虚拟机和GC的代码执行也要消耗一定的内存。




编译过程



    不论是物理机还是虚拟机，大部分的程序代码从开始编译到最终转化成物理机的目标代码或虚拟机能执行的指令集之前，都会按照如下图所示的各个步骤进行：




    

    其中绿色的模块可以选择性实现。很容易看出，上图中间的那条分支是解释执行的过程（即一条字节码一条字节码地解释执行，如JavaScript），而下面的那条分支就是传统编译原理中从源代码到目标机器代码的生成过程。

    如今，基于物理机、虚拟机等的语言，大多都遵循这种基于现代经典编译原理的思路，在执行前先对程序源码进行词法解析和语法解析处理，把源码转化为抽象语法树。对于一门具体语言的实现来说，词法和语法分析乃至后面的优化器和目标代码生成器都可以选择独立于执行引擎，形成一个完整意义的编译器去实现，这类代表是C/C++语言。也可以把抽象语法树或指令流之前的步骤实现一个半独立的编译器，这类代表是Java语言。又或者可以把这些步骤和执行引擎全部集中在一起实现，如大多数的JavaScript执行器。




Javac编译

   在Java中提到“编译”，自然很容易想到Javac编译器将*.java文件编译成为*.class文件的过程，这里的Javac编译器称为前端编译器，其他的前端编译器还有诸如Eclipse JDT中的增量式编译器ECJ等。相对应的还有后端编译器，它在程序运行期间将字节码转变成机器码（现在的Java程序在运行时基本都是解释执行加编译执行），如HotSpot虚拟机自带的JIT（Just In Time Compiler）编译器（分Client端和Server端）。另外，有时候还有可能会碰到静态提前编译器（AOT，Ahead Of Time Compiler）直接把*.java文件编译成本地机器代码，如GCJ、Excelsior JET等，这类编译器我们应该比较少遇到。

    下面简要说下Javac编译（前端编译）的过程。

    词法、语法分析


    词法分析是将源代码的字符流转变为标记（Token）集合。单个字符是程序编写过程中的的最小元素，而标记则是编译过程的最小元素，关键字、变量名、字面量、运算符等都可以成为标记，比如整型标志int由三个字符构成，但是它只是一个标记，不可拆分。
    语法分析是根据Token序列来构造抽象语法树的过程。抽象语法树是一种用来描述程序代码语法结构的树形表示方式，语法树的每一个节点都代表着程序代码中的一个语法结构，如bao、类型、修饰符、运算符等。经过这个步骤后，编译器就基本不会再对源码文件进行操作了，后续的操作都建立在抽象语法树之上。

    填充符号表

    完成了语法分析和词法分析之后，下一步就是填充符号表的过程。符号表是由一组符号地址和符号信息构成的表格。符号表中所登记的信息在编译的不同阶段都要用到，在语义分析（后面的步骤）中，符号表所登记的内容将用于语义检查和产生中间代码，在目标代码生成阶段，党对符号名进行地址分配时，符号表是地址分配的依据。
    语义分析
     语法树能表示一个结构正确的源程序的抽象，但无法保证源程序是符合逻辑的。而语义分析的主要任务是读结构上正确的源程序进行上下文有关性质的审查。语义分析过程分为标注检查和数据及控制流分析两个步骤：


标注检查步骤检查的内容包括诸如变量使用前是否已被声明、变量和赋值之间的数据类型是否匹配等。数据及控制流分析是对程序上下文逻辑更进一步的验证，它可以检查出诸如程序局部变量在使用前是否有赋值、方法的每条路径是否都有返回值、是否所有的受查异常都被正确处理了等问题。

    字节码生成
    字节码生成是Javac编译过程的最后一个阶段。字节码生成阶段不仅仅是把前面各个步骤所生成的信息转化成字节码写到磁盘中，编译器还进行了少量的代码添加和转换工作。 实例构造器&lt;init&gt;（）方法和类构造器&lt;clinit&gt;（）方法就是在这个阶段添加到语法树之中的（这里的实例构造器并不是指默认的构造函数，而是指我们自己重载的构造函数，如果用户代码中没有提供任何构造函数，那编译器会自动添加一个没有参数、访问权限与当前类一致的默认构造函数，这个工作在填充符号表阶段就已经完成了）。

JIT编译
    Java程序最初是仅仅通过解释器解释执行的，即对字节码逐条解释执行，这种方式的执行速度相对会比较慢，尤其当某个方法或代码块运行的特别频繁时，这种方式的执行效率就显得很低。于是后来在虚拟机中引入了JIT编译器（即时编译器），当虚拟机发现某个方法或代码块运行特别频繁时，就会把这些代码认定为“Hot Spot Code”（热点代码），为了提高热点代码的执行效率，在运行时，虚拟机将会把这些代码编译成与本地平台相关的机器码，并进行各层次的优化，完成这项任务的正是JIT编译器。
    现在主流的商用虚拟机（如Sun HotSpot、IBM J9）中几乎都同时包含解释器和编译器（三大商用虚拟机之一的JRockit是个例外，它内部没有解释器，因此会有启动相应时间长之类的缺点，但它主要是面向服务端的应用，这类应用一般不会重点关注启动时间）。二者各有优势：当程序需要迅速启动和执行时，解释器可以首先发挥作用，省去编译的时间，立即执行；当程序运行后，随着时间的推移，编译器逐渐会返回作用，把越来越多的代码编译成本地代码后，可以获取更高的执行效率。解释执行可以节约内存，而编译执行可以提升效率。
    HotSpot虚拟机中内置了两个JIT编译器：Client Complier和Server Complier，分别用在客户端和服务端，目前主流的HotSpot虚拟机中默认是采用解释器与其中一个编译器直接配合的方式工作。
运行过程中会被即时编译器编译的“热点代码”有两类：


被多次调用的方法。被多次调用的循环体。

    两种情况，编译器都是以整个方法作为编译对象，这种编译也是虚拟机中标准的编译方式。要知道一段代码或方法是不是热点代码，是不是需要触发即时编译，需要进行Hot Spot Detection（热点探测）。目前主要的热点 判定方式有以下两种：


基于采样的热点探测：采用这种方法的虚拟机会周期性地检查各个线程的栈顶，如果发现某些方法经常出现在栈顶，那这段方法代码就是“热点代码”。这种探测方法的好处是实现简单高效，还可以很容易地获取方法调用关系，缺点是很难精确地确认一个方法的热度，容易因为受到线程阻塞或别的外界因素的影响而扰乱热点探测。基于计数器的热点探测：采用这种方法的虚拟机会为每个方法，甚至是代码块建立计数器，统计方法的执行次数，如果执行次数超过一定的阀值，就认为它是“热点方法”。这种统计方法实现复杂一些，需要为每个方法建立并维护计数器，而且不能直接获取到方法的调用关系，但是它的统计结果相对更加精确严谨。

    在HotSpot虚拟机中使用的是第二种——基于计数器的热点探测方法，因此它为每个方法准备了两个计数器：方法调用计数器和回边计数器。
    方法调用计数器用来统计方法调用的次数，在默认设置下，方法调用计数器统计的并不是方法被调用的绝对次数，而是一个相对的执行频率，即一段时间内方法被调用的次数。
    回边计数器用于统计一个方法中循环体代码执行的次数（准确地说，应该是回边的次数，因为并非所有的循环都是回边），在字节码中遇到控制流向后跳转的指令就称为“回边”。
    在确定虚拟机运行参数的前提下，这两个计数器都有一个确定的阀值，当计数器的值超过了阀值，就会触发JIT编译。触发了JIT编译后，在默认设置下，执行引擎并不会同步等待编译请求完成，而是继续进入解释器按照解释方式执行字节码，直到提交的请求被编译器编译完成为止（编译工作在后台线程中进行）。当编译工作完成后，下一次调用该方法或代码时，就会使用已编译的版本。
    由于方法计数器触发即时编译的过程与回边计数器触发即时编译的过程类似，因此这里仅给出方法调用计数器触发即时编译的流程：





   

   Javac字节码编译器与虚拟机内的JIT编译器的执行过程合起来其实就等同于一个传统的编译器所执行的编译过程。


语法糖（Syntactic Sugar），也称糖衣语法，是由英国计算机学家Peter.J.Landin发明的一个术语，指在计算机语言中添加的某种语法，这种语法对语言的功能并没有影响，但是更方便程序员使用。Java中最常用的语法糖主要有泛型、变长参数、条件编译、自动拆装箱、内部类等。虚拟机并不支持这些语法，它们在编译阶段就被还原回了简单的基础语法结构，这个过程成为解语法糖。



    泛型是JDK1.5之后引入的一项新特性，Java语言在还没有出现泛型时，只能通过Object是所有类型的父类和类型强制转换这两个特点的配合来实现泛型的功能，这样实现的泛型功能要在程序运行期才能知道Object真正的对象类型，在Javac编译期，编译器无法检查这个Object的强制转型是否成功，这便将一些风险转接到了程序运行期中。

    Java语言在JDK1.5之后引入的泛型实际上只在程序源码中存在，在编译后的字节码文件中，就已经被替换为了原来的原生类型，并且在相应的地方插入了强制转型代码，因此对于运行期的Java语言来说，ArrayList&lt;String&gt;和ArrayList&lt;Integer&gt;就是同一个类。所以泛型技术实际上是Java语言的一颗语法糖，Java语言中的泛型实现方法称为类型擦除，基于这种方法实现的泛型被称为伪泛型。

    下面是一段简单的Java泛型代码：



[java] view
 plaincopy






Map&lt;Integer,String&gt; map = new HashMap&lt;Integer,String&gt;();  
map.put(1,"No.1");  
map.put(2,"No.2");  
System.out.println(map.get(1));  
System.out.println(map.get(2));  


    将这段Java代码编译成Class文件，然后再用字节码反编译工具进行反编译后，将会发现泛型都变回了原生类型，如下面的代码所示：





[java] view
 plaincopy






Map map = new HashMap();  
map.put(1,"No.1");  
map.put(2,"No.2");  
System.out.println((String)map.get(1));  
System.out.println((String)map.get(2));  


    为了更详细地说明类型擦除，再看如下代码（这些问题在JDK1.7之后已经不存在，若已经是使用1.7版本后的，无需关注，并且有一些JDK1.6页不存在这些问题了，具体没有关注，大家可以选择性看）：





[java] view
 plaincopy






import java.util.List;  
public class FanxingTest{  
    public void method(List&lt;String&gt; list){  
        System.out.println("List String");  
    }  
    public void method(List&lt;Integer&gt; list){  
        System.out.println("List Int");  
    }  
}  




    当我用Javac编译器编译这段代码时，报出了如下错误：





FanxingTest.java:3: 名称冲突：method(java.util.List&lt;java.lang.String&gt;) 和 method

(java.util.List&lt;java.lang.Integer&gt;) 具有相同疑符

        public void method(List&lt;String&gt; list){

                    ^

FanxingTest.java:6: 名称冲突：method(java.util.List&lt;java.lang.Integer&gt;) 和 metho

d(java.util.List&lt;java.lang.String&gt;) 具有相同疑符

        public void method(List&lt;Integer&gt; list){

                    ^

2 错误



    这是因为泛型List&lt;String&gt;和List&lt;Integer&gt;编译后都被擦除了，变成了一样的原生类型List，擦除动作导致这两个方法的特征签名变得一模一样，在Class类文件结构一文中讲过，Class文件中不能存在特征签名相同的方法。

    把以上代码修改如下：




[java] view
 plaincopy






import java.util.List;  
public class FanxingTest{  
    public int method(List&lt;String&gt; list){  
        System.out.println("List String");  
        return 1;  
    }  
    public boolean method(List&lt;Integer&gt; list){  
        System.out.println("List Int");  
        return true;  
    }  
}  


    发现这时编译可以通过了（注意：Java语言中true和1没有关联，二者属于不同的类型，不能相互转换，不存在C语言中整数值非零即真的情况）。两个不同类型的返回值的加入，使得方法的重载成功了。这是为什么呢？

    我们知道，Java代码中的方法特征签名只包括了方法名称、参数顺序和参数类型，并不包括方法的返回值，因此方法的返回值并不参与重载方法的选择，这样看来为重载方法加入返回值貌似是多余的。对于重载方法的选择来说，这确实是多余的，但我们现在要解决的问题是让上述代码能通过编译，让两个重载方法能够合理地共存于同一个Class文件之中，这就要看字节码的方法特征签名，它不仅包括了Java代码中方法特征签名中所包含的那些信息，还包括方法返回值及受查异常表。为两个重载方法加入不同的返回值后，因为有了不同的字节码特征签名，它们便可以共存于一个Class文件之中。

    自动拆装箱、变长参数等语法糖也都是在编译阶段就把它们该语法糖结构还原为了原生的语法结构，因此在Class文件中也只存在其对应的原生类型，这里不再一一说明。


方法解析

    Class文件的编译过程中不包含传统编译中的连接步骤，一切方法调用在Class文件里面存储的都只是符号引用，而不是方法在实际运行时内存布局中的入口地址。这个特性给Java带来了更强大的动态扩展能力，使得可以在类运行期间才能确定某些目标方法的直接引用，称为动态连接，也有一部分方法的符号引用在类加载阶段或第一次使用时转化为直接引用，这种转化称为静态解析。这在前面的“Java内存区域与内存溢出”一文中有提到。

    静态解析成立的前提是：方法在程序真正执行前就有一个可确定的调用版本，并且这个方法的调用版本在运行期是不可改变的。换句话说，调用目标在编译器进行编译时就必须确定下来，这类方法的调用称为解析。

    在Java语言中，符合“编译器可知，运行期不可变”这个要求的方法主要有静态方法和私有方法两大类，前者与类型直接关联，后者在外部不可被访问，这两种方法都不可能通过继承或别的方式重写出其他的版本，因此它们都适合在类加载阶段进行解析。

   Java虚拟机里共提供了四条方法调用字节指令，分别是：



invokestatic：调用静态方法。invokespecial：调用实例构造器&lt;init&gt;方法、私有方法和父类方法。invokevirtual：调用所有的虚方法。invokeinterface：调用接口方法，会在运行时再确定一个实现此接口的对象。

    只要能被invokestatic和invokespecial指令调用的方法，都可以在解析阶段确定唯一的调用版本，符合这个条件的有静态方法、私有方法、实例构造器和父类方法四类，它们在类加载时就会把符号引用解析为该方法的直接引用。这些方法可以称为非虚方法（还包括final方法），与之相反，其他方法就称为虚方法（final方法除外）。这里要特别说明下final方法，虽然调用final方法使用的是invokevirtual指令，但是由于它无法覆盖，没有其他版本，所以也无需对方发接收者进行多态选择。Java语言规范中明确说明了final方法是一种非虚方法。

    解析调用一定是个静态过程，在编译期间就完全确定，在类加载的解析阶段就会把涉及的符号引用转化为可确定的直接引用，不会延迟到运行期再去完成。而分派调用则可能是静态的也可能是动态的，根据分派依据的宗量数（方法的调用者和方法的参数统称为方法的宗量）又可分为单分派和多分派。两类分派方式两两组合便构成了静态单分派、静态多分派、动态单分派、动态多分派四种分派情况。

    


静态分派   
    所有依赖静态类型来定位方法执行版本的分派动作，都称为静态分派，静态分派的最典型应用就是多态性中的方法重载。静态分派发生在编译阶段，因此确定静态分配的动作实际上不是由虚拟机来执行的。下面通过一段方法重载的示例程序来更清晰地说明这种分派机制：




[java] view
 plaincopy






class Human{  
}    
class Man extends Human{  
}  
class Woman extends Human{  
}  
  
public class StaticPai{  
  
    public void say(Human hum){  
        System.out.println("I am human");  
    }  
    public void say(Man hum){  
        System.out.println("I am man");  
    }  
    public void say(Woman hum){  
        System.out.println("I am woman");  
    }  
  
    public static void main(String[] args){  
        Human man = new Man();  
        Human woman = new Woman();  
        StaticPai sp = new StaticPai();  
        sp.say(man);  
        sp.say(woman);  
    }  
}  

    上面代码的执行结果如下：

    I am human
    I am human
   以上结果的得出应该不难分析。在分析为什么会选择参数类型为Human的重载方法去执行之前，先看如下代码：

Human man = new Man（）;
    我们把上面代码中的“Human”称为变量的静态类型，后面的“Man”称为变量的实际类型。静态类型和实际类型在程序中都可以发生一些变化，区别是静态类型的变化仅仅在使用时发生，变量本身的静态类型不会被改变，并且最终的静态类型是在编译期可知的，而实际类型变化的结果在运行期才可确定。
    回到上面的代码分析中，在调用say（）方法时，方法的调用者（回忆上面关于宗量的定义，方法的调用者属于宗量）都为sp的前提下，使用哪个重载版本，完全取决于传入参数的数量和数据类型（方法的参数也是数据宗量）。代码中刻意定义了两个静态类型相同、实际类型不同的变量，可见编译器（不是虚拟机，因为如果是根据静态类型做出的判断，那么在编译期就确定了）在重载时是通过参数的静态类型而不是实际类型作为判定依据的。并且静态类型是编译期可知的，所以在编译阶段，Javac编译器就根据参数的静态类型决定使用哪个重载版本。这就是静态分派最典型的应用。







动态分派  
   动态分派与多态性的另一个重要体现——方法覆写有着很紧密的关系。向上转型后调用子类覆写的方法便是一个很好地说明动态分派的例子。这种情况很常见，因此这里不再用示例程序进行分析。很显然，在判断执行父类中的方法还是子类中覆盖的方法时，如果用静态类型来判断，那么无论怎么进行向上转型，都只会调用父类中的方法，但实际情况是，根据对父类实例化的子类的不同，调用的是不同子类中覆写的方法，很明显，这里是要根据变量的实际类型来分派方法的执行版本的。而实际类型的确定需要在程序运行时才能确定下来，这种在运行期根据实际类型确定方法执行版本的分派过程称为动态分派。

 

单分派和多分派

    前面给出：方法的接受者（亦即方法的调用者）与方法的参数统称为方法的宗量。但分派是根据一个宗量对目标方法进行选择，多分派是根据多于一个宗量对目标方法进行选择。

    为了方便理解，下面给出一段示例代码：



[java] view
 plaincopy






class Eat{  
}  
class Drink{  
}  
  
class Father{  
    public void doSomething(Eat arg){  
        System.out.println("爸爸在吃饭");  
    }  
    public void doSomething(Drink arg){  
        System.out.println("爸爸在喝水");  
    }  
}  
  
class Child extends Father{  
    public void doSomething(Eat arg){  
        System.out.println("儿子在吃饭");  
    }  
    public void doSomething(Drink arg){  
        System.out.println("儿子在喝水");  
    }  
}  
  
public class SingleDoublePai{  
    public static void main(String[] args){  
        Father father = new Father();  
        Father child = new Child();  
        father.doSomething(new Eat());  
        child.doSomething(new Drink());  
    }  
}  


    运行结果应该很容易预测到，如下：

    爸爸在吃饭
    儿子在喝水
    我们首先来看编译阶段编译器的选择过程，即静态分派过程。这时候选择目标方法的依据有两点：一是方法的接受者（即调用者）的静态类型是Father还是Child，二是方法参数类型是Eat还是Drink。因为是根据两个宗量进行选择，所以Java语言的静态分派属于多分派类型。
    再来看运行阶段虚拟机的选择，即动态分派过程。由于编译期已经了确定了目标方法的参数类型（编译期根据参数的静态类型进行静态分派），因此唯一可以影响到虚拟机选择的因素只有此方法的接受者的实际类型是Father还是Child。因为只有一个宗量作为选择依据，所以Java语言的动态分派属于单分派类型。

     




    根据以上论证，我们可以总结如下：目前的Java语言（JDK1.6）是一门静态多分派、动态单分派的语言。



















&gt;&gt; 站长推荐工具




ChinaZ站长工具：站长之家推出的工具，国内站长最常用的网站SEO查询工具，功能全面。
超级外链工具：主要用于提高网站外链，可以批量增加外链，利用站长工具的查询功能增加反链，全部实现自动化提交。
搜索引擎登录口大全：涵盖国内外所有搜索引擎的网站登录入口。
Alexa：国内应用最广泛的网站排名查询工具，很多网站都以Alexa排名做标准，Alexa适合与同类型网站比较。
中文网站排行TOP500：个人感觉比alexa好，卢松松博客也赫然在列哦（在站长资源栏目）！
中国网站排名：以网站访问流量统计数据为依据适时发布“中国网站排名”。





&gt;&gt; 自媒体/公众帐号平台




QQ公众平台：QQ推出公众号，和微信一样QQ公众号分为订阅号和服务号两种，具体看卢松松注册QQ公众号时截图。
微信公众平台：载体是微信手机客户端，海量用户，营销效果超好，订阅用户超500位就可以申请认证。
腾讯媒体公众平台：它和微信公众平台可同步发布，主要面向腾讯新闻客户端推送，但是服务做的比较一般
今日头条媒体平台：文章工审核，发布速度比较慢，但是数据特别亮眼，往往一些趣味性的文章可以达到60万的阅读量，上千的收藏量。
搜狐新闻自媒体平台：后台很简洁，发布也很方便，我在该平台发布文章，几乎是秒过。流量的话还行，个别文章会有上千的阅读量。
网易云阅读开放平台：注册过程还是挺顺利，但是没有任何推荐的情况下，流量也很少，不多介绍了!
网易新闻媒体开放平台：出现在网易新闻手机客户端。
百度百家自媒体平台：百度联盟的广告全部分给自媒体人，申请方式Baijia@baidu.com
360自媒体平台：最近更新有点慢哦，可能是对自媒体不重视的原因，但流量入口很多，文章获得流量不菲。
360百科自媒体：优先收录有特色的媒体账号。 您提交的账号，会在七个工作日内处理。
米聊VIP账号：VIP账号订阅发布平台，目前米聊注册用户27000万，VIP账号采取邀请制。
飞信公众平台：中国移动推出的公众平台，认证非常麻烦，还要填表格、提交营业执照、加盖公章等。
博客投稿：在卢松松博客投稿会，您的文章会发布到大量媒体平台上，文章曝光率高。
微博自媒体平台：新浪旗下公众账号。申请标准为单月阅读数在300万以上，并且能够提供优质内容链接证明。
微淘公众平台：用淘宝ID登录后台，这个信息流的账号运营者将来自淘宝商家、媒体机构,或来自某个消费领域的意见领袖等。
易信公众平台：网易与中国电信推出的“易信”，除了具备微信的大多数功能之外，易信与微信最大的区别可通过易信给用户发送手机短信。
来往公众帐号：目前处于测试阶段，注册公众账号按照要求提交相应的资料，将在10个工作日内处理申请，建议按照要求去操作。





&gt;&gt; SEO查询工具




SEO综合查询：站长之家推出的工具，可快速查询网站SEO概况。
爱站：最出名的就是它的百度权重查询，虽然百度官方没有发布过任何权重值的信息，此类第三方工具仅供参考。
站长帮手：即时了解哪些友情链接私自撤下链接，能自动识别JS链接、iframe链接等欺骗链接的方式，现在也逐步发展为一个综合性站长工具站了。
国外SEO工具：覆盖功能最多的一款SEO查询网站，英文版网站使用。
网站流量工具：增长网站流量工具可以不断的刷新您的网站页面，让您网站流量立即倍增，迅速提升Alexa排名。
Alexa查询工具：可以查询Alexa的世界排名。
Alexa工具：alexa世界排名工具是一款提高网站alexa排名，增强网站竞争力的alexa排名优化的在线工具。





&gt;&gt; 网站管理员工具




百度站长平台：站长必备的网站管理员工具，主要服务于百度网页收录的数据提交，国内站长必备。
（新）好搜站长平台：360推出的站长平台，目前功能有sitemap、官网标注、索引查询、客服电话提交、等等
Google网站管理员工具：免费提供网页在Google上展示率详细报告的一个站长在线管理平台，站长可以在此查询站点在Google的索引和排名情况。
搜狗站长平台：功能都差不多，其特色功能有匹配中文站点名、匹配网站favicon，这次搜狗推出站长平台太低调了。
Bing网站管理员工具：使用有关搜索查询、爬网和搜索流量的 Bing 数据推动更多访问者访问您的网站。
即刻搜索站长中心：人民网旗下搜索引擎即刻推出的站长平台，目前来说平台功能还稍稍简单。
安全联盟站长平台：主要作用是网站安全检测,漏洞修复,漏洞扫描等功能。
Yandex 网站管理工具：Yandex是俄罗斯第一大搜索引擎,也是欧洲第二大流行搜索引擎，创建于1997年。





&gt;&gt; 网站被K申诉通道




百度网页申诉：只有一人处理申诉问题，然后分发到各个小组处理，很少回复，诚恳申诉，直入主题，网站被处理几率较大。

Google网站申诉：登陆Google网站管理员工具即可。

腾讯电脑管家网站申诉：QQ聊天窗口输入网址出现绿色对勾、红色叉（不信任网站）均可以在这里申诉。
知道创宇安全联盟申诉通道：百度搜索结果中出现的风险提示，均来自SCANV(知道创宇)的网址库。
360网盾申诉：360网盾拦截木马病毒网站，采取自动加人工的审核方法，核实您申诉的网址是否存在欺骗、不健康或者其他恶意信息的行为。
金山云安全网站申诉：主要通过杀毒软件拦截的网页，如果出现误报可以向金山申诉。
更多申诉登陆口点此进入……





&gt;&gt; 网站速度测试工具




阿里测：功能强大，这个用来测试站点速度和提供优化方案蛮不错。
卡卡网：国内常用的一款网站测速工具，优点是测试的节点多。
分布式监测点：来自监控宝，国内常用的一款网站测速工具，优点是检测速度快。
gtmetrix：国外一款测速工具，优点是能提供详细数据。
whichloadsfaster：国外一款网站速度对比工具，可以比较两个网站打开速度。





&gt;&gt; 免费CDN




DnsPod：国内老牌DNS服务商，为各类网站提供高质量的电信、网通、教育网双线或者三线智能DNS免费解析，提高网站解析速度。
DnsPod国际版：国内的IP是不可以在国际版注册的，需要有国外的IP才行，或者把浏览器语言改为英语才能正常访问。
360网站卫士：功能很多，有免费CDN、CC保护、网站防火墙、DDOS保护、页面压缩、访问加速等功能。
安全宝Mini CDN：新兴的免费CDN服务，注册门槛较高，使用评测少，不好鉴别网站加速好坏。
加速乐：免费CDN、平均加速200%以上，访问量提升19%，是唯一一款使用前后不会影响网站访问及搜索引擎排名的免费CDN平台。
Webluker：一站式运维服务综合平台，虽然整个技术团队比较年轻，但是已经成长为国内最知名的CDN服务商了。
CloudFlare：比较早的免费CDN服务了，如果你的网站访问用户是全世界的，那么CloudFlare一定适合你。
云盾：新兴力量、后起之秀，"云盾"安全防护系统为网站、在线应用提供一站式的安全加速解决方案。
Nimsoft：国外CDN，在全球数十个国家有服务器（包括在中国），放在国外的网站推荐使用，并提供网站检测工具。





&gt;&gt; 网站安全检测




安全联盟：是一个中立、公正、可控的第三方组织，目前已经与百度、腾讯、招商银行等近800家机构、企业等官方网站达成合作。
360网站安全检测：360网站安全检测，我认为是功能最全的系统了，提供免费的网站漏洞检测、网页挂马检测、网页篡改监控服务。
监控宝：卢松松博客在使用，监控您的站点是否可以访问,发送故障通知,深入分析响应时间,生成性能报告,帮助您改善性能,提升服务品质。
百度网站安全检测工具：很重要，引用腾讯、金山、瑞星、小红伞、知道创宇的数据库，如果你的网站已在搜索结果中被标示不安全，可以提交申诉。
腾讯电脑管家安全检测：在QQ聊天窗口中发的网址，会调用此数据库，作用较大。
瑞星网站密码安全检测系统：通过全面的分析报告，为管理员提供快速修复网站密码安全隐患的建议。
诺顿在线网站安全检测：可以帮您了解网站的真实性与安全性，避免上网中病毒、木马，防止被钓鱼网站欺骗。
安全宝：特色功能，修复网站漏洞、免费mini CDN加速、可视化网站报告，创新工场旗下一员。
SCANV安全中心：与百度深入合作的安全检测网站，百度搜索结果的风险提示有部分数据就引用自SCANV，站长值得重视。





&gt;&gt; 网站联盟广告大全




百度联盟：做网站必备的赚钱工具，审核较严格，需要备案，付款方便，但要扣税，广告种类多。
Google adsense：站长投放最多的联盟广告，单价高，美元结算，申请方便，但监控非常严格，一点失误就会导致用就封闭帐号。
淘宝联盟：适合淘宝客类站长使用，广告投放方便，提现容易，适合电商类的淘宝客。
搜狗联盟：作为百度联盟的补充，如果被封可考虑用搜狗联盟。






&gt;&gt; 网站广告管家




百度广告管家：卢松松博客在用的广告管家工具，优点是操作简单、容易上手，缺点是有些时候影响网页打开速度。
Google DFP 广告管理系统：上手困难，但功能强大，国内站长用的不多。
CNZZ广告管家：免费托管的智能广告管理系统，依托于数据统计，在国内的用户量也不小。功能与百度广告管家一样。





&gt;&gt; 广告图片在线制作




百度创意专家：广告牌快速生成器，适合百度推广用户使用，物料模板很多。
Google Web Designer：入门级HTML5广告应用设计工具，无缝打造DoubleClick和AdMob广告，可选任何通用的发布环境；
阿里妈妈广告牌制作：可快速生成动画广告牌，制作Flash效果较好，支持用户自行设计图案、自定义广告牌尺寸等个性化服务。
55LA广告牌制作：老牌banner制作网站，卢松松一直在使用，素材多，制作方便，站长必备的图片工具。
美图秀秀网页版：简单易用，功能强大，海量的饰品、边框、场景素材以及独有图片特效可以使您的图片获得绝妙的效果。
Canva：Canva 致力于为用户提供一个设计图形，通过简单的拖拉拽操作和搜索 Canva 提供的 100 多万张图片字体等素材，即使你不是专业的设计师，也能很轻松地设计出令人满意的图片。





&gt;&gt; 统计工具




Google Analytics：一款专业级别的免费统计工具，数据精准，自定义程度非常高，功能非常全，但新人上手较困难。
百度统计：符合中国站长使用习惯的统计工具，它提供了专业的流量统计和分析（可能利于百度收录），统计IP数比其他工具略低。
CNZZ统计：国内站长用的最多的统计工具，功能全面，是国内免费数据统计的领导者。
51LA统计：操作方便，数据一目了然，卢松松用的时间最长的一款简单的统计工具，有时候会有些小问题。





&gt;&gt; 社会化工具




多说评论：目前站长用的最多的插件了，第三方社会化评论系统，功能同上！
灯鹭社会化评论：功能最全的一款社会化工具，包含社会化登陆和分享功能，代码简洁、加载速度快，支持二次开发。
JiaThis分享：国内中小网站使用量最大的分享工具，数据分析强大，代码简洁。
bShare分享：社会化分享工具，可把文章一键分享到上百个社会化网站中。优点是与同类工具比后台统计数据全面、专业。
无觅相关文章插件：利用数据挖掘的技术，在读者阅读时显示最相关的内容，从而提升访问量，延长读者逗留在您网站的时间。
友言：一键同步评论留言分享到社交平台，实时采集SNS相关留言评论，迅速提升网站社会化流量。
友荐相关文章推荐工具：JiaThis旗下网站，与无觅相关文章插件类似，但代码简洁，同时还能在、各自合作网站实现站站互推。
乐知相关文章插件：bshare旗下网站，代码简洁，功能同上！
云推荐：阿里云旗下面向站长的智能文章推荐工具！基于阿里云先进的云计算系统，支持海量网页数据和用户行为数据的分析计算。
百度推荐工具：该工具是通过对用户访问内容和行为的数据分析，向用户相关的文章内容，以此提高网站流量和黏性。






&gt;&gt; 适合站长的开放平台




搜狗开放平台：搜搜并入搜狗，所以搜狗很有潜力，包含数据开放平台、官网认证开放平台、站长平台。
QQ邮箱开放平台：载体是QQ邮箱，通过邮箱用户可以订阅你的网站、博客，订阅人数非常大，但很难倒回流量。
新浪微博开放平台：中小站长不容易申请，一旦申请成功，会获得不少流量回报。
腾讯微博开放平台：中小站长不容易申请，共享腾讯海量用户，传播力度非常大。
QQ互联：通过QQ互联，网站主和开发者可以申请接入QQ登录、用户可以使用QQ账号登录接入的站点。
百度移动开放平台：通过CNAME的方式解析域名到百度，可以实现快速建立适合百度搜索的WAP网站。
360开放平台大全：拥有360软件开放平台、WEB应用开放平台、浏览器开放平台、团购开放平台、游戏开放平台、手机开放平台等开放平台








&gt;&gt; 搜索引擎网站收录地址大全 【点此提交您的搜索引擎】




360好搜URL提交：http://zhanzhang.haosou.com/?m=PageInclude&amp;a=index
百度搜索网址提交入口口：http://zhanzhang.baidu.com/sitesubmit/index
百度死链提交入口：http://zhanzhang.baidu.com/badlink/index
百度信誉申请：http://trust.baidu.com/vstar/feedback
搜狗URL提交：http://zhanzhang.sogou.com/index.php/urlSubmit/index
360好搜搜索引擎登录入口：http://info.so.360.cn/site_submit.html
360好搜新闻源收录入口：http://info.so.360.cn/news_submit.html
360网站点评平台（红番茄）：http://wangzhan.360.cn/dianping/reg
Google网址提交入口：https://www.google.com/webmasters/tools/submit-url?pli=1
Google新闻网站内容：http://www.google.com/support/news_pub/bin/request.py?contact_type=suggest_content&amp;hl=cn
搜狗网站收录提交入口:http://www.sogou.com/feedback/urlfeedback.php
盘古数据开放平台：http://open.panguso.com/data/resource/url/new
bing(必应)网页提交登录入口：http://www.bing.com/toolbox/submit-site-url
简搜搜索引擎登陆口：http://www.jianso.com/add_site.html
雅虎中国网站登录口：http://sitemap.cn.yahoo.com/
搜索引擎登陆入口大全：http://www.zui5.com/addurl.html
网易有道搜索引擎登录口：http://tellbot.youdao.com/report
中搜免费登录服务：http://register.zhongsou.com/NetSearch/frontEnd/free_protocol.htm
MSN必应网站登录口：http://cn.bing.com/docs/submit.aspx?FORM=WSDD2
Alexa网站登录入口：http://www.alexa.com/help/webmasters
TOM搜索网站登录口：http://search.tom.com/tools/weblog/log.php
铭万网B2B(必途)网址登陆口：http://search.b2b.cn/pageIncluded/AddPage.php
博客大全提交：http://lusongsong.com/daohang/login.asp
蚁搜搜索网站登录口：http://www.antso.com/apply.asp
快搜搜索网站登录口：http://www.kuaisou.com/main/inputweb.asp
汕头搜索登录口：http://www.stsou.com/join.asp
孙悟空搜索网站登录：http://www.swkong.com/add.php
博客大全提交：http://lusongsong.com/daohang/login.asp
天网网站登陆口：http://home.tianwang.com/denglu.htm
速搜全球登陆口：http://www.suso.com.cn/suso/link.asp
酷帝网站目录提交入口：http://www.coodir.com/accounts/addsite.asp
快搜网站登陆口：http://www.kuaisou.com/main/inputweb.asp
找人网登陆口：http://m.zhaoren.net/djxunzhi.htm
搜猫搜索引擎登录入口：http://test.somao123.com/search/url_submit.php
智搜网站登录入口：http://www.zxyt.cn/url/site_submit.php
站长搜网址提交：http://www.zhanzhangsou.com/url_submit.html
一淘网开放搜索申请入口：http://open.etao.com/apply_intro.htm?spm=0.0.0.0.unaXx8
站长之家网站排行榜：http://top.chinaz.com/include.aspx
爱搜搜索引擎登录入口：http://www.aiso0.com/search/url_submit.php
SOSO搜搜网站收录提交入口:http://help.soso.com/help_web_09.shtml






&gt;&gt; 独立博客收录提交网址




百度博客提交: http://ping.baidu.com/ping.html
博客大全提交：http://lusongsong.com/daohang/login.asp
Google博客提交：http://blogsearch.google.com/ping
FeedSky提交博客: http://www.feedsky.com
搜狗(SoGou)博客提交：http://www.sogou.com/feedback/blogfeedback.php
必应 Bing博客提交：http://www.bing.com/toolbox/submit-site-url





&gt;&gt; 英文搜索网站收录地址




Dmoz网站登录入口：http://www.dmoz.org/World/Chinese_Simplified
NetSearch登陆口：http://intelseek.com/add_url_form.asp
Freewebsubmission.com 搜索引擎批量提交：http://www.freewebsubmission.com/
快速登录20个搜索引擎：http://www.trafficzap.com/searchsubmit.php
HotBot登录口：http://www.hotbot.com/prefs_filters.asp?prov=Inktomifilter=web
netscape登录口：http://about.netscape.com/
AddMe登陆口 ：http://www.addme.com/submission/free-submission-start.php
NetSearch登录口：http://www.netsearch.org/promo/submit.htm
AddMe登录口：http://www.addme.com/s0new.htm
Link it All登录口：http://www.that-special-gift.com/ffa/links.html
Voyager登录口：http://www.voyagersearch.com/cgi-bin/q/search.cgi?NAVG=AddURL
Gigablast登录口：http://www.gigablast.com/addurl
Aeiwei登录口：http://www.aeiwi.com/submit.html
Infotiger登录口：http://www.infotiger.com/addurl.html
Nationaldirectory登录口：http://www.nationaldirectory.com/addurl/
WhatUseek登录口：http://www.whatuseek.com/addurl-secondary.shtml
Exactseek登录口：http://www.exactseek.com/add.html
Walhello登录口：http://www.walhello.com/addlinkgl.html
Scrubtheweb登录口：http://www.scrubtheweb.com/addurl.html
hit-parade登录口：http://www.hit-parade.com/inscription.asp
excite登录口：http://registration.excite.com/excitereg/login.jsp
voodoo-it德国搜索引擎：http://www.voodoo-it.de/main.aspx?task=dombooking
viesearch登陆入口：http://viesearch.com/submit
ScrubTheWeb?登陆入口：http://www.scrubtheweb.com/addurl.html
ExactSeek登陆入口：http://www.exactseek.com/add.html
FyberSearch登陆入口：http://www.fybersearch.com/service/add-url.php
SecretSELabs登陆入口：http://www.secretsearchenginelabs.com/add-url.php
SoMuch登陆入口：http://www.somuch.com/submit-links/
GhetoSearch登陆入口：http://www.ghetosearch.com/add-url.php
Anoox登陆入口：http://www.anoox.com/add_for_indexing_free.php
FreePRWebDirectory登陆入口：http://www.freeprwebdirectory.com/submit.php
SWD登陆入口：http://www.submissionwebdirectory.com/submit.php
A1WebDirectory登陆入口：http://www.a1webdirectory.org/submit.php
Web World登陆入口：http://www.webworldindex.com/
SonicRun登陆入口：http://search.sonicrun.com/freelisting
1WebsDirectory登陆入口：http://www.1websdirectory.com/
Info Tiger登陆入口：http://www.infotiger.com/addurl.html
Online Society登陆入口：http://www.onlinesociety.org/submit.php





&gt;&gt; 网址导航站收录申请登陆口大全




hao123网址收录：http://submit.hao123.com/static/auditSys/wztj.htm
360网址导航收录入口：http://hao.360.cn/url.html
谷歌265上网导航网站提交：http://www.265.com/submit.html
牛企导航提交入口：http://www.zui4.com/member/?mod=website&amp;act=add
牛商网址导航提交入口：http://www.niushangdaohang.com/member/?mod=website&amp;act=add
2345网址导航申请收录入口：http://www.2345.com/help/submitweb.htm
必应网址导航提交：https://feedback.discoverbing.com/default.aspx?locale=zh-CN&amp;productkey=bingweb&amp;scrx=1
搜狗网址导航收录入口：http://123.sogou.com/about/shoulu.html
博客大全申请收录入口：http://lusongsong.com/daohang/login.asp
QQ导航网站收录申请规则：http://support.qq.com/cgi-bin/content_...
搜狗网址导航收录申请：http://123.sogou.com/shoulu.html
114啦网址收录：http://url.114la.com/
金山网址导航收录申请：http://123.duba.net/apply/
瑞星网址导航收录申请：http://hao.rising.cn/catalog/slsq.html
好看123网址导航收录申请：http://www.haokan123.com/urlsubmit/url_submit.html
466傲游网址导航申请收录网站：http://bbs.maxthon.cn/viewthread.php?tid=584498&amp;extra=
1616网址导航收录：http://www.1616.net/jd/misc/coop.htm
淘网址(tao123)收录申请：http://krq.tao123.com/collectsite/
0460网站之家收录：http://www.0460.com/member/login.aspx
赶驴啊网站收录提交入口：http://www.ganlva.com/url-submit/
hao123网站收录规则：http://www.hao123.cn/hezuo.htm
114网址导航收录申请：http://www.114.com.cn/index.php?view=websubmit
726网址收录口：http://www.726.com/url-submit/
1166网址收录口：http://www.1166.com/tool/add.html
中商网址导航链接提交：http://www.cb114.cn/apps/about.html
7999网址收录口：http://7999.com/misc/coop.htm
369网址大全新站提交：http://wvw.369.com/us/url.htm
568网址导航网址提交：http://www.568.cc/abc/website-add.html
找军事网址提交：http://www.zhaojunshi.com/url-submit/
19687网站大全网址提交：http://www.19687.com/apps/about.html#add
易看网址大全：http://www.ekan123.com/shoulu.htm
1181网址登陆：http://link.1181.com/adduser.asp
57616网址导航登陆：http://www.57616.com/apps/about.html#add
Jia123网址网址提交：http://bbs.jia123.com/index.asp?boardid=2
6617网址提交：http://www.6617.com/sqsl.shtml
46网址提交：http://www.46.com/html/url_submit.htm
6617网址提交：http://www.6617.com/sqsl.shtml
我搜网址提交：http://hao.woso.cn/us/url.html
258商业搜索：http://www.258.com/service/submit.php





&gt;&gt; 网站管理员工具大全（搜索引擎）：




（新）神马站长平台：神马搜索专注于移动互联网，应该是目前移动端访问量最大的搜索引擎。
好搜站长平台：360推出的站长平台，目前功能有sitemap、官网标注、索引查询、客服电话提交、等等
百度站长平台：站长必备的网站管理员工具，主要服务于百度网页收录的数据提交，国内站长必备。
Google网站管理员工具：免费提供网页在Google上展示率详细报告的一个站长在线管理平台，站长可以在此查询站点在Google的索引和排名情况。
搜狗站长平台：功能都差不多，其特色功能有匹配中文站点名、匹配网站favicon，这次搜狗推出站长平台太低调了。
Bing网站管理员工具：使用有关搜索查询、爬网和搜索流量的 Bing 数据推动更多访问者访问您的网站。
即刻搜索站长中心：人民网旗下搜索引擎即刻推出的站长平台，目前来说平台功能还稍稍简单。
安全联盟站长平台：主要作用是网站安全检测,漏洞修复,漏洞扫描等功能。
Yandex 网站管理工具：Yandex是俄罗斯第一大搜索引擎,也是欧洲第二大流行搜索引擎，创建于1997年。





&gt;&gt; 开放平台注册应用大全：




QQ空间认证：http://page.opensns.qq.com/apply.html
搜狗官网认证：http://help.sogou.com/renzheng/
（新）搜狗问问开放平台：http://open.wenwen.sogou.com/
百度官网认证：http://guanwang.baidu.com/vcard/officialsite
360官网认证：http://zhanzhang.so.com/?m=SiteCertification&amp;a=siteVerify
Discuz! 开放平台：http://open.discuz.net/
PHPCMS开放平台：http://open.phpcms.cn/
搜搜论坛开放计划：http://open.soso.com/datacoop/bbs/submitbbs.html （仅适用于Discus，会带来大量外链）
搜狗开放平台：http://open.sogou.com/ （搜搜并入搜狗，所以搜狗很有潜力）
新浪微博开放平台：http://open.weibo.com/
微游戏开放平台：http://open.weibo.com/game/
腾讯微博开放平台：http://dev.open.t.qq.com/
微信开放平台：http://open.weixin.qq.com/
腾讯社区开放平台：http://opensns.qq.com/
腾讯Q+平台：http://dev.qplus.com/
拍拍网开放平台：http://pop.paipai.com/
QQ互联：http://connect.qq.com/
百度开放平台：http://open.baidu.com/
百度开发者中心：http://developer.baidu.com/
百度知道开放平台：http://open.zhidao.baidu.com/
人人网开放平台：http://dev.renren.com/
网易微博开放平台：http://open.t.163.com/
网易云阅读开放平台：http://open.yuedu.163.com/
搜狐微博开放平台：http://open.t.sohu.com/
搜狐新闻客户端全媒体平台：http://mp.k.sohu.com/
搜狐博客开放平台：http://ow.blog.sohu.com/
淘宝开放平台：http://open.taobao.com
支付宝开放平台：http://bizpartner.alipay.com/denglu/index.htm
阿里巴巴开放平台：http://open.1688.com/
豆瓣API key：http://www.douban.com/service/apikey/apply
UC优视开放平台：http://www.uc.cn/business/ucly.shtml
天涯开放平台：http://open.tianya.cn/
Google站长开发者：https://www.google.com/accounts/ManageDomains
开心开放平台：http://open.kaixin001.com/
天翼开放平台：http://open.189.cn/
360软件开放平台：http://rz.360.cn/
360应用开放平台：http://dev.app.360.cn/
雅虎开放平台：https://developer.apps.yahoo.com/projects
Twitter开放平台：https://dev.twitter.com/
Facebook开放平台：https://developers.facebook.com/
56视频开放平台：http://dev.56.com/
亿起发--开放平台：http://open.yiqifa.com/





&gt;&gt; 向搜索引擎递交sitemap大全（网站地图）：




搜狗sitemap提交：http://zhanzhang.sogou.com/index.php/sitemap/index/type/sitemap 可帮助sogou爬虫抓取你的网站，目前采用邀请制。
360sitemap提交：http://zhanzhang.so.com/?m=Sitemap&amp;a=listSite 有助于360更全面、更快速地对网站进行抓取。
腾讯搜搜：http://open.soso.com/sitemap/ 搜搜开放平台提供了提交sitemap的功能。
百度：http://sitemap.baidu.com/ 百度站长平台，期待很久了，可惜一直在内测中。暂时无法提交。
雅虎中国：http://sitemap.cn.yahoo.com/ 雅虎中国的站长工具很早就提供了提交sitemap的功能，还支持rss。
Google：https://www.google.com/webmasters/tools/ 可谓最强大的网站管理员工具，提交sitemap当然是最基本的。
Yandex：http://webmaster.yandex.com/ Yandex是俄罗斯最大的搜索引擎，相对于俄罗斯的百度。管理员工具提供了类似Google Webmaster的功能，非常强大。
Bing：http://www.bing.com/toolbox/webmaster/ 微软的强力产品，在美国市场占有一定搜索份额。管理员工具功能也很强大。
Yahoo!：https://siteexplorer.search.yahoo.com/ 雅虎英文站，因为同微软的bing合作关系，提交sitemap后提示已经提交给了微软。
Ask：http://submissions.ask.com/ping?sitemap=http://www.YourWebSite.com/sitemap.xml 修改红色部分的url为自己的sitemap地址，直接在浏览器提交。
最后，在robots.txt文件中添加sitemap，搜索引擎抓取robots.txt的时候就可以获取sitemap。方法非常简单，只要在robots.txt的第一行或者最后一行按以下格式加入sitemap地址即可。
Sitemap: http://www.example.com/sitemap.xml





网站被K申诉通道




百度网页申诉：http://zhanzhang.baidu.com/feedback
百度新闻源投诉：http://tousu.baidu.com/news/add/
腾讯QQ电脑管家网站申诉：http://guanjia.qq.com/complaint.html
Google网站申诉：http://www.google.com/webmasters/
雅虎网站申诉：http://help.cn.yahoo.com/feedback.html?product=onesearch&amp;source=1W5
知道创宇（Scanv）安全联盟申诉通道：http://www.anquan.org/seccenter/appeal_verify/
360网盾申诉：http://wd.360.cn/appeal/appeal.html
360网页快照删除申请：http://info.so.360.cn/cache_remove.html
金山云安全网站申诉：http://fish.ijinshan.com/Kws/appeal (注：搜狗浏览器遇到拦截，也可在金山申诉)
瑞星卡卡网站申诉：http://tool.ikaka.com/ssinfo.asp
申请腾讯电脑管认证服务：http://guanjia.qq.com/online_server/certify/index.html
360网站点评站长申诉通道：http://dianping.360.cn/complaint













类加载过程

    类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：加载、验证、准备、解析、初始化、使用和卸载七个阶段。它们开始的顺序如下图所示：




    其中类加载的过程包括了加载、验证、准备、解析、初始化五个阶段。在这五个阶段中，加载、验证、准备和初始化这四个阶段发生的顺序是确定的，而解析阶段则不一定，它在某些情况下可以在初始化阶段之后开始，这是为了支持Java语言的运行时绑定（也成为动态绑定或晚期绑定）。另外注意这里的几个阶段是按顺序开始，而不是按顺序进行或完成，因为这些阶段通常都是互相交叉地混合进行的，通常在一个阶段执行的过程中调用或激活另一个阶段。

    这里简要说明下Java中的绑定：绑定指的是把一个方法的调用与方法所在的类(方法主体)关联起来，对java来说，绑定分为静态绑定和动态绑定：



静态绑定：即前期绑定。在程序执行前方法已经被绑定，此时由编译器或其它连接程序实现。针对java，简单的可以理解为程序编译期的绑定。java当中的方法只有final，static，private和构造方法是前期绑定的。动态绑定：即晚期绑定，也叫运行时绑定。在运行时根据具体对象的类型进行绑定。在java中，几乎所有的方法都是后期绑定的。

    下面详细讲述类加载过程中每个阶段所做的工作。




   加载



    加载时类加载过程的第一个阶段，在加载阶段，虚拟机需要完成以下三件事情：

    1、通过一个类的全限定名来获取其定义的二进制字节流。

    2、将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。

    3、在Java堆中生成一个代表这个类的java.lang.Class对象，作为对方法区中这些数据的访问入口。

    注意，这里第1条中的二进制字节流并不只是单纯地从Class文件中获取，比如它还可以从Jar包中获取、从网络中获取（最典型的应用便是Applet）、由其他文件生成（JSP应用）等。

    相对于类加载的其他阶段而言，加载阶段（准确地说，是加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，因为开发人员既可以使用系统提供的类加载器来完成加载，也可以自定义自己的类加载器来完成加载。

    加载阶段完成后，虚拟机外部的 二进制字节流就按照虚拟机所需的格式存储在方法区之中，而且在Java堆中也创建一个java.lang.Class类的对象，这样便可以通过该对象访问方法区中的这些数据。

    说到加载，不得不提到类加载器，下面就具体讲述下类加载器。

    类加载器虽然只用于实现类的加载动作，但它在Java程序中起到的作用却远远不限于类的加载阶段。对于任意一个类，都需要由它的类加载器和这个类本身一同确定其在就Java虚拟机中的唯一性，也就是说，即使两个类来源于同一个Class文件，只要加载它们的类加载器不同，那这两个类就必定不相等。这里的“相等”包括了代表类的Class对象的equals（）、isAssignableFrom（）、isInstance（）等方法的返回结果，也包括了使用instanceof关键字对对象所属关系的判定结果。

    站在Java虚拟机的角度来讲，只存在两种不同的类加载器：



启动类加载器：它使用C++实现（这里仅限于Hotspot，也就是JDK1.5之后默认的虚拟机，有很多其他的虚拟机是用Java语言实现的），是虚拟机自身的一部分。所有其他的类加载器：这些类加载器都由Java语言实现，独立于虚拟机之外，并且全部继承自抽象类java.lang.ClassLoader，这些类加载器需要由启动类加载器加载到内存中之后才能去加载其他的类。



    站在Java开发人员的角度来看，类加载器可以大致划分为以下三类：



启动类加载器：Bootstrap ClassLoader，跟上面相同。它负责加载存放在JDK\jre\lib(JDK代表JDK的安装目录，下同)下，或被-Xbootclasspath参数指定的路径中的，并且能被虚拟机识别的类库（如rt.jar，所有的java.*开头的类均被Bootstrap ClassLoader加载）。启动类加载器是无法被Java程序直接引用的。扩展类加载器：Extension ClassLoader，该加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载JDK\jre\lib\ext目录中，或者由java.ext.dirs系统变量指定的路径中的所有类库（如javax.*开头的类），开发者可以直接使用扩展类加载器。应用程序类加载器：Application ClassLoader，该类加载器由sun.misc.Launcher$AppClassLoader来实现，它负责加载用户类路径（ClassPath）所指定的类，开发者可以直接使用该类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。



     应用程序都是由这三种类加载器互相配合进行加载的，如果有必要，我们还可以加入自定义的类加载器。因为JVM自带的ClassLoader只是懂得从本地文件系统加载标准的java
 class文件，因此如果编写了自己的ClassLoader，便可以做到如下几点：

 1）在执行非置信代码之前，自动验证数字签名。

 2）动态地创建符合用户特定需要的定制化构建类。

 3）从特定的场所取得java class，例如数据库中和网络中。

事实上当使用Applet的时候，就用到了特定的ClassLoader，因为这时需要从网络上加载java class，并且要检查相关的安全信息，应用服务器也大都使用了自定义的ClassLoader技术。



    这几种类加载器的层次关系如下图所示：




    这种层次关系称为类加载器的双亲委派模型。我们把每一层上面的类加载器叫做当前层类加载器的父加载器，当然，它们之间的父子关系并不是通过继承关系来实现的，而是使用组合关系来复用父加载器中的代码。该模型在JDK1.2期间被引入并广泛应用于之后几乎所有的Java程序中，但它并不是一个强制性的约束模型，而是Java设计者们推荐给开发者的一种类的加载器实现方式。

    双亲委派模型的工作流程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把请求委托给父加载器去完成，依次向上，因此，所有的类加载请求最终都应该被传递到顶层的启动类加载器中，只有当父加载器在它的搜索范围中没有找到所需的类时，即无法完成该加载，子加载器才会尝试自己去加载该类。

    使用双亲委派模型来组织类加载器之间的关系，有一个很明显的好处，就是Java类随着它的类加载器（说白了，就是它所在的目录）一起具备了一种带有优先级的层次关系，这对于保证Java程序的稳定运作很重要。例如，类java.lang.Object类存放在JDK\jre\lib下的rt.jar之中，因此无论是哪个类加载器要加载此类，最终都会委派给启动类加载器进行加载，这边保证了Object类在程序中的各种类加载器中都是同一个类。






   验证
    验证的目的是为了确保Class文件中的字节流包含的信息符合当前虚拟机的要求，而且不会危害虚拟机自身的安全。不同的虚拟机对类验证的实现可能会有所不同，但大致都会完成以下四个阶段的验证：文件格式的验证、元数据的验证、字节码验证和符号引用验证。





文件格式的验证：验证字节流是否符合Class文件格式的规范，并且能被当前版本的虚拟机处理，该验证的主要目的是保证输入的字节流能正确地解析并存储于方法区之内。经过该阶段的验证后，字节流才会进入内存的方法区中进行存储，后面的三个验证都是基于方法区的存储结构进行的。
元数据验证：对类的元数据信息进行语义校验（其实就是对类中的各数据类型进行语法校验），保证不存在不符合Java语法规范的元数据信息。字节码验证：该阶段验证的主要工作是进行数据流和控制流分析，对类的方法体进行校验分析，以保证被校验的类的方法在运行时不会做出危害虚拟机安全的行为。符号引用验证：这是最后一个阶段的验证，它发生在虚拟机将符号引用转化为直接引用的时候（解析阶段中发生该转化，后面会有讲解），主要是对类自身以外的信息（常量池中的各种符号引用）进行匹配性的校验。








   准备
    准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区中分配。对于该阶段有以下几点需要注意：



    1、这时候进行内存分配的仅包括类变量（static），而不包括实例变量，实例变量会在对象实例化时随着对象一块分配在Java堆中。

    2、这里所设置的初始值通常情况下是数据类型默认的零值（如0、0L、null、false等），而不是被在Java代码中被显式地赋予的值。

   假设一个类变量的定义为：

public static int value = 3；

    那么变量value在准备阶段过后的初始值为0，而不是3，因为这时候尚未开始执行任何Java方法，而把value赋值为3的putstatic指令是在程序编译后，存放于类构造器&lt;clinit&gt;（）方法之中的，所以把value赋值为3的动作将在初始化阶段才会执行。

    下表列出了Java中所有基本数据类型以及reference类型的默认零值：




   这里还需要注意如下几点：



对基本数据类型来说，对于类变量（static）和全局变量，如果不显式地对其赋值而直接使用，则系统会为其赋予默认的零值，而对于局部变量来说，在使用前必须显式地为其赋值，否则编译时不通过。对于同时被static和final修饰的常量，必须在声明的时候就为其显式地赋值，否则编译时不通过；而只被final修饰的常量则既可以在声明时显式地为其赋值，也可以在类初始化时显式地为其赋值，总之，在使用前必须为其显式地赋值，系统不会为其赋予默认零值。对于引用数据类型reference来说，如数组引用、对象引用等，如果没有对其进行显式地赋值而直接使用，系统都会为其赋予默认的零值，即null。如果在数组初始化时没有对数组中的各元素赋值，那么其中的元素将根据对应的数据类型而被赋予默认的零值。



    3、如果类字段的字段属性表中存在ConstantValue属性，即同时被final和static修饰，那么在准备阶段变量value就会被初始化为ConstValue属性所指定的值。

   假设上面的类变量value被定义为： 

public static final int value = 3；

    编译时Javac将会为value生成ConstantValue属性，在准备阶段虚拟机就会根据ConstantValue的设置将value赋值为3。回忆上一篇博文中对象被动引用的第2个例子，便是这种情况。我们可以理解为static
 final常量在编译期就将其结果放入了调用它的类的常量池中。






   解析

   解析阶段是虚拟机将常量池中的符号引用转化为直接引用的过程。在Class类文件结构一文中已经比较过了符号引用和直接引用的区别和关联，这里不再赘述。前面说解析阶段可能开始于初始化之前，也可能在初始化之后开始，虚拟机会根据需要来判断，到底是在类被加载器加载时就对常量池中的符号引用进行解析（初始化之前），还是等到一个符号引用将要被使用前才去解析它（初始化之后）。

    对同一个符号引用进行多次解析请求时很常见的事情，虚拟机实现可能会对第一次解析的结果进行缓存（在运行时常量池中记录直接引用，并把常量标示为已解析状态），从而避免解析动作重复进行。

    解析动作主要针对类或接口、字段、类方法、接口方法四类符号引用进行，分别对应于常量池中的CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTANT_Methodref_info、CONSTANT_InterfaceMethodref_info四种常量类型。



    1、类或接口的解析：判断所要转化成的直接引用是对数组类型，还是普通的对象类型的引用，从而进行不同的解析。

    2、字段解析：对字段进行解析时，会先在本类中查找是否包含有简单名称和字段描述符都与目标相匹配的字段，如果有，则查找结束；如果没有，则会按照继承关系从上往下递归搜索该类所实现的各个接口和它们的父接口，还没有，则按照继承关系从上往下递归搜索其父类，直至查找结束，查找流程如下图所示：







   从下面一段代码的执行结果中很容易看出来字段解析的搜索顺序：





[java] view
 plaincopy






class Super{  
    public static int m = 11;  
    static{  
        System.out.println("执行了super类静态语句块");  
    }  
}  
  
  
class Father extends Super{  
    public static int m = 33;  
    static{  
        System.out.println("执行了父类静态语句块");  
    }  
}  
  
class Child extends Father{  
    static{  
        System.out.println("执行了子类静态语句块");  
    }  
}  
  
public class StaticTest{  
    public static void main(String[] args){  
        System.out.println(Child.m);  
    }  
}  

    执行结果如下：

    执行了super类静态语句块
    执行了父类静态语句块
    33
    如果注释掉Father类中对m定义的那一行，则输出结果如下：

    执行了super类静态语句块
    11

   另外，很明显这就是上篇博文中的第1个例子的情况，这里我们便可以分析如下：static变量发生在静态解析阶段，也即是初始化之前，此时已经将字段的符号引用转化为了内存引用，也便将它与对应的类关联在了一起，由于在子类中没有查找到与m相匹配的字段，那么m便不会与子类关联在一起，因此并不会触发子类的初始化。

    最后需要注意：理论上是按照上述顺序进行搜索解析，但在实际应用中，虚拟机的编译器实现可能要比上述规范要求的更严格一些。如果有一个同名字段同时出现在该类的接口和父类中，或同时在自己或父类的接口中出现，编译器可能会拒绝编译。如果对上面的代码做些修改，将Super改为接口，并将Child类继承Father类且实现Super接口，那么在编译时会报出如下错误：

StaticTest.java:24: 对 m 的引用不明确，Father 中的 变量 m 和 Super 中的 变量 m
都匹配
                System.out.println(Child.m);
                                        ^
1 错误



        3、类方法解析：对类方法的解析与对字段解析的搜索步骤差不多，只是多了判断该方法所处的是类还是接口的步骤，而且对类方法的匹配搜索，是先搜索父类，再搜索接口。

    4、接口方法解析：与类方法解析步骤类似，知识接口不会有父类，因此，只递归向上搜索父接口就行了。


    初始化
    初始化是类加载过程的最后一步，到了此阶段，才真正开始执行类中定义的Java程序代码。在准备阶段，类变量已经被赋过一次系统要求的初始值，而在初始化阶段，则是根据程序员通过程序指定的主观计划去初始化类变量和其他资源，或者可以从另一个角度来表达：初始化阶段是执行类构造器&lt;clinit&gt;()方法的过程。

   这里简单说明下&lt;clinit&gt;（）方法的执行规则:

    1、&lt;clinit&gt;（）方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序所决定的，静态语句块中只能访问到定义在静态语句块之前的变量，定义在它之后的变量，在前面的静态语句中可以赋值，但是不能访问。

    2、&lt;clinit&gt;（）方法与实例构造器&lt;init&gt;（）方法（类的构造函数）不同，它不需要显式地调用父类构造器，虚拟机会保证在子类的&lt;clinit&gt;（）方法执行之前，父类的&lt;clinit&gt;（）方法已经执行完毕。因此，在虚拟机中第一个被执行的&lt;clinit&gt;（）方法的类肯定是java.lang.Object。

    3、&lt;clinit&gt;（）方法对于类或接口来说并不是必须的，如果一个类中没有静态语句块，也没有对类变量的赋值操作，那么编译器可以不为这个类生成&lt;clinit&gt;（）方法。

    4、接口中不能使用静态语句块，但仍然有类变量（final static）初始化的赋值操作，因此接口与类一样会生成&lt;clinit&gt;（）方法。但是接口鱼类不同的是：执行接口的&lt;clinit&gt;（）方法不需要先执行父接口的&lt;clinit&gt;（）方法，只有当父接口中定义的变量被使用时，父接口才会被初始化。另外，接口的实现类在初始化时也一样不会执行接口的&lt;clinit&gt;（）方法。

    5、虚拟机会保证一个类的&lt;clinit&gt;（）方法在多线程环境中被正确地加锁和同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的&lt;clinit&gt;（）方法，其他线程都需要阻塞等待，直到活动线程执行&lt;clinit&gt;（）方法完毕。如果在一个类的&lt;clinit&gt;（）方法中有耗时很长的操作，那就可能造成多个线程阻塞，在实际应用中这种阻塞往往是很隐蔽的。




    下面给出一个简单的例子，以便更清晰地说明如上规则：





[java] view
 plaincopy






class Father{  
    public static int a = 1;  
    static{  
        a = 2;  
    }  
}  
  
class Child extends Father{  
    public static int b = a;  
}  
  
public class ClinitTest{  
    public static void main(String[] args){  
        System.out.println(Child.b);  
    }  
}  

   执行上面的代码，会打印出2，也就是说b的值被赋为了2。

    我们来看得到该结果的步骤。首先在准备阶段为类变量分配内存并设置类变量初始值，这样A和B均被赋值为默认值0，而后再在调用&lt;clinit&gt;（）方法时给他们赋予程序中指定的值。当我们调用Child.b时，触发Child的&lt;clinit&gt;（）方法，根据规则2，在此之前，要先执行完其父类Father的&lt;clinit&gt;（）方法，又根据规则1，在执行&lt;clinit&gt;（）方法时，需要按static语句或static变量赋值操作等在代码中出现的顺序来执行相关的static语句，因此当触发执行Father的&lt;clinit&gt;（）方法时，会先将a赋值为1，再执行static语句块中语句，将a赋值为2，而后再执行Child类的&lt;clinit&gt;（）方法，这样便会将b的赋值为2.

    如果我们颠倒一下Father类中“public static int a = 1;”语句和“static语句块”的顺序，程序执行后，则会打印出1。很明显是根据规则1，执行Father的&lt;clinit&gt;（）方法时，根据顺序先执行了static语句块中的内容，后执行了“public static int a = 1;”语句。

    另外，在颠倒二者的顺序之后，如果在static语句块中对a进行访问（比如将a赋给某个变量），在编译时将会报错，因为根据规则1，它只能对a进行赋值，而不能访问。





总结
     整个类加载过程中，除了在加载阶段用户应用程序可以自定义类加载器参与之外，其余所有的动作完全由虚拟机主导和控制。到了初始化才开始执行类中定义的Java程序代码（亦及字节码），但这里的执行代码只是个开端，它仅限于&lt;clinit&gt;（）方法。类加载过程中主要是将Class文件（准确地讲，应该是类的二进制字节流）加载到虚拟机内存中，真正执行字节码的操作，在加载完成后才真正开始。


类初始化是类加载过程的最后一个阶段，到初始化阶段，才真正开始执行类中的Java程序代码。虚拟机规范严格规定了有且只有四种情况必须立即对类进行初始化：



遇到new、getstatic、putstatic、invokestatic这四条字节码指令时，如果类还没有进行过初始化，则需要先触发其初始化。生成这四条指令最常见的Java代码场景是：使用new关键字实例化对象时、读取或设置一个类的静态字段（static）时（被static修饰又被final修饰的，已在编译期把结果放入常量池的静态字段除外）、以及调用一个类的静态方法时。使用Java.lang.refect包的方法对类进行反射调用时，如果类还没有进行过初始化，则需要先触发其初始化。当初始化一个类的时候，如果发现其父类还没有进行初始化，则需要先触发其父类的初始化。当虚拟机启动时，用户需要指定一个要执行的主类，虚拟机会先执行该主类。
    虚拟机规定只有这四种情况才会触发类的初始化，称为对一个类进行主动引用，除此之外所有引用类的方式都不会触发其初始化，称为被动引用。下面举一些例子来说明被动引用。



    1、通过子类引用父类中的静态字段，这时对子类的引用为被动引用，因此不会初始化子类，只会初始化父类





[java] view
 plaincopy






class Father{  
    public static int m = 33;  
    static{  
        System.out.println("父类被初始化");  
    }  
}  
  
class Child extends Father{  
    static{  
        System.out.println("子类被初始化");  
    }  
}  
  
public class StaticTest{  
    public static void main(String[] args){  
        System.out.println(Child.m);  
    }  
}  

    执行后输出的结果如下：



    父类被初始化
    33


    对于静态字段，只有直接定义这个字段的类才会被初始化，因此，通过其子类来引用父类中定义的静态字段，只会触发父类的初始化而不会触发子类的初始化。




    2、常量在编译阶段会存入调用它的类的常量池中，本质上没有直接引用到定义该常量的类，因此不会触发定义常量的类的初始化





[java] view
 plaincopy






class Const{  
    public static final String NAME = "我是常量";  
    static{  
        System.out.println("初始化Const类");  
    }  
}  
  
public class FinalTest{  
    public static void main(String[] args){  
        System.out.println(Const.NAME);  
    }  
}  

    执行后输出的结果如下：



    我是常量


    虽然程序中引用了const类的常量NAME，但是在编译阶段将此常量的值“我是常量”存储到了调用它的类FinalTest的常量池中，对常量Const.NAME的引用实际上转化为了FinalTest类对自身常量池的引用。也就是说，实际上FinalTest的Class文件之中并没有Const类的符号引用入口，这两个类在编译成Class文件后就不存在任何联系了。




    3、通过数组定义来引用类，不会触发类的初始化





[java] view
 plaincopy






class Const{  
    static{  
        System.out.println("初始化Const类");  
    }  
}  
  
public class ArrayTest{  
    public static void main(String[] args){  
        Const[] con = new Const[5];  
    }  
}  

    执行后不输出任何信息，说明Const类并没有被初始化。



    但这段代码里触发了另一个名为“LLConst”的类的初始化，它是一个由虚拟机自动生成的、直接继承于java.lang.Object的子类，创建动作由字节码指令newarray触发，很明显，这是一个对数组引用类型的初初始化，而该数组中的元素仅仅包含一个对Const类的引用，并没有对其进行初始化。如果我们加入对con数组中各个Const类元素的实例化代码，便会触发Const类的初始化，如下：





[java] view
 plaincopy






class Const{  
    static{  
        System.out.println("初始化Const类");  
    }  
}  
  
public class ArrayTest{  
    public static void main(String[] args){  
        Const[] con = new Const[5];  
        for(Const a:con)  
            a = new Const();  
    }  
}  

    这样便会得到如下输出结果：



    初始化Const类
    根据四条规则的第一条，这里的new触发了Const类。




    最后看一下接口的初始化过程与类初始化过程的不同。

    接口也有初始化过程，上面的代码中我们都是用静态语句块来输出初始化信息的，而在接口中不能使用“static{}”语句块，但编译器仍然会为接口生成&lt;clinit&gt;类构造器，用于初始化接口中定义的成员变量（实际上是static final修饰的全局常量）。

   二者在初始化时最主要的区别是：当一个类在初始化时，要求其父类全部已经初始化过了，但是一个接口在初始化时，并不要求其父接口全部都完成了初始化，只有在真正使用到父接口的时候（如引用接口中定义的常量），才会初始化该父接口。这点也与类初始化的情况很不同，回过头来看第2个例子就知道，调用类中的static final常量时并不会 触发该类的初始化，但是调用接口中的static
 final常量时便会触发该接口的初始化。






为Maven新手介绍如何使用Eclipse创建Maven Web工程的方法






工具/原料



Eclipse开发工具

Maven插件

Tomcat





方法/步骤




1


使用Eclipse创建Maven Web工程







2


找到Maven Project，点击Next







3


勾选上Create a simple project （不使用骨架），Next







4


填写工程名称和包名，并选择war类型，Finish







5


选择packing是war类型，在main下会生成 webapp目录







6


使用eclipse发布到tomcat下，需要把项目转成dynamic web project。

选择工程单击右键，选择properties 并找到 Project Facets ，并点击Convert to faceted form…










勾选Dynamic Web Module 并点击ok  (3.0只有tomcat7才支持)










这时工程结构下会产生一个Web Content目录










虽然此时我们可以发布到tomcat中，但这不符合maven的结构，继续操作。

把WebContent下面两个目录 META-INF ，WEB-INF 直接复制到src/main/webapp目录下，并删掉WebContent目录，结果如下










修改发布规则：先择工程单击右键， 选择 Properties，

选择Deployment Assembly：把WebContent Remove掉；测试类我们也不需要发布，test的两个目录页可以remove










重新指定WEB路径：点击add，选择Folder










在src/main下找到webapp目录，然后finish










把当前的build path 指向 Maven Dependency， 直接点击add，选择Java Build Path Entries 然后next

















完成后如下图










进入开发：

（1）pom.xml可以从http://www.mvnrepository.com/ 加入需要jar包的配置路径；

（2）webapp下可以创建web页面的目录结构；

（3）main/java里创建java程序包结构。





END





注意事项



Eclipse、Tomcat事先安装

Maven插件要事先安装到Eclipse




问题：很多人可能i会在创建maven工程是遇到这样的问题，创建一个maven工程后，其默认的jdk版本是1.5或更低，而现在一般的工程都要求jdk版本为1.7或更高，于是我们在项目属性中将其jdk版本修改为所要的版本，但修改后发现做maven的update后，jdk版本又回到最初状态了，或者是将版本更改后，会有一些错误。


以下操作可以帮助你修改其默认配置：
找到maven的setting.xml文件，在setting.xml文件的profiles节点下增加：
&lt;profile&gt;
    &lt;id&gt;jdk-1.7&lt;/id&gt;
    &lt;activation&gt;
        &lt;activeByDefault&gt;true&lt;/activeByDefault&gt;
        &lt;jdk&gt;1.7&lt;/jdk&gt;
    &lt;/activation&gt;
    &lt;properties&gt;
        &lt;maven.compiler.source&gt;1.7&lt;/maven.compiler.source&gt;
        &lt;maven.compiler.target&gt;1.7&lt;/maven.compiler.target&gt;
        &lt;maven.compiler.compilerVersion&gt;1.7&lt;/maven.compiler.compilerVersion&gt;
    &lt;/properties&gt;
&lt;/profile&gt; 就好了，这里配置的是1.7， 你可以修改成任何你需要的版本。


出现这个问题主要是hibernate4里不在有cacheprovider类，cacheprovider在hibernate3中才有，
用hibernate4就应该用hibernate4的SessionFactory。
具体的sessionfactory配置：
&lt;bean id="mysf" class="org.springframework.orm.hibernate4.LocalSessionFactoryBean"&gt;
    &lt;property name="dataSource" ref="ds"/&gt;

今天在做SSI框架整合的时候报了一个这样的错误：Action class [userAction] not found - action - file:/D:/tomcat-6.0.29/webapps/SSIBlank/WEB-INF/classes/struts.xml:10:54，找了好久，一直以为我配置的问题或者是缓存的原因，翻来覆去搞了好久也没搞好，最后想想...原来是这样，具体的异常详细信息如下： 
严重: Exception starting filter Struts2.1 
Unable to load configuration. - action - file:/D:/tomcat-6.0.29/webapps/SSIBlank/WEB-INF/classes/struts.xml:10:54 
at org.apache.struts2.dispatcher.Dispatcher.init(Dispatcher.java:431) 
at org.apache.struts2.dispatcher.ng.InitOperations.initDispatcher(InitOperations.java:69) 
at org.apache.struts2.dispatcher.ng.filter.StrutsPrepareAndExecuteFilter.init(StrutsPrepareAndExecuteFilter.java:51)
at org.apache.catalina.core.ApplicationFilterConfig.getFilter(ApplicationFilterConfig.java:295) 
at org.apache.catalina.core.ApplicationFilterConfig.setFilterDef(ApplicationFilterConfig.java:422) 
at org.apache.catalina.core.ApplicationFilterConfig.&lt;init&gt;(ApplicationFilterConfig.java:115) 
at org.apache.catalina.core.StandardContext.filterStart(StandardContext.java:4001) 
at org.apache.catalina.core.StandardContext.start(StandardContext.java:4651) 
at org.apache.catalina.core.ContainerBase.addChildInternal(ContainerBase.java:791) 
at org.apache.catalina.core.ContainerBase.addChild(ContainerBase.java:771) 
at org.apache.catalina.core.StandardHost.addChild(StandardHost.java:546) 
at org.apache.catalina.startup.HostConfig.deployDirectory(HostConfig.java:1041) 
at org.apache.catalina.startup.HostConfig.deployDirectories(HostConfig.java:964) 
at org.apache.catalina.startup.HostConfig.deployApps(HostConfig.java:502) 
at org.apache.catalina.startup.HostConfig.start(HostConfig.java:1277) 
at org.apache.catalina.startup.HostConfig.lifecycleEvent(HostConfig.java:321) 
at org.apache.catalina.util.LifecycleSupport.fireLifecycleEvent(LifecycleSupport.java:119) 
at org.apache.catalina.core.ContainerBase.start(ContainerBase.java:1053) 
at org.apache.catalina.core.StandardHost.start(StandardHost.java:785) 
at org.apache.catalina.core.ContainerBase.start(ContainerBase.java:1045) 
at org.apache.catalina.core.StandardEngine.start(StandardEngine.java:445) 
at org.apache.catalina.core.StandardService.start(StandardService.java:519) 
at org.apache.catalina.core.StandardServer.start(StandardServer.java:710) 
at org.apache.catalina.startup.Catalina.start(Catalina.java:581) 
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) 
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) 
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) 
at java.lang.reflect.Method.invoke(Method.java:597) 
at org.apache.catalina.startup.Bootstrap.start(Bootstrap.java:289) 
at org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:414) 
Caused by: Unable to load configuration. - action - file:/D:/tomcat-6.0.29/webapps/SSIBlank/WEB-INF/classes/struts.xml:10:54 
at com.opensymphony.xwork2.config.ConfigurationManager.getConfiguration(ConfigurationManager.java:58) 
at org.apache.struts2.dispatcher.Dispatcher.init_PreloadConfiguration(Dispatcher.java:374) 
at org.apache.struts2.dispatcher.Dispatcher.init(Dispatcher.java:418) 
... 29 more 
Caused by: Action class [userAction] not found - action - file:/D:/tomcat-6.0.29/webapps/SSIBlank/WEB-INF/classes/struts.xml:10:54 
at com.opensymphony.xwork2.config.providers.XmlConfigurationProvider.verifyAction(XmlConfigurationProvider.java:409)
at com.opensymphony.xwork2.config.providers.XmlConfigurationProvider.addAction(XmlConfigurationProvider.java:354)
at com.opensymphony.xwork2.config.providers.XmlConfigurationProvider.addPackage(XmlConfigurationProvider.java:468)
at com.opensymphony.xwork2.config.providers.XmlConfigurationProvider.loadPackages(XmlConfigurationProvider.java:264)
at org.apache.struts2.config.StrutsXmlConfigurationProvider.loadPackages(StrutsXmlConfigurationProvider.java:111)
at com.opensymphony.xwork2.config.impl.DefaultConfiguration.reloadContainer(DefaultConfiguration.java:193) 
at com.opensymphony.xwork2.config.ConfigurationManager.getConfiguration(ConfigurationManager.java:55) 
... 31 more 

    面对出现异常的情况一定要冷静的心态，不要看报了一大串异常就觉得无从下手，感到心烦意乱，其实报的异常越多说明你出现的问题越容易找（这是我自己的观点），哈哈...在看异常的时候抓住最后的Caused by，这才是引起异常的最终原因。 
下来看我们这个异常: 
检查步骤： 
1、看看你struts.xml文件中action中对应的class属性的值是否可以在Spring的配置文件中找到对应的id值。 
2、如果你确定你的配置没有出现问题，那么一定是你导入包的时候少了包，这时候你检查下你的项目中是否有以下三个jar包，struts2-spring-plugin-2.0.11.1.jar、commons-fileupload-1.2.1.jar和commons-io-1.3.2.jar。 
3、导入jar包之后如果还是有同样的错误，这时候你需要清理缓存或者把项目重新部署下，这样应该就可以解决问题了。 


最基本的Hibernate3.3.2之 JAR包（必要）：




包名


位置


用途




hibernate3.jar


/hibernate


核心JAR包




antlr.jar


/hibernate/lib/required


Another Tool for Language Recognition，可以构造语言识别器，解析HQL需要




commons-collections.jar


/hibernate/lib/required


包含了一些Apache开发的集合类，功能比java.util.*强大




dom4j.jar


/hibernate/lib/required


越来越多的Java软件都在使用dom4j来操作XML，Hibernate也不例外




javassist.jar


/hibernate/lib/required


操作字节码，跟cglib相关




jta.jar


/hibernate/lib/required


定义JTA规范的JAR包，当Hibernate使用JTA的时候需要




slf4j.jar


/hibernate/lib/required


整合各志框架种日的工具




slf4j-nop.jar


/slf4j


包含了对slf4j.jar的实现类





注意：slf4.jar和slf4j-nop.jar之间的版本需要匹配，如果Hibernate中使用早期的slf4j.jar，可以从slf4j官方网站下载新的JAR包将其置换掉

 

如果要使用Annotation，还需要下面的JAR包：




包名


位置


用途




hibernate-annotations.jar


/hibernate-annotations


使用Hibernate Annotation的核心JAR包




ejb3-persistence.jar


/hibernate-annotations/lib


实体类中使用的注解都是在这个JAR包中定义的




hibernate-commons-annotations.jar


/hibernate-annotations/lib


 




使用javax.persistence下的Annotation可以不依赖Hibernate的JAR包，这样的话可以切换到其他的ORM框架

 

如果要使用log4j，则需要添加相关的JAR包：




包名


位置


用途




log4j.jar


很多框架中都有


生成用户定制日志




slf4j-log4j.jar


/slf4j


将slf4j和log4j关联起来的JAR包





当然别忘记了在类路径下放log4j的配置文件哦





org.springframework.aop-3.0.6.RELEASE


Spring的面向切面编程,提供AOP(面向切面编程)实现




org.springframework.asm- 3.0.6.RELEASE


Spring独立的asm程序,Spring2.5.6的时候需要asmJar 包3.0.6开始提供他自己独立的asmJar




org.springframework.aspects- 3.0.6.RELEASE


Spring提供对AspectJ框架的整合




org.springframework.beans-3.0.6.RELEASE


SpringIoC(依赖注入)的基础实现




org.springframework.context.support-3.0.6.RELEASE


Spring-context的扩展支持,用于MVC方面




org.springframework.context-3.0.6.RELEASE


Spring提供在基础IoC功能上的扩展服务，此外还提供许多企业级服务的支持，如邮件服务、任务调度、JNDI定位、EJB集成、远程访问、缓存以及各种视图层框架的封装等




org.springframework.core-3.0.6.RELEASE


Spring3.0.6的核心工具包




org.springframework.expression-3.0.6.RELEASE


Spring表达式语言




org.springframework.instrument.tomcat-3.0.6.RELEASE


Spring3.0.6对Tomcat的连接池的集成




org.springframework.instrument-3.0.6.RELEASE


Spring3.0.6对服务器的代理接口




org.springframework.jdbc-3.0.6.RELEASE


对JDBC的简单封装




org.springframework.jms-3.0.6.RELEASE


为简化JMS API的使用而作的简单封装




org.springframework.orm-3.0.6.RELEASE


整合第三方的ORM框架，如hibernate,ibatis,jdo，以及 spring的JPA实现




org.springframework.oxm-3.0.6.RELEASE


Spring 对Object/XMl的映射支持,可以让Java与XML之间来回切换




org.springframework.test-3.0.6.RELEASE


对Junit等测试框架的简单封装




org.springframework.transaction-3.0.6.RELEASE


为JDBC、Hibernate、JDO、JPA等提供的一致的声明式和编程式事务管理




org.springframework.web.portlet-3.0.6.RELEASE


基于protlet的MVC实现




org.springframework.web.servlet-3.0.6.RELEASE


基于servlet的MVC实现




org.springframework.web.struts-3.0.6.RELEASE


整合Struts的时候的支持




org.springframework.web-3.0.6.RELEASE


SpringWeb下的工具包







Struts2.3.4 所需的Jar包及介绍




Jar包的分类


jar包名称


jar包版本


jar包
文件名


jar包
的作用


jar包内包含的主要包路径及主要类


依赖的自有jar包名称


依赖的第三方jar包名称


本jar包是否为第三方包




Struts
2.3.4
的
核
心
包


struts2-core
-2.3.4.jar


2.3.4


struts2-core
-2.3.4


struts2的核心包


org.apache.struts2.dispatcher.ng.filter.StrutsPrepareAndExecuteFilter


xwork-core
-2.3.4.jar


 


否




xwork-core
-2.3.4.jar
 


2.3.4


xwork-core
-2.3.4


xwork核心包


com.opensymphony.xwork2/ com.opensymphony.xwork2.cinfig/ com.opensymphony.xwork2.ognl/


 


 


否




aopalliance.jar
 


1.0


aopalliance
 


这个包为AOP提供了最普通和通用的接口


org.aopalliance.aop/org.aopalliance.aop.intercept


 


 


否




commons-fileupload-1.2.2.jar


1.2.2
 


commons-fileupload-1.2.2
 


Struts文件的上传下载


org.apacher.commons.fileupload/ org.apacher.commons.fileupload.util


 


 


否




commons-lang
3-3.1.jar


3.3.1
 


commons-lang3-3.1


为java.lang包提供扩展


org.apacher.commons.lang3/ org.apacher.commons.lang3.builder


 


 


否




commons-logging
-1.1.1.jar


1.1.1


commons-logging
-1.1.1
 


Jakarta的通用日志记录包


org.apacher.commons.logging/org.apacher.commons.logging.impl
 


 


 


否




freemarker-2.3.19.jar
 


2.3.19


freemarker-2.3.19
 


FreeMarker是一个模板引擎，一个基于模板生成文本输出的通用工具


 


 


 


否




ognl-3.0.5.jar
 


3.0.5


ognl-3.0.5
 


支持ognl表达式


Ognl


 


 


否




辅
助
Jar
包


struts2-spring
-plugin-2.3.4.jar
 


2.3.4
 


struts2-spring
-plugin-2.3.4
 


struts2和spring整合需要的包


 


 


 


否




antlr-2.7.2.jar
 


2.7.2


antlr-2.7.2


它是这样的一种工具,它可以接受词文法语言描述,并能产生识别这些语言的语句的程序


 


 


 


 




asm-3.3.jar
 


3.3


asm-3.3


操作java字节码的类库


 


 


 


 




asm-commons-3.3.jar


3.3


asm-commons-3.3


提供了基于事件的表现形式


 


 


 


 




asm-tree-3.3.jar
 


3.3


asm-tree-3.3
 


提供了基于对象的表现形式


 


 


 


 




classworlds-1.1.jar


1.1


classworlds-1.1


基于java操作类装载的开发框架。java的classloader的机制和本地类可以引起头痛，多为某些类型的应用程序开发的混乱。


 


 


 


 




 
 
commons-beanutils-1.8.0.jar
 


1.8.0


commons-beanutils-1.8.0


jakarta commons项目中的一个子项目。这个项目开发的目的是帮助开发者动态的获取/设值JavaBean的属性，同时解决每次都要写getXXX和setXXX的麻烦


 


 


 


 




commons-chain-1.2.jar
 


1.2
 


commons-chain-1.2


Apache 的 Commons-Chain 项目已将命令模式(Command)和责任链(Chain of Responsebility)模式两者完美的结合


 


 


 


 




 
commons-collections-3.1.jar
 
 


3.1


commons-collections-3.1


包含了一些Apache开发的集合类，扩展了标准的Java Collection框架，提供了额外的Map、List 和Set实现以及多个有用的工具类库。功能比java.util.*强大。


 


 


 


 




commons-digester-2.0.jar
 


2.0


commons-digester-2.0


Jakarta Struts中的一个工具，用于处理struts-config.xml配置文件


 


 


 


 




 
 
commons-logging-api-1.1.jar
 


1.1


commons-logging-api-1.1


Apache Commons包中的一个，包含了一些数据类型工具类，是java.lang.*的扩展。


 


 


 


 




commons-validator-1.3.1.jar
 


1.3.1
 


commons-validator-1.3.1


校验方法)和校验规则。支持校验规则的和错误消息的国际化。 struts使用它对表单进行验证
 


 


 


 


 




dwr-1.1.1.jar
 


1.1.1


dwr-1.1.1


Direct Web Remoting是一个WEB远程调用框架.Java开发利用这个框架可以让AJAX开发变得很简单.


 


 


 


 




 
 
ezmorph-1.0.6.jar
 


1.0.6


ezmorph-1.0.6


EZMorph是一个简单的java类库用于将一种对象转换成另外一种对象。EZMorph原先是Json-lib项目中的转换器。EZMorph支持原始数据类型（Primitive），对象（Object），多维护数组转换与DynaBeans的转换。struts2中，json的处理便使用了EZMorph库


 


 


 


 




google-collections-1.0.jar
 


1.0


google-collections-1.0


对现有Java集合类的一个扩展。


 


 


 


 




 
 
jackson-core-asl-1.9.2.jar


1.9.2


jackson-core-asl-1.9.2


一个高性能的解析器的核心库


 


 


 


 




json-lib-2.3-jdk15.jar
 


2.3
 


json-lib-2.3-jdk15
 
 


提供了强大的JSON支持，利用Ajax提交上来的JSON字符串进行解析，可以转化为POJO对象，可以从POJO转化为js可以识别的JSON对象。


 


 


 


 




juli-6.0.18.jar
 


6.0.18


juli-6.0.18


用于tomcat 错误日志查看


 


 


 


 




oro-2.0.8.jar
 


2.0.8


oro-2.0.8


RO一套文本处理工具,能提供perl5.0兼容的正则表达式,AWK-like正则表达式, glob表达式。还提供替换,分割,文件名过虑等功能


 


 


 


 




oval-1.31.jar
 


1.31


oval-1.31


OVal是一个提供事务和对象的可扩展验证框架的任何类型的Java对象。


 


 


 


 




plexus-container-default-1.0-alpha-10.jar
 


1.0
 
 


plexus-container-default-1.0-alpha-10


Plexus项目提供完整的软件栈，用于创建和执行软件项目。根据丛容器，应用程序可以利用面向组件编程构建模块化，它可以轻易地组装和重用可重用组件。根据Plexus容器，应用程序可以利用面向组件编程构建模块化，它可以轻易地组装和重用可重用组件。


 


 


 


 




plexus-utils-1.2.jar
 


1.2
 


plexus-utils


Plexus项目提供完整的软件栈，用于创建和执行软件项目。根据丛容器，应用程序可以利用面向组件编程构建模块化，它可以轻易地组装和重用可重用组件。


 


 


 


 




sitemesh-2.4.2.jar
 


2.4.2


sitemesh-2.4.2


SiteMesh是一个用来在JSP中实现页面布局和装饰（layout and decoration）的框架组件，能够帮助网站开发人员较容易实现页面中动态内容和静态装饰外观的分离。


 


 


 


 




 
 
struts2-codebehind-plugin-2.3.4.jar


2.3.4


struts2-codebehind-plugin-2.3.4


通常JSP页面来自于文件系统。利用这个插件，你可以将jsp页面部署到jar包中


 


 


 


 




struts2-config-browser-plugin-2.3.4.jar
 


2.3.4


struts2-config-browser-plugin-2.3.4


struts配置浏览器所需要的插件


 


 


 


 




struts2-convention-plugin-2.3.4.jar
 


2.3.4
 


struts2-convention-plugin-2.3.4


在默认情况下该公约插件查找操作类在以下软件包支柱,struts2的行为或行动,任何包相匹配这些名称将被考虑作为根包为常规插件。


 


 


 


 




 
 
struts2-dojo-plugin-2.3.4.jar
 


2.3.4
 
 


struts2-dojo-plugin-2.3.4


为struts所提供的一些控件例如：日历


 


 


 


 




struts2-dwr-plugin-2.3.4.jar
 


2.3.4


struts2-dwr-plugin-2.3.4


用于整合DWR


 


 


 


 




struts2-embeddedjsp-plugin-2.3.4.jar
 


2.3.4


struts2-embeddedjsp-plugin-2.3.4


用于将jsp页面放在jar包中


 


 


 


 




struts2-jasperreports-plugin-2.3.4.jar


2.3.4


struts2-jasperreports-plugin-2.3.4


用于整合JasperReports


 


 


 


 




struts2-javatemplates-plugin-2.3.4.jar


2.3.4


struts2-javatemplates-plugin-2.3.4


Apache提供的'javatemplates'用于代替默认的Freemarker渲染器


 


 


 


 




struts2-jfreechart-plugin-2.3.4.jar
 


2.3.4


struts2-jfreechart-plugin-2.3.4


struts2使用jfreechart的插件包


 


 


 


 




struts2-jsf-plugin-2.3.4.jar
 


2.3.4


struts2-jsf-plugin-2.3.4


sturts整合jsf的插件包


 


 


 


 




struts2-json-plugin-2.3.4.jar


2.3.4


struts2-json-plugin-2.3.4


struts2所用到的json插件包


 


 


 


 




struts2-junit-plugin-2.3.4.jar


2.3.4


struts2-junit-plugin-2.3.4


struts所提供的junit调试


 


 


 


 




struts2-osgi-plugin-2.3.4.jar
 


2.3.4


struts2-osgi-plugin-2.3.4


这个插件提供了支持启动一个实例的Apache Felix在一个web应用程序,和扫描安装的bundle的Struts配置。还提供了一个管理包


 


 


 


 




struts2-oval-plugin-2.3.4.jar


2.3.4


struts2-oval-plugin-2.3.4


插件定义了拦截器”ovalValidation”和拦截器堆栈”ovalValidationStack”在“oval-default”包。使用这个拦截器,扩大“oval-default””包


 


 


 


 




struts2-plexus-plugin-2.3.4.jar
 


2.3.4


struts2-plexus-plugin-2.3.4


使用该插件,当配置Struts动作,拦截器,在Struts或结果。xml,设置class属性包含丛对象id,而不是实际的Java类。这将允许丛来创建对象和注入任何依赖关系也由管理丛。


 


 


 


 




struts2-portlet-plugin-2.3.4.jar


2.3.4


struts2-portlet-plugin-2.3.4


Portlet的插件,用于发展中JSR286 Portlet使用Struts


 


 


 


 




struts2-rest-plugin-2.3.4.jar
 


2.3.4


struts2-rest-plugin-2.3.4


rest插件用于自动处理序列化,并反序列化每种格式。


 


 


 


 




struts2-sitegraph-plugin-2.3.4.jar


2.3.4


struts2-sitegraph-plugin-2.3.4


生成一个web应用程序的图形视图


 


 


 


 




struts2-struts1-plugin-2.3.4.jar


2.3.4


struts2-struts1-plugin-2.3.4


这个jar包是用于将strusts和spring进行整合的一个插件，在处理数据库的事物时，通过这个插件将数据源配置到底层的sessionFactory中，然后再将sessionFactory注入到相应Dao层或者service层，在配置请求页面的处理结果页面配置struts.xml文件由spring进行管理的


 


 


 


 




struts2-testng-plugin-2.3.4.jar


2.3.4


struts2-testng-plugin-2.3.4


这个插件是用来在单元测试,而不是在运行时。因此,它包含在您的构建的类路径中,但不要将它部署WEB-INF/lib在Struts2的应用程序


 


 


 


 




struts2-tiles-plugin-2.3.4.jar


2.3.4


struts2-tiles-plugin-2.3.4


这个插件可以安装插件jar复制到应用程序的WEB-INF/lib 目录中


 


 


 


 




struts2-tiles-plugin-2.3.4.jar


2.3.4


struts2-tiles-plugin-2.3.4


这个插件可以安装插件jar复制到应用程序的WEB-INF/lib 目录中


 


 


 


 




testng-5.1-jdk15.jar


5.1


testng-5.1-jdk15


TestNG是一个测试框架从JUnit和NUnit启发,但该框架引入了一些新功能,使它更强大,也更容易使用。而该jar包就是用于整合使用该框架。


 


 


 


 




tiles-api-2.0.6.jar


2.0.6


tiles-api-2.0.6


提供对tiles的支持：类和标记库在一个JSP环境中使用tiles。


 


 


 


 




tiles-core-2.0.6.jar
 


2.0.6


tiles-core-2.0.6


tiles核心库,包括基本的实现的api。


 


 


 


 




tiles-jsp-2.0.6.jar


2.0.6


tiles-jsp-2.0.6


提供对tilesJSP的支持:类和标记库在一个JSP环境使用tiles。


 


 


 


 




velocity-1.6.3.jar


1.6.3


velocity-1.6.3


Java模板技术-velocity


 


 


 


 




xmlpull-1.1.3.1.jar
 


1.1.3.1


xmlpull-1.1.3.1


支持可扩展的XML


 


 


 


 




xpp3_min-1.1.4c.jar
 


1.1.4


xpp3_min-1.1.4c


Java对象和XML之间相互转换所需JAR包


 


 


 


 




xstream-1.4.2.jar


1.4.2


xstream-1.4.2


xstream 提供对象和xml之间的转换


 


 


 


 


















平台无关性

    Java是与平台无关的语言，这得益于Java源代码编译后生成的存储字节码的文件，即Class文件，以及Java虚拟机的实现。不仅使用Java编译器可以把Java代码编译成存储字节码的Class文件，使用JRuby等其他语言的编译器也可以把程序代码编译成Class文件，虚拟机并不关心Class的来源是什么语言，只要它符合一定的结构，就可以在Java中运行。Java语言中的各种变量、关键字和运算符的语义最终都是由多条字节码命令组合而成的，因此字节码命令所能提供的语义描述能力肯定会比Java语言本身更强大，这便为其他语言实现一些有别于Java的语言特性提供了基础，而且这也正是在类加载时要进行安全验证的原因。

 

类文件结构

    Class文件是一组以8位字节为基础单位的二进制流，各个数据项目严格按照顺序紧凑地排列在Class文件中，中间没有添加任何分隔符，这使得整个Class文件中存储的内容几乎全部都是程序运行的必要数据。根据Java虚拟机规范的规定，Class文件格式采用一种类似于C语言结构体的伪结构来存储，这种伪结构中只有两种数据类型：无符号数和表。无符号数属于基本数据类型，以u1、u2、u4、u8来分别代表1、2、4、8个字节的无符号数。表是由多个无符号数或其他表作为数据项构成的符合数据类型，所有的表都习惯性地以“_info”结尾。

    整个Class文件本质上就是一张表，它由如下所示的数据项构成。

    从表中可以看出，无论是无符号数还是表，当需要描述同一类型但数量不定的多个数据时，经常会使用一个前置的容量计数器加若干个连续的该数据项的形式，称这一系列连续的摸一个类型的数据为某一类型的集合，比如，fields_count个field_info表数据构成了字段表集合。这里需要说明的是：Class文件中的数据项，都是严格按照上表中的顺序和数量被严格限定的，每个字节代表的含义，长度，先后顺序等都不允许改变。

    下表列出了Class文件中各个数据项的具体含义：



    从表中可以看出，无论是无符号数还是表，当需要描述同一类型但数量不定的多个数据时，经常会在其前面使用一个前置的容量计数器来记录其数量，而便跟着若干个连续的数据项，称这一系列连续的某一类型的数据为某一类型的集合，如：fields_count个field_info表数据便组成了方法表集合。这里需要注意的是：Class文件中各数据项是按照上表的顺序和数量被严格限定的，每个字节代表的含义、长度、先后顺序都不允许改变。

   magic与version

    每个Class文件的头4个字节称为魔数（magic），它的唯一作用是判断该文件是否为一个能被虚拟机接受的Class文件。它的值固定为0xCAFEBABE。紧接着magic的4个字节存储的是Class文件的次版本号和主版本号，高版本的JDK能向下兼容低版本的Class文件，但不能运行更高版本的Class文件。

   constant_pool

    major_version之后是常量池（constant_pool）的入口，它是Class文件中与其他项目关联最多的数据类型，也是占用Class文件空间最大的数据项目之一。

    常量池中主要存放两大类常量：字面量和符号引用。字面量比较接近于Java层面的常量概念，如文本字符串、被声明为final的常量值等。而符号引用总结起来则包括了下面三类常量：

类和接口的全限定名（即带有包名的Class名，如：org.lxh.test.TestClass）字段的名称和描述符（private、static等描述符）方法的名称和描述符（private、static等描述符）

    虚拟机在加载Class文件时才会进行动态连接，也就是说，Class文件中不会保存各个方法和字段的最终内存布局信息，因此，这些字段和方法的符号引用不经过转换是无法直接被虚拟机使用的。当虚拟机运行时，需要从常量池中获得对应的符号引用，再在类加载过程中的解析阶段将其替换为直接引用，并翻译到具体的内存地址中。

    这里说明下符号引用和直接引用的区别与关联：

符号引用：符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。符号引用与虚拟机实现的内存布局无关，引用的目标并不一定已经加载到了内存中。直接引用：直接引用可以是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。直接引用是与虚拟机实现的内存布局相关的，同一个符号引用在不同虚拟机实例上翻译出来的直接引用一般不会相同。如果有了直接引用，那说明引用的目标必定已经存在于内存之中了。

    常量池中的每一项常量都是一个表，共有11种（JDK1.7之前）结构各不相同的表结构数据，没中表开始的第一位是一个u1类型的标志位（1-12，缺少2），代表当前这个常量属于的常量类型。11种常量类型所代表的具体含义如下表所示：



    这11种常量类型各自均有自己的结构。在CONSTANT_Class_info型常量的结构中有一项name_index属性，该常属性中存放一个索引值，指向常量池中一个CONSTANT_Utf8_info类型的常量，该常量中即保存了该类的全限定名字符串。而CONSTANT_Fieldref_info、CONSTANT_Methodref_info、CONSTANT_InterfaceMethodref_info型常量的结构中都有一项index属性，存放该字段或方法所属的类或接口的描述符CONSTANT_Class_info的索引项。另外，最终保存的诸如Class名、字段名、方法名、修饰符等字符串都是一个CONSTANT_Utf8_info类型的常量，也因此，Java中方法和字段名的最大长度也即是CONSTANT_Utf8_info型常量的最大长度，在CONSTANT_Utf8_info型常量的结构中有一项length属性，它是u2类型的，即占用2个字节，那么它的最大的length即为65535。因此，Java程序中如果定义了超过64KB英文字符的变量或方法名，将会无法编译。

   下表给出了常量池中11种数据类型的结构：






    常量


项目


  类型  


描述




 
CONSTANT_Utf8_info


tag


u1


值为1




length


u2


UF-8编码的字符串占用的字节数




bytes


u1


长度为length的UTF-8编码的字符串




 
CONSTANT_Integer_info


tag


u1


值为3




bytes


u4


按照高位在前存储的int值




 
CONSTANT_Float_info


tag


u1


值为4




bytes


u4


按照高位在前存储的float值




 
CONSTANT_Long_info


tag


u1


值为5




bytes


u8


按照高位在前存储的long值




 
CONSTANT_Double_info


tag


u1


值为6




bytes


u8


按照高位在前存储的double值




 
CONSTANT_Class_info


tag


u1


值为7




index


u2


指向全限定名常量项的索引




 
CONSTANT_String_info


tag


u1


值为8




index


u2


指向字符串字面量的索引




 
CONSTANT_Fieldref_info


tag


u1


值为9




index


u2


指向声明字段的类或接口描述符CONSTANT_Class_info的索引项




index


u2


指向字段名称及类型描述符CONSTANT_NameAndType_info的索引项




 
CONSTANT_Methodref_info


tag


u1


值为10




index


u2


指向声明方法的类描述符CONSTANT_Class_info的索引项




index


u2


指向方法名称及类型描述符CONSTANT_NameAndType_info的索引项




 
CONSTANT_InrerfaceMethodref_info


tag


u1


值为11




index


u2


指向声明方法的接口描述符CONSTANT_Class_info的索引项




index


u2


指向方法名称及类型描述符CONSTANT_NameAndType_info的索引项




 
CONSTANT_NameAndType_info


tag


u1


值为12




index


u2


指向字段或方法名称常量项目的索引




index


u2


指向该字段或方法描述符常量项的索引










    access_flag


    在常量池结束之后，紧接着的2个字节代表访问标志（access_flag），这个标志用于识别一些类或接口层次的访问信息，包括：这个Class是类还是接口，是否定义为public类型，abstract类型，如果是类的话，是否声明为final，等等。每种访问信息都由一个十六进制的标志值表示，如果同时具有多种访问信息，则得到的标志值为这几种访问信息的标志值的逻辑或。

   this_class、super_class、interfaces

    类索引（this_class）和父类索引（super_class）都是一个u2类型的数据，而接口索引集合（interfaces）则是一组u2类型的数据集合，Class文件中由这三项数据来确定这个类的继承关系。类索引、父类索引和接口索引集合都按照顺序排列在访问标志之后，类索引和父类索引两个u2类型的索引值表示，它们各自指向一个类型为COMNSTANT_Class_info的类描述符常量，通过该常量中的索引值找到定义在COMNSTANT_Utf8_info类型的常量中的全限定名字符串。而接口索引集合就用来描述这个类实现了哪些接口，这些被实现的接口将按implements语句（如果这个类本身是个接口，则应当是extend语句）后的接口顺序从左到右排列在接口的索引集合中。

    fields

    字段表（field_info）用于描述接口或类中声明的变量。字段包括了类级变量或实例级变量，但不包括在方法内声明的变量。字段的名字、数据类型、修饰符等都是无法固定的，只能引用常量池中的常量来描述。下面是字段表的最种格式：



 

    其中的access_flags与类中的access_flagsfei类似，是表示数据类型的修饰符，如public、static、volatile等。后面的name_index和descriptor_index都是对常量池的引用，分别代表字段的简单名称及字段和方法的描述符。这里简单解释下“简单名称”、“描述符”和“全限定名”这三种特殊字符串的概念。

    前面有所提及，全限定名即指一个事物的完整的名称，如在org.lxh.test包下的TestClass类的全限定名为：org/lxh/test/TestClass，即把包名中的“.”改为“/”，为了使连续的多个全限定名之间不产生混淆，在使用时最后一般会加入一个“，”来表示全限定名结束。简单名称则是指没有类型或参数修饰的方法或字段名称，如果一个类中有这样一个方法boolean  get（int name）和一个变量private
 final static int m，则他们的简单名称则分别为get（）和m。

    而描述符的作用则是用来描述字段的数据类型、方法的参数列表（包括数量、类型以及顺序等）和返回值的。根据描述符规则，详细的描述符标示字的含义如下表所示：



 

    对于数组类型，每一维度将使用一个前置的“[”字符来描述，如一个整数数组“int [][]”将为记录为“[[I”，而一个String类型的数组“String[]”将被记录为“[Ljava/lang/String”

    用方法描述符描述方法时，按照先参数后返回值的顺序描述，参数要按照严格的顺序放在一组小括号内，如方法 int getIndex(String name,char[] tgc,int start,int end,char target)的描述符为“（Ljava/lang/String[CIIC）I”。

    字段表包含的固定数据项目到descriptor_index为止就结束了，但是在它之后还紧跟着一个属性表集合用于存储一些额外的信息。比如，如果在类中有如下字段的声明：staticfinalint m = 2；那就可能会存在一项名为ConstantValue的属性，它指向常量2。关于attribute_info的详细内容，在后面关于属性表的项目中会有详细介绍。

    最后需要注意一点：字段表集合中不会列出从父类或接口中继承而来的字段，但有可能列出原本Java代码中不存在的字段。比如在内部类中为了保持对外部类的访问性，会自动添加指向外部类实例的字段。

    methods

    方法表（method_info）的结构与属性表的结构相同，不过多赘述。方法里的Java代码，经过编译器编译成字节码指令后，存放在方法属性表集合中一个名为“Code”的属性里，关于属性表的项目，同样会在后面详细介绍。

    与字段表集合相对应，如果父类方法在子类中没有被覆写，方法表集合中就不会出现来自父类的方法信息。但同样，有可能会出现由编译器自动添加的方法，最典型的便是类构造器“&lt;clinit&gt;”方法和实例构造器“&lt;init&gt;”方法。

    在Java语言中，要重载一个方法，除了要与原方法具有相同的简单名称外，还要求必须拥有一个与原方法不同的特征签名，特征签名就是一个方法中各个参数在常量池中的字段符号引用的集合，也就是因为返回值不会包含在特征签名之中，因此Java语言里无法仅仅依靠返回值的不同来对一个已有方法进行重载。

    attributes

    属性表（attribute_info）在前面已经出现过多系，在Class文件、字段表、方法表中都可以携带自己的属性表集合，以用于描述某些场景专有的信息。

    属性表集合的限制没有那么严格，不再要求各个属性表具有严格的顺序，并且只要不与已有的属性名重复，任何人实现的编译器都可以向属性表中写入自己定义的属性信息，但Java虚拟机运行时会忽略掉它不认识的属性。Java虚拟机规范中预定义了9项虚拟机应当能识别的属性（JDK1.5后又增加了一些新的特性，因此不止下面9项，但下面9项是最基本也是必要，出现频率最高的），如下表所示：




    对于每个属性，它的名称都需要从常量池中引用一个CONSTANT_Utf8_info类型的常量来表示，每个属性值的结构是完全可以自定义的，只需说明属性值所占用的位数长度即可。一个符合规则的属性表至少应具有“attribute_name_info”、“attribute_length”和至少一项信息属性。

    1）Code属性

    前面已经说过，Java程序方法体中的代码讲过Javac编译后，生成的字节码指令便会存储在Code属性中，但并非所有的方法表都必须存在这个属性，比如接口或抽象类中的方法就不存在Code属性。如果方法表有Code属性存在，那么它的结构将如下表所示：




    attribute_name_index是一项指向CONSTANT_Utf8_info型常量的索引，常量值固定为“Code”，它代表了该属性的名称。attribute_length指示了属性值的长度，由于属性名称索引与属性长度一共是6个字节，所以属性值的长度固定为整个属性表的长度减去6个字节。

    max_stack代表了操作数栈深度的最大值，max_locals代表了局部变量表所需的存储空间，它的单位是Slot，并不是在方法中用到了多少个局部变量，就把这些局部变量所占Slot之和作为max_locals的值，原因是局部变量表中的Slot可以重用。

    code_length和code用来存储Java源程序编译后生成的字节码指令。code用于存储字节码指令的一系列字节流，它是u1类型的单字节，因此取值范围为0x00到0xFF，那么一共可以表达256条指令，目前，Java虚拟机规范已经定义了其中200条编码值对应的指令含义。code_length虽然是一个u4类型的长度值，理论上可以达到2^32-1，但是虚拟机规范中限制了一个方法不允许超过65535条字节码指令，如果超过了这个限制，Javac编译器将会拒绝编译。

    字节码指令之后是这个方法的显式异常处理表集合（exception_table），它对于Code属性来说并不是必须存在的。它的格式如下表所示：



    它包含四个字段，这些字段的含义为：如果字节码从第start_pc行到第end_pc行之间（不含end_pc行）出现了类型为catch_type或其子类的异常（catch_type为指向一个CONSTANT_Class_info型常量的索引），则转到第handler_pc行继续处理，当catch_pc的值为0时，代表人和的异常情况都要转到handler_pc处进行处理。异常表实际上是Java代码的一部分，编译器使用异常表而不是简单的跳转命令来实现Java异常即finally处理机制，也因此，finally中的内容会在try或catch中的return语句之前执行，并且在try或catch跳转到finally之前，会将其内部需要返回的变量的值复制一份副本到最后一个本地表量表的Slot中，也因此便有了http://blog.csdn.net/ns_code/article/details/17485221这篇文章中出现的情况。


    Code属性是Class文件中最重要的一个属性，如果把一个Java程序中的信息分为代码和元数据两部分，那么在整个Class文件里，Code属性用于描述代码，所有的其他数据项目都用于描述元数据。

    2）Exception属性

    这里的Exception属性的作用是列举出方法中可能抛出的受查异常，也就是方法描述时在throws关键字后面列举的异常。它的结构很简单，只有attribute_name_index、attribute_length、number_of_exceptions、exception_index_table四项，从字面上便很容易理解，这里不再详述。

    3）LineNumberTable属性

    它用于描述Java源码行号与字节码行号之间的对应关系。

    4）LocalVariableTable属性

    它用于描述栈帧中局部变量表中的变量与Java源码中定义的变量之间的对应关系。

    5）SourceFile属性

    它用于记录生成这个Class文件的源码文件名称。

    6）ConstantValue属性

    ConstantValue属性的作用是通知虚拟机自动为静态变量赋值，只有被static修饰的变量才可以使用这项属性。在Java中，对非static类型的变量（也就是实例变量）的赋值是在实例构造器&lt;init&gt;方法中进行的；而对于类变量（static变量），则有两种方式可以选择：在类构造其中赋值，或使用ConstantValue属性赋值。

    目前Sun Javac编译器的选择是：如果同时使用final和static修饰一个变量（即全局常量），并且这个变量的数据类型是基本类型或String的话，就生成ConstantValue属性来进行初始化（编译时Javac将会为该常量生成ConstantValue属性，在类加载的准备阶段虚拟机便会根据ConstantValue为常量设置相应的值），如果该变量没有被final修饰，或者并非基本类型及字符串，则选择在&lt;clinit&gt;方法中进行初始化。

    虽然有final关键字才更符合”ConstantValue“的含义，但在虚拟机规范中并没有强制要求字段必须用final修饰，只要求了字段必须用static修饰，对final关键字的要求是Javac编译器自己加入的限制。因此，在实际的程序中，只有同时被final和static修饰的字段才有ConstantValue属性。而且ConstantValue的属性值只限于基本类型和String，很明显这是因为它从常量池中也只能够引用到基本类型和String类型的字面量。

    下面简要说明下final、static、static final修饰的字段赋值的区别：

static修饰的字段在类加载过程中的准备阶段被初始化为0或null等默认值，而后在初始化阶段（触发类构造器&lt;clinit&gt;）才会被赋予代码中设定的值，如果没有设定值，那么它的值就为默认值。final修饰的字段在运行时被初始化（可以直接赋值，也可以在实例构造器中赋值），一旦赋值便不可更改；static final修饰的字段在Javac时生成ConstantValue属性，在类加载的准备阶段根据ConstantValue的值为该字段赋值，它没有默认值，必须显式地赋值，否则Javac时会报错。可以理解为在编译期即把结果放入了常量池中。

    7）InnerClasses属性

    该属性用于记录内部类与宿主类之间的关联。如果一个类中定义了内部类，那么编译器将会为它及它所包含的内部类生成InnerClasses属性。

    8）Deprecated属性和Synthetic属性

    该属性用于表示某个类、字段和方法，已经被程序作者定为不再推荐使用，它可以通过在代码中使用@Deprecated注释进行设置。

    9）Synthetic属性

    该属性代表此字段或方法并不是Java源代码直接生成的，而是由编译器自行添加的，如this字段和实例构造器、类构造器等。


内存区域

    Java虚拟机在执行Java程序的过程中会把他所管理的内存划分为若干个不同的数据区域。Java虚拟机规范将JVM所管理的内存分为以下几个运行时数据区：程序计数器、Java虚拟机栈、本地方法栈、Java堆、方法区。下面详细阐述各数据区所存储的数据类型。










   程序计数器（Program Counter Register）

    一块较小的内存空间，它是当前线程所执行的字节码的行号指示器，字节码解释器工作时通过改变该计数器的值来选择下一条需要执行的字节码指令，分支、跳转、循环等基础功能都要依赖它来实现。每条线程都有一个独立的的程序计数器，各线程间的计数器互不影响，因此该区域是线程私有的。

    当线程在执行一个Java方法时，该计数器记录的是正在执行的虚拟机字节码指令的地址，当线程在执行的是Native方法（调用本地操作系统方法）时，该计数器的值为空。另外，该内存区域是唯一一个在Java虚拟机规范中么有规定任何OOM（内存溢出：OutOfMemoryError）情况的区域。

 

   Java虚拟机栈（Java Virtual Machine Stacks）

   该区域也是线程私有的，它的生命周期也与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧，栈它是用于支持续虚拟机进行方法调用和方法执行的数据结构。对于执行引擎来讲，活动线程中，只有栈顶的栈帧是有效的，称为当前栈帧，这个栈帧所关联的方法称为当前方法，执行引擎所运行的所有字节码指令都只针对当前栈帧进行操作。栈帧用于存储局部变量表、操作数栈、动态链接、方法返回地址和一些额外的附加信息。在编译程序代码时，栈帧中需要多大的局部变量表、多深的操作数栈都已经完全确定了，并且写入了方法表的Code属性之中。因此，一个栈帧需要分配多少内存，不会受到程序运行期变量数据的影响，而仅仅取决于具体的虚拟机实现。

在Java虚拟机规范中，对这个区域规定了两种异常情况：

    1、如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常。

    2、如果虚拟机在动态扩展栈时无法申请到足够的内存空间，则抛出OutOfMemoryError异常。

    这两种情况存在着一些互相重叠的地方：当栈空间无法继续分配时，到底是内存太小，还是已使用的栈空间太大，其本质上只是对同一件事情的两种描述而已。在单线程的操作中，无论是由于栈帧太大，还是虚拟机栈空间太小，当栈空间无法分配时，虚拟机抛出的都是StackOverflowError异常，而不会得到OutOfMemoryError异常。而在多线程环境下，则会抛出OutOfMemoryError异常。

    下面详细说明栈帧中所存放的各部分信息的作用和数据结构。 

   1、局部变量表

   局部变量表是一组变量值存储空间，用于存放方法参数和方法内部定义的局部变量，其中存放的数据的类型是编译期可知的各种基本数据类型、对象引用（reference）和returnAddress类型（它指向了一条字节码指令的地址）。局部变量表所需的内存空间在编译期间完成分配，即在Java程序被编译成Class文件时，就确定了所需分配的最大局部变量表的容量。当进入一个方法时，这个方法需要在栈中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。

    局部变量表的容量以变量槽（Slot）为最小单位。在虚拟机规范中并没有明确指明一个Slot应占用的内存空间大小（允许其随着处理器、操作系统或虚拟机的不同而发生变化），一个Slot可以存放一个32位以内的数据类型：boolean、byte、char、short、int、float、reference和returnAddresss。reference是对象的引用类型，returnAddress是为字节指令服务的，它执行了一条字节码指令的地址。对于64位的数据类型（long和double），虚拟机会以高位在前的方式为其分配两个连续的Slot空间。

    虚拟机通过索引定位的方式使用局部变量表，索引值的范围是从0开始到局部变量表最大的Slot数量，对于32位数据类型的变量，索引n代表第n个Slot，对于64位的，索引n代表第n和第n+1两个Slot。

    在方法执行时，虚拟机是使用局部变量表来完成参数值到参数变量列表的传递过程的，如果是实例方法（非static），则局部变量表中的第0位索引的Slot默认是用于传递方法所属对象实例的引用，在方法中可以通过关键字“this”来访问这个隐含的参数。其余参数则按照参数表的顺序来排列，占用从1开始的局部变量Slot，参数表分配完毕后，再根据方法体内部定义的变量顺序和作用域分配其余的Slot。

    局部变量表中的Slot是可重用的，方法体中定义的变量，作用域并不一定会覆盖整个方法体，如果当前字节码PC计数器的值已经超过了某个变量的作用域，那么这个变量对应的Slot就可以交给其他变量使用。这样的设计不仅仅是为了节省空间，在某些情况下Slot的复用会直接影响到系统的而垃圾收集行为。

    2、操作数栈

    操作数栈又常被称为操作栈，操作数栈的最大深度也是在编译的时候就确定了。32位数据类型所占的栈容量为1,64为数据类型所占的栈容量为2。当一个方法开始执行时，它的操作栈是空的，在方法的执行过程中，会有各种字节码指令（比如：加操作、赋值元算等）向操作栈中写入和提取内容，也就是入栈和出栈操作。

    Java虚拟机的解释执行引擎称为“基于栈的执行引擎”，其中所指的“栈”就是操作数栈。因此我们也称Java虚拟机是基于栈的，这点不同于Android虚拟机，Android虚拟机是基于寄存器的。

    基于栈的指令集最主要的优点是可移植性强，主要的缺点是执行速度相对会慢些；而由于寄存器由硬件直接提供，所以基于寄存器指令集最主要的优点是执行速度快，主要的缺点是可移植性差。

    3、动态连接

    每个栈帧都包含一个指向运行时常量池（在方法区中，后面介绍）中该栈帧所属方法的引用，持有这个引用是为了支持方法调用过程中的动态连接。Class文件的常量池中存在有大量的符号引用，字节码中的方法调用指令就以常量池中指向方法的符号引用为参数。这些符号引用，一部分会在类加载阶段或第一次使用的时候转化为直接引用（如final、static域等），称为静态解析，另一部分将在每一次的运行期间转化为直接引用，这部分称为动态连接。

    4、方法返回地址

    当一个方法被执行后，有两种方式退出该方法：执行引擎遇到了任意一个方法返回的字节码指令或遇到了异常，并且该异常没有在方法体内得到处理。无论采用何种退出方式，在方法退出之后，都需要返回到方法被调用的位置，程序才能继续执行。方法返回时可能需要在栈帧中保存一些信息，用来帮助恢复它的上层方法的执行状态。一般来说，方法正常退出时，调用者的PC计数器的值就可以作为返回地址，栈帧中很可能保存了这个计数器值，而方法异常退出时，返回地址是要通过异常处理器来确定的，栈帧中一般不会保存这部分信息。

    方法退出的过程实际上等同于把当前栈帧出站，因此退出时可能执行的操作有：恢复上层方法的局部变量表和操作数栈，如果有返回值，则把它压入调用者栈帧的操作数栈中，调整PC计数器的值以指向方法调用指令后面的一条指令。

 

   本地方法栈（Native Method Stacks）

    该区域与虚拟机栈所发挥的作用非常相似，只是虚拟机栈为虚拟机执行Java方法服务，而本地方法栈则为使用到的本地操作系统（Native）方法服务。

 

   Java堆（Java Heap）

    Java Heap是Java虚拟机所管理的内存中最大的一块，它是所有线程共享的一块内存区域。几乎所有的对象实例和数组都在这类分配内存。Java Heap是垃圾收集器管理的主要区域，因此很多时候也被称为“GC堆”。

    根据Java虚拟机规范的规定，Java堆可以处在物理上不连续的内存空间中，只要逻辑上是连续的即可。如果在堆中没有内存可分配时，并且堆也无法扩展时，将会抛出OutOfMemoryError异常。   

 

   方法区（Method Area）

    方法区也是各个线程共享的内存区域，它用于存储已经被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。方法区域又被称为“永久代”，但这仅仅对于Sun HotSpot来讲，JRockit和IBM J9虚拟机中并不存在永久代的概念。Java虚拟机规范把方法区描述为Java堆的一个逻辑部分，而且它和Java Heap一样不需要连续的内存，可以选择固定大小或可扩展，另外，虚拟机规范允许该区域可以选择不实现垃圾回收。相对而言，垃圾收集行为在这个区域比较少出现。该区域的内存回收目标主要针是对废弃常量的和无用类的回收。运行时常量池是方法区的一部分，Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池（Class文件常量池），用于存放编译器生成的各种字面量和符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。运行时常量池相对于Class文件常量池的另一个重要特征是具备动态性，Java语言并不要求常量一定只能在编译期产生，也就是并非预置入Class文件中的常量池的内容才能进入方法区的运行时常量池，运行期间也可能将新的常量放入池中，这种特性被开发人员利用比较多的是String类的intern（）方法。

    根据Java虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。

 

    直接内存（Direct Memory）





直接内存并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域，它直接从操作系统中分配，因此不受Java堆大小的限制，但是会受到本机总内存的大小及处理器寻址空间的限制，因此它也可能导致OutOfMemoryError异常出现。在JDK1.4中新引入了NIO机制，它是一种基于通道与缓冲区的新I/O方式，可以直接从操作系统中分配直接内存，即在堆外分配内存，这样能在一些场景中提高性能，因为避免了在Java堆和Native堆中来回复制数据。关于NIO的详细使用可以参考我的Java网络编程系列中关于NIO的相关文章。




内存溢出



    下面给出个内存区域内存溢出的简单测试方法






    这里有一点要重点说明，在多线程情况下，给每个线程的栈分配的内存越大，反而越容易产生内存溢出异常。操作系统为每个进程分配的内存是有限制的，虚拟机提供了参数来控制Java堆和方法区这两部分内存的最大值，忽略掉程序计数器消耗的内存（很小），以及进程本身消耗的内存，剩下的内存便给了虚拟机栈和本地方法栈，每个线程分配到的栈容量越大，可以建立的线程数量自然就越少。因此，如果是建立过多的线程导致的内存溢出，在不能减少线程数的情况下，就只能通过减少最大堆和每个线程的栈容量来换取更多的线程。



    另外，由于Java堆内也可能发生内存泄露（Memory Leak），这里简要说明一下内存泄露和内存溢出的区别：

    内存泄露是指分配出去的内存没有被回收回来，由于失去了对该内存区域的控制，因而造成了资源的浪费。Java中一般不会产生内存泄露，因为有垃圾回收器自动回收垃圾，但这也不绝对，当我们new了对象，并保存了其引用，但是后面一直没用它，而垃圾回收器又不会去回收它，这边会造成内存泄露，

    内存溢出是指程序所需要的内存超出了系统所能分配的内存（包括动态扩展）的上限。






对象实例化分析

    对内存分配情况分析最常见的示例便是对象实例化:
Object obj = new Object();
   这段代码的执行会涉及java栈、Java堆、方法区三个最重要的内存区域。假设该语句出现在方法体中，及时对JVM虚拟机不了解的Java使用这，应该也知道obj会作为引用类型（reference）的数据保存在Java栈的本地变量表中，而会在Java堆中保存该引用的实例化对象，但可能并不知道，Java堆中还必须包含能查找到此对象类型数据的地址信息（如对象类型、父类、实现的接口、方法等），这些类型数据则保存在方法区中。

    另外，由于reference类型在Java虚拟机规范里面只规定了一个指向对象的引用，并没有定义这个引用应该通过哪种方式去定位，以及访问到Java堆中的对象的具体位置，因此不同虚拟机实现的对象访问方式会有所不同，主流的访问方式有两种：使用句柄池和直接使用指针。
    通过句柄池访问的方式如下：


   通过直接指针访问的方式如下：







    这两种对象的访问方式各有优势，使用句柄访问方式的最大好处就是reference中存放的是稳定的句柄地址，在对象呗移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而reference本身不需要修改。使用直接指针访问方式的最大好处是速度快，它节省了一次指针定位的时间开销。目前Java默认使用的HotSpot虚拟机采用的便是是第二种方式进行对象访问的。


在学习Java的过程当中，我们第一天就会学习到JDK的安装。在安装JDK的过程当中，一个很重要的环节就是设置操作系统的环境变量。一个是path，另一个是classpath。这两个环境变量，很多初学者只是了解应该怎样设置给背下来了，并不知道设置这两个环境变量的作用是什么？今天我们就一起来探索一下，因为这两个环境变量非常的重要，特别是classpath这个环境变量，对开发当中各种配置文件，部署描述符的编写非常的重要！


首先看一下path这个环境变量的作用。要想明白path的作用，首先先要考虑一个问题，比如：


当我们在命令行当中，输入”ipconfig”这个命令然后按下回车键之后，为什么能现实出当前计算机网卡的相关参数（包括IP地址，子网掩码等）？请大家想一想！


其实仔细的想一想，就会大概的猜出来，其实但你执行ipconfig命令的时候，实际上是调用了一个程序，这个程序在什么地方呢？在操作系统的安装目录当中，具体是在\WINDOWS\system32\ipconfig.exe这个位置。当你执行ipconfig的时候，其实就是运行了ipconfig.exe这个程序（如果大家想验证的话，可以尝试把ipconfig.exe这个文件剪切到其他的目录里面，再尝试执行这个命令，就会发现这个命令已经不能执行了）。根据这样的一个情况我们可以大概的猜测一下，就是当我们执行了javac和java这两个命令的时候，也应该是类似的，就是说在硬盘上应该有java.exe和javac.exe这两个文件。那么这两个文件在什么地方呢？就在JDK安装目录下的bin目录，大家去找一找，不难发现这两个文件。那么现在问题就来了，当我们在命令行当中执行某个命令的时候，操作系统是怎样找到这个命令所对应的exe文件（有的时候是bat文件，因为这种情况目前我们还用不少，所以在这里就不再讨论了）？


这个时候就轮到我们的path这个环境变量大限身手了。首先我们先看一下现在path的值是什么，在命令行当中输入set path 这个命令就可以看到了：


由这个结果我们可以看出，环境变量的值，是一系列的目录，目录和目录之间使用“；”分割开。当你在命令行当中执行ipconfig 这个命令的时候，首先操作系统会从path变量所制定的第一个目录，也就是”C:\Program files\Common Files\NetSarang”这个目录当中寻找ipconfig.exe，如果没有找到就会到第二个目录当中寻找。以此类推，直到找到为止。如果在Path所指定的所有目录当中都没有找到，就会报出一个错误。同样的，如果你想在命令行当中编译或者运行Java程序，就必须使用到JDK所提供的java和javac这两个命令，所以我们要把java.exe和javac.exe所在的目录加入到path这个环境变量当中，这样操作系统就可以顺利的执行这两个命令了。


其次，我们看classpath的作用。在了解这个环境变量的作用之前，首先还是先要了解一下java程序运行的步骤。当我们执行“java Test”这样的命令时，会启动Java虚拟机，并执行如下的动作：


classpath的作用是体现在上述的第一个步骤。


执行“java Test”这样的命令时，java虚拟机会寻找一个名为Test.class的文件，然后由类装载器装载这个类，那么问题就是类装载器究竟要到哪个目录里去寻找Test.class这个文件呢？这个时候classpath就起作用了，classpath值的设置方式和path类似，都是一系列的目录（当然还可能包括jar文件，其实jar文件也是目录，目录里面有很多的class文件），java虚拟机就是到这些目录当中去寻找所需要的class文件。比如说在我的g:\src目录当中有一个Test.java文件，编译过后生成了Test.calss文件。这个时候我们想执行这个文件，就要执行“java
 Test”命令，类装载器会从classpath所指定的目录当中去寻找Test.class这个文件，如果在classpath所指定的第一个目录当中没有找到，就到第二个目录去找，直到找到为止，如果在所有的目录当中都没有找到，就会报出一个错误。在一般的教科书上，都会让学生把classpath的值设置为“.”，这是因为“.”代表的是当前目录，什么叫当前目录呢？



当打开命令行时，在“&gt;”之前的目录就是当前目录，也就是说在这个目录下执行“java Test”命令，java虚拟机的类装载器就会在g:\src下寻找Test.class文件。







RPM 是 Red Hat Package Manager 的缩写，本意是Red Hat 软件包管理，顾名思义是Red Hat 贡献出来的软件包管理；在Fedora 、Redhat、Mandriva、SuSE、YellowDog等主流发行版本，以及在这些版本基础上二次开发出来的发行版采用；

RPM包里面都包含什么？里面包含可执行的二进制程序，这个程序和Windows的软件包中的.exe文件类似是可执行的；RPM包中还包括程序运行时所需要的文件，这也和Windows的软件包类似，Windows的程序的运行，除了.exe文件以外，也有其它的文件；

一个RPM 包中的应用程序，有时除了自身所带的附加文件保证其正常以外，还需要其它特定版本文件，这就是软件包的依赖关系；依赖关系并不是Linux特有的， Windows操作系统中也是同样存在的；比如我们在Windows系统中运行3D游戏，在安装的时候，他可能会提示，要安装Direct 9 ；Linux和Windows原理是差不多的；

软件安装流程图：

 



本文使用范围：

1、本文是对RPM管理的软件的说明，对通过file.tar.gz 或file.tar.bz2源码包用 make ;make install 安装的软件无效；
2、安装软件时，最好用各自发行版所提供的系统软件包管理工具，对于Fedora/Redhat 您可以参考如下文章；

1）Fedora 系统管理软件包工具 system-config-packages，方便的添加和移除系统安装盘提供的软件包，详情请看 《Fedora 软件包管理器system-config-packages》

2）Redhat 系统管理软件包工具,新一点的系统应该是 redhat-config-packages ，用法和 《Fedora 软件包管理器system-config-packages》 一样；

3）apt + synaptic 软件包在线安装、移除、升级工具； 用法：《用apt+synaptic 在线安装或升级Fedora core 4.0 软件包》
4）yum 软件包在线安装、升级、移除工具；用法：《Fedora/Redhat 在线安装更新软件包，yum 篇》

5）所有的yum和apt 教程 《apt and yum》

目前 apt和yum 已经极为成熟了，建议我们安装软件时，采用 apt或者yum ；如果安装系统盘提供的软件包，可以用 system-config-packages 或redhat-config-packages ；

一、RPM包管理的用途；


1、可以安装、删除、升级和管理软件；当然也支持在线安装和升级软件；
2、通过RPM包管理能知道软件包包含哪些文件，也能知道系统中的某个文件属于哪个软件包；
3、可以在查询系统中的软件包是否安装以及其版本；
4、作为开发者可以把自己的程序打包为RPM 包发布；
5、软件包签名GPG和MD5的导入、验证和签名发布
6、依赖性的检查，查看是否有软件包由于不兼容而扰乱了系统；


二、RPM 的使用权限；

RPM软件的安装、删除、更新只有root权限才能使用；对于查询功能任何用户都可以操作；如果普通用户拥有安装目录的权限，也可以进行安装；


三、rpm 的一点简单用法；

我们除了软件包管理器以外，还能通过rpm 命令来安装；是不是所有的软件包都能通过rpm 命令来安装呢？不是的，文件以.rpm 后缀结尾的才行；有时我们在一些网站上找到file.rpm ，都要用 rpm 来安装；




目前go语言在window或者linux操作系统上，最好的go语言开发调试环境都是由eclipse+goclipse插件+gdb搭建的。如果你还没有搭建好go语言的开发环境，请参考这篇博文《windows下Go语言的安装和开发环境搭建》。

一般大家用eclipse都是开发java，如果要开发go，那就得安装goclipse插件了，这样才能有代码高亮、自动编译、联想提示、跳转到函数定义等丰富功能；如果还想要调试的功能，就还得有gdb；如果你还想引入github上的开源库，那还需要git客户端。下面一一介绍如果安装和使用：

安装goclipse

在安装goclipse前，需要事先安装好jdk8。goclipse下载地址：http://goclipse.github.io/releases/ ，由于我朝的高墙存在，可能这个地址访问不稳定，甚至有的人根本访问不了，建议参考goclipse官网的文档，把releases目录下的内容下载到本地后解压，使用本地的路径作为url来安装，比如：file:///D:/goclipse.github.io-master/releases/，搞java的安装eclipse插件应该比较熟悉，安装过程也比较简单，直接点下一步，接受，yes，重启eclipse就可以了（可能由于国内网速的原因，安装过程可能比较长）。如果安装成功，可以在Window–&gt;Preferences里面左边的树形菜单里看到Go，点Go，然后在右边设置GOROOT的路径为go的安装目录即可，下面的几个Go
 tool的路径会被自动识别到。此时应该看到如下的效果：



下面创建一个go项目来检验一下，在菜单栏如下操作File–&gt;New–&gt;Other–&gt;选择Go–&gt;选择Go Project–&gt;Next–&gt;给项目取个名字（比如gotest）–&gt;Finish，创建成功，然后在项目的src目录下创建一个带main入口函数的源文件test。



配置gbd




创建带main函数的源文件


然后编辑代码看看高亮和代码提示的效果



golang代码联想


上面的效果不错吧，goclipse现在已经在方法提示、autocomplete和查看方法变量声明等功能方面支持得很好了，而且这些功能不用额外配置，因为goclipse中包含了一个gocode（用于Go语言的自动补全工具），在安装goclipse的时候会自动安装上gocode（比如：我的gocode在D:\software\green_software\eclipse-j2ee\eclipse\plugins\com.googlecode.goclipse.gocode_0.7.6.v439\tools\windows_amd64），所以gocode一般不用额外的安装和配置，只需要勾选让其在eclipse启动时自动启动即可，配置路径为：Window-&gt;Perferences-&gt;Go-&gt;Gocode，这样eclipse在启动后，你可以在Window资源管理器的进程列表中看到有gocode这个进程。如下图：



goclipse的gocode配置


如果你没有gocode，或者gocode没有启动，或者你想用最新的gocode，那么你可以在启动eclipse之前使用如下的命令手动启动gocode：

gocode.exe -s -sock=tcp


这样你就可以在eclipse中使用点号来联想方法和字段，以及用alt+/来自动补全方法和字段。

运行这个程序有两个办法，一个是cd到这个工程的bin目录下，执行下面自动编链接好的exe文件，另一个是在eclipse上右键main函数所在的源文件–&gt;Run As–&gt;Run Go Application，即可。

我平时在使用过程中，发现一个奇怪的问题，就是自己的代码不能自动编译也不能运行了，研究一番才发现是工程的src目录配置不对，理论上这个配置不需要自己手动配的，但是如果你也碰到这种情况，你可以看看这个src目录是否配置正确了，见图你就知道了：



新引入的go项目后检查项目配置


安装GDB

想一想，如果写代码不能调试，那就只能通过fmt.Println(“xxx”)这种方式，那是多么痛苦啊，让自己的开发环境可以动态的调试是很有必要的。下面介绍下，如何安装和配置GDB，让eclipse支持go语言代码的挑食的。

由于go编译器编译出来的可执行程序是按照gdb的标准的，所以目前调试go语言代码必须要有gdb，需要在windows上装一个，linux上装gdb很容易，但是windows上比较麻烦一下，比较常用的做法是装MinGW，然后用里面的gdb。但是我推荐另一个做法：

下载另一个自带了gdb的go语言集成开发软件liteide（绿色软件，解压即可），里面的bin目录下有gdb.exe和gdb64.exe，这两文件前者用于32位操作系统，后者用于64位操作系统。

然后把你操作系统对应的那个gdb配置到goclipse插件里面，操作如下：Window–&gt;Preferences–&gt;打开Go节点–&gt;选择Debug，然后设置GDB，我的操作是64位的，所以选择了gdb64.exe。如图：



配置gdb


这样就ok了，现在可以去试试，在代码里设断点看效果了。（当然现在这个debug功能还没有那么完善，但是大部分的情况都是可以动态查看变量的值的，某未及之处只能通过输出的方式来做了。）

配置GOPATH变量关联go的SDK源码

如果不使用eclipse+goclipse，而使用记事本写代码的话，就必须要配置gopath，尽管使用goclipse后可以不设置GOPATH环境变量，但是那样就不能在eclipse里面直接关联查看go的源码了。如果想让自己的代码中选择一个函数，然后按F3（或者按住ctrl点某个函数）就能看到源码的话（eclipse常用的关联代码的功能），就需要给goclipse配置GOPATH，配置好了以后你可以按住ctrl点某个函数，就可以跳到go的源码中直接查看源码的实现，这个对学习go很有帮助，强烈推荐大家使用。配置效果如图：



在eclipse中设置gopath


配置完了以后，就可以看到Project Explorer里面多出了一个GOROOT节点，这个节点下的都是go的源码，没事多看看很有好处！

用git来下载第三方库

由于现在github非常火，很多开源爱好者都把自己的代码托管到了github、bitbucket、google code上，go语言本身也是开源。想学go语言的同学难免会去这些地方看其他人写的好的代码，不过最好是把这些代码下载自己把玩一番。要下载这些代码就需要使用git客户端，它可以让你用简单的命令就可以把代码下载下来，并打包好。这样你就可以方便的使用了。下面介绍下git客户端的下载和安装：

git的windows客户端下载地址为：http://code.google.com/p/msysgit/downloads/list?q=full+installer+official+git

安装过程中有一个步骤需要注意的，这一步可以让你在dos命令行中使用git命令，这样比较方便一点，如图：



git安装，让你的git命令可以在windows控制台里使用


这时候你就可以在windows命令行中使用git命令了，现在试试看看好用不，我在bitbucket上有个开源的工具包，以这个作为例子试试看~~

先cd到你的工程的src目录下，然后键入这个命令：go get -u bitbucket.org/weager/utils

这个命令中的-u可以在你曾经下载过这个包时，自动更新这个包。此时，应该能在src目录下看到bitbucket.org目录，这目录里面有一个weager目录，这个目录下就是utils包的代码了。

然后运行打包命令：go install bitbucket.org/weager/utils

此时会在pkg目录下产生于src相同的目录，在utils目录下会有一个utils.a文件，这就是打包后生成的文件。见图：



go项目目录结构以及下载的包


下载了包以后，就可以在你的工程中使用这个包了，比如：



go语言代码中引入第三方库代码演示


 

 

到此为止，go语言的开发环境完成了，可以开始开发了，good luck 


1.  for循环

          for循环形式： for（表达式1；表达式2；表达式3）

          流程图：

            

           图1 for循环流程图

     

2.  while循环

           while循环形式：

                               while（判断条件）

                                 {

                                    执行语句；

                                  }

          流程图：

          

            图2 while循环流程图

    

3.  do-while循环

           do-while循环形式：

                                    do
                                        {

                                          执行语句；

                                        }while（条件判断）

           do-while循环流程图：

            

                 图3 do-while循环流程图


安装说明
系统环境：centos7
安装方式：rpm安装
软件：jdk-8u60-linux-x64.rpm
下载地址：http://www.oracle.com/technetwork/java/javase/downloads/index.html


检验系统原版本
[root@zck ~]# java -version
java version "1.7.0_"
OpenJDK Runtime Environment (IcedTea6 1.11.1) (rhel-1.45.1.11.1.el6-x86_64)
OpenJDK 64-Bit Server VM (build 20.0-b12, mixed mode)


进一步查看JDK信息：
[root@localhost ~]#  rpm -qa | grep java
javapackages-tools-3.4.1-6.el7_0.noarch
tzdata-java-2014i-1.el7.noarch
java-1.7.0-openjdk-headless-1.7.0.71-2.5.3.1.el7_0.x86_64
java-1.7.0-openjdk-1.7.0.71-2.5.3.1.el7_0.x86_64
python-javapackages-3.4.1-6.el7_0.noarch


卸载OpenJDK，执行以下操作：
[root@localhost ~]# rpm -e --nodeps tzdata-java-2014i-1.el7.noarch
[root@localhost ~]# rpm -e --nodeps java-1.7.0-openjdk-headless-1.7.0.71-2.5.3.1.el7_0.x86_64
[root@localhost ~]# rpm -e --nodeps java-1.7.0-openjdk-1.7.0.71-2.5.3.1.el7_0.x86_64


安装JDK
上传新的jdk-8u25-linux-x64.rpm软件到/usr/local/执行以下操作：
[root@zck local]# rpm -ivh jdk-8u25-linux-x64.rpm


JDK默认安装在/usr/java中。


验证安装
执行以下操作，查看信息是否正常：
[root@localhost ~]# java
[root@localhost ~]# javac
[root@localhost ~]# java -version
java version "1.8.0_60"
Java(TM) SE Runtime Environment (build 1.8.0_60-b27)
Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode)


配置环境变量
我的机器安装完jdk-7-linux-x64.rpm后不用配置环境变量也可以正常执行javac、java –version操作，因此我没有进行JDK环境变量的配置。但是为了以后的不适之需，这里还是记录一下怎么进行配置，操作如下：
修改系统环境变量文件
vi /etc/profile


向文件里面追加以下内容：
JAVA_HOME=/usr/java/jdk1.8.0_60
JRE_HOME=/usr/java/jdk1.8.0_60/jre
PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin
CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib
export JAVA_HOME JRE_HOME PATH CLASSPATH


使修改生效
[root@localhost ~]# source /etc/profile   //使修改立即生效
[root@localhost ~]#        echo $PATH   //查看PATH值


查看系统环境状态
[root@localhost ~]# echo $PATH
/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin:/usr/java/jdk1.8.0_60/bin:/usr/java/jdk1.8.0_60/jre/bin
   


1.新建文件夹
mkdir 文件名
新建一个名为test的文件夹在home下
mkdir /home/test


2.新建文本
在home下新建一个test.sh脚本
 vi /home/test.sh


3.删除文件或文件夹
1、删除home目录下的test目录
 rm /home/test


2、这种不带参数的删除方法经常会提示无法删除，因为权限不够。
 rm -r /home/test


3、-r是递归的删除参数表中的目录及其子目录。 目录将被清空并且删除。 当删除目录包含的具有写保护的文件时用户通常是被提示的。
rm -rf /home/test


4、f是不提示用户，删除目录下的所有文件。请注意检查路径，输成别的目录就悲剧了。
 rm -ir /home/test


5、-i是交互模式。使用这个选项，rm命令在删除任何文件前提示用户确认。


4.移动文件或文件夹
mv [options] 源文件或目录 目标文件或目录
示例：
1、移动hscripts文件夹/目录下的所有文件，目录和子目录到tmp目录mv hscripts tmp
分析：在上述命令中，如果tmp目录已经存在，mv命令将移动hscripts文件夹/目录下的所有文件，目录和子目录到tmp目录。 如果没有tmp目录，它将重命名 hscripts目录为tmp目录。


2、移动多个文件/更多问价到另一目录
mv file1.txt tmp/file2.txt newdir
这个命令移动当前目录的file1.txt文件和tmp文件夹/目录的file2.txt文件到newdir目录。
参数：
-i：交互方式操作。如果mv操作将导致对已存在的目标文件的覆盖，此时系统询问是否重写，要求用户回答”y”或”n”，这样可以避免误覆盖文件。
-f：禁止交互操作。mv操作要覆盖某个已有的目标文件时不给任何指示，指定此参数后i参数将不再起作用。


5.复制文件或文件夹
cp [options] 来源档(source) 目的檔(destination)
参数：
-a ：相当于 -pdr 的意思；
-d ：若来源文件为连结文件的属性(link file)，则复制连结文件属性而非档案本身；
-f ：为强制 (force) 的意思，若有重复或其它疑问时，不会询问使用者，而强制复制；
-i ：若目的檔(destination)已经存在时，在覆盖时会先询问是否真的动作！
-l ：进行硬式连结 (hard link) 的连结档建立，而非复制档案本身；
-p ：连同档案的属性一起复制过去，而非使用预设属性；
-r ：递归持续复制，用于目录的复制行为；
-s ：复制成为符号连结文件 (symbolic link)，亦即『快捷方式』档案；
-u ：若 destination 比 source 旧才更新 destination ！
最后需要注意的，如果来源档有两个以上，则最后一个目的文件一定要是『目录』才行！
示例:

1、复制两个文件:
cp file1 file2
上述cp命令复制文件file1.php 的内容到文件file2.php中。
2、备份拷贝的文件:
cp -b file1.php file2.php
创建文件file1.php的带着符号 ‘~’的备份文件file2.php~。
3、复制文件夹和子文件夹:
cp -R scripts scripts1
上面的 cp 命令从 scripts 复制文件夹和子文件夹到 scripts1。
 
6、创建目录
mkdir 文件名
mkdir /var/www/test


大致总结了一下linux下各种格式的压缩包的压缩、解压方法。但是部分方法我没有用到，也就不全，希望大家帮我补充，我将随时修改完善，谢谢！


     .tar 

　　解包：tar xvf FileName.tar 

　　打包：tar cvf FileName.tar DirName 

　　（注：tar是打包，不是压缩！） 

　　——————————————— 

　　.gz 

　　解压 1：gunzip FileName.gz 

　　解压2：gzip -d FileName.gz 

　　压缩：gzip FileName 

　　.tar.gz 和 .tgz 

　　解压：tar zxvf FileName.tar.gz 

　　压缩：tar zcvf FileName.tar.gz DirName 

　　——————————————— 

     .bz2 

　　解压1：bzip2 -d FileName.bz2 

　　解压2：bunzip2 FileName.bz2 

　　压缩： bzip2 -z FileName 

　　.tar.bz2 

　　解压：tar jxvf FileName.tar.bz2        或tar --bzip xvf FileName.tar.bz2 

　　压缩：tar jcvf FileName.tar.bz2 DirName 

　　 ——————————————— 

　　.bz 

　　解压1：bzip2 -d FileName.bz 

　　解压2：bunzip2 FileName.bz 

　　压缩：未知 

　　.tar.bz 

　　解压：tar jxvf FileName.tar.bz 

　　压缩：未知 

　　———————————————

      .Z 

　　解压：uncompress FileName.Z 

　　压缩：compress FileName 

　　.tar.Z 

　　解压：tar Zxvf FileName.tar.Z 

　　压缩：tar Zcvf FileName.tar.Z DirName 

　　——————————————— 

　　.zip 

　　解压：unzip FileName.zip 

　　压缩：zip FileName.zip DirName 

　　压缩一个目录使用 -r 参数，-r 递归。例： $ zip -r FileName.zip DirName 

　　——————————————— 

　　.rar 

　　解压：rar x FileName.rar 

　　压缩：rar a FileName.rar DirName 

　　 

　　rar 请到：http://www.rarsoft.com/download.htm 下载！ 

　　解压后请将rar_static拷贝到/usr /bin目录（其他由$PATH环境变量指定的目录也可以）： 

　　[root@www2 tmp]# cp rar_static /usr/bin/rar 

　　———————————————

      .lha 

　　解压：lha -e FileName.lha 

　　压缩：lha -a FileName.lha FileName 

　　 

　　lha请到：http://www.infor.kanazawa-it.ac.jp/~ishii/lhaunix/下载！ 

　　&gt;解压后请将 lha拷贝到/usr/bin目录（其他由$PATH环境变量指定的目录也可以）： 

　　[root@www2 tmp]# cp lha /usr/bin/ 

　　——————————————— 

　　.rpm 

　　解包：rpm2cpio FileName.rpm | cpio -div 

　　——————————————— 

　　.deb 

　　解包：ar p FileName.deb data.tar.gz | tar zxf - 

　　——————————————— 

　　.tar .tgz .tar.gz .tar.Z .tar.bz .tar.bz2 .zip .cpio .rpm .deb .slp .arj .rar .ace .lha .lzh .lzx .lzs .arc .sda .sfx .lnx .zoo .cab .kar           .cpt .pit .sit .sea 

　　解压：sEx x FileName.* 

　　压缩：sEx a FileName.* FileName 

　　 

　　sEx只是调用相关程序，本身并无压缩、解压功能，请注意！ 

　　sEx请到： http://sourceforge.net/projects/sex下载！ 

　　解压后请将sEx拷贝到/usr/bin目录（其他由$PATH环境变量指定的目录也可以）： 

　　[root@www2 tmp]# cp sEx /usr/bin/　　Linux下常见文件解压方法及命令 

　　系统·System

      1.以.a为扩展名的文件: 

　　#tar xv file.a 

　　2.以.z为扩展名的文件: 

　　#uncompress file.Z 

　　3.以.gz为扩展名的文件: 

　　#gunzip file.gz 

　　4.以.bz2为扩展名的文件: 

　　#bunzip2 file.bz2 

　　5.以.tar.Z为扩展名的文件: 

　　#tar xvZf file.tar.Z 

　　或 #compress -dc file.tar.Z | tar xvf 

　　6.以.tar.gz/.tgz为扩展名的文件: 

　　#tar xvzf file.tar.gz 

　　或 gzip -dc file.tar.gz | tar xvf - 

　　7.以.tar.bz2为扩展名的文件: 

　　#tar xvIf file.tar.bz2 

　　或 bzip2 -dc file.tar.bz2 | xvf - 

　　8.以.cpio.gz/.cgz为扩展名的文件: 

　　#gzip -dc file.cgz | cpio -div 

　　9. 以.cpio/cpio为扩展名的文件:

      #cpio -div file.cpio 

　　或cpio -divc file.cpio 

　　10.以.rpm为扩展名的文件安装: 

　　#rpm -i file.rpm 

　　11.以.rpm为扩展名的文件解压缩： 

　　 #rpm2cpio file.rpm | cpio -div 

　　12.以.deb为扩展名的文件安装： 

　　#dpkg -i file.deb 

　　13.以.deb为扩展名的文件解压缩: 

　　#dpkg-deb -fsys-tarfile file.deb | tar xvf - ar p 

　　file.deb data.tar.gz | tar xvzf - 

　　14.以.zip为扩展名的文件: 

　　#unzip file.zip 

　　在linux下解压Winzip格式的文件 

　　要是装了jdk的话，可以用 jar命令；还可以使用unzip命令。 

　　直接解压.tar.gz文件 

　　xxxx.tar.gz文件使用tar带zxvf参数，可以一次解压开。XXXX为文件名。 例如： 

　　$tar zxvf xxxx.tar.gz 各种压缩文件的解压（安装方法）

     文件扩展名 解压（安装方法） 

　　　 

　　.a ar xv file.a 

　　.Z uncompress file.Z 

　　.gz gunzip file.gz 

　　.bz2 bunzip2 file.bz2 

　　.tar.Z tar xvZf file.tar.Z 

　　compress -dc file.tar.Z | tar xvf - 

　　.tar.gz/.tgz tar xvzf file.tar.gz 

　　gzip -dc file.tar.gz | tar xvf - 

　　.tar.bz2 tar xvIf file.tar.bz2 

　　bzip2 -dc file.tar.bz2 | xvf - 

　　.cpio.gz/.cgz gzip -dc file.cgz | cpio -div 

　　.cpio/cpio cpio -div file.cpio 

　　cpio -divc file.cpio 

　　.rpm/install rpm -i file.rpm 

　　.rpm/extract rpm2cpio file.rpm | cpio -div 

　　.deb/install dpkg -i file.deb 

　　.deb/exrtact dpkg-deb -fsys-tarfile file.deb | tar xvf - 

　　ar p file.deb data.tar.gz | tar xvzf - 

　　.zip unzip file.zip



      bzip2 -d myfile.tar.bz2 | tar xvf 

 
     tar xvfz myfile.tar.bz2





      x 是解压 

　　v 是复杂输出 

　　f 是指定文件 

　　z gz格式




      gzip 

　　gzip[选项]要压缩（或解压缩）的文件名 

　　-c将输出写到标准输出上，并保留原有文件。 

　　-d将压缩文件压缩。 

　　-l对每个压缩文件，显示下列字段：压缩文件的大小，未压缩文件的大小、压缩比、未压缩文件的名字 

　　-r递归式地查找指定目录并压缩或压缩其中的所有文件。 

　　-t测试压缩文件是正完整。 

　　-v对每一个压缩和解压缩的文件，显示其文件名和压缩比。 

　　-num-用指定的数字调整压缩的速度。 

　　举例： 

　　把/usr目录并包括它的子目录在内的全部文件做一备份，备份文件名为usr.tar 

　　tar cvf usr.tar /home 

　　把/usr 目录并包括它的子目录在内的全部文件做一备份并进行压缩，备份文件名是usr.tar.gz 

　　tar czvf usr.tar.gz /usr 

　　压缩一组文件，文件的后缀为tar.gz 

　　#tar cvf back.tar /back/ 

　　#gzip -q back.tar 

　　or 

　　#tar cvfz back.tar.gz /back/ 

　　释放一个后缀为tar.gz 的文件。 

　　#tar zxvf back.tar.gz 

　　#gzip back.tar.gz 

　　#tar xvf back.tar




Centos默认自带VI，但VI功能没VIM丰富，可以安装VIM取代VI。

1、用Yum查找源中的VIM包，看是否已经安装VIM
yum search vim

2、到已安装VIM的系统中查看VIM属于哪个软件包：
which vim

3、安装VIM：
yum install vim-enhanced
   

此处主要介绍使用yum的方式安装


1、安装软件包

$sudo yum install samba samba-client

2、关防火墙(否则，这个服务是不允许连接的，不象SSH默认是允许连接，SAMBA因为不安全的原因，端口是被封掉的。）

$sudo systemctl stop firewalld.service

$sudo setenforce 0



3、启动服务

[sdx@localhost samba]$ sudo systemctl restart smb.service

[sdx@localhost samba]$ sudo systemctl restart nmb.service



本文介绍centos7下如何安装git，对于其他版本，请参考其对应版本的安装文档。


1、查看系统是否已经安装git

输入 git 或git --version
若提示：找不到git命令，则表示还未安装git。
2、安装git
yum install git


查看是否安装成功
git 或 git --version


3、卸载git
yum remove git







先执行下面的命令，查看所有的已安装软件名称。rpm -qa 然后执行rpm -ql 软件名称就可以显示软件的安装路径。



冒泡排序是非常容易理解和实现，，以从小到大排序举例：

设数组长度为N。

1．比较相邻的前后二个数据，如果前面数据大于后面的数据，就将二个数据交换。

2．这样对数组的第0个数据到N-1个数据进行一次遍历后，最大的一个数据就“沉”到数组第N-1个位置。

3．N=N-1，如果N不为0就重复前面二步，否则排序完成。




按照定义很容易写出代码：





//冒泡排序1  
void BubbleSort1(int a[], int n)  
{  
       int i, j;  
       for (i = 0; i &lt; n; i++)  
              for (j = 1; j &lt; n - i; j++)  
                     if (a[j - 1] &gt; a[j])  
                            Swap(a[j - 1], a[j]);  
}  



下面对其进行优化，设置一个标志，如果这一趟发生了交换，则为true，否则为false。明显如果有一趟没有发生交换，说明排序已经完成。








//冒泡排序2  
void BubbleSort2(int a[], int n)  
{  
       int j, k;  
       bool flag;  
  
       k = n;  
       flag = true;  
       while (flag)  
       {  
              flag = false;  
              for (j = 1; j &lt; k; j++)  
                     if (a[j - 1] &gt; a[j])  
                     {  
                            Swap(a[j - 1], a[j]);  
                            flag = true;  
                     }  
              k--;  
       }  
}  



再做进一步的优化。如果有100个数的数组，仅前面10个无序，后面90个都已排好序且都大于前面10个数字，那么在第一趟遍历后，最后发生交换的位置必定小于10，且这个位置之后的数据必定已经有序了，记录下这位置，第二次只要从数组头部遍历到这个位置就可以了。





//冒泡排序3  
void BubbleSort3(int a[], int n)  
{  
    int j, k;  
    int flag;  
      
    flag = n;  
    while (flag &gt; 0)  
    {  
        k = flag;  
        flag = 0;  
        for (j = 1; j &lt; k; j++)  
            if (a[j - 1] &gt; a[j])  
            {  
                Swap(a[j - 1], a[j]);  
                flag = j;  
            }  
    }  
}  
冒泡排序毕竟是一种效率低下的排序方法，在数据规模很小时，可以采用。数据规模比较大时，最好用其它排序方法。


一． JavaEE的架构
二． JavaEE的核心技术简介
三． JavaEE平台中的角色
四． 当前流行的JavaEE平台
五．  JavaEE的应用
 
一．JavaEE架构：

JavaEE的运行环境定义了4种类型的应用组件：
l       Applet客户端
l       Application客户端
l       Web组件
l       EJB组件
 
 
二．JavaEE核心技术：13种
 
   EJB、CORBA、RMI、JSP、Java Servlet、JavaBean、JDBC、XML、……

EJB — JavaEE的基石：
l       EJB (Enterprise JavaBeans) ：
           一个Java服务器端组件开发的规范，定义了一个用来开发面向对象分布式应用组件的标准方法，软件厂商根据它来实现EJB服务器。
           Java程序员可以将一些EJB组件组合起来，从而方便、快捷地建构起分布式应用程序。EJB规范在简化分布式应用程序开发复杂性方面也做了大量的工作，EJB程序员不必太担心事务处理、多线程、资源管理等方面的问题，可以专注于支持应用所需的商业逻辑，而不用担心周围框架的实现问题。使用EJB可以使整个程序分块明确，并且EJB可以使用其它EJB或JDBC等服务，从而增强了分布式应用程序的可扩展性和性能；另外，EJB的使用增强了整个系统程序的可靠性、可管理性和可移植性。


l       EJB组件
     EJB分为三种：会话EJB、实体EJB和消息驱动EJB
 
l       EJB容器
      是EJB组件的运行环境，为部署的EJB组件提供各种服务（事务、安全、远程客户端的网络发布、资源管理等）。容器厂商也可以在容器或服务器中提供额外服务的接口。
 
l       EJB服务器
      管理EJB容器的高端进程或应用程序，并提供对系统服务的访问。EJB服务器也可以提供厂商自己的特性，如优化的数据库访问接口，对其他服务（如CORBA服务）的访问等。

CORBA体系结构：核心－ORB



CORBA技术：
l       CORBA（Common Object Request Broker Architecture）是一个开发分布式对象系统标准（规范），它独立于平台，也独立于语言。由OMG制定。
l       在这个体系结构中，一个对象可以被本机上的客户或远程客户通过方法激活来访问。客户（一个对象或应用）无须知道被调用对象（称为服务对象）的运行环境，也无须知道实现这个对象的编程语言，客户只要知道服务对象的逻辑地址和提供的接口。
l       这种互操作性的关键是IDL（Interface Definition Language、接口定义语言），IDL说明对象接口中的方法，这些方法可以被其它对象（或应用）激活。
 
RMI技术：
l       RMI(Remote Method Invoke)是一种被EJB使用的更底层的协议，正如其名字所表示的那样，RMI协议调用远程对象上方法，使用序列化方式在客户端和服务器端的对象之间传递数据。


RMI和CORBA相比：
l       两者的关键差别在于语言环境，Java RMI是一个分布式对象计算的纯Java解决方案(如，在Java RMI中，对象的接口用Java定义，而不是用IDL)；
l       其次，CORBA没有定义安全服务，而Java RMI继承了Java的安全性；
l       再者，CORBA有不同的实现，不同的独立软件开发商的不同实现均有独特性，这使得在不同平台上的匹配比较困难，而且不是所有CORBA产品开发商都支持所有平台，而几乎所有平台都支持Java虚拟机，因此Java RMI具有更高的可移植性。如果客户对象和服务对象都基于Java虚拟机，那么Java RMI是分布对象计算的最好选择。当然，IIOP（Internet Inter-ORB Protocol）已经提供了Java RMI和CORBA的互操作能力，而且两者的发展有互相借鉴的趋势。
 
JSP技术：
l       JSP是服务器端的脚本语言，是以Java和Servlet为基础开发而成的动态网页生成技术，它的底层实现是Java Servlet。
l       JSP(Java Server Pages)页面由HTML代码和嵌入其中的Java代码所组成。服务器在页面被客户端所请求以后对这些Java代码进行处理，然后将生成的HTML页面返回给客户端的浏览器。
 
l       特点：面向对象，跨平台，和Servlet一样稳定，可以使用Servlet提供的API，克服了Servlet的缺点。
l       应用：一般和JavaBeans结合使用，从而将界面表现和业务逻辑分离。


JSP和ASP的比较（一）：
相似：
 
l       都是运行于服务器端的脚本语言，两者都是动态网页生成技术。
l       这两项技术都使用HTML来决定网页的版面，都是在HTML 代码中混合某种程序代码，由语言引擎解释执行程序代码。HTML代码主要负责描述信息的显示样式，而程序代码则用来描述处理逻辑。
JSP和ASP的比较（二）：
不同：
 
l       JSP是由Sun推出的一项技术，是基于JavaServlet以及整个java体系的Web开发技术，利用这一技术可以建立先进、安全和跨平台的动态网站。ASP是MS公司推出的技术，只能在MS的平台上运行，无法实现跨平台，也无安全性保障。
l       ASP下的编程语言是 VBScript 之类的脚本语言，而JSP 使用的是Java。
l       ASP 与 JSP 还有一个更为本质的区别：两种语言引擎用完全不同的方式处理页面中嵌入的程序代码。在 ASP 下， VBScript 代码被 ASP 引擎解释执行；在 JSP 下，代码被编译成 Servlet 并由 Java 虚拟机执行，这种编译操作仅在对 JSP 页面的第一次请求时发生。
 
 
Java Servlet技术：
 
l       Servlets(＝Server ＋Applet)：是一些运行于Web服务器端的Java小程序，用来扩展Web服务器的功能。
l       Servlets用特定的Java解决方案替代了其它的Web服务器方编程模式（如：CGI，ISAPI等），因而继承了Java的所有特性(跨平台、多线程、OO)。
l       Servlets可以嵌入在不同的Java Web服务器之中，因为用来编写Servlets的Servlet API对于服务器环境和协议没有任何特殊的要求，所以Servlets具有很强的可移植性，也不像利用CGI程序等其它方式那样具有性能局限。
l       Servlets也同样使用HTTP协议与客户端进行通讯，所以有时也称Sevlets为“HTTP Servlets”。
l       Servlet是一种扩展Web服务器功能的简单而相似的技巧，而且由于它是用Java编写的，所以能够访问整个Java API库，包括用于访问企业数据库的JDBC API。
 
 
Java Servlet和JSP的比较：
l       两者都是基于Java的技术，所以都继承了Java的所有特性（跨平台、多线程、OO），都可以使用Java强大的API。
l       两者工作方式相似：JSP代码先被JSP容器转换为Servlet代码再编译为类。
l       两者在JavaEE体系结构中的工作层次相同，都负责与客户端的连接。
 
l       Servlets是一些运行于Web服务器端的Java小程序；而JSP是脚本，编写起来更简单容易。
l       Servlet主要用于从客户端接收请求信息，而JSP主要负责将服务器端信息传送到客户端。
l       使用Servlet的真正意义在于：可以将界面设计和业务逻辑设计分离。
 
 
JavaBean技术：
l       JavaBean是基于Java的组件模型，有点类似于Microsoft的COM组件。
l       在Java平台中，通过JavaBean可以无限扩充Java程序的功能，通过JavaBean的组合可以快速的生成新的应用程序。
l       对于程序员来说，最好的一点就是JavaBean可以实现代码的重复利用，另外对于程序的易维护性等等也有很重大的意义。
l       JavaBean通过Java虚拟机(Java Virtual Machine)执行，运行JavaBean最小的需求是JDK1.1或者以上的版本。
l       JavaBean传统的应用在于可视化的领域，如AWT下的应用。自从Jsp诞生后，JavaBean更多的应用在了非可视化领域，在服务器端应用方面表现出来了越来越强的生命力。
 
 
JDBC技术：
l       JDBC是一组API，定义了用来访问数据源的标准Java类库，使用这个类库可以以一种标准的方法、方便地访问数据库资源。
l       JDBC的目标是使应用程序开发人员使用JDBC可以连接任何提供了JDBC驱动程序的数据库系统，这样就使得程序员无需对特定的数据库系统的特点有过多的了解，从而大大简化和加快了开发过程。
l       JDBC API为访问不同的数据库提供了一种统一的途径，象ODBC一样，JDBC对开发者屏蔽了一些细节问题，
l       JDBC对数据库的访问也具有平台无关性。
 
XML技术：
l       XML(Extensible Markup Language)是一种可以用来定义其它标记语言的语言，被用来在不同的商务过程中共享数据。
l       XML的发展和Java是相互独立的，但是它和Java具有的相同目标即平台独立性。通过将Java和XML的组合，可以得到一个完美的具有平台独立性的解决方案。
l       JavaEE平台全面支持和实施XML，这种强大的组合可使XML具备跨平台的兼容性，甚至用于对XML代码进行语法检查和调试的工具也可与平台无关。
l       因为XML可实施独立于平台的数据，而JavaEE平台则可实施独立于平台的解决方案，所以JavaEE技术和XML技术分别是企业开发的阴阳两极。XML可通过移植的方式表现数据，因此就对Java技术的可移植性构成了补充。
 
JavaEE其它核心技术：
       JNDI(Java Naming and  Directory Interface)、           
       JMAPI(Java  Management API)、
       JTS/JTA(Java Transaction Service/API)、   
       JMS( Java Messaging Service)、
       Java Security API。
 
l       JavaEE核心技术中最常用的技术：
EJB、 JSP、Java Servlet、JavaBean、JDBC、……
 
l       开发大型应用：异构、分布、数据交换
 
三.JavaEE平台中的角色
 
在JavaEE平台中规定了七种角色，这七种角色在开发JavaEE平台及JavaEE应用中承担各自的任务。
（1）JavaEE平台开发商
（2）应用组件提供者
（3）应用组装者
（4）应用发布者
（5）系统管理员
（6）工具提供者
（7）系统组件提供者
 
（1）JavaEE平台开发商
l       JavaEE平台开发者提供实现基于JavaEE规范的产品，包括运行JavaEE应用的容器、JavaEE平台API。JavaEE平台开发者必须提供JavaEE规范规定的应用组件到网络协议的映射，提供JavaEE应用的发布与管理工具。
（2）应用组件提供者
应用组件提供者开发JavaEE应用组件，包括JSP、Servlet及EJB等。
（3）应用组装者
应用组装者负责将应用组件提供者开发的JavaEE应用组件组装为JavaEE应用。
（4）应用发布者
l       应用发布者将组装好的JavaEE应用发布到JavaEE应用的容器中，配置其运行环境，并启动JavaEE应用运行。
（5）系统管理员
l       系统管理员负责配置管理整个企业或组织的网络与计算环境，其中包括运行在JavaEE平台上的JavaEE应用。
（6）工具提供者
l       工具提供者提供JavaEE平台之外的JavaEE应用开发、组装、发布及管理工具。
（7）系统组件提供者
系统组件提供者提供系统级的通用的组件，如连接企业现有ERP系统的适配器等。
 
四．当前流行的JavaEE平台
l       目前市场上已经有许多成熟的实现JavaEE规范的产品，其中有的是商业公司的产品，而有的是开放源代码的免费产品。
 
商业公司的产品
 
商业公司的产品除Interstage外，另外主要还有BEA WebLogic、IBM WebSphere、Oracle Application Server、Borland Enterprise Server、SUN iPlanet Application Server等。这些产品一般都包括一组完整的产品线，用来支持JavaEE应用从开发、组装、发布及管理的整个过程。
 
组成
（1）应用服务器
      商业公司产品中的应用服务器一般都完全支持JavaEE规范的应用服务器，除包括Servlet容器、EJB容器外，还提供WEB Services、CORBA等服务。
（2）应用集成化开发环境
商业公司的产品提供支持开发JavaEE应用的集成开发环境，可以大大提高应用开发、调试的效率。
（3）JavaEE规范之外的工具
除了在JavaEE规范中规定的部分外，商业公司的产品一般还包括提供服务器负载均衡、安全控制、开发企业门户等功能在内的工具。
 
开放源代码的产品
l       开放源代码的产品中有如Apache Tomcat及JBOSS等产品。这些产品不仅是免费的，而且能够提供很好的功能和性能，因此也有很广泛的应用。
l       （1）Apache Tomcat
    Apache Tomcat 是一个Servlet容器，它支持Servlet/JSP规范。有些商业公司的JavaEE平台产品中使用它作为自己应用服务器的Servlet容器，或者在JavaEE应用集成开发环境中作为调试应用程序的服务器。
l       （2）JBOSS
      JBOSS 是一个EJB容器，但是因为它是基于JMX微内核结构开发的，所以很容易与其它产品集成在一起使用，如可以很方便地将JBOSS和Tomcat集成在一起使用。另外，JBOSS还有配置简单、应用热发布（不用停止服务器及应用的情况下发布或升级应用）等优点。
 
五．JavaEE的应用（一）
 


五．JavaEE的应用（二）

使用JavaEE开发企业应用要注意的问题：
       结合本企业的实际情况选用最适当的技术，需要终合考虑企业规模、业务特征、应用能力、预算费用、性能、开发周期、管理成本、维护成本等各种因素，还需要有一定的前瞻性。
